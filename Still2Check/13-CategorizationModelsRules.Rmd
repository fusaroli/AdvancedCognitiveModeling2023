---
title: "13-CategorizationModelsRules"
output: html_document
date: "2025-03-21"
---
# Rule-Based Models of Categorization

## Theoretical Foundations

Rule-based models represent a fundamentally different approach to categorization compared to exemplar and prototype models. While similarity-based models (exemplars and prototypes) assume that categorization is based on overall similarity to stored representations, rule-based models propose that people form explicit rules that define category membership.

This rule-based approach aligns with how we often talk about categories in everyday life—we describe them in terms of necessary and sufficient conditions ("A bachelor is an unmarried man") or simple inclusion rules ("If it has feathers and a beak, it's a bird"). Rule-based models formalize this intuition into computational mechanisms that can be tested against human behavior.

### Core Assumptions of Rule-Based Models

1. **Explicit Rules**: Categories are represented by explicit rules that define boundaries in feature space
2. **Rule Testing**: Learning involves formulating, testing, and revising rules
3. **Selective Attention**: Rules typically focus on a subset of relevant features, ignoring others
4. **Deterministic Boundaries**: Rules create sharp, often axis-aligned boundaries between categories
5. **Verbal Representation**: Rules are often easily verbalizable (e.g., "If height > 2.5, then Category A"), and might actually become easier to learn and represent through verbalization.

### Rules vs. Similarity-Based Approaches

The distinction between rule-based and similarity-based approaches lies not just in the computational details, but in fundamental assumptions about how the mind represents categories:

| Aspect | Rule-Based Models | Similarity-Based Models |
|--------|------------------|------------------------|
| **Representation** | Explicit decision rules | Stored examples or prototypes |
| **Decision Process** | Rule application | Similarity computation |
| **Feature Use** | Selective (focus on rule-relevant features) | Holistic (all features might contribute, tho' attention might say otherwise) |
| **Category Boundaries** | Sharp and often axis-aligned | Fuzzy and sensitive to overall similarity |
| **Individual Differences** | Different rules | Different attention weights |
| **Generalization Pattern** | Rectangle-like regions | Similarity-gradient regions |

## The Bayesian Particle Filter Approach to Rule Learning

Implementing a rule-based model presents unique challenges. Unlike exemplar and prototype models, where the representation is straightforward, rule-based models need mechanisms for:

1. Generating candidate rules
2. Testing rules against observed data
3. Switching between rules when necessary
4. Maintaining uncertainty about which rule is correct

The Bayesian particle filter provides an elegant solution to these challenges. Originally developed for tracking physical objects, particle filters have been adapted to model how humans track and update hypotheses. In our context, each "particle" represents a possible categorization rule, and the filter maintains and updates a distribution over these rules.

### Mathematical Formulation of the Bayesian Particle Filter for Rules

In the particle filter framework:

1. **Particles**: Each particle represents a candidate rule
2. **Weights**: Each particle has a weight representing its probability
3. **Update**: Particle weights are updated based on how well they predict observed data
4. **Resampling**: Periodically, particles are resampled to focus on high-probability rules

#### 1. Rule Representation

We'll represent rules as axis-aligned decision boundaries. In a two-dimensional feature space (height and position), a rule might be:

"If height > θ₁, then Category 1"

Or more complex:

"If height > θ₁ AND position < θ₂, then Category 1"

Each particle contains the parameters defining such a rule (e.g., θ₁, θ₂), plus an indicator of which dimensions it uses and the logical operation (AND/OR).

#### 2. Initialization

We initialize with N particles, each representing a random rule:
- Random dimension(s) to use in the rule
- Random threshold value(s) for each dimension
- Random logical operation (if using multiple dimensions)
- Equal initial weights (1/N)

#### 3. Weight Update

When we observe a new example (features x, category y), we update each particle's weight:

w_i ∝ w_i × P(y|x, rule_i)

Where P(y|x, rule_i) is the probability of category y given features x under rule i. For deterministic rules, this is 1 if the rule correctly predicts the category and 0 if it doesn't. To allow for noise, we can use:

P(y|x, rule_i) = (1-ε) if rule_i predicts y, and ε otherwise

Where ε is a small error probability (e.g., 0.05).

#### 4. Resampling

After multiple updates, most particles may have very low weights. To concentrate computation on high-probability rules, we resample particles proportional to their weights, then reset weights to 1/N.

#### 5. Decision Rule

To make a categorization decision for a new stimulus, we weight each particle's prediction by its probability:

P(y=1|x) = ∑ᵢ wᵢ × P(y=1|x, rule_i)

This essentially takes a weighted vote across all rule hypotheses.

## Implementing the Bayesian Particle Filter for Rule Learning

Let's implement this model in R. We'll focus on binary categorization in a two-dimensional feature space, matching our previous examples.

```r
# Define a rule class
rule <- function(dimensions, thresholds, operations, prediction) {
  list(
    dimensions = dimensions,   # Which dimensions the rule uses (e.g., c(1, 2) for both)
    thresholds = thresholds,   # Threshold values for each dimension (e.g., c(2.5, 3.2))
    operations = operations,   # ">" or "<" for each dimension 
    operation_logic = ifelse(length(dimensions) > 1, sample(c("AND", "OR"), 1), NA),  # How dimensions are combined
    prediction = prediction    # Category prediction (0 or 1)
  )
}

# Function to evaluate a rule on a stimulus
evaluate_rule <- function(rule, stimulus) {
  # Initialize result based on whether we evaluate multiple dimensions
  if (length(rule$dimensions) > 1) {
    # Start with neutral values for AND/OR logic
    result <- ifelse(rule$operation_logic == "AND", TRUE, FALSE)
  } else {
    # Single dimension doesn't need AND/OR logic
    result <- NULL
  }
  
  # Evaluate each dimension
  for (i in seq_along(rule$dimensions)) {
    dim_idx <- rule$dimensions[i]
    threshold <- rule$thresholds[i]
    operation <- rule$operations[i]
    
    # Evaluate this dimension's condition
    if (operation == ">") {
      dim_result <- stimulus[dim_idx] > threshold
    } else {
      dim_result <- stimulus[dim_idx] < threshold
    }
    
    # Combine with previous results based on logic
    if (is.null(result)) {
      result <- dim_result  # First/only dimension
    } else if (rule$operation_logic == "AND") {
      result <- result & dim_result
    } else {  # OR logic
      result <- result | dim_result
    }
  }
  
  # Convert TRUE/FALSE to predicted category
  return(ifelse(result, rule$prediction, 1 - rule$prediction))
}

# Generate a random rule
generate_random_rule <- function(n_dimensions, n_features) {
  # Randomly select which dimensions to use (at least 1, up to n_features)
  dimensions <- sample(1:n_features, size = sample(1:min(n_dimensions, n_features), 1))
  
  # Generate thresholds and operations for each dimension
  thresholds <- numeric(length(dimensions))
  operations <- character(length(dimensions))
  
  for (i in seq_along(dimensions)) {
    # Thresholds between 0 and 5 (matching our feature range)
    thresholds[i] <- runif(1, 0, 5)
    # Operations can be ">" or "<"
    operations[i] <- sample(c(">", "<"), 1)
  }
  
  # Randomly determine which category this rule predicts
  prediction <- sample(0:1, 1)
  
  return(rule(dimensions, thresholds, operations, prediction))
}

# Generate initial particles (rules)
initialize_particles <- function(n_particles, n_dimensions, n_features) {
  particles <- list()
  weights <- rep(1/n_particles, n_particles)
  
  for (i in 1:n_particles) {
    particles[[i]] <- generate_random_rule(n_dimensions, n_features)
  }
  
  return(list(particles = particles, weights = weights))
}

# Update particle weights based on new observation
update_weights <- function(particles, weights, stimulus, category, error_prob = 0.05) {
  new_weights <- numeric(length(weights))
  
  for (i in seq_along(particles)) {
    # Get prediction for this rule
    prediction <- evaluate_rule(particles[[i]], stimulus)
    
    # Update weight based on whether prediction matches category
    if (prediction == category) {
      new_weights[i] <- weights[i] * (1 - error_prob)
    } else {
      new_weights[i] <- weights[i] * error_prob
    }
  }
  
  # Normalize weights
  new_weights <- new_weights / sum(new_weights)
  
  return(new_weights)
}

# Resample particles based on weights
resample_particles <- function(particles, weights, n_particles) {
  # Sample indices with replacement based on weights
  indices <- sample(1:length(particles), size = n_particles, replace = TRUE, prob = weights)
  
  # Create new particle list and reset weights
  new_particles <- particles[indices]
  new_weights <- rep(1/n_particles, n_particles)
  
  return(list(particles = new_particles, weights = new_weights))
}

# Main rule-based model using particle filter
rule_particle_filter <- function(n_particles, n_dimensions, error_prob, obs, cat_one, quiet = TRUE) {
  # Initialize
  n_trials <- nrow(obs)
  n_features <- ncol(obs)
  
  # Generate initial particles
  particle_system <- initialize_particles(n_particles, n_dimensions, n_features)
  particles <- particle_system$particles
  weights <- particle_system$weights
  
  # Store response probabilities
  r <- numeric(n_trials)
  
  # Process each trial
  for (i in 1:n_trials) {
    # Debug info
    if (!quiet && i %% 10 == 0) {
      print(paste("i =", i))
    }
    
    # Make prediction for current stimulus
    stimulus <- as.numeric(obs[i, ])
    predictions <- sapply(particles, function(p) evaluate_rule(p, stimulus))
    
    # Calculate probability of category 1
    r[i] <- sum(weights * (predictions == 1))
    
    # If not the last trial, update particles based on feedback
    if (i < n_trials) {
      # Update weights
      weights <- update_weights(particles, weights, stimulus, cat_one[i], error_prob)
      
      # Resample if effective sample size is too low
      effective_size <- 1 / sum(weights^2)
      if (effective_size < n_particles / 2) {
        particle_system <- resample_particles(particles, weights, n_particles)
        particles <- particle_system$particles
        weights <- particle_system$weights
      }
    }
  }
  
  # Return binary responses based on probabilities
  return(rbinom(n_trials, 1, r))
}
```

Let's break down this implementation:

1. **Rule Representation**: Each rule specifies which dimensions it uses, the threshold for each dimension, whether each dimension should be greater or less than the threshold, and how dimensions are combined (for multi-dimensional rules).

2. **Particle System**: The model maintains a set of rule hypotheses (particles) and their associated probabilities (weights).

3. **Weight Update**: When new data is observed, the model increases weights for rules that correctly predict the category and decreases weights for rules that don't.

4. **Resampling**: When the effective number of particles gets too low (most weights near zero), the model resamples particles to focus computation on high-probability rules.

5. **Decision Making**: The probability of assigning a stimulus to category 1 is the weighted average of predictions across all particles.

This implementation captures the key cognitive processes hypothesized by rule-based models:
- Generation of candidate rules
- Testing rules against evidence
- Adapting to new information
- Maintaining uncertainty across multiple rule hypotheses

## Simulating Categorization Behavior with the Rule-Based Model

Now let's simulate how our rule-based model would behave on the same categorization task we used for the exemplar and prototype models:

```r
# Function to simulate responses using the rule-based model
simulate_rule_responses <- function(agent, n_particles, n_dimensions, error_prob) {
    observations <- experiment %>%
        select(c("height", "position"))
    
    category <- experiment$category
    
    # Simulate responses
    responses <- rule_particle_filter(
        n_particles = n_particles,
        n_dimensions = n_dimensions,
        error_prob = error_prob,
        obs = as.matrix(observations),
        cat_one = category
    )
    
    # Record results
    tmp_simulated_responses <- experiment %>%
        mutate(
            trial = seq(nrow(experiment)),
            sim_response = responses,
            correct = ifelse(category == sim_response, 1, 0),
            performance = cumsum(correct) / seq_along(correct),
            n_particles = n_particles,
            n_dimensions = n_dimensions,
            error_prob = error_prob,
            agent = agent
        )

    return(tmp_simulated_responses)
}

# Simulate responses across parameter values
plan(multisession, workers = availableCores())

param_df <- dplyr::tibble(
    expand_grid(
        agent = 1:10,
        n_particles = c(50, 100, 200),
        n_dimensions = c(1, 2),
        error_prob = c(0.05, 0.1, 0.2)
    )
)

rule_responses <- future_pmap_dfr(param_df,
    simulate_rule_responses,
    .options = furrr_options(seed = TRUE)
)
```

We can visualize how different parameter settings affect performance:

```r
# Visualize effect of number of particles
p1 <- rule_responses %>%
  mutate(n_particles = as.factor(n_particles)) %>%
  ggplot(aes(trial, performance, group = n_particles, color = n_particles)) +
  geom_smooth() +
  theme_bw() +
  facet_grid(n_dimensions ~ error_prob, 
             labeller = labeller(
               n_dimensions = function(x) paste("Dimensions:", x),
               error_prob = function(x) paste("Error Prob:", x)
             )) +
  labs(
    title = "Effect of Number of Particles on Rule Learning",
    x = "Trial",
    y = "Proportion Correct",
    color = "Particles"
  )

p1
```

This visualization shows how the model's performance is affected by:
1. The number of particles (more particles = more rule hypotheses)
2. The number of dimensions used in rules (1D = simpler rules, 2D = more complex rules)
3. The error probability (higher error = more tolerance for rules that don't perfectly fit the data)

## Visualizing Rule Learning Over Time

One of the most interesting aspects of rule-based models is watching how rule hypotheses evolve over time. Let's add a function to track the rules the model considers most likely at different points in training:

```r
# Function to track top rules during learning
track_rule_learning <- function(n_particles, n_dimensions, error_prob, obs, cat_one, top_k = 3) {
  # Initialize
  n_trials <- nrow(obs)
  n_features <- ncol(obs)
  
  # Generate initial particles
  particle_system <- initialize_particles(n_particles, n_dimensions, n_features)
  particles <- particle_system$particles
  weights <- particle_system$weights
  
  # Store top rules at each step
  rule_trajectory <- tibble(
    trial = integer(),
    rank = integer(),
    weight = numeric(),
    dimension1 = integer(),
    operation1 = character(),
    threshold1 = numeric(),
    dimension2 = integer(),
    operation2 = character(),
    threshold2 = numeric(),
    logic = character(),
    prediction = integer()
  )
  
  # Process each trial
  for (i in 1:n_trials) {
    # Get current stimulus
    stimulus <- as.numeric(obs[i, ])
    
    # Record top rules at this step
    ordered_idx <- order(weights, decreasing = TRUE)[1:min(top_k, length(weights))]
    
    for (k in 1:length(ordered_idx)) {
      idx <- ordered_idx[k]
      p <- particles[[idx]]
      
      # Extract rule info, handling both 1D and 2D rules
      dim1 <- if(length(p$dimensions) >= 1) p$dimensions[1] else NA
      op1 <- if(length(p$operations) >= 1) p$operations[1] else NA
      thresh1 <- if(length(p$thresholds) >= 1) p$thresholds[1] else NA
      
      dim2 <- if(length(p$dimensions) >= 2) p$dimensions[2] else NA
      op2 <- if(length(p$operations) >= 2) p$operations[2] else NA
      thresh2 <- if(length(p$thresholds) >= 2) p$thresholds[2] else NA
      
      # Add to trajectory
      rule_trajectory <- rule_trajectory %>% add_row(
        trial = i,
        rank = k,
        weight = weights[idx],
        dimension1 = dim1,
        operation1 = op1,
        threshold1 = thresh1,
        dimension2 = dim2,
        operation2 = op2,
        threshold2 = thresh2,
        logic = if(is.null(p$operation_logic) || is.na(p$operation_logic)) "N/A" else p$operation_logic,
        prediction = p$prediction
      )
    }
    
    # If not the last trial, update particles based on feedback
    if (i < n_trials) {
      # Update weights
      weights <- update_weights(particles, weights, stimulus, cat_one[i], error_prob)
      
      # Resample if effective sample size is too low
      effective_size <- 1 / sum(weights^2)
      if (effective_size < n_particles / 2) {
        particle_system <- resample_particles(particles, weights, n_particles)
        particles <- particle_system$particles
        weights <- particle_system$weights
      }
    }
  }
  
  return(rule_trajectory)
}

# Track rule learning for visualization
rule_tracking <- track_rule_learning(
  n_particles = 100,
  n_dimensions = 2,
  error_prob = 0.1,
  obs = as.matrix(experiment[, c("height", "position")]),
  cat_one = experiment$category
)

# Create a function to convert rules to human-readable text
rule_to_text <- function(row) {
  # Handle 1D rules
  if (is.na(row$dimension2)) {
    if (row$dimension1 == 1) {
      dim_name <- "Height"
    } else {
      dim_name <- "Position"
    }
    
    rule_text <- paste0("If ", dim_name, " ", row$operation1, " ", round(row$threshold1, 2),
                       ", then Category ", row$prediction)
  } else {
    # Handle 2D rules
    if (row$dimension1 == 1) {
      dim1_name <- "Height"
      dim2_name <- "Position"
    } else {
      dim1_name <- "Position"
      dim2_name <- "Height"
    }
    
    rule_text <- paste0("If ", dim1_name, " ", row$operation1, " ", round(row$threshold1, 2),
                       " ", row$logic, " ", dim2_name, " ", row$operation2, " ", 
                       round(row$threshold2, 2), ", then Category ", row$prediction)
  }
  
  return(rule_text)
}

# Add rule text to our tracking data
rule_tracking <- rule_tracking %>%
  rowwise() %>%
  mutate(rule_text = rule_to_text(cur_data_row())) %>%
  ungroup()

# Visualize how the top rule evolves over time
ggplot(rule_tracking %>% filter(rank == 1)) +
  geom_point(aes(trial, weight), size = 3) +
  geom_line(aes(trial, weight)) +
  geom_text(aes(trial, weight, label = rule_text), 
            hjust = -0.1, vjust = 0, size = 3) +
  xlim(0, nrow(experiment) + 20) +  # Add space for rule text
  ylim(0, 1) +
  labs(
    title = "Evolution of the Top Rule Hypothesis",
    subtitle = "Weight shows probability assigned to each rule",
    x = "Trial",
    y = "Rule Weight (Probability)"
  ) +
  theme_minimal()
```

This visualization shows how the model's belief in different rules evolves over time. At the beginning, it might consider simple rules focusing on a single dimension. As it sees more examples, it may discover that more complex rules involving multiple dimensions better explain the category structure.

We can also visualize the decision boundaries created by the top rules:

```r
# Function to generate decision boundary for a rule
generate_rule_boundary <- function(rule, grid_points) {
  # Apply rule to each grid point
  predictions <- apply(as.matrix(grid_points[, c("position", "height")]), 1, 
                      function(x) evaluate_rule(rule, x))
  
  # Add predictions to grid
  grid_points$prediction <- predictions
  
  return(grid_points)
}

# Create a grid of points in the stimulus space
grid_points <- expand.grid(
  position = seq(min(stimuli$position) - 0.5, max(stimuli$position) + 0.5, length.out = 50),
  height = seq(min(stimuli$height) - 0.5, max(stimuli$height) + 0.5, length.out = 50)
)

# Get top rule from the end of training
top_rule <- rule_tracking %>% 
  filter(trial == max(trial) & rank == 1)

# Create rule object
final_rule <- list(
  dimensions = c(top_rule$dimension1, if(!is.na(top_rule$dimension2)) top_rule$dimension2 else NULL),
  thresholds = c(top_rule$threshold1, if(!is.na(top_rule$threshold2)) top_rule$threshold2 else NULL),
  operations = c(top_rule$operation1, if(!is.na(top_rule$operation2)) top_rule$operation2 else NULL),
  operation_logic = top_rule$logic,
  prediction = top_rule$prediction
)

# Generate boundary
grid_with_predictions <- generate_rule_boundary(final_rule, grid_points)

# Visualize decision boundary
ggplot() +
  # Background colors for decision regions
  geom_tile(data = grid_with_predictions, 
            aes(position, height, fill = factor(prediction)), 
            alpha = 0.3) +
  
  # Actual stimuli
  geom_point(data = stimuli, 
             aes(position, height, color = category),
             size = 3) +
  
  # Labels and theme
  scale_fill_manual(values = c("0" = "tomato", "1" = "skyblue"), 
                   name = "Predicted Category") +
  labs(
    title = "Rule-Based Model Decision Boundary",
    subtitle = top_rule$rule_text,
    x = "Position",
    y = "Height",
    color = "True Category"
  ) +
  theme_minimal()
```

This visualization shows the distinctive rectangular decision boundaries created by rule-based models. Unlike the curved boundaries of similarity-based models, rule-based models partition the feature space into regions with sharp, axis-aligned boundaries.

## Implementing the Rule-Based Model in Stan

To estimate the parameters of our rule-based model from observed categorization data, we'll take a different approach than we did with the exemplar and prototype models. Because the particle filter involves discrete rule hypotheses that change over time, it's not straightforward to implement in Stan, which works best with continuous parameter spaces.

Instead, we'll implement a simplified version that focuses on estimating key parameters:

1. **Error probability (ε)**: How likely the model is to predict the wrong category
2. **Rule complexity preference**: Whether simpler (1D) or more complex (2D) rules are preferred

```stan
// Simplified Rule-Based Model (for parameter estimation)

data {
  int<lower=1> ntrials;               // Number of trials
  int<lower=1> nfeatures;             // Number of feature dimensions
  array[ntrials] int<lower=0, upper=1> cat_one;  // True category labels
  array[ntrials] int<lower=0, upper=1> y;        // Observed decisions
  array[ntrials, nfeatures] real obs;  // Stimulus features
}

parameters {
  real<lower=0, upper=1> error_prob;  // Error probability
  real complexity_weight;             // Weight for rule complexity (negative = favor simple)
}

model {
  // Priors
  target += beta_lpdf(error_prob | 2, 10);  // Prior favors low error
  target += normal_lpdf(complexity_weight | 0, 1);  // Prior for complexity preference
  
  // Log likelihood calculation using pre-specified rule candidates
  for (i in 1:ntrials) {
    vector[4] rule_log_probs;  // Log probabilities for different rules
    
    // Rule 1: Height > 2.5 => Category 1
    int pred1 = obs[i, 1] > 2.5 ? 1 : 0;
    rule_log_probs[1] = pred1 == cat_one[i] ? log1m(error_prob) : log(error_prob);
    
    // Rule 2: Position > 2.5 => Category 1
    int pred2 = obs[i, 2] > 2.5 ? 1 : 0;
    rule_log_probs[2] = pred2 == cat_one[i] ? log1m(error_prob) : log(error_prob);
    
    // Rule 3: Height > 2.5 AND Position < 2.5 => Category 1
    int pred3 = (obs[i, 1] > 2.5 && obs[i, 2] < 2.5) ? 1 : 0;
    rule_log_probs[3] = pred3 == cat_one[i] ? log1m(error_prob) : log(error_prob);
    
    // Rule 4: Height > 2.5 OR Position > 2.5 => Category 1
    int pred4 = (obs[i, 1] > 2.5 || obs[i, 2] > 2.5) ? 1 : 0;
    rule_log_probs[4] = pred4 == cat_one[i] ? log1m(error_prob) : log(error_prob);
    
    // Add complexity penalty/bonus
    rule_log_probs[1] += 0;  // Simple rule (1D)
    rule_log_probs[2] += 0;  // Simple rule (1D)
    rule_log_probs[3] += complexity_weight;  // Complex rule (2D)
    rule_log_probs[4] += complexity_weight;  // Complex rule (2D)
    
    // Sum over all rules (marginalize)
    target += log_sum_exp(rule_log_probs) - log(4);
  }
}

generated quantities {
  // Log likelihood for model comparison
  array[ntrials] real log_lik;
  
  for (i in 1:ntrials) {
    vector[4] rule_log_probs;
    
    // Rule 1: Height > 2.5 => Category 1
    int pred1 = obs[i, 1] > 2.5 ? 1 : 0;
    rule_log_probs[1] = pred1 == cat_one[i] ? log1m(error_prob) : log(error_prob);
    
    // Rule 2: Position > 2.5 => Category 1
    int pred2 = obs[i, 2] > 2.5 ? 1 : 0;
    rule_log_probs[2] = pred2 == cat_one[i] ? log1m(error_prob) : log(error_prob);
    
    // Rule 3: Height > 2.5 AND Position < 2.5 => Category 1
    int pred3 = (obs[i, 1] > 2.5 && obs[i, 2] < 2.5) ? 1 : 0;
    rule_log_probs[3] = pred3 == cat_one[i] ? log1m(error_prob) : log(error_prob);
    
    // Rule 4: Height > 2.5 OR Position > 2.5 => Category 1
    int pred4 = (obs[i, 1] > 2.5 || obs[i, 2] > 2.5) ? 1 : 0;
    rule_log_probs[4] = pred4 == cat_one[i] ? log1m(error_prob) : log(error_prob);
    
    // Add complexity penalty/bonus
    rule_log_probs[1] += 0;
    rule_log_probs[2] += 0;
    rule_log_probs[3] += complexity_weight;
    rule_log_probs[4] += complexity_weight;
    
    // Sum over all rules
    log_lik[i] = log_sum_exp(rule_log_probs) - log(4);
  }
  
  // Generate predictions
  array[ntrials] int pred;
  for (i in 1:ntrials) {
    vector[4] rule_probs;
    
    // Calculate unnormalized rule probabilities
    rule_probs[1] = exp(0);  // Simple rule 1
    rule_probs[2] = exp(0);  // Simple rule 2
    rule_probs[3] = exp(complexity_weight);  // Complex rule 1
    rule_probs[4] = exp(complexity_weight);  // Complex rule 2
    
    // Normalize
    rule_probs = rule_probs / sum(rule_probs);
    
    // Get predictions from each rule
    int pred1 = obs[i, 1] > 2.5 ? 1 : 0;
    int pred2 = obs[i, 2] > 2.5 ? 1 : 0;
    int pred3 = (obs[i, 1] > 2.5 && obs[i, 2] < 2.5) ? 1 : 0;
    int pred4 = (obs[i, 1] > 2.5 || obs[i, 2] > 2.5) ? 1 : 0;
    
    // Weighted prediction
    real p1 = rule_probs[1] * ((pred1 == 1) ? 1-error_prob : error_prob);
    real p2 = rule_probs[2] * ((pred2 == 1) ? 1-error_prob : error_prob);
    real p3 = rule_probs[3] * ((pred3 == 1) ? 1-error_prob : error_prob);
    real p4 = rule_probs[4] * ((pred4 == 1) ? 1-error_prob : error_prob);
    
    // Overall probability of category 1
    real p_cat1 = p1 + p2 + p3 + p4;
    
    // Generate prediction
    pred[i] = bernoulli_rng(p_cat1);
  }
}
```

This simplified model:
1. Evaluates a fixed set of candidate rules rather than using a particle filter
2. Weighs rules by their complexity and how well they fit the data
3. Estimates the error probability and complexity preference parameters

## Cognitive Insights from Rule-Based Models

Rule-based models offer several important cognitive insights:

### 1. Explicit Hypothesis Testing

Unlike similarity-based models, which gradually adjust weights, rule-based models involve explicit hypothesis testing—forming candidate rules, testing them against data, and revising or replacing them.

### 2. All-or-None Learning

Rule-based models often predict more abrupt transitions in learning curves compared to similarity-based models. Once the correct rule is discovered, performance can jump dramatically.

### 3. Attention as Selection Rather Than Weighting

In rule-based models, attention operates by selecting relevant dimensions rather than by gradually adjusting weights. This creates sharper attention patterns.

### 4. Verbalizability

The rules in rule-based models are typically easy to verbalize, matching how people often describe their categorization strategies (e.g., "I looked for whether it was taller than X").

### 5. Individual Differences in Strategy

Different individuals might discover different but equally valid rules for the same category structure, explaining why people sometimes report using different strategies.

## Contrasting with Similarity-Based Models

Rule-based models differ from similarity-based models (exemplar and prototype) in several key ways:

1. **Feature Integration**: Similarity models integrate information across all features, while rule-based models often focus on a subset of features.

2. **Decision Boundaries**: Rule-based models create rectangular, axis-aligned decision boundaries, while similarity models create curved, more complex boundaries.

3. **Learning Trajectories**: Rule-based models predict more abrupt learning, while similarity models predict gradual improvements.

4. **Individual Differences**: Rule-based models predict qualitatively different strategies across individuals, while similarity models predict quantitative differences in attention weights.

5. **Category Representation**: Rule-based models explicitly represent category boundaries, while similarity models represent category contents (exemplars or prototypes).

## Strengths of the Rule-Based Approach

Rule-based models have several strengths:

1. **Cognitive Plausibility**: People can often verbalize rules they use for categorization, suggesting explicit rule use.

2. **Efficiency for Simple Structures**: For categories with simple, axis-aligned boundaries, rules are computationally efficient.

3. **Natural Explanation for Sharp Boundaries**: Some categories do have sharp, criterial boundaries that rule-based models naturally capture.

4. **Alignment with Formal Instruction**: Many categories are explicitly taught using rules (e.g., grammatical categories).

5. **Logical Operations**: Rule-based models naturally handle logical operations (AND, OR, NOT) that are more complex to implement in similarity models.

## Limitations of the Rule-Based Approach

Despite their strengths, rule-based models have important limitations:

1. **Struggle with Family Resemblance**: Categories defined by overall similarity rather than necessary and sufficient features are challenging for rule-based models.

2. **Difficulty with Complex Boundaries**: Categories with diagonal or curved boundaries require complex combinations of rules.

3. **All-or-None Predictions**: Rule-based models sometimes predict sharper category boundaries than humans actually show.

4. **Fixed Feature Spaces**: Standard rule-based models assume a fixed set of features rather than allowing for feature creation.

## Extensions to the Basic Model

Several extensions have been developed to address these limitations:

1. **Hybrid Models**: COVIS (COmpetition between Verbal and Implicit Systems) proposes that rule-based and similarity-based systems operate in parallel.

2. **Rule-Plus-Exception Models**: RULEX combines rule-based categorization with memory for exceptions that don't fit the rules.

3. **Decision Bound Models**: These extend rule-based models to allow for arbitrary linear decision boundaries, not just axis-aligned ones.

4. **Hierarchical Rule Discovery**: More sophisticated rule discovery processes can create and test complex combinations of features.

## The Bayesian Approach to Rules

The Bayesian particle filter approach we've implemented offers several advantages:

1. **Maintaining Uncertainty**: Rather than committing to a single rule, it maintains uncertainty across multiple rule hypotheses.

2. **Incremental Learning**: It learns incrementally, adjusting beliefs with each new example.

3. **Rational Allocation of Belief**: It assigns higher probability to rules that better explain the observed data.

4. **Complexity Trade-offs**: It can naturally implement a trade-off between rule complexity and fit to data.

This approach represents a compromise between the cognitive plausibility of rule-based models and the mathematical rigor of Bayesian inference. It captures the idea that people may consider multiple rule hypotheses simultaneously, weighting them by their explanatory power.

## Summary: The Rule-Based Approach to Categorization

Rule-based models provide a fundamentally different perspective on categorization compared to similarity-based approaches. They emphasize explicit hypothesis testing, selective attention to relevant features, and sharp category boundaries.

The Bayesian particle filter implementation we've explored captures many of these key features while adding a principled way to handle uncertainty across multiple rule hypotheses. It represents one of several promising approaches to formalizing rule-based categorization in a computational framework.

In the next section, we'll compare all three model types—exemplar, prototype, and rule-based—to understand their relative strengths and limitations in accounting for human categorization behavior.
 