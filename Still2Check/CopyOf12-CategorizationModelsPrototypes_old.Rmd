---
title: "12-CategorizationModelsPrototypes"
output:
  html_document:
    mathjax: default
  pdf_document: default
date: "2025-03-21"
---
# Prototype-Based Models of Categorization

## Theoretical Foundations

Prototype theory emerged as an alternative to both the classical view of categories (based on necessary and sufficient conditions) and exemplar-based accounts. The core idea is elegantly simple: rather than storing all individual exemplars in memory, the cognitive system abstracts a summary representation—a prototype—for each category. New items are then categorized based on their similarity to these prototypes.

### Core Assumptions of Prototype Models

1. **Category Abstraction**: Categories are represented by central tendencies or prototypes rather than collections of exemplars
2. **Economical Representation**: Only prototype information is stored, not individual exemplars
3. **Similarity-Based Decisions**: Categorization is based on similarity to category prototypes
4. **Typicality Effects**: Items more similar to the prototype are processed more fluently and judged as more typical

Unlike exemplar models, which maintain that people store individual instances, prototype models propose a more economical representation: the cognitive system extracts and stores the central tendency of the category. This provides a cognitively efficient way to represent categories while capturing many of the phenomena observed in human categorization.

## Prototype Models vs. Exemplar Models

The debate between prototype and exemplar theories has been one of the most productive in cognitive psychology. The key differences include:

| Aspect | Prototype Models | Exemplar Models |
|--------|------------------|-----------------|
| **Representation** | Abstract summary (central tendency) | Collection of individual instances |
| **Memory Requirements** | Economical (one prototype per category) | Potentially high (all exemplars) |
| **Typicality Prediction** | Items similar to prototype are most typical | Items similar to many exemplars are most typical |
| **Category Boundaries** | Smoother, based on distance from prototypes | Potentially more complex, based on similarity to all exemplars |
| **Unusual Members** | May not influence the prototype much | Explicitly represented and influence decisions |

## The Kalman Filter Approach to Prototype Learning

Traditional prototype models often assumed a static prototype computed as the average of all category members. However, this doesn't capture the dynamic nature of human learning, where we continuously update our category representations as we encounter new examples.

The Kalman filter provides an elegant mathematical framework for implementing a dynamic prototype model. Originally developed for tracking physical systems, the Kalman filter is ideal for modeling prototype learning because it:

1. **Updates incrementally** with each new observation
2. **Balances prior knowledge** with new evidence
3. **Maintains uncertainty** about the prototype location
4. **Adjusts learning rate** based on certainty

### Mathematical Formulation of the Kalman Filter Prototype Model

The Kalman filter prototype model tracks each category's prototype as a probability distribution rather than a fixed point. Specifically, for each category, we maintain:

- A prototype location (mean vector μ)
- An uncertainty measure (covariance matrix Σ)

#### 1. Initialization

For each category C, we initialize:
- Prototype location: μ₀ (often set to the first exemplar or a prior expectation)
- Uncertainty: Σ₀ (high initial uncertainty)

#### 2. Update Equations

When a new exemplar x is observed for category C, we update the prototype and uncertainty as follows:

**Prototype Update**:
μₜ = μₜ₋₁ + K(x - μₜ₋₁)

**Uncertainty Update**:
Σₜ = (I - K)Σₜ₋₁

**Kalman Gain**:
K = Σₜ₋₁(Σₜ₋₁ + R)⁻¹

Where:
- μₜ is the updated prototype location
- Σₜ is the updated uncertainty
- K is the Kalman gain (learning rate)
- R is the observation noise (constant or learned)

The Kalman gain K is crucial—it determines how much weight to give to the new observation versus the existing prototype. When uncertainty is high, K is larger, giving more weight to new observations. As uncertainty decreases with more observations, K decreases, making the prototype more stable.

#### 3. Categorization Decision

Given multiple categories, the probability of assigning a new stimulus x to category C is given by:

P(C|x) ∝ exp(-0.5(x - μ)ᵀ(Σ + R)⁻¹(x - μ))

This is based on the multivariate normal density, essentially measuring how likely the observation x is under category C's prototype distribution.

## Implementing the Kalman Filter Prototype Model

Let's implement a Kalman filter prototype model in R. For simplicity, we'll start with a univariate case and then extend to the multivariate case needed for our categorization task.

### Univariate Kalman Filter (for clear explanation)

```{r, 12 univariate kalman filter}

library(mvtnorm)
# Control regeneration of simulations/fits
regenerate_simulations <- FALSE # Set to FALSE to load saved results

# Simple univariate Kalman filter for tracking a prototype
kalman_update <- function(mu_prev, sigma_prev, observation, r) {
  # Calculate Kalman gain
  k <- sigma_prev / (sigma_prev + r)
  
  # Update mean (prototype location)
  mu_new <- mu_prev + k * (observation - mu_prev)
  
  # Update variance (uncertainty)
  sigma_new <- (1 - k) * sigma_prev
  
  # Return updated values
  return(list(mu = mu_new, sigma = sigma_new, k = k))
}
```

This function:
1. Takes the current prototype (mu_prev), uncertainty (sigma_prev), and a new observation
2. Calculates the Kalman gain (k) based on current uncertainty
3. Updates the prototype by moving it toward the observation, weighted by the gain
4. Updates the uncertainty, which always decreases with more observations
5. Returns the updated prototype, uncertainty, and gain

The beauty of the Kalman filter is that the gain automatically adapts: when uncertainty is high (early learning), the gain is high, leading to larger updates. As uncertainty decreases (more observations), the gain decreases, making the prototype more stable.

### Multivariate Kalman Filter for Categorization

For categorization tasks with multiple feature dimensions, we need a multivariate version of the Kalman filter:

```{r, 12 multivariate kalman filter}
# Multivariate Kalman filter for tracking category prototypes
multivariate_kalman_update <- function(mu_prev, sigma_prev, observation, r_matrix) {
  # Ensure inputs are matrices/vectors
  mu_prev <- as.numeric(mu_prev)
  observation <- as.numeric(observation)
  sigma_prev <- as.matrix(sigma_prev)
  r_matrix <- as.matrix(r_matrix)
  
  n_dim <- length(mu_prev)
  I <- diag(n_dim) # Identity matrix
  
  # Calculate Kalman gain
  # Use tryCatch for potential singularity, though unlikely with added R
  S_inv <- tryCatch(solve(sigma_prev + r_matrix), error = function(e) {
      warning("Matrix inversion failed in Kalman gain calculation. Using pseudo-inverse or adding jitter might help.")
      MASS::ginv(sigma_prev + r_matrix) # Fallback using pseudo-inverse
  })
  k_matrix <- sigma_prev %*% S_inv
  
  # Update mean (prototype location)
  innovation <- observation - mu_prev
  mu_new <- mu_prev + k_matrix %*% innovation
  
  # Update covariance (uncertainty) using Joseph form
  # sigma_new = (I - K) * sigma_prev * (I - K)' + K * R * K'
  IK_term <- (I - k_matrix)
  sigma_new <- IK_term %*% sigma_prev %*% t(IK_term) + k_matrix %*% r_matrix %*% t(k_matrix)
  
  # Ensure symmetry (numerical precision can sometimes cause minor asymmetry)
  sigma_new <- (sigma_new + t(sigma_new)) / 2
  
  # Return updated values
  return(list(mu = as.numeric(mu_new), sigma = sigma_new, k = k_matrix))
}
```

For our categorization task, we'll use this to track prototypes for each category:

```{r, 12 prototype kalman}
# Prototype model using Kalman filter for categorization
prototype_kalman <- function(r_value, obs, cat_one, quiet = TRUE) {
  # Create empty vector for response probabilities
  response_probs <- c()
  
  n_trials <- nrow(obs)
  n_features <- ncol(obs)
  
  # Initialize prototypes for each category (Consistent with Stan)
  prototype_cat_0 <- list(
    mu = rep(0, n_features),      # Initial prototype location (aligned with Stan)
    sigma = diag(10, n_features)  # Initial uncertainty (high, aligned with Stan)
  )
  
  prototype_cat_1 <- list(
    mu = rep(0, n_features),      # Initial prototype location (aligned with Stan)
    sigma = diag(10, n_features)  # Initial uncertainty (high, aligned with Stan)
  )
  
  # Observation noise (fixed for simplicity, could be learned)
  r_matrix <- diag(r_value, n_features)
  
  # Log-Sum-Exp function for stable normalization
  log_sum_exp <- function(v) {
    max_v <- max(v)
    max_v + log(sum(exp(v - max_v)))
  }
  
  # Process each trial
  for (i in 1:n_trials) {
    # Debug info
    if (!quiet && i %% 10 == 0) {
      print(paste("i =", i))
    }
    
    current_obs <- as.numeric(obs[i, ])
    
    # Calculate response probability based on current prototypes using MVN density
    
    # Calculate covariance matrices including observation noise
    cov_cat_0 <- prototype_cat_0$sigma + r_matrix
    cov_cat_1 <- prototype_cat_1$sigma + r_matrix
    
    # Calculate log determinants
    # Use determinant() from base R, ensure log = TRUE
    log_det_0 <- determinant(cov_cat_0, logarithm = TRUE)$modulus[1] 
    log_det_1 <- determinant(cov_cat_1, logarithm = TRUE)$modulus[1]
    
    # Calculate Mahalanobis squared distances
    # Use tryCatch for potential singularity if cov matrix becomes ill-conditioned
    prec_cat_0 <- tryCatch(solve(cov_cat_0), error = function(e) MASS::ginv(cov_cat_0))
    prec_cat_1 <- tryCatch(solve(cov_cat_1), error = function(e) MASS::ginv(cov_cat_1))
    
    diff0 <- current_obs - prototype_cat_0$mu
    diff1 <- current_obs - prototype_cat_1$mu
    
    dist_sq_0 <- sum(diff0 * (prec_cat_0 %*% diff0)) # Quadratic form: t(diff) %*% prec %*% diff
    dist_sq_1 <- sum(diff1 * (prec_cat_1 %*% diff1))
    
    # Calculate log probabilities (proportional to MVN density)
    log_prob_0 <- -0.5 * (dist_sq_0 + log_det_0 + n_features * log(2 * pi))
    log_prob_1 <- -0.5 * (dist_sq_1 + log_det_1 + n_features * log(2 * pi))
    
    # Normalize using log-sum-exp to get probability of category 1
    # Handle cases where one log_prob might be -Inf (if cov matrix was singular)
    if (!is.finite(log_prob_0) && !is.finite(log_prob_1)) {
        prob_cat_1 <- 0.5 # Undefined, default to 0.5
    } else if (!is.finite(log_prob_0)) {
        prob_cat_1 <- 1.0 # Only category 1 has finite probability
    } else if (!is.finite(log_prob_1)) {
        prob_cat_1 <- 0.0 # Only category 0 has finite probability
    } else {
        prob_cat_1 <- exp(log_prob_1 - log_sum_exp(c(log_prob_0, log_prob_1)))
    }
    
    # Ensure probability is within bounds
    prob_cat_1 <- max(min(prob_cat_1, 0.999), 0.001)
    
    response_probs <- c(response_probs, prob_cat_1)
    
    # Update prototype for the correct category after decision
    if (i < n_trials) {  # No need to update after the last trial
      if (cat_one[i] == 1) {
        # Update category 1 prototype using revised update function
        update <- multivariate_kalman_update(
          prototype_cat_1$mu, 
          prototype_cat_1$sigma, 
          current_obs, 
          r_matrix
        )
        prototype_cat_1$mu <- update$mu
        prototype_cat_1$sigma <- update$sigma
      } else {
        # Update category 0 prototype using revised update function
        update <- multivariate_kalman_update(
          prototype_cat_0$mu, 
          prototype_cat_0$sigma, 
          current_obs, 
          r_matrix
        )
        prototype_cat_0$mu <- update$mu
        prototype_cat_0$sigma <- update$sigma
      }
    }
  }
  
  # Return simulated binary responses based on calculated probabilities
  return(rbinom(n_trials, 1, response_probs))
}
```

Let's break down this implementation:

1. **Initialization**:
   - We start with uninformative prototypes (centered at 0.5 with high uncertainty)
   - The observation noise (r_matrix) determines how much variance we expect around the prototype

2. **Decision Process**:
   - For each new stimulus, we calculate its Mahalanobis distance to each category's prototype
   - The Mahalanobis distance accounts for both the prototype location and uncertainty
   - We convert these distances to probabilities using a softmax function

3. **Prototype Update**:
   - After each trial, we update the prototype of the correct category using the Kalman filter
   - The update moves the prototype toward the new observation and reduces uncertainty
   - The amount of movement depends on the current uncertainty level

4. **Learning Dynamics**:
   - Early in learning, large updates occur due to high uncertainty
   - As learning progresses, updates become smaller, stabilizing the prototypes
   - Eventually, the prototypes converge to the category centers

### The Observation Noise Parameter

- Small r_value: Assumes observations are very precise; prototypes move less and become more certain quickly
- Large r_value: Assumes observations have high variability; prototypes move more and remain uncertain longer

This parameter can be interpreted as representing the learner's assumptions about category variability or their perceptual noise.

## Simulating Categorization Behavior with the Prototype Model

Let's now simulate categorization behavior using our prototype model with the same experimental setup we used for the GCM:

```{r, 12 simulate prototype driven responses}
# Function to simulate responses using the prototype model
simulate_prototype_responses <- function(agent, r_value) {
    # Ensure using correct columns from experiment data
    observations <- as.matrix(experiment %>% dplyr::select(all_of(c("height", "position"))))
    category <- experiment$category # Assuming category is 0/1
    
    # Simulate responses using the REVISED prototype_kalman function
    responses <- prototype_kalman(
        r_value,
        observations,
        category
    )
    
    # Record results
    tmp_simulated_responses <- experiment %>%
        mutate(
            trial = 1:n(), # Ensure trial sequence is correct
            sim_response = responses,
            correct = ifelse(category == sim_response, 1, 0),
            performance = cumsum(correct) / trial,
            r_value = r_value,
            agent = agent
        )

    return(tmp_simulated_responses)
}

# Simulate responses across different r_values
plan(multisession, workers = availableCores())

param_df <- dplyr::tibble(
    expand_grid(
        agent = 1:10,
        r_value = c(0.1, 0.5, 1.0, 2.0, 5.0)
    )
)

prototype_responses <- future_pmap_dfr(param_df,
    simulate_prototype_responses,
    .options = furrr_options(seed = TRUE)
)
```

We can visualize how the observation noise parameter affects performance:

```{r, 12 visualize observation noise}
prototype_responses %>%
  mutate(r_value = as.factor(r_value)) %>%
  ggplot(aes(trial, performance, group = interaction(agent, r_value), color = r_value)) +
  stat_summary(fun = mean, geom = "line", alpha = 0.8) + # Plot average performance
  stat_summary(fun.data = mean_se, geom = "ribbon", alpha = 0.2, aes(fill = r_value)) + # Show SE ribbon
  theme_bw() +
  labs(
    title = "Categorization Performance with Revised Prototype Model",
    subtitle = "Effect of observation noise parameter (r_value)",
    x = "Trial",
    y = "Proportion Correct (Average over Agents)",
    color = "r-value",
    fill = "r-value"
  )
```

## Visualizing Prototype Learning

To better understand how prototypes evolve over time, let's visualize the prototype locations and uncertainty throughout learning:

```{r, 12 visualizing prorotype learning}

track_prototypes <- function(r_value, obs, cat_one) {
  n_trials <- nrow(obs)
  n_features <- ncol(obs)

  # Initialize prototypes (Aligned with simulation/Stan)
  prototype_cat_0 <- list(
    mu = rep(0, n_features),
    sigma = diag(10, n_features)
  )

  prototype_cat_1 <- list(
    mu = rep(0, n_features),
    sigma = diag(10, n_features)
  )

  # Observation noise
  r_matrix <- diag(r_value, n_features)

  # Storage for tracking prototype evolution
  prototype_history <- tibble(
    trial = integer(),
    category = integer(),
    feature1_mean = numeric(), # Corresponds to height
    feature2_mean = numeric(), # Corresponds to position
    cov_matrix = list()        # Store the full 2x2 covariance matrix
  )

  # Process each trial
  for (i in 1:n_trials) {
    # Store current prototype state before update
    prototype_history <- prototype_history %>% add_row(
      trial = i,
      category = 0,
      feature1_mean = prototype_cat_0$mu[1], # Assuming mu[1] is height
      feature2_mean = prototype_cat_0$mu[2], # Assuming mu[2] is position
      cov_matrix = list(prototype_cat_0$sigma) # Store the matrix
    ) %>% add_row(
      trial = i,
      category = 1,
      feature1_mean = prototype_cat_1$mu[1],
      feature2_mean = prototype_cat_1$mu[2],
      cov_matrix = list(prototype_cat_1$sigma) # Store the matrix
    )

    # Update prototype for the correct category using REVISED update function
    # Use <= to include update based on the last trial's feedback
    if (i <= n_trials) {
      current_obs <- as.numeric(obs[i, ])
      if (cat_one[i] == 1) {
        # Update category 1 prototype
        update <- multivariate_kalman_update(
          prototype_cat_1$mu,
          prototype_cat_1$sigma,
          current_obs,
          r_matrix
        )
        prototype_cat_1$mu <- update$mu
        prototype_cat_1$sigma <- update$sigma
      } else {
        # Update category 0 prototype
        update <- multivariate_kalman_update(
          prototype_cat_0$mu,
          prototype_cat_0$sigma,
          current_obs,
          r_matrix
        )
        prototype_cat_0$mu <- update$mu
        prototype_cat_0$sigma <- update$sigma
      }
    }
  }

  # Add final state after last update (state at trial n_trials + 1)
    prototype_history <- prototype_history %>% add_row(
      trial = n_trials + 1,
      category = 0,
      feature1_mean = prototype_cat_0$mu[1],
      feature2_mean = prototype_cat_0$mu[2],
      cov_matrix = list(prototype_cat_0$sigma)
    ) %>% add_row(
      trial = n_trials + 1,
      category = 1,
      feature1_mean = prototype_cat_1$mu[1],
      feature2_mean = prototype_cat_1$mu[2],
      cov_matrix = list(prototype_cat_1$sigma)
    )

  return(prototype_history)
}

# Track prototypes for visualization (using the actual experiment data)
# Determine number of trials from experiment data if possible, otherwise use nrow(obs)
n_trials_actual <- if ("id" %in% names(experiment)) max(experiment$id) else nrow(experiment)

prototype_trajectory <- track_prototypes(
  r_value = 1.0, # Example r_value
  obs = as.matrix(experiment[, c("height", "position")]),
  cat_one = experiment$category
)

# Helper function to create ellipse data from mean and covariance
# Requires the ellipse package
get_ellipse <- function(mu, sigma, level = 0.68) {
  if (!requireNamespace("ellipse", quietly = TRUE)) {
    warning("Package 'ellipse' needed for detailed uncertainty ellipses. Install it via install.packages('ellipse').")
    return(NULL) # Return NULL if package not available
  }
  # Ensure mu is numeric vector and sigma is matrix
  mu <- as.numeric(mu)
  sigma <- as.matrix(sigma)
  # Check dimensions
  if(length(mu) != 2 || !all(dim(sigma) == c(2,2))) {
      warning("Ellipse plotting requires 2D mean vector and 2x2 covariance matrix.")
      return(NULL)
  }
  # Ensure covariance is positive definite for ellipse calculation
  # Add small jitter if needed
  eigen_vals <- eigen(sigma, symmetric = TRUE, only.values = TRUE)$values
  if(any(eigen_vals <= 1e-6)) {
      warning("Covariance matrix may not be positive definite for ellipse plotting. Adding jitter.")
      sigma <- sigma + diag(ncol(sigma)) * 1e-6
  }

  # Calculate points on the ellipse boundary
  ellipse_points <- tryCatch(ellipse::ellipse(sigma, centre = mu, level = level),
                             error = function(e) {
                                 warning(paste("Ellipse calculation failed:", e$message))
                                 NULL
                             })
  if (is.null(ellipse_points)) return(NULL)
  # Convert to data frame with expected names (feature1=height, feature2=position)
  as.data.frame(ellipse_points) %>% setNames(c("feature1_mean", "feature2_mean")) # Ensure names match plot aesthetics
}


# Visualize prototype evolution
# Get final prototype states
final_prototypes <- prototype_trajectory %>% filter(trial == max(trial))

# Create ellipse data for final states
# Use rowwise and list columns carefully
ellipse_data_list <- final_prototypes %>%
  rowwise() %>%
  # Pass mu in the order expected by get_ellipse (feature1=height, feature2=position)
  mutate(ellipse_df = list(get_ellipse(c(feature1_mean, feature2_mean), cov_matrix[[1]]))) %>%
  ungroup() %>%
  dplyr::select(category, ellipse_df) %>%
  filter(!sapply(ellipse_df, is.null)) # Remove rows where ellipse failed

# Check if ellipse data was successfully generated
if (nrow(ellipse_data_list) > 0) {
    ellipse_data_unnested <- ellipse_data_list %>% unnest(ellipse_df)
} else {
    warning("Could not generate ellipse data for plotting.")
    ellipse_data_unnested <- NULL # Set to NULL if empty
}


# Base plot
p_trajectory <- ggplot() +
  # Plot stimuli
  geom_point(data = stimuli,
             aes(position, height, color = as.factor(category)),
             size = 4, alpha = 0.3) +

  # Plot prototype trajectory (path during trials 1 to n_trials)
  geom_path(data = prototype_trajectory %>% filter(trial <= n_trials_actual), # Use actual number of trials
            aes(feature2_mean, feature1_mean, group = category, color = as.factor(category)),
            linetype = "dashed", arrow = arrow(type = "closed", length = unit(0.1, "inches"))) +

  # Plot final prototype means (state after last trial)
  geom_point(data = final_prototypes,
             aes(feature2_mean, feature1_mean, color = as.factor(category)),
             size = 3) +

  # Labels and theme
  scale_color_discrete(name = "Category") +
  labs(
    title = "Prototype Learning with Kalman Filter (Revised)",
    subtitle = "Dashed lines show prototype trajectory, ellipses show final 68% uncertainty",
    x = "Position",
    y = "Height"
  ) +
  theme_minimal() +
  coord_cartesian(xlim = range(stimuli$position, prototype_trajectory$feature2_mean, na.rm=T),
                  ylim = range(stimuli$height, prototype_trajectory$feature1_mean, na.rm=T))

# Add ellipses if data exists
if (!is.null(ellipse_data_unnested)) {
  # Plot ellipses using geom_path, mapping x to feature2_mean and y to feature1_mean
  p_trajectory <- p_trajectory +
    geom_path(data = ellipse_data_unnested, aes(feature2_mean, feature1_mean, color = as.factor(category)), alpha = 0.7)
}

# Print the final plot
print(p_trajectory)
```

This visualization shows:
1. The stimulus space with actual category members
2. The trajectory of each prototype as it updates with new observations
3. The final prototype locations with uncertainty ellipses

Notice how the prototypes start at (2.5,2.5) and gradually move toward the center of each category. The uncertainty ellipses show the model's confidence about each prototype's location.

## Comparing Prototype and Exemplar Models

To directly compare the prototype (Kalman filter) model with the exemplar (GCM) model, we can:

1. Fit both models to the same data
2. Compare their fit using methods like LOO-CV
3. Analyze which model better captures human categorization patterns

One way to visualize the difference between these models is to look at their decision boundaries:

```{r, 12 comparing exemplars and gcm}
# Create a grid of points in the stimulus space
grid_points <- expand.grid(
  position = seq(min(stimuli$position) - 0.5, max(stimuli$position) + 0.5, length.out = 50),
  height = seq(min(stimuli$height) - 0.5, max(stimuli$height) + 0.5, length.out = 50)
)

# Function to get prototype model predictions for grid points
get_prototype_predictions <- function(r_value, training_obs, training_cat) {
  # Train the model on observed data
  n_features <- ncol(training_obs)
  n_trials <- nrow(training_obs)
  
  # Initialize prototypes
  prototype_cat_0 <- list(
    mu = rep(0, n_features),
    sigma = diag(10, n_features)
  )
  
  prototype_cat_1 <- list(
    mu = rep(0, n_features),
    sigma = diag(10, n_features)
  )
  
  # Observation noise
  r_matrix <- diag(r_value, n_features)
  
  # Train model on observed data
  for (i in 1:n_trials) {
    if (training_cat[i] == 1) {
      # Update category 1 prototype
      update <- multivariate_kalman_update(
        prototype_cat_1$mu, 
        prototype_cat_1$sigma, 
        as.numeric(training_obs[i, ]), 
        r_matrix
      )
      prototype_cat_1$mu <- update$mu
      prototype_cat_1$sigma <- update$sigma
    } else {
      # Update category 0 prototype
      update <- multivariate_kalman_update(
        prototype_cat_0$mu, 
        prototype_cat_0$sigma, 
        as.numeric(training_obs[i, ]), 
        r_matrix
      )
      prototype_cat_0$mu <- update$mu
      prototype_cat_0$sigma <- update$sigma
    }
  }
  
  # Get predictions for grid points
  predictions <- apply(as.matrix(grid_points), 1, function(point) {
    # Calculate distances to prototypes
    sigma_cat_0 <- prototype_cat_0$sigma + r_matrix
    dist_cat_0 <- mahalanobis(point, prototype_cat_0$mu, solve(sigma_cat_0))
    
    sigma_cat_1 <- prototype_cat_1$sigma + r_matrix
    dist_cat_1 <- mahalanobis(point, prototype_cat_1$mu, solve(sigma_cat_1))
    
    # Convert to probability
    prob_cat_1 <- exp(-0.5 * dist_cat_1) / (exp(-0.5 * dist_cat_0) + exp(-0.5 * dist_cat_1))
    return(prob_cat_1)
  })
  
  return(predictions)
}

# Function to get GCM predictions for grid points
get_gcm_predictions <- function(w, c, training_obs, training_cat) {
  # Get predictions for grid points
  predictions <- apply(as.matrix(grid_points), 1, function(point) {
    similarities <- numeric(nrow(training_obs))
    
    # Calculate similarity to all training exemplars
    for (i in 1:nrow(training_obs)) {
      sim <- similarity(distance(point, as.numeric(training_obs[i,]), w), c)
      similarities[i] <- sim
    }
    
    # Calculate probability of category 1
    numerator <- mean(similarities[training_cat == 1])
    denominator <- mean(similarities[training_cat == 1]) + mean(similarities[training_cat == 0])
    
    if (denominator == 0) return(0.5)  # Avoid division by zero
    return(numerator / denominator)
  })
  
  return(predictions)
}

# Get predictions for both models
prototype_preds <- get_prototype_predictions(
  r_value = 1.0,
  training_obs = as.matrix(stimuli[, c("height", "position")]),
  training_cat = as.numeric(as.character(stimuli$category))
)

gcm_preds <- get_gcm_predictions(
  w = c(0.5, 0.5),
  c = 1.0,
  training_obs = as.matrix(stimuli[, c("height", "position")]),
  training_cat = as.numeric(as.character(stimuli$category))
)

# Create visualization data
decision_data <- grid_points %>%
  mutate(
    prototype_prob = prototype_preds,
    gcm_prob = gcm_preds,
    prototype_decision = prototype_prob > 0.5,
    gcm_decision = gcm_prob > 0.5
  )

# Visualize decision boundaries
p1 <- ggplot() +
  # Background colors for decision regions
  geom_tile(data = decision_data, 
            aes(position, height, fill = prototype_decision), 
            alpha = 0.3) +
  
  # Decision boundary contour
  stat_contour(data = decision_data, 
               aes(position, height, z = prototype_prob),
               breaks = 0.5, color = "black", size = 1) +
  
  # Actual stimuli
  geom_point(data = stimuli, 
             aes(position, height, color = category),
             size = 3) +
  
  # Labels and theme
  scale_fill_manual(values = c("FALSE" = "tomato", "TRUE" = "skyblue")) +
  labs(
    title = "Prototype Model Decision Boundary",
    x = "Position",
    y = "Height",
    fill = "Category 1",
    color = "True Category"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

p2 <- ggplot() +
  # Background colors for decision regions
  geom_tile(data = decision_data, 
            aes(position, height, fill = gcm_decision), 
            alpha = 0.3) +
  
  # Decision boundary contour
  stat_contour(data = decision_data, 
               aes(position, height, z = gcm_prob),
               breaks = 0.5, color = "black", size = 1) +
  
  # Actual stimuli
  geom_point(data = stimuli, 
             aes(position, height, color = category),
             size = 3) +
  
  # Labels and theme
  scale_fill_manual(values = c("FALSE" = "tomato", "TRUE" = "skyblue")) +
  labs(
    title = "Exemplar Model (GCM) Decision Boundary",
    x = "Position",
    y = "Height",
    fill = "Category 1",
    color = "True Category"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Compare the two models side by side
p1 + p2
```

While the example is not really fit for this comparison (sorry, I didn't think of it earlier on!), the visualization highlights a key difference between prototype and exemplar models: the shape of their decision boundaries. The prototype model tends to create smoother, more regular boundaries based on distance from centroids. The exemplar model can create more complex boundaries that conform to the specific distribution of training examples.

## Implementing the Prototype Model in Stan

To estimate the parameters of our prototype model from observed categorization data, we'll implement it in Stan:

```{r, 12 stan prototype model}
prototype_single_stan <- "
// Prototype Model using Kalman Filter
// This model implements a dynamic prototype-based categorization approach
// where category representations are updated sequentially as new examples are observed

data {
  int<lower=1> ntrials;                // Number of trials
  int<lower=1> nfeatures;              // Number of feature dimensions
  array[ntrials] int<lower=0, upper=1> cat_one;  // True category labels
  array[ntrials] int<lower=0, upper=1> y;        // Observed decisions
  array[ntrials, nfeatures] real obs;  // Stimulus features
  real<lower=0, upper=1> b;            // Response bias (usually 0.5 for no bias)
}

parameters {
  // We model observation noise on log scale for better sampling
  real log_r;                          // Log observation noise parameter
}

transformed parameters {
  // Transform log_r back to natural scale with reasonable bounds
  real<lower=0.01, upper=10.0> r_value = exp(log_r);
  
  // Response probabilities for each trial
  array[ntrials] real<lower=0.001, upper=0.999> p;
  
  // Initialize prototype means for each category
  // We use the first observation of each category if available,
  // otherwise start with the midpoint of the feature space
  vector[nfeatures] mu_cat0;
  vector[nfeatures] mu_cat1;
  
  // Initialize uncertainty matrices (covariance) for each prototype
  // High initial values reflect uncertainty before seeing examples
  matrix[nfeatures, nfeatures] sigma_cat0;
  matrix[nfeatures, nfeatures] sigma_cat1;
  
  // Set initial values based on first observations
  {
    // Find first examples of each category
    int first_cat0 = 0;
    int first_cat1 = 0;
    
    for (i in 1:ntrials) {
      if (cat_one[i] == 0 && first_cat0 == 0) first_cat0 = i;
      if (cat_one[i] == 1 && first_cat1 == 0) first_cat1 = i;
      if (first_cat0 > 0 && first_cat1 > 0) break;
    }
    
    // Initialize means - if no examples of a category, use middle values
    if (first_cat0 > 0) {
      for (j in 1:nfeatures) mu_cat0[j] = obs[first_cat0, j];
    } else {
      mu_cat0 = rep_vector(2.5, nfeatures); // Middle of typical feature range
    }
    
    if (first_cat1 > 0) {
      for (j in 1:nfeatures) mu_cat1[j] = obs[first_cat1, j];
    } else {
      mu_cat1 = rep_vector(2.5, nfeatures); // Middle of typical feature range
    }
    
    // Initialize uncertainty matrices
    sigma_cat0 = diag_matrix(rep_vector(5.0, nfeatures));
    sigma_cat1 = diag_matrix(rep_vector(5.0, nfeatures));
  }
  
  // Observation noise matrix - constant for all observations
  matrix[nfeatures, nfeatures] r_matrix = diag_matrix(rep_vector(r_value, nfeatures));
  
  // Process trials sequentially to simulate the learning process
  for (i in 1:ntrials) {
    // Extract current observation
    vector[nfeatures] current_obs = to_vector(obs[i]);
    
    // Calculate response probability based on current prototypes
    if (i == 1 || sum(cat_one[1:(i-1)]) == 0 || sum(cat_one[1:(i-1)]) == (i-1)) {
      // No examples of one category, use response bias
      p[i] = b;
    } else {
      // Calculate distances to prototypes using Mahalanobis distance
      // Add observation noise to account for perceptual/memory variance
      matrix[nfeatures, nfeatures] cov_cat0 = sigma_cat0 + r_matrix;
      matrix[nfeatures, nfeatures] cov_cat1 = sigma_cat1 + r_matrix;
      
      // Compute precision matrices for efficiency and stability
      matrix[nfeatures, nfeatures] prec_cat0 = inverse_spd(cov_cat0);
      matrix[nfeatures, nfeatures] prec_cat1 = inverse_spd(cov_cat1);
      
      // Mahalanobis distance calculation - quadratic form
      vector[nfeatures] diff0 = current_obs - mu_cat0;
      vector[nfeatures] diff1 = current_obs - mu_cat1;
      
      real dist_cat0 = dot_product(diff0, prec_cat0 * diff0);
      real dist_cat1 = dot_product(diff1, prec_cat1 * diff1);
      
      // Log determinants for normalization term in multivariate normal
      real logdet_cat0 = log_determinant(cov_cat0);
      real logdet_cat1 = log_determinant(cov_cat1);
      
      // Calculate log probabilities with complete multivariate normal formula
      real log_p0 = -0.5 * (dist_cat0 + logdet_cat0 + nfeatures * log(2 * pi())) + log(1-b);
      real log_p1 = -0.5 * (dist_cat1 + logdet_cat1 + nfeatures * log(2 * pi())) + log(b);
      
      // Convert to probability using log-sum-exp for numerical stability
      p[i] = exp(log_p1 - log_sum_exp(log_p0, log_p1));
      
      // Bound probabilities for numerical stability
      p[i] = fmax(fmin(p[i], 0.999), 0.001);
    }
    
    // After making a prediction, update the prototype of the correct category
    // This simulates learning from feedback (except on the last trial)
    if (i < ntrials) {
      // Select which prototype to update based on true category
      if (cat_one[i] == 1) {
        // Update category 1 prototype using Kalman filter equations
        
        // Innovation: difference between observation and current mean
        vector[nfeatures] innovation = current_obs - mu_cat1;
        
        // Combined uncertainty (prior uncertainty + observation noise)
        matrix[nfeatures, nfeatures] S = sigma_cat1 + r_matrix;
        
        // Kalman gain calculation
        matrix[nfeatures, nfeatures] K = sigma_cat1 * inverse_spd(S);
        
        // Update mean (prototype location)
        mu_cat1 = mu_cat1 + K * innovation;
        
        // Update covariance (uncertainty)
        // Joseph form ensures numerical stability and symmetry
        matrix[nfeatures, nfeatures] I = diag_matrix(rep_vector(1.0, nfeatures));
        sigma_cat1 = (I - K) * sigma_cat1 * (I - K)' + K * r_matrix * K';
      } else {
        // Update category 0 prototype - same procedure
        vector[nfeatures] innovation = current_obs - mu_cat0;
        matrix[nfeatures, nfeatures] S = sigma_cat0 + r_matrix;
        matrix[nfeatures, nfeatures] K = sigma_cat0 * inverse_spd(S);
        mu_cat0 = mu_cat0 + K * innovation;
        matrix[nfeatures, nfeatures] I = diag_matrix(rep_vector(1.0, nfeatures));
        sigma_cat0 = (I - K) * sigma_cat0 * (I - K)' + K * r_matrix * K';
      }
    }
  }
}

model {
  // Prior for log observation noise
  // Normal prior centered at 0 (r_value = 1) with reasonable spread
  target += normal_lpdf(log_r | 0, 1);  
  
  // Likelihood: model choices as a function of calculated probabilities
  target += bernoulli_lpmf(y | p);
}

generated quantities {
  // Log likelihood for model comparison
  array[ntrials] real log_lik;
  for (i in 1:ntrials) {
    log_lik[i] = bernoulli_lpmf(y[i] | p[i]);
  }
  
  // Final prototype locations for interpretation
  array[nfeatures] real final_prototype_cat0 = to_array_1d(mu_cat0);
  array[nfeatures] real final_prototype_cat1 = to_array_1d(mu_cat1);
  
  // Final uncertainty (diagonal elements of covariance matrix)
  array[nfeatures] real final_uncertainty_cat0;
  array[nfeatures] real final_uncertainty_cat1;
  for (j in 1:nfeatures) {
    final_uncertainty_cat0[j] = sqrt(sigma_cat0[j,j]);
    final_uncertainty_cat1[j] = sqrt(sigma_cat1[j,j]);
  }
  
  // Generate predictions for posterior predictive checks
  array[ntrials] int pred;
  for (i in 1:ntrials) {
    pred[i] = bernoulli_rng(p[i]);
  }
  
  // Observation noise on original scale for interpretation
  real observation_noise = r_value;
}"

# Write the model to a file
write_stan_file(
  prototype_single_stan,
  dir = "stan/",
  basename = "W12_prototype_single.stan"
)

prototype_single_stan <- cmdstan_model(
    file.path("stan/W12_prototype_single.stan"),
    cpp_options = list(stan_threads = TRUE)
  )
```

This Stan implementation:

1. Takes observed categorization decisions and stimuli as input
2. Estimates the observation noise parameter from the data
3. Implements the same Kalman filter prototype updating as our R model
4. Calculates response probabilities based on similarity to prototypes
5. Returns final prototype locations and predictions

We can fit this model to behavioral data and compare it to the GCM to see which better describes human categorization behavior.


## Parameter Recovery Analysis for the Prototype Model

To validate our prototype model implementation, we should perform parameter recovery analysis. This involves:

1. Generating synthetic data with known parameter values
2. Fitting the model to recover these parameters
3. Comparing recovered parameters to the true generating values

Here, we'll focus on recovering the observation noise parameter (r_value), which is the key parameter in our Kalman filter prototype model:

```{r, 12 prototype parameter recovery}

# Function to simulate data with known r_value
generate_prototype_data <- function(true_r_value, n_trials = 300) {
  # Generate new stimuli features and categories
  features <- matrix(0, nrow = n_trials, ncol = 2)
category <- rep(0:1, each = n_trials/2)
# Generate data around two centroids
for (i in 1:n_trials) {
  if (category[i] == 0) {
    features[i,] <- c(-1.5, -1.5) + rnorm(2, 0, 0.8)
  } else {
    features[i,] <- c(1.5, 1.5) + rnorm(2, 0, 0.8)
  }
}
  
  # Generate responses using the prototype model with known r_value
  responses <- prototype_kalman(true_r_value, features, category)
  
  return(list(
    responses = responses,
    true_r_value = true_r_value,
    obs = features,
    cat_one = category
  ))
}

# Better function to prepare data for Stan
prepare_prototype_stan_data <- function(data) {
  list(
    ntrials = length(data$responses),
    nfeatures = ncol(data$obs),
    cat_one = data$cat_one,
    y = data$responses,
    obs = data$obs,
    b = 0.5  # Assuming no response bias
  )
}


if (regenerate_simulations) {

# Generate synthetic data across a range of r_values
r_values_to_test <- c(0.1, 0.5, 1.0, 2.0, 3.0, 4.0, 5.0)
recovery_results <- tibble(
  true_r_value = numeric(),
  estimated_r_value = numeric(),
  est_lower = numeric(),
  est_upper = numeric()
)

# For each true r_value, generate data and fit the model
for (r_val in r_values_to_test) {
  # Generate synthetic data
  synth_data <- generate_prototype_data(r_val)
  
  # Prepare for Stan
  stan_data <- prepare_prototype_stan_data(synth_data)
  
  # Fit model (assuming the Stan model is already compiled)
  fit <- prototype_single_stan$sample(
    data = stan_data,
    seed = 123,
    chains = 2,
    parallel_chains = 2,
    threads_per_chain = 1,
    iter_warmup = 1000,
    iter_sampling = 1000,
    refresh = 0
  )
  
  # Extract posterior for r_value
  draws <- as_draws_df(fit$draws("r_value"))
  estimate <- mean(draws$r_value)
  ci <- quantile(draws$r_value, c(0.025, 0.975))
  
  # Store results
  recovery_results <- recovery_results %>% add_row(
    true_r_value = r_val,
    estimated_r_value = estimate,
    est_lower = ci[1],
    est_upper = ci[2]
  )
}

  # Save model fits
  write_csv(recovery_results, "simdata/W12_prototype_recovery.csv")
  
  cat("Models fitted and saved.\n")
} else {
  # Load existing model fits
  recovery_results <- read_csv("simdata/W12_prototype_recovery.csv")
  
  cat("Loaded existing model fits.\n")
}


# Visualize parameter recovery
ggplot(recovery_results, aes(x = true_r_value, y = estimated_r_value)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = est_lower, ymax = est_upper), width = 0.1) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  labs(
    title = "Parameter Recovery for Prototype Model",
    subtitle = "Error bars show 95% credible intervals",
    x = "True r-value",
    y = "Estimated r-value"
  ) +
  theme_minimal()
```

Good parameter recovery would show estimated values close to the true values (points near the diagonal line) with reasonable uncertainty (error bars that include the true value). Poor recovery would indicate potential issues with the model's identifiability or implementation.

This parameter recovery clearly sucks :-) Such is the life of the modeler, sometimes your generative model (the simulation) makes perfect sense, but the inference just doesn't work out. I'll try different formalizations of the prototype model in the next year(s).

## Cognitive Insights from the Prototype Model

### 1. Incremental Learning

The Kalman filter model captures the dynamic, incremental nature of human learning (n.b. not all prototype models do that, some compute a static average based on some training data and never update it). People don't wait to see all examples before forming a category representation—they update their understanding with each new example.

### 2. Uncertainty-Driven Learning

The Kalman gain modulates learning based on uncertainty, mirroring how humans learn faster when their knowledge is uncertain and more slowly as they become confident. This creates a natural "fast-then-slow" learning curve similar to what we observe in human behavior.

### 3. Selective Attention Emerges Naturally

Though we didn't implement it explicitly, the Kalman filter can naturally develop different levels of certainty along different feature dimensions (as the uncertainty can vary between dimensions). This creates an emergent form of selective attention without requiring explicit attention parameters like in the GCM. These uncertainty estimates can be extracted and used to better understand the data on which the model is fitted.

### 4. Memory Efficiency

Prototype models provide a computationally efficient account of categorization, storing only summary statistics rather than individual exemplars. This aligns with the fact that humans can effectively categorize even when their memory for specific examples is poor.

## Contrasting with Exemplar Models

1. **Memory Requirements**: The prototype model stores only means and covariance matrices—a fixed memory footprint regardless of category size. The exemplar model's memory requirements grow linearly with the number of examples.

2. **Abstraction**: The prototype model abstracts away individual examples, focusing on the central tendency. The exemplar model preserves the details of each individual example.

3. **Decision Boundaries**: Prototype models typically produce smoother, more regular decision boundaries based on distance from category centers. Exemplar models can produce more complex boundaries shaped by the specific distribution of examples.

4. **Behavioral Predictions**:
   - Prototype models predict that the most typical (central) members will be categorized most easily (e.g. more accurately, but perhaps also faster)
   - Exemplar models predict advantages for distinctive or isolated exemplars
   - Prototype models predict poorer memory for specific examples if we encounter them again

5. **Forgetting**: The prototype model naturally accommodates forgetting of specific examples, while the exemplar model would need an explicit forgetting mechanism.

## Strengths of the Prototype Approach

The prototype approach has several strengths as a model of human categorization:

1. **Cognitive Efficiency**: Prototypes provide an efficient summary of category information, requiring minimal memory resources.

2. **Handling Noise**: By averaging across examples, prototype models naturally handle noisy or variable data.

3. **Graceful Degradation**: Prototype representations remain robust even when specific exemplars are forgotten.

4. **Explanation of Typicality Effects**: Prototype models naturally explain why typical category members are processed more fluently.

5. **Good Fit for Natural Categories**: Many natural categories have a graded, prototype structure (e.g., birds, furniture) that prototype models capture well.

## Limitations of the Prototype Approach

Despite its strengths, the prototype approach also has important limitations:

1. **Difficulty with Complex Categories**: Prototype models struggle with categories that have complex internal structure, such as those defined by rules or relations.

2. **Limited Use of Distributional Information**: By focusing on central tendency, traditional prototype models ignore useful information about the distribution of features.

3. **Insensitivity to Specific Examples**: Prototype models can't easily account for cases where specific examples strongly influence categorization decisions.

4. **Challenge of Disjunctive Categories**: Categories with multiple distinct clusters (e.g., the category of "games") are difficult for single-prototype models to handle.

## Extensions to the Basic Model

Several extensions can address some of these limitations:

1. **Multiple Prototypes per Category**: Allow categories to be represented by multiple prototypes, better handling disjunctive categories (e.g. via k-means).

2. **Feature Correlations**: Explicitly model correlations between features in the prototype representation.

3. **Hierarchical Structure**: Implement hierarchical prototype models to capture taxonomic category structures.

4. **Mixture of Prototypes and Exemplars**: Combine elements of both approaches, using prototypes for more similar exemplars and remember the exemplars that are further from the prototype.

## Conclusion: The Prototype and Exemplar Debate

The debate between prototype and exemplar theories of categorization has been one of the most productive in cognitive psychology, leading to refined theories and empirical tests that have deepened our understanding of human categorization.

Current evidence suggests that neither approach alone fully accounts for human categorization behavior:

1. Humans show prototype effects, categorizing items more quickly and accurately when they're close to the category center.

2. Humans also show exemplar effects, being influenced by specific, distinctive examples and showing correlations between recognition and categorization performance.

3. Many researchers now favor hybrid or multiple-system accounts, where prototype-based and exemplar-based processes coexist and potentially interact.

The Kalman filter implementation of prototype learning provides a dynamic, uncertainty-sensitive approach that addresses some criticisms of traditional prototype models while maintaining their cognitive efficiency. By integrating ideas from Bayesian learning theory with classic prototype models, this approach offers a sophisticated account of category learning that can be directly compared with exemplar models like the GCM.

### The Prototype-Exemplar Spectrum and Multiple-Prototype Models

It's important to recognize that prototype and exemplar models are not strictly distinct approaches, but rather represent two ends of a theoretical spectrum. The core difference lies in the granularity of representation: exemplar models store all individual instances, while traditional prototype models store a single central tendency. However, we can imagine a continuum of intermediate approaches:

* Pure exemplar models: Store all instances with no abstraction

* Clustered exemplar models: Store instances but group similar ones

* Multiple-prototype models: Store several prototypes per category

* Single-prototype models: Store one prototype per category

Multiple-prototype models offer an appealing middle ground that maintains much of the computational efficiency of prototype models while capturing more complex category structures. There are several ways to extend our Kalman filter approach to implement multiple centroids per category:

* K-means clustering: First cluster the exemplars of each category into k subclusters, then apply the Kalman filter separately to each cluster

* Mixture of Gaussians: Represent each category as a mixture of Gaussian distributions, with each component tracking a different subcategory prototype

* Adaptive resonance theory: Dynamically create new prototypes when an observation is too dissimilar from existing prototypes

* Splitting criteria: Monitor the variance of exemplars around each prototype and split the prototype when variance exceeds a threshold

In the next section, we'll explore the third major approach to categorization: rule-based models, which represent a fundamentally different perspective on how humans organize the world into categories.
