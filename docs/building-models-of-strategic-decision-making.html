<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Building Models of Strategic Decision-Making | Advanced Cognitive Modeling Notes</title>
  <meta name="description" content="My notes for the advanced cognitive modeling course - 2026" />
  <meta name="generator" content="bookdown 0.46 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Building Models of Strategic Decision-Making | Advanced Cognitive Modeling Notes" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="My notes for the advanced cognitive modeling course - 2026" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Building Models of Strategic Decision-Making | Advanced Cognitive Modeling Notes" />
  
  <meta name="twitter:description" content="My notes for the advanced cognitive modeling course - 2026" />
  

<meta name="author" content="Riccardo Fusaroli" />


<meta name="date" content="2026-02-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="the-pizza-experiment.html"/>
<link rel="next" href="from-verbal-descriptions-to-formal-models.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="lib/css/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="lib/css/style.css" type="text/css" />
<link rel="stylesheet" href="lib/css/lesson.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Cognitive Modeling</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Advanced Cognitive Modeling</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#course-philosophy-and-approach"><i class="fa fa-check"></i><b>1.1</b> Course Philosophy and Approach</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#course-structure-and-learning-path"><i class="fa fa-check"></i><b>1.2</b> Course Structure and Learning Path</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#prerequisites-and-preparation"><i class="fa fa-check"></i><b>1.3</b> Prerequisites and Preparation</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#course-resources"><i class="fa fa-check"></i><b>1.4</b> Course Resources</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#about-these-notes"><i class="fa fa-check"></i><b>1.5</b> About These Notes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html"><i class="fa fa-check"></i><b>2</b> The Pizza Experiment</a>
<ul>
<li class="chapter" data-level="2.1" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#from-pizza-to-cognitive-models-an-introduction"><i class="fa fa-check"></i><b>2.1</b> From Pizza to Cognitive Models: An Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#why-start-with-pizza"><i class="fa fa-check"></i><b>2.2</b> Why Start with Pizza?</a></li>
<li class="chapter" data-level="2.3" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#learning-objectives"><i class="fa fa-check"></i><b>2.3</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.4" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#part-1-exploring-the-pizza-stone-temperature-data"><i class="fa fa-check"></i><b>2.4</b> Part 1: Exploring the Pizza Stone Temperature Data</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#initial-data-visualization"><i class="fa fa-check"></i><b>2.4.1</b> Initial Data Visualization</a></li>
<li class="chapter" data-level="2.4.2" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#key-observations"><i class="fa fa-check"></i><b>2.4.2</b> Key Observations</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#part-2-initial-statistical-modeling"><i class="fa fa-check"></i><b>2.5</b> Part 2: Initial Statistical Modeling</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#model-setup-and-priors"><i class="fa fa-check"></i><b>2.5.1</b> Model Setup and Priors</a></li>
<li class="chapter" data-level="2.5.2" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#linear-mixed-effects-model"><i class="fa fa-check"></i><b>2.5.2</b> Linear Mixed-Effects Model</a></li>
<li class="chapter" data-level="2.5.3" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#lognormal-mixed-effects-model"><i class="fa fa-check"></i><b>2.5.3</b> Lognormal Mixed-Effects Model</a></li>
<li class="chapter" data-level="2.5.4" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#model-comparison-and-visualization"><i class="fa fa-check"></i><b>2.5.4</b> Model Comparison and Visualization</a></li>
<li class="chapter" data-level="2.5.5" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#model-assessment"><i class="fa fa-check"></i><b>2.5.5</b> Model Assessment</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#part-3-understanding-the-physics-model"><i class="fa fa-check"></i><b>2.6</b> Part 3: Understanding the Physics Model</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#the-basic-temperature-evolution-equation"><i class="fa fa-check"></i><b>2.6.1</b> The Basic Temperature Evolution Equation</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#part-4-implementing-the-physics-based-model"><i class="fa fa-check"></i><b>2.7</b> Part 4: Implementing the Physics-Based Model</a></li>
<li class="chapter" data-level="2.8" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#part-5-model-analysis-and-practical-applications"><i class="fa fa-check"></i><b>2.8</b> Part 5: Model Analysis and Practical Applications</a></li>
<li class="chapter" data-level="2.9" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#conclusion-from-pizza-to-cognitive-principles"><i class="fa fa-check"></i><b>2.9</b> Conclusion: From Pizza to Cognitive Principles</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html"><i class="fa fa-check"></i><b>3</b> Building Models of Strategic Decision-Making</a>
<ul>
<li class="chapter" data-level="3.1" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#learning-goals"><i class="fa fa-check"></i><b>3.1</b> Learning Goals</a></li>
<li class="chapter" data-level="3.2" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#introduction-observing-behavior-to-theorize-mechanisms"><i class="fa fa-check"></i><b>3.2</b> Introduction: Observing Behavior to Theorize Mechanisms</a></li>
<li class="chapter" data-level="3.3" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#the-matching-pennies-game"><i class="fa fa-check"></i><b>3.3</b> The Matching Pennies Game</a></li>
<li class="chapter" data-level="3.4" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#game-structure"><i class="fa fa-check"></i><b>3.4</b> Game Structure</a></li>
<li class="chapter" data-level="3.5" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#empirical-investigation"><i class="fa fa-check"></i><b>3.5</b> Empirical Investigation</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#data-collection-protocol"><i class="fa fa-check"></i><b>3.5.1</b> Data Collection Protocol</a></li>
<li class="chapter" data-level="3.5.2" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#initial-observations"><i class="fa fa-check"></i><b>3.5.2</b> Initial Observations</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#empirical-explorations"><i class="fa fa-check"></i><b>3.6</b> Empirical explorations</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#from-observation-to-theory-identifying-potential-mechanisms"><i class="fa fa-check"></i><b>3.6.1</b> From Observation to Theory: Identifying Potential Mechanisms</a></li>
<li class="chapter" data-level="3.6.2" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#the-distinction-between-participant-and-researcher-perspectives"><i class="fa fa-check"></i><b>3.6.2</b> The distinction between participant and researcher perspectives</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#candidate-models-a-hierarchy-of-cognitive-complexity"><i class="fa fa-check"></i><b>3.7</b> Candidate Models: A Hierarchy of Cognitive Complexity</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-0-the-static-agent-no-learning"><i class="fa fa-check"></i><b>3.7.1</b> Level 0: The Static Agent (No Learning)</a></li>
<li class="chapter" data-level="3.7.2" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#the-biased-agent-random-choice"><i class="fa fa-check"></i><b>3.7.2</b> The Biased Agent (Random Choice):</a></li>
<li class="chapter" data-level="3.7.3" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-1-heuristics-the-immediate-past"><i class="fa fa-check"></i><b>3.7.3</b> Level 1: Heuristics &amp; The Immediate Past</a></li>
<li class="chapter" data-level="3.7.4" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-2-integrating-history-the-moving-average"><i class="fa fa-check"></i><b>3.7.4</b> Level 2: Integrating History (The Moving Average)</a></li>
<li class="chapter" data-level="3.7.5" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-3-reinforcement-learning-elegant-decay"><i class="fa fa-check"></i><b>3.7.5</b> Level 3: Reinforcement Learning (Elegant Decay)</a></li>
<li class="chapter" data-level="3.7.6" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-4-the-bayesian-update-static-uncertainty"><i class="fa fa-check"></i><b>3.7.6</b> Level 4: The Bayesian Update (Static Uncertainty)</a></li>
<li class="chapter" data-level="3.7.7" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-5-the-kalman-filter-dynamic-uncertainty"><i class="fa fa-check"></i><b>3.7.7</b> Level 5: The Kalman Filter (Dynamic Uncertainty)</a></li>
<li class="chapter" data-level="3.7.8" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-6-the-hierarchical-gaussian-filter-meta-learning"><i class="fa fa-check"></i><b>3.7.8</b> Level 6: The Hierarchical Gaussian Filter (Meta-Learning)</a></li>
<li class="chapter" data-level="3.7.9" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-7-recursive-strategies-theory-of-mind"><i class="fa fa-check"></i><b>3.7.9</b> Level 7: Recursive Strategies (Theory of Mind)</a></li>
<li class="chapter" data-level="3.7.10" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#handling-heterogeneity-mixture-models"><i class="fa fa-check"></i><b>3.7.10</b> Handling Heterogeneity: Mixture Models</a></li>
<li class="chapter" data-level="3.7.11" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#plausibility-check-cognitive-constraints"><i class="fa fa-check"></i><b>3.7.11</b> Plausibility Check: Cognitive Constraints</a></li>
<li class="chapter" data-level="3.7.12" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#relationships-between-models"><i class="fa fa-check"></i><b>3.7.12</b> Relationships Between Models</a></li>
<li class="chapter" data-level="3.7.13" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#handling-heterogeneity-mixture-models-1"><i class="fa fa-check"></i><b>3.7.13</b> Handling Heterogeneity: Mixture Models</a></li>
<li class="chapter" data-level="3.7.14" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#cognitive-modeling-vs.-traditional-statistical-approaches-e.g.-glm"><i class="fa fa-check"></i><b>3.7.14</b> Cognitive Modeling vs. Traditional Statistical Approaches (e.g., GLM)</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#conclusion-from-observations-to-verbal-theories"><i class="fa fa-check"></i><b>3.8</b> Conclusion: From Observations to Verbal Theories</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html"><i class="fa fa-check"></i><b>4</b> From verbal descriptions to formal models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#learning-goals-1"><i class="fa fa-check"></i><b>4.1</b> Learning Goals</a></li>
<li class="chapter" data-level="4.2" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#the-value-of-formalization-and-simulation"><i class="fa fa-check"></i><b>4.2</b> The Value of Formalization and Simulation</a></li>
<li class="chapter" data-level="4.3" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#defining-general-conditions"><i class="fa fa-check"></i><b>4.3</b> Defining general conditions</a></li>
<li class="chapter" data-level="4.4" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#implementing-a-random-agent"><i class="fa fa-check"></i><b>4.4</b> Implementing a Random Agent</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#encapsulating-the-agent-in-a-function"><i class="fa fa-check"></i><b>4.4.1</b> Encapsulating the Agent in a Function</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#implementing-a-win-stay-lose-shift-wsls-agent"><i class="fa fa-check"></i><b>4.5</b> Implementing a Win-Stay-Lose-Shift (WSLS) Agent</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#implementing-the-wsls-function"><i class="fa fa-check"></i><b>4.5.1</b> Implementing the WSLS Function</a></li>
<li class="chapter" data-level="4.5.2" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#simulating-wsls-vs.-opponents"><i class="fa fa-check"></i><b>4.5.2</b> Simulating WSLS vs. Opponents</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#scaling-up-the-virtual-experiment"><i class="fa fa-check"></i><b>4.6</b> Scaling Up: The Virtual Experiment</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#visualizing-results"><i class="fa fa-check"></i><b>4.6.1</b> Visualizing Results</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#conclusion-the-forward-model"><i class="fa fa-check"></i><b>4.7</b> Conclusion: The Forward Model</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#the-problem-of-inference"><i class="fa fa-check"></i><b>4.7.1</b> The Problem of Inference</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html"><i class="fa fa-check"></i><b>5</b> From simulation to model fitting</a>
<ul>
<li class="chapter" data-level="5.1" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#learning-goals-2"><i class="fa fa-check"></i><b>5.1</b> Learning Goals</a></li>
<li class="chapter" data-level="5.2" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#the-challenge-inferring-latent-parameters"><i class="fa fa-check"></i><b>5.2</b> The Challenge: Inferring Latent Parameters</a></li>
<li class="chapter" data-level="5.3" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#simulating-data"><i class="fa fa-check"></i><b>5.3</b> Simulating data</a></li>
<li class="chapter" data-level="5.4" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#building-our-first-stan-model-inferring-bias-rate"><i class="fa fa-check"></i><b>5.4</b> Building our First Stan Model: Inferring Bias Rate</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#model"><i class="fa fa-check"></i><b>5.4.1</b> Model</a></li>
<li class="chapter" data-level="5.4.2" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#assessing-model-quality"><i class="fa fa-check"></i><b>5.4.2</b> Assessing model quality</a></li>
<li class="chapter" data-level="5.4.3" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#summarizing-the-results"><i class="fa fa-check"></i><b>5.4.3</b> Summarizing the results</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#validating-the-model-parameter-recovery"><i class="fa fa-check"></i><b>5.5</b> Validating the Model: Parameter Recovery</a></li>
<li class="chapter" data-level="5.6" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#moving-beyond-simple-bias-memory-models"><i class="fa fa-check"></i><b>5.6</b> Moving Beyond Simple Bias: Memory Models</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#memory-model-1-glm-like-approach-external-predictor"><i class="fa fa-check"></i><b>5.6.1</b> Memory Model 1: GLM-like Approach (External Predictor)</a></li>
<li class="chapter" data-level="5.6.2" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#summarizing-the-results-1"><i class="fa fa-check"></i><b>5.6.2</b> Summarizing the results</a></li>
<li class="chapter" data-level="5.6.3" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#memory-model-2-internal-state-variable"><i class="fa fa-check"></i><b>5.6.3</b> Memory Model 2: Internal State Variable</a></li>
<li class="chapter" data-level="5.6.4" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#memory-model-3-exponential-forgetting-relation-to-rl"><i class="fa fa-check"></i><b>5.6.4</b> Memory Model 3: Exponential Forgetting (Relation to RL)</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#memory-model-4-bayesian-agent-optimal-updating"><i class="fa fa-check"></i><b>5.7</b> Memory Model 4: Bayesian Agent (Optimal Updating)</a></li>
<li class="chapter" data-level="5.8" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#relationship-to-rescorla-wagner"><i class="fa fa-check"></i><b>5.8</b> Relationship to Rescorla-Wagner</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#connection-to-kalman-filters"><i class="fa fa-check"></i><b>5.8.1</b> Connection to Kalman Filters</a></li>
<li class="chapter" data-level="5.8.2" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#connection-to-hierarchical-gaussian-filter-hgf"><i class="fa fa-check"></i><b>5.8.2</b> Connection to Hierarchical Gaussian Filter (HGF)</a></li>
<li class="chapter" data-level="5.8.3" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#implications-for-model-development"><i class="fa fa-check"></i><b>5.8.3</b> Implications for Model Development</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#conclusion-estimating-parameters-and-exploring-memory"><i class="fa fa-check"></i><b>5.9</b> Conclusion: Estimating Parameters and Exploring Memory</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Cognitive Modeling Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="building-models-of-strategic-decision-making" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Building Models of Strategic Decision-Making<a href="building-models-of-strategic-decision-making.html#building-models-of-strategic-decision-making" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>You’ve just played Matching Pennies and discussed strategies with your classmates. You probably noticed patterns in your opponent’s play, tried to be unpredictable, and maybe even changed your strategy mid-game. This chapter helps you translate those observations and intuitions into the language of cognitive modeling—preparing you to implement formal models in Chapter 3.</p>
<div id="learning-goals" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Learning Goals<a href="building-models-of-strategic-decision-making.html#learning-goals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This chapter bridges the gap between observing behavior and developing testable theories. By the end of this chapter, using the Matching Pennies game as a case study, you will be able to:</p>
<ul>
<li><strong>Identify Key Modeling Steps:</strong> Understand the process of moving from behavioral observations and participant reflections to formulating initial verbal theories of underlying cognitive strategies.</li>
<li><strong>Appreciate Theory Building Challenges:</strong> Recognize common issues in theory development, such as the participant vs. researcher perspective, the need for simplification, and incorporating known cognitive constraints.</li>
<li><strong>Generate Candidate Models:</strong> Propose several distinct verbal models (e.g., random choice, simple heuristics, memory-based strategies) that could plausibly explain behavior in a strategic decision-making task.</li>
<li><strong>Connect to Formalization:</strong> Understand <em>why</em> translating these verbal models into precise, formal models (covered in the next chapter) is a necessary step for rigorous testing and simulation.</li>
</ul>
</div>
<div id="introduction-observing-behavior-to-theorize-mechanisms" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Introduction: Observing Behavior to Theorize Mechanisms<a href="building-models-of-strategic-decision-making.html#introduction-observing-behavior-to-theorize-mechanisms" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Chapter 1 emphasized the importance of modeling underlying generative mechanisms. To do this for cognition, we first need a behavior to explain. This chapter uses the <strong>Matching Pennies game</strong> as our initial cognitive phenomenon. It’s a simple strategic interaction, yet rich enough to illustrate the process of developing and refining cognitive models.</p>
<p>Our goal here is not yet to build the final computational models, but to practice the crucial preceding steps:
1. Observing behavior in a specific task (through experiments and data exploration).
2. Reflecting on potential cognitive strategies and constraints (drawing on observations, participant reports, and cognitive science principles).
3. Formulating initial <em>verbal</em> theories or candidate models that describe the potential underlying mechanisms.</p>
<p>This process lays the groundwork for Chapter 3, where we will translate these verbal ideas into precise, formal models ready for simulation and testing.</p>
</div>
<div id="the-matching-pennies-game" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> The Matching Pennies Game<a href="building-models-of-strategic-decision-making.html#the-matching-pennies-game" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the matching pennies game, two players engage in a series of choices. One player attempts to match the other’s choice, while the other player aims to achieve a mismatch, and they repeatedly play with each other. This is a prototypical example of interacting behaviors that are usually tackled by game theory, and bring up issues of theory of mind and recursivity.</p>
<p>For an introduction see the paper: Waade, Peter T., et al. “Introducing tomsup: Theory of mind simulations using Python.” Behavior Research Methods 55.5 (2023): 2197-2231.</p>
</div>
<div id="game-structure" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Game Structure<a href="building-models-of-strategic-decision-making.html#game-structure" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The game proceeds as follows:</p>
<ol style="list-style-type: decimal">
<li>Two players sit facing each other</li>
<li>Each round, both players choose either “left” or “right” to indicate where they believe a penny is hidden</li>
<li>The matcher wins by choosing the same hand as their opponent</li>
<li>The hider wins by choosing the opposite hand</li>
<li>Points are awarded: +1 for winning, -1 for losing</li>
<li>Repeat</li>
</ol>
<p>This simple structure creates a rich environment for studying decision-making strategies, learning, and adaptation.</p>
</div>
<div id="empirical-investigation" class="section level2 hasAnchor" number="3.5">
<h2><span class="header-section-number">3.5</span> Empirical Investigation<a href="building-models-of-strategic-decision-making.html#empirical-investigation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="data-collection-protocol" class="section level3 hasAnchor" number="3.5.1">
<h3><span class="header-section-number">3.5.1</span> Data Collection Protocol<a href="building-models-of-strategic-decision-making.html#data-collection-protocol" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If you are attending my class you have been (or will be) asked to participate in a matching pennies game. This game provides the foundation for our modeling efforts. By observing gameplay and collecting data, we can develop models that capture the cognitive processes underlying decision-making in strategic situations.</p>
<p>Participants play 30 rounds as the matcher and 30 rounds as the hider, allowing us to observe behavior in both roles. While playing, participants track their scores, which can provide quantitative data for later analysis. Participants are also asked to reflect on their strategies and the strategies they believe their opponents are using, as that provides valuable materials to build models on.</p>
</div>
<div id="initial-observations" class="section level3 hasAnchor" number="3.5.2">
<h3><span class="header-section-number">3.5.2</span> Initial Observations<a href="building-models-of-strategic-decision-making.html#initial-observations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Through the careful observation and discussion of gameplay we do in class, several patterns typically emerge. For instance, players often demonstrate strategic adaptation, adjusting their choices based on their opponent’s previous moves. They may attempt to identify patterns in their opponent’s behavior while trying to make their own choices less predictable. The tension between exploitation of perceived patterns and maintenance of unpredictability creates fascinating dynamics for modeling.</p>
</div>
</div>
<div id="empirical-explorations" class="section level2 hasAnchor" number="3.6">
<h2><span class="header-section-number">3.6</span> Empirical explorations<a href="building-models-of-strategic-decision-making.html#empirical-explorations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Below you can observe how a previous year of CogSci did against bots (computational agents) playing according to different strategies. Look at the plots below, where the x axes indicate trial, the y axes how many points the CogSci’ers scored (0 being chance, negative means being completely owned by the bots, positive owning the bot) and the different colors indicate different strategies employed by the bots. Strategy “-2” was a Win-Stay-Lose-Shift bot: when it got a +1, it repeated its previous move (e.g. right if it had just played right), otherwise it would perform the opposite move (e.g. left if it had just played right). Strategy “-1” was a biased Nash both, playing “right” 80% of the time. Strategy “0” indicates a reinforcement learning bot; “1” a bot assuming you were playing according to a reinforcement learning strategy and trying to infer your learning and temperature parameters; “2” a bot assuming you were following strategy “1” and trying to accordingly infer your parameters.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="building-models-of-strategic-decision-making.html#cb18-1" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb18-2"><a href="building-models-of-strategic-decision-making.html#cb18-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="building-models-of-strategic-decision-making.html#cb19-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb19-2"><a href="building-models-of-strategic-decision-making.html#cb19-2" tabindex="-1"></a></span>
<span id="cb19-3"><a href="building-models-of-strategic-decision-making.html#cb19-3" tabindex="-1"></a><span class="co"># --- 1. Data Loading / Generation ---</span></span>
<span id="cb19-4"><a href="building-models-of-strategic-decision-making.html#cb19-4" tabindex="-1"></a>data_path <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;MP_MSc_CogSci22.csv&quot;</span>)</span>
<span id="cb19-5"><a href="building-models-of-strategic-decision-making.html#cb19-5" tabindex="-1"></a></span>
<span id="cb19-6"><a href="building-models-of-strategic-decision-making.html#cb19-6" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">file.exists</span>(data_path)) {</span>
<span id="cb19-7"><a href="building-models-of-strategic-decision-making.html#cb19-7" tabindex="-1"></a>  d <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(data_path)</span>
<span id="cb19-8"><a href="building-models-of-strategic-decision-making.html#cb19-8" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb19-9"><a href="building-models-of-strategic-decision-making.html#cb19-9" tabindex="-1"></a>  <span class="co"># Generate synthetic data if file is missing (Reproducibility check)</span></span>
<span id="cb19-10"><a href="building-models-of-strategic-decision-making.html#cb19-10" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb19-11"><a href="building-models-of-strategic-decision-making.html#cb19-11" tabindex="-1"></a>  n_students <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb19-12"><a href="building-models-of-strategic-decision-making.html#cb19-12" tabindex="-1"></a>  n_trials <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb19-13"><a href="building-models-of-strategic-decision-making.html#cb19-13" tabindex="-1"></a>  strategies <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb19-14"><a href="building-models-of-strategic-decision-making.html#cb19-14" tabindex="-1"></a>  d <span class="ot">&lt;-</span> <span class="fu">expand_grid</span>(</span>
<span id="cb19-15"><a href="building-models-of-strategic-decision-making.html#cb19-15" tabindex="-1"></a>    <span class="at">ID =</span> <span class="fu">factor</span>(<span class="dv">1</span><span class="sc">:</span>n_students),</span>
<span id="cb19-16"><a href="building-models-of-strategic-decision-making.html#cb19-16" tabindex="-1"></a>    <span class="at">BotStrategy =</span> strategies,</span>
<span id="cb19-17"><a href="building-models-of-strategic-decision-making.html#cb19-17" tabindex="-1"></a>    <span class="at">Role =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="co"># 0=Matcher, 1=Hider</span></span>
<span id="cb19-18"><a href="building-models-of-strategic-decision-making.html#cb19-18" tabindex="-1"></a>    <span class="at">Trial =</span> <span class="dv">1</span><span class="sc">:</span>n_trials</span>
<span id="cb19-19"><a href="building-models-of-strategic-decision-making.html#cb19-19" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb19-20"><a href="building-models-of-strategic-decision-making.html#cb19-20" tabindex="-1"></a>    <span class="fu">mutate</span>(</span>
<span id="cb19-21"><a href="building-models-of-strategic-decision-making.html#cb19-21" tabindex="-1"></a>      <span class="co"># Random payoffs for demonstration</span></span>
<span id="cb19-22"><a href="building-models-of-strategic-decision-making.html#cb19-22" tabindex="-1"></a>      <span class="at">Payoff =</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="fu">n</span>(), <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.45</span>, <span class="fl">0.55</span>))</span>
<span id="cb19-23"><a href="building-models-of-strategic-decision-making.html#cb19-23" tabindex="-1"></a>    )</span>
<span id="cb19-24"><a href="building-models-of-strategic-decision-making.html#cb19-24" tabindex="-1"></a>  <span class="fu">warning</span>(<span class="st">&quot;Using synthetic data for demonstration.&quot;</span>)</span>
<span id="cb19-25"><a href="building-models-of-strategic-decision-making.html#cb19-25" tabindex="-1"></a>}</span>
<span id="cb19-26"><a href="building-models-of-strategic-decision-making.html#cb19-26" tabindex="-1"></a></span>
<span id="cb19-27"><a href="building-models-of-strategic-decision-making.html#cb19-27" tabindex="-1"></a><span class="co"># --- 2. Data Cleaning (Crucial Step!) ---</span></span>
<span id="cb19-28"><a href="building-models-of-strategic-decision-making.html#cb19-28" tabindex="-1"></a><span class="co"># Map cryptic codes to human-readable labels</span></span>
<span id="cb19-29"><a href="building-models-of-strategic-decision-making.html#cb19-29" tabindex="-1"></a>bot_labels <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb19-30"><a href="building-models-of-strategic-decision-making.html#cb19-30" tabindex="-1"></a>  <span class="st">&quot;-2&quot;</span> <span class="ot">=</span> <span class="st">&quot;WSLS Bot&quot;</span>,</span>
<span id="cb19-31"><a href="building-models-of-strategic-decision-making.html#cb19-31" tabindex="-1"></a>  <span class="st">&quot;-1&quot;</span> <span class="ot">=</span> <span class="st">&quot;Bias Bot (80%)&quot;</span>,</span>
<span id="cb19-32"><a href="building-models-of-strategic-decision-making.html#cb19-32" tabindex="-1"></a>  <span class="st">&quot;0&quot;</span>  <span class="ot">=</span> <span class="st">&quot;RL Bot&quot;</span>,</span>
<span id="cb19-33"><a href="building-models-of-strategic-decision-making.html#cb19-33" tabindex="-1"></a>  <span class="st">&quot;1&quot;</span>  <span class="ot">=</span> <span class="st">&quot;ToM-1 Bot&quot;</span>,</span>
<span id="cb19-34"><a href="building-models-of-strategic-decision-making.html#cb19-34" tabindex="-1"></a>  <span class="st">&quot;2&quot;</span>  <span class="ot">=</span> <span class="st">&quot;ToM-2 Bot&quot;</span></span>
<span id="cb19-35"><a href="building-models-of-strategic-decision-making.html#cb19-35" tabindex="-1"></a>)</span>
<span id="cb19-36"><a href="building-models-of-strategic-decision-making.html#cb19-36" tabindex="-1"></a></span>
<span id="cb19-37"><a href="building-models-of-strategic-decision-making.html#cb19-37" tabindex="-1"></a>d_clean <span class="ot">&lt;-</span> d <span class="sc">%&gt;%</span></span>
<span id="cb19-38"><a href="building-models-of-strategic-decision-making.html#cb19-38" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb19-39"><a href="building-models-of-strategic-decision-making.html#cb19-39" tabindex="-1"></a>    <span class="co"># Make BotStrategy a factor with meaningful names</span></span>
<span id="cb19-40"><a href="building-models-of-strategic-decision-making.html#cb19-40" tabindex="-1"></a>    <span class="at">BotStrategy =</span> <span class="fu">factor</span>(BotStrategy, </span>
<span id="cb19-41"><a href="building-models-of-strategic-decision-making.html#cb19-41" tabindex="-1"></a>                         <span class="at">levels =</span> <span class="fu">names</span>(bot_labels), </span>
<span id="cb19-42"><a href="building-models-of-strategic-decision-making.html#cb19-42" tabindex="-1"></a>                         <span class="at">labels =</span> bot_labels),</span>
<span id="cb19-43"><a href="building-models-of-strategic-decision-making.html#cb19-43" tabindex="-1"></a>    <span class="co"># Make Role a factor</span></span>
<span id="cb19-44"><a href="building-models-of-strategic-decision-making.html#cb19-44" tabindex="-1"></a>    <span class="at">Role =</span> <span class="fu">factor</span>(Role, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Matcher&quot;</span>, <span class="st">&quot;Hider&quot;</span>))</span>
<span id="cb19-45"><a href="building-models-of-strategic-decision-making.html#cb19-45" tabindex="-1"></a>  )</span>
<span id="cb19-46"><a href="building-models-of-strategic-decision-making.html#cb19-46" tabindex="-1"></a></span>
<span id="cb19-47"><a href="building-models-of-strategic-decision-making.html#cb19-47" tabindex="-1"></a><span class="co"># --- 3. Plot Collective Performance ---</span></span>
<span id="cb19-48"><a href="building-models-of-strategic-decision-making.html#cb19-48" tabindex="-1"></a><span class="fu">ggplot</span>(d_clean, <span class="fu">aes</span>(<span class="at">x =</span> Trial, <span class="at">y =</span> Payoff, <span class="at">color =</span> BotStrategy)) <span class="sc">+</span></span>
<span id="cb19-49"><a href="building-models-of-strategic-decision-making.html#cb19-49" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="at">span =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb19-50"><a href="building-models-of-strategic-decision-making.html#cb19-50" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb19-51"><a href="building-models-of-strategic-decision-making.html#cb19-51" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>Role) <span class="sc">+</span></span>
<span id="cb19-52"><a href="building-models-of-strategic-decision-making.html#cb19-52" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb19-53"><a href="building-models-of-strategic-decision-making.html#cb19-53" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Human vs. Machine: Average Performance&quot;</span>,</span>
<span id="cb19-54"><a href="building-models-of-strategic-decision-making.html#cb19-54" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">&quot;Positive values indicate humans winning against bots&quot;</span>,</span>
<span id="cb19-55"><a href="building-models-of-strategic-decision-making.html#cb19-55" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Average Payoff&quot;</span>,</span>
<span id="cb19-56"><a href="building-models-of-strategic-decision-making.html#cb19-56" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&quot;Opponent Strategy&quot;</span></span>
<span id="cb19-57"><a href="building-models-of-strategic-decision-making.html#cb19-57" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb19-58"><a href="building-models-of-strategic-decision-making.html#cb19-58" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb19-59"><a href="building-models-of-strategic-decision-making.html#cb19-59" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span></code></pre></div>
<p><img src="series_files/figure-html/02-load-and-clean-data-1.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<p>That doesn’t look too good, ah? What about individual variability? In the plot below we indicate the score of each of the former students, against the different bots.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="building-models-of-strategic-decision-making.html#cb20-1" tabindex="-1"></a><span class="co"># --- Plot 2: Individual Variability in Scores ---</span></span>
<span id="cb20-2"><a href="building-models-of-strategic-decision-making.html#cb20-2" tabindex="-1"></a><span class="co"># Calculate the total score for each student (ID) against each bot strategy.</span></span>
<span id="cb20-3"><a href="building-models-of-strategic-decision-making.html#cb20-3" tabindex="-1"></a>d_summary <span class="ot">&lt;-</span> d <span class="sc">%&gt;%</span></span>
<span id="cb20-4"><a href="building-models-of-strategic-decision-making.html#cb20-4" tabindex="-1"></a>  <span class="fu">group_by</span>(ID, BotStrategy, Role) <span class="sc">%&gt;%</span> <span class="co"># Group by student, bot, and role</span></span>
<span id="cb20-5"><a href="building-models-of-strategic-decision-making.html#cb20-5" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">TotalScore =</span> <span class="fu">sum</span>(Payoff), <span class="at">.groups =</span> <span class="st">&quot;drop&quot;</span>) <span class="co"># Calculate total score</span></span>
<span id="cb20-6"><a href="building-models-of-strategic-decision-making.html#cb20-6" tabindex="-1"></a></span>
<span id="cb20-7"><a href="building-models-of-strategic-decision-making.html#cb20-7" tabindex="-1"></a><span class="co"># Visualize the distribution of total scores for each bot strategy.</span></span>
<span id="cb20-8"><a href="building-models-of-strategic-decision-making.html#cb20-8" tabindex="-1"></a><span class="co"># geom_boxplot shows the distribution, geom_point shows individual student scores.</span></span>
<span id="cb20-9"><a href="building-models-of-strategic-decision-making.html#cb20-9" tabindex="-1"></a><span class="fu">print</span>(</span>
<span id="cb20-10"><a href="building-models-of-strategic-decision-making.html#cb20-10" tabindex="-1"></a>  <span class="fu">ggplot</span>(d_summary, <span class="fu">aes</span>(<span class="at">x =</span> BotStrategy, <span class="at">y =</span> TotalScore)) <span class="sc">+</span></span>
<span id="cb20-11"><a href="building-models-of-strategic-decision-making.html#cb20-11" tabindex="-1"></a>    <span class="fu">geom_boxplot</span>(<span class="fu">aes</span>(<span class="at">fill =</span> Role), <span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">outlier.shape =</span> <span class="cn">NA</span>) <span class="sc">+</span> <span class="co"># Boxplot showing distribution</span></span>
<span id="cb20-12"><a href="building-models-of-strategic-decision-making.html#cb20-12" tabindex="-1"></a>    <span class="fu">geom_jitter</span>(<span class="fu">aes</span>(<span class="at">color =</span> ID), <span class="at">width =</span> <span class="fl">0.2</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span> <span class="co"># Individual student points</span></span>
<span id="cb20-13"><a href="building-models-of-strategic-decision-making.html#cb20-13" tabindex="-1"></a>    <span class="fu">facet_wrap</span>(<span class="sc">~</span>Role) <span class="sc">+</span> <span class="co"># Separate plots for Matcher and Hider</span></span>
<span id="cb20-14"><a href="building-models-of-strategic-decision-making.html#cb20-14" tabindex="-1"></a>    <span class="fu">labs</span>(</span>
<span id="cb20-15"><a href="building-models-of-strategic-decision-making.html#cb20-15" tabindex="-1"></a>      <span class="at">title =</span> <span class="st">&quot;Distribution of Total Scores Against Different Bots&quot;</span>,</span>
<span id="cb20-16"><a href="building-models-of-strategic-decision-making.html#cb20-16" tabindex="-1"></a>      <span class="at">subtitle =</span> <span class="st">&quot;Shows individual student variability&quot;</span>,</span>
<span id="cb20-17"><a href="building-models-of-strategic-decision-making.html#cb20-17" tabindex="-1"></a>      <span class="at">x =</span> <span class="st">&quot;Bot Strategy&quot;</span>,</span>
<span id="cb20-18"><a href="building-models-of-strategic-decision-making.html#cb20-18" tabindex="-1"></a>      <span class="at">y =</span> <span class="st">&quot;Total Score (Sum of Payoffs)&quot;</span>,</span>
<span id="cb20-19"><a href="building-models-of-strategic-decision-making.html#cb20-19" tabindex="-1"></a>      <span class="at">fill =</span> <span class="st">&quot;Player Role&quot;</span></span>
<span id="cb20-20"><a href="building-models-of-strategic-decision-making.html#cb20-20" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb20-21"><a href="building-models-of-strategic-decision-making.html#cb20-21" tabindex="-1"></a>    <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb20-22"><a href="building-models-of-strategic-decision-making.html#cb20-22" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) <span class="co"># Hide legend for individual IDs</span></span>
<span id="cb20-23"><a href="building-models-of-strategic-decision-making.html#cb20-23" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="series_files/figure-html/02%20plot%20individual%20performance%20in%20MP-1.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<div id="from-observation-to-theory-identifying-potential-mechanisms" class="section level3 hasAnchor" number="3.6.1">
<h3><span class="header-section-number">3.6.1</span> From Observation to Theory: Identifying Potential Mechanisms<a href="building-models-of-strategic-decision-making.html#from-observation-to-theory-identifying-potential-mechanisms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The plots above reveal patterns: average performance changes over time, varies by opponent, and differs across individuals. Gameplay observations and participant reflections (from class discussion or collected data) add qualitative insights – perhaps players mention trying to be unpredictable, guessing opponent biases, or repeating winning moves.</p>
<p>The crucial next step is to distill these rich, complex observations into simplified, plausible <strong>mechanisms</strong> or <strong>strategies</strong>. This involves abstraction:</p>
<ul>
<li><p><strong>Identifying Core Patterns:</strong> What recurring behaviors seem most important? (e.g., reacting to wins/losses, tracking opponent frequencies).</p></li>
<li><p><strong>Simplifying:</strong> Can we capture the essence of a strategy without modeling every detail of a player’s thought process or interaction? (e.g., modeling WSLS instead of complex pattern detection).</p></li>
<li><p><strong>Drawing on Cognitive Principles:</strong> How do known cognitive constraints (like limited memory or processing errors, discussed below) shape plausible strategies?</p></li>
</ul>
<p>For instance, observing that players often change their choice after a loss might lead us to propose a “Lose-Shift” component as part of a candidate model. Observing that performance differs against biased vs. adaptive bots suggests players might be trying to learn or adapt, leading to memory-based or learning models.</p>
<p>This process generates <em>verbal models</em> – initial hypotheses about the strategies at play. Key modeling considerations guide this translation:</p>
<ul>
<li><p>What information do players likely use? (Own past choices? Opponent’s choices? Payoffs?)</p></li>
<li><p>How far back does memory plausibly extend? (Last trial? Last 5 trials? Exponential decay?)</p></li>
<li><p>What is the role of randomness? (True randomness? Exploration? Implementation errors?)</p></li>
<li><p>How might strategies adapt over time or differ between individuals?</p></li>
</ul>
<p>Answering these helps refine our verbal models, paving the way for formalization. The goal isn’t to capture everything, but to propose distinct, testable mechanisms.</p>
</div>
<div id="the-distinction-between-participant-and-researcher-perspectives" class="section level3 hasAnchor" number="3.6.2">
<h3><span class="header-section-number">3.6.2</span> The distinction between participant and researcher perspectives<a href="building-models-of-strategic-decision-making.html#the-distinction-between-participant-and-researcher-perspectives" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As participants we might not be aware of the strategy we use, or we might believe something erroneous. The exercise here is to act as researchers: what are the principles underlying the participants’ behaviors, no matter what the participants know or believe? Note that talking to participants and being participants helps developing ideas, but it’s not the end point of the process. Also note that as cognitive scientists we can rely on what we have learned about cognitive processes (e.g. memory).</p>
<p>Another important component of the distinction is that participants leave in a rich world: they rely on facial expressions and bodily posture, the switch strategies, etc. On the other hand, the researcher is trying to identify one or few at most “simple” strategies. Rich bodily interactions and mixtures or sequences of multiple strategies are not a good place to start modeling. These aspects are a poor starting point for building your first model, and are often pretty difficult to fit to empirical data. Nevertheless, they are important intuitions that the researcher should (eventually?) accommodate.</p>
</div>
</div>
<div id="candidate-models-a-hierarchy-of-cognitive-complexity" class="section level2 hasAnchor" number="3.7">
<h2><span class="header-section-number">3.7</span> Candidate Models: A Hierarchy of Cognitive Complexity<a href="building-models-of-strategic-decision-making.html#candidate-models-a-hierarchy-of-cognitive-complexity" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Based on our behavioral observations and cognitive principles (and the many discussions in class during the years), we can organize our candidate models into a hierarchy. Note that this is a chapter on verbal models, but I couldn’t resist adding some discussion of the math behind the verbal intuitions…
We start with simple agents that ignore history, move to learning agents that track uncertainty and volatility, and conclude with strategic agents that model the opponent’s mind.</p>
<div id="level-0-the-static-agent-no-learning" class="section level3 hasAnchor" number="3.7.1">
<h3><span class="header-section-number">3.7.1</span> Level 0: The Static Agent (No Learning)<a href="building-models-of-strategic-decision-making.html#level-0-the-static-agent-no-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The simplest assumption is that the agent does not learn or adapt to the opponent at all.
They simply act according to a fixed internal preference.</p>
</div>
<div id="the-biased-agent-random-choice" class="section level3 hasAnchor" number="3.7.2">
<h3><span class="header-section-number">3.7.2</span> The Biased Agent (Random Choice):<a href="building-models-of-strategic-decision-making.html#the-biased-agent-random-choice" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><em>Concept</em>: The agent is a biased coin flipper. They have a static preference (e.g., “I generally prefer Right”) that does not change over time.</p></li>
<li><p><em>Traditional Formulation (Bernoulli Process)</em>: We model the choice <span class="math inline">\(y_t\)</span> at trial <span class="math inline">\(t\)</span> as a draw from a Bernoulli distribution with a fixed rate parameter <span class="math inline">\(\theta\)</span>: <span class="math display">\[y_t \sim \text{Bernoulli}(\theta)\]</span></p></li>
<li><p><em>The “Update” Rule</em>: Because this agent is static, there is no update rule, in other words, a learning of 0. The parameter <span class="math inline">\(\theta\)</span> remains constant regardless of wins or losses. <span class="math display">\[\theta_{t+1} = \theta_{t}\]</span></p></li>
<li><p><em>Variable Definitions</em>:</p>
<ul>
<li><span class="math inline">\(y_t \in \{0, 1\}\)</span>: The choice (e.g., Left/Right).</li>
<li><span class="math inline">\(\theta \in [0, 1]\)</span>: The fixed probability of choosing 1 (bias).</li>
</ul></li>
<li><p><em>Looking Ahead</em>: This model might seem too simple to be useful, but it is the foundation of Bayesian inference. In the next chapter, we will write a function to simulate this agent. In the following chapter, we will then learn how to take a sequence of choices and mathematically work backwards to find the most likely value of <span class="math inline">\(\theta\)</span>.</p></li>
</ul>
</div>
<div id="level-1-heuristics-the-immediate-past" class="section level3 hasAnchor" number="3.7.3">
<h3><span class="header-section-number">3.7.3</span> Level 1: Heuristics &amp; The Immediate Past<a href="building-models-of-strategic-decision-making.html#level-1-heuristics-the-immediate-past" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The next step up is an agent that reacts to feedback but has a “memory” of only one trial. They live entirely in the moment.</p>
<div id="deterministic-win-stay-lose-shift-wsls" class="section level4 hasAnchor" number="3.7.3.1">
<h4><span class="header-section-number">3.7.3.1</span> Deterministic Win-Stay-Lose-Shift (WSLS):<a href="building-models-of-strategic-decision-making.html#deterministic-win-stay-lose-shift-wsls" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p><em>Concept</em>: A rigid heuristic: “If I won, I do the same thing. If I lost, I switch.”</p></li>
<li><p><em>Traditional Formulation (Conditional Probability)</em>: <span class="math display">\[P(y_t = y_{t-1} | outcome_{t-1}) = \begin{cases} 1 &amp; \text{if } outcome_{t-1} = \text{win} \\ 0 &amp; \text{if } outcome_{t-1} = \text{loss} \end{cases}\]</span></p></li>
<li><p><em>Variable Definitions</em>:<span class="math inline">\(outcome_{t-1}\)</span>: The feedback (Win/Loss) from the previous trial.</p></li>
</ul>
</div>
<div id="probabilistic-win-stay-lose-shift-logistic-regression" class="section level4 hasAnchor" number="3.7.3.2">
<h4><span class="header-section-number">3.7.3.2</span> Probabilistic Win-Stay-Lose-Shift (Logistic Regression):<a href="building-models-of-strategic-decision-making.html#probabilistic-win-stay-lose-shift-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p><em>Concept</em>: We relax the strict rule. The agent is more likely to stay after a win, but real behavior is noisy.</p></li>
<li><p><em>Traditional Formulation (GLM)</em>: We define the probability of “staying” (<span class="math inline">\(P_{stay}\)</span>) as a function of the previous outcome using a logistic curve. <span class="math display">\[P(stay_t) = \text{logit}^{-1}(\beta_0 + \beta_1 \cdot outcome_{t-1})\]</span></p></li>
<li><p><em>The “Update” Rule (Markov Transition)</em>: While not “learning” a value, the agent updates their action probability based on the state of the previous trial. <span class="math display">\[P(y_t = y_{t-1}) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 \cdot outcome_{t-1})}}\]</span></p></li>
<li><p><em>Variable Definitions</em>:</p>
<ul>
<li><span class="math inline">\(\text{logit}^{-1}(x) = \frac{1}{1+e^{-x}}\)</span>: The inverse logit (sigmoid) function.</li>
</ul>
<p>*<span class="math inline">\(\beta_0\)</span>: The baseline tendency to stay (perseveration).</p>
<ul>
<li><span class="math inline">\(\beta_1\)</span>: The sensitivity to feedback. A high <span class="math inline">\(\beta_1\)</span> makes the agent look like the deterministic heuristic above; <span class="math inline">\(\beta_1 \approx 0\)</span> implies the agent ignores feedback.</li>
</ul></li>
</ul>
</div>
</div>
<div id="level-2-integrating-history-the-moving-average" class="section level3 hasAnchor" number="3.7.4">
<h3><span class="header-section-number">3.7.4</span> Level 2: Integrating History (The Moving Average)<a href="building-models-of-strategic-decision-making.html#level-2-integrating-history-the-moving-average" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Real agents usually care about more than just the last trial. They integrate history over time to form an expectation.</p>
<div id="the-moving-average-windowed-memory" class="section level4 hasAnchor" number="3.7.4.1">
<h4><span class="header-section-number">3.7.4.1</span> The Moving Average (Windowed Memory):<a href="building-models-of-strategic-decision-making.html#the-moving-average-windowed-memory" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p><em>Concept</em>: “I think the future will look like the average of the recent past.”</p></li>
<li><p><em>Traditional Formulation (Batch Average)</em>:<span class="math display">\[\mu_{t} = \frac{1}{N} \sum_{i=1}^{N} x_{t-i}\]</span></p></li>
<li><p><em>Transformation to Update Rule</em>: To make this iterative, we can express the new average <span class="math inline">\(\mu_t\)</span> as the old average <span class="math inline">\(\mu_{t-1}\)</span> plus a correction. <span class="math display">\[\mu_{t} = \mu_{t-1} + \frac{1}{N} (x_{t} - x_{t-N})\]</span></p></li>
<li><p><em>Critique</em>: This reveals a massive memory cost: to update the average, in this mathematical formulation, the agent needs to remember exactly what happened <span class="math inline">\(N\)</span> trials ago (<span class="math inline">\(x_{t-N}\)</span>) to “remove” it.</p></li>
<li><p><em>Variable Definitions</em>:</p>
<ul>
<li><p><span class="math inline">\(\mu_t\)</span>: The predicted value at trial <span class="math inline">\(t\)</span>.</p></li>
<li><p><span class="math inline">\(N\)</span>: The window size (e.g., 10 trials).</p></li>
<li><p><span class="math inline">\(x_t\)</span>: The outcome at trial <span class="math inline">\(t\)</span>.</p></li>
</ul></li>
</ul>
</div>
</div>
<div id="level-3-reinforcement-learning-elegant-decay" class="section level3 hasAnchor" number="3.7.5">
<h3><span class="header-section-number">3.7.5</span> Level 3: Reinforcement Learning (Elegant Decay)<a href="building-models-of-strategic-decision-making.html#level-3-reinforcement-learning-elegant-decay" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Reinforcement Learning (RL) is mathematically the elegant solution to the Moving Average’s memory problem. It replaces the “perfect memory of <span class="math inline">\(N\)</span> trials” with a “fading memory of everything.</p>
<ul>
<li><p><em>“Traditional Formulation (Exponential Weighted Average)</em>:Instead of a sum over <span class="math inline">\(N\)</span>, we define value as a weighted sum of all past history, where weights decay geometrically. <span class="math display">\[V_{t} = (1-\alpha) \cdot V_{t-1} + \alpha \cdot Reward_{t}\]</span></p></li>
<li><p><em>Transformation to Update Rule (The Delta Rule)</em>: By rearranging terms, we get the famous error-correction format: <span class="math display">\[V_{t} = V_{t-1} + \alpha \cdot (Reward_{t} - V_{t-1})\]</span></p></li>
<li><p><em>Why is this “Learning”?</em> The term <span class="math inline">\((Reward_{t} - V_{t-1})\)</span> is the Prediction Error (PE). The agent compares reality (<span class="math inline">\(Reward\)</span>) to their expectation (<span class="math inline">\(V\)</span>) and nudges their belief by a step size <span class="math inline">\(\alpha\)</span>.</p></li>
<li><p><em>Variable Definitions</em>:</p>
<ul>
<li><span class="math inline">\(V_t\)</span>: The estimated value (e.g., probability of win) at trial <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(\alpha \in [0, 1]\)</span>: The Learning Rate. High <span class="math inline">\(\alpha\)</span> = fast forgetting; Low <span class="math inline">\(\alpha\)</span> = long memory.<span class="math inline">\(PE\)</span>: The difference between what happened and what was expected.</li>
</ul></li>
</ul>
</div>
<div id="level-4-the-bayesian-update-static-uncertainty" class="section level3 hasAnchor" number="3.7.6">
<h3><span class="header-section-number">3.7.6</span> Level 4: The Bayesian Update (Static Uncertainty)<a href="building-models-of-strategic-decision-making.html#level-4-the-bayesian-update-static-uncertainty" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In RL, the learning rate <span class="math inline">\(\alpha\)</span> is a fixed number. In Bayesian inference, the “learning rate” becomes adaptive based on certainty.</p>
<ul>
<li><p><em>Traditional Formulation (Bayes Theorem for Gaussians)</em>: We combine a Prior distribution (<span class="math inline">\(\mathcal{N}(\mu_{prior}, \sigma^2_{prior})\)</span>) with Likelihood (<span class="math inline">\(\mathcal{N}(Data, \sigma^2_{noise})\)</span>) to get a Posterior.<span class="math display">\[\text{Posterior Mean} = \frac{\sigma^2_{noise}\mu_{prior} + \sigma^2_{prior}Data}{\sigma^2_{noise} + \sigma^2_{prior}}\]</span></p></li>
<li><p><em>Transformation to Update Rule (Kalman Gain)</em>: We can algebraically rearrange the posterior mean into an “Update + Error” format similar to RL:<span class="math display">\[\mu_{new} = \mu_{prior} + K \cdot (Data - \mu_{prior})\]</span> Here, <span class="math inline">\(K\)</span> is the Kalman Gain:<span class="math display">\[K = \frac{\sigma^{2}_{prior}}{\sigma^{2}_{prior} + \sigma^{2}_{noise}}\]</span></p></li>
<li><p><em>Implication</em>: If the agent is very certain (<span class="math inline">\(\sigma^2_{prior} \to 0\)</span>), then <span class="math inline">\(K \to 0\)</span>. The agent stops learning because they are “sure” they know the truth.</p></li>
<li><p><em>Variable Definitions</em>:</p>
<ul>
<li><span class="math inline">\(\sigma^2_{prior}\)</span>: Uncertainty of the agent’s belief.</li>
<li><span class="math inline">\(\sigma^2_{noise}\)</span>: Uncertainty/noise of the environment.</li>
</ul></li>
</ul>
</div>
<div id="level-5-the-kalman-filter-dynamic-uncertainty" class="section level3 hasAnchor" number="3.7.7">
<h3><span class="header-section-number">3.7.7</span> Level 5: The Kalman Filter (Dynamic Uncertainty)<a href="building-models-of-strategic-decision-making.html#level-5-the-kalman-filter-dynamic-uncertainty" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Real environments change (volatility). The Kalman Filter extends the Bayesian update by adding a Prediction Step that prevents the agent from becoming “too sure.”</p>
<ul>
<li><p><em>Traditional Formulation (State Space Model)</em>: We assume the true value drifts over time with random noise <span class="math inline">\(Q\)</span>.<span class="math display">\[x_t = x_{t-1} + w_t, \quad w_t \sim \mathcal{N}(0, Q)\]</span></p></li>
<li><p><em>Transformation to Update Rule (Two-Step Process)</em>:</p>
<ul>
<li>Predict (Inflate Uncertainty): Before seeing data, add Process Noise <span class="math inline">\(Q\)</span>.<span class="math display">\[\sigma^2_{prediction} = \sigma^2_{previous} + Q\]</span></li>
<li>Update (Dynamic Gain): Calculate a new gain <span class="math inline">\(K_t\)</span> based on this inflated uncertainty.<span class="math display">\[K_{t} = \frac{\sigma^2_{prediction}}{\sigma^2_{prediction} + R}\]</span></li>
<li>Correct:<span class="math display">\[\mu_{t} = \mu_{t-1} + K_t \cdot (Outcome_t - \mu_{t-1})\]</span></li>
</ul></li>
<li><p><em>Key Insight</em>: Because we add <span class="math inline">\(Q\)</span> at every step, <span class="math inline">\(\sigma^2\)</span> never hits zero. The gain <span class="math inline">\(K_t\)</span> settles at a dynamic equilibrium.</p></li>
<li><p><em>Variable Definitions</em>:</p>
<ul>
<li><p><span class="math inline">\(Q\)</span>: Process Noise (Volatility). How much the world changes per trial.</p></li>
<li><p><span class="math inline">\(R\)</span>: Measurement Noise.</p></li>
</ul></li>
</ul>
</div>
<div id="level-6-the-hierarchical-gaussian-filter-meta-learning" class="section level3 hasAnchor" number="3.7.8">
<h3><span class="header-section-number">3.7.8</span> Level 6: The Hierarchical Gaussian Filter (Meta-Learning)<a href="building-models-of-strategic-decision-making.html#level-6-the-hierarchical-gaussian-filter-meta-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Kalman Filter assumes the volatility (<span class="math inline">\(Q\)</span>) is constant. But what if the opponent plays steadily for 20 rounds, then suddenly starts switching wildly? The HGF introduces a hierarchy to track this.</p>
<ul>
<li><p><em>Concept</em>:</p>
<ul>
<li><p>Level 1 (<span class="math inline">\(x_1\)</span>): The value (Probability of Right).</p></li>
<li><p>Level 2 (<span class="math inline">\(x_2\)</span>): The volatility of Level 1.</p></li>
</ul></li>
<li><p><em>Transformation to Update Rule (Volatile Learning Rates)</em>: In the HGF, the uncertainty of the lower level is driven by the value of the higher level. <span class="math display">\[\sigma^2_{1} \propto \exp(x_2)\]</span> Substituting this into the Kalman Gain equation:<span class="math display">\[K_1 \approx \frac{\exp(x_2)}{\exp(x_2) + R}\]</span></p></li>
<li><p>Implication:If Level 2 detects high volatility (<span class="math inline">\(x_2 \uparrow\)</span>), the learning rate <span class="math inline">\(K_1\)</span> spikes <span class="math inline">\(\to 1\)</span>.If Level 2 detects stability (<span class="math inline">\(x_2 \downarrow\)</span>), the learning rate <span class="math inline">\(K_1\)</span> drops <span class="math inline">\(\to 0\)</span>.Result: An adaptive learning rate that reacts to environmental stability.</p></li>
</ul>
</div>
<div id="level-7-recursive-strategies-theory-of-mind" class="section level3 hasAnchor" number="3.7.9">
<h3><span class="header-section-number">3.7.9</span> Level 7: Recursive Strategies (Theory of Mind)<a href="building-models-of-strategic-decision-making.html#level-7-recursive-strategies-theory-of-mind" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Finally, we move from learning about the environment to learning about the agent. This is Theory of Mind (ToM), which can be formally reframed as Recursive Reinforcement Learning.</p>
<ul>
<li><p><em>Concept</em>: The agent (<span class="math inline">\(k\)</span>-ToM) tracks the opponent’s strategy by simulating them.</p></li>
<li><p><em>Traditional Formulation (Recursive Simulation)</em>: A 1-ToM agent simulates a 0-ToM opponent (e.g., a simple bias learner).A 2-ToM agent simulates a 1-ToM opponent.</p></li>
<li><p><em>Update Rule (Recursive Value)</em>: The value of an action <span class="math inline">\(a\)</span> is derived from the predicted probability of the opponent’s counter-move <span class="math inline">\(\hat{a}_{op}\)</span>:<span class="math display">\[V_{k}(a) \propto P(\text{Op plays } \hat{a}_{op} | \text{Op is level } k-1)\]</span> The recursion “bottoms out” at a Level 0 model (usually RL or Bias).</p></li>
</ul>
</div>
<div id="handling-heterogeneity-mixture-models" class="section level3 hasAnchor" number="3.7.10">
<h3><span class="header-section-number">3.7.10</span> Handling Heterogeneity: Mixture Models<a href="building-models-of-strategic-decision-making.html#handling-heterogeneity-mixture-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Real behavior is often a mix of these strategies. A player might act randomly for 5 trials, then switch to WSLS.Concept: We assume the data is generated by a probabilistic blend of <span class="math inline">\(M\)</span> different candidate models.Mathematical Formulation:The likelihood of the data <span class="math inline">\(D\)</span> is a weighted sum of the likelihoods from each model <span class="math inline">\(m\)</span>:<span class="math display">\[P(D | \Theta) = \sum_{m=1}^{M} w_m \cdot P(D | \text{Model}_m, \theta_m)\]</span>Variable Definitions:<span class="math inline">\(w_m\)</span>: The mixing weight (probability of using Model <span class="math inline">\(m\)</span>), where <span class="math inline">\(\sum w_m = 1\)</span>.<span class="math inline">\(P(D|\text{Model}_m)\)</span>: How well the specific model (e.g., RL) explains the data.</p>
<p>Sometimes one can be lucky and integrate the “mixed” models into one equation (see an example here: <a href="https://betanalpha.github.io/assets/chapters_html/reading_times.html" class="uri">https://betanalpha.github.io/assets/chapters_html/reading_times.html</a>)</p>
</div>
<div id="plausibility-check-cognitive-constraints" class="section level3 hasAnchor" number="3.7.11">
<h3><span class="header-section-number">3.7.11</span> Plausibility Check: Cognitive Constraints<a href="building-models-of-strategic-decision-making.html#plausibility-check-cognitive-constraints" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>You probably noticed you couldn’t remember every single move your opponent made. Maybe you lost track of older trials, and recent trials felt more important. These aren’t failures: they’re features of human cognition. Our models should reflect these constraints to be cognitively realistic. Let’s see what difference these constraints make for predictions.</p>
<div id="memory-limitations" class="section level4 hasAnchor" number="3.7.11.1">
<h4><span class="header-section-number">3.7.11.1</span> Memory Limitations<a href="building-models-of-strategic-decision-making.html#memory-limitations" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><em>Constraint:</em> Humans have limited working memory and exhibit forgetting, often approximated by exponential decay. Perfect recall of long trial sequences is unrealistic.</li>
<li><em>Modeling Implication:</em> This favors models incorporating memory decay or finite history windows (like imperfect memory models or RL with a learning rate &lt; 1) over perfect memory models. It suggests that even bias-tracking models should discount older information.</li>
</ul>
</div>
<div id="perseveration-tendencies" class="section level4 hasAnchor" number="3.7.11.2">
<h4><span class="header-section-number">3.7.11.2</span> Perseveration Tendencies<a href="building-models-of-strategic-decision-making.html#perseveration-tendencies" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><em>Constraint:</em> People sometimes exhibit perseveration – repeating a previous action, especially if it was recently successful or chosen, even if a different strategy might suggest otherwise. This can be distinct from rational “win-stay”.</li>
<li><em>Modeling Implication:</em> This might be incorporated as an additional bias parameter influencing the choice probability (e.g., a small added probability of repeating the last action <span class="math inline">\(a_{t-1}\)</span> regardless of outcome) or interact with feedback processing (e.g., strengthening the ‘stay’ tendency after wins).</li>
</ul>
</div>
<div id="noise-and-errors" class="section level4 hasAnchor" number="3.7.11.3">
<h4><span class="header-section-number">3.7.11.3</span> Noise and Errors<a href="building-models-of-strategic-decision-making.html#noise-and-errors" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><em>Constraint:</em> Human behavior is inherently noisy. People make mistakes, have attentional lapses, press the wrong button, or misunderstand feedback. Behavior rarely perfectly matches a deterministic strategy.</li>
<li><em>Modeling Implication:</em> Models should almost always include a “noise” component. This can be implemented in several ways:
<ul>
<li><strong>Lapse Rate:</strong> A probability (e.g., <span class="math inline">\(\epsilon\)</span>) that on any given trial, the agent makes a random choice instead of following their primary strategy (as used in the Mixture Model chapter).</li>
<li><strong>Decision Noise (Softmax):</strong> In models where choices are based on comparing values (like RL), a ‘temperature’ parameter can control the stochasticity. High temperature leads to more random choices, low temperature leads to more deterministic choices based on values.</li>
<li><strong>Imperfect Heuristics:</strong> Parameters within a strategy might reflect imperfect application (e.g., in WSLS, <span class="math inline">\(p_{stay\_win} &lt; 1\)</span> or <span class="math inline">\(p_{shift\_loss} &lt; 1\)</span>). This can also capture asymmetric responses to feedback (e.g., being more likely to shift after a loss than stay after a win).
<ul>
<li><em>Exploration:</em> Note that we talked about noise and errors, but random deviations can also be framed as adaptive exploration, allowing the agent to test actions that their current strategy deems suboptimal.</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="a-note-on-ideal-observers" class="section level4 hasAnchor" number="3.7.11.4">
<h4><span class="header-section-number">3.7.11.4</span> A Note on Ideal Observers<a href="building-models-of-strategic-decision-making.html#a-note-on-ideal-observers" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>It is important to distinguish between <strong>Heuristic Models</strong> (like WSLS) and <strong>Ideal Observer Models</strong> (like the Kalman Filter or HGF). Heuristics attempt to describe the <em>process</em> a human uses. Ideal observers describe the <em>optimal computation</em> given the uncertainty. When we fit models like the HGF to human data, we are effectively asking: “In what specific ways does the human deviate from optimality?” (e.g., do they overestimate how volatile the opponent is?).</p>
</div>
</div>
<div id="relationships-between-models" class="section level3 hasAnchor" number="3.7.12">
<h3><span class="header-section-number">3.7.12</span> Relationships Between Models<a href="building-models-of-strategic-decision-making.html#relationships-between-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>It’s useful to note that these candidate models aren’t always entirely distinct. Often, simpler models emerge as special cases of more complex ones:</p>
<ul>
<li><p>A Random Choice model is like a Memory-Based model where the influence of memory is zero.</p></li>
<li><p>WSLS can be seen as a specific type of RL model with a very high learning rate and sensitivity only to the immediately preceding trial’s outcome.</p></li>
<li><p>A 0-ToM model might resemble a Bias Tracking or RL model.</p></li>
</ul>
<p>Recognizing these connections can guide a principled modeling approach, starting simple and adding complexity only as needed and justified by data or theory.</p>
<p>This is what we called “model nesting” in a future chapter. It’s very elegant in that it allows to directly compare several models in a non-exclusive fashion, simply based on parameter values. A good example is also provided in Betancourt’s case study on reading times: <a href="https://betanalpha.github.io/assets/chapters_html/reading_times.html" class="uri">https://betanalpha.github.io/assets/chapters_html/reading_times.html</a></p>
</div>
<div id="handling-heterogeneity-mixture-models-1" class="section level3 hasAnchor" number="3.7.13">
<h3><span class="header-section-number">3.7.13</span> Handling Heterogeneity: Mixture Models<a href="building-models-of-strategic-decision-making.html#handling-heterogeneity-mixture-models-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sometimes the models cannot be nested, or we might want to capture the possibility that different participants (or even the same participant at different times) use different strategies. For instance, some players might predominantly use WSLS, while others rely more on bias tracking. This is where <em>mixture models</em> become relevant (explored in detail in a future chapter).</p>
<ul>
<li><p><em>Concept:</em> Instead of assuming <em>one</em> model generated all the data, a mixture model assumes the data is a probabilistic blend from <em>multiple</em> candidate models (e.g., 70% of choices from WSLS, 30% from Random Bias).</p></li>
<li><p><em>Purpose:</em> Allows capturing heterogeneity within or across individuals without needing to know <em>a priori</em> which strategy was used on which trial or by which person. The model estimates the <em>probability</em> that each data point came from each component strategy.</p></li>
<li><p><em>Challenge:</em> Mixture models often require substantial data to reliably distinguish between components and estimate their mixing proportions.</p></li>
</ul>
</div>
<div id="cognitive-modeling-vs.-traditional-statistical-approaches-e.g.-glm" class="section level3 hasAnchor" number="3.7.14">
<h3><span class="header-section-number">3.7.14</span> Cognitive Modeling vs. Traditional Statistical Approaches (e.g., GLM)<a href="building-models-of-strategic-decision-making.html#cognitive-modeling-vs.-traditional-statistical-approaches-e.g.-glm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>How does this modeling approach differ from standard statistical analyses you might have learned, like ANOVAs or the General Linear Model - GLM?</p>
<ul>
<li><strong>Focus:</strong> GLM approaches typically focus on identifying <em>statistical effects</em>: Does factor X significantly influence outcome Y? (e.g., Does the opponent’s strategy affect the player’s win rate?). Cognitive modeling focuses on identifying the underlying <em>process or mechanism</em>: <em>How</em> does the opponent’s strategy lead to changes in the player’s choices via specific computations (like learning, memory updating, or strategic reasoning)?</li>
<li><strong>Theory:</strong> Cognitive models are usually derived from theories about mental processes. GLMs are more general statistical tools, often used agnostically regarding the specific cognitive mechanism.</li>
<li><strong>Parameters:</strong> Cognitive models estimate parameters that often have direct psychological interpretations (e.g., learning rate, memory decay, decision threshold, bias weight). GLM parameters represent statistical associations (e.g., regression coefficients).</li>
<li><strong>Data Level:</strong> Cognitive models often predict behavior at the trial level (e.g., predicting the choice on trial <em>t</em> based on history up to <em>t-1</em>). GLM analyses often aggregate data (e.g., comparing average win rates across conditions).</li>
<li><strong>Prediction vs. Explanation:</strong> While both aim to explain data, cognitive modeling often places a stronger emphasis on generating the observed behavior pattern from the hypothesized mechanism, allowing for simulation and prediction of fine-grained details.</li>
</ul>
<p><em>Example Revisited:</em> In the Matching Pennies game:
* A GLM approach might test if <code>Payoff ~ BotStrategy * Role + (1|ID)</code> shows a significant effect of <code>BotStrategy</code>.
* A cognitive modeling approach would fit different strategy models (WSLS, RL, etc.) to the choice data and compare them (using methods from Ch 7) to see which <em>mechanism</em> best explains the choices made against different bots, potentially revealing <em>why</em> performance differs (e.g., due to changes in estimated learning rates or strategy weights).</p>
<p>Both approaches are valuable, but cognitive modeling aims for a deeper, mechanistic level of explanation about the underlying cognitive processes.</p>
</div>
</div>
<div id="conclusion-from-observations-to-verbal-theories" class="section level2 hasAnchor" number="3.8">
<h2><span class="header-section-number">3.8</span> Conclusion: From Observations to Verbal Theories<a href="building-models-of-strategic-decision-making.html#conclusion-from-observations-to-verbal-theories" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This chapter took us from observing behavior in a specific task – the Matching Pennies game – to the crucial stage of formulating initial theories about the cognitive processes involved. We explored how analyzing gameplay data, considering participant reports, applying cognitive principles (like memory limits and error proneness), and contrasting different potential strategies (Random, WSLS, Memory-based, RL, k-ToM) helps us generate plausible <em>verbal models</em>.</p>
<p>We saw that the path from raw behavior to a testable model involves significant abstraction and simplification. We also highlighted the importance of distinguishing between the participant’s experience and the researcher’s theoretical stance, and how cognitive modeling differs from traditional statistical approaches by focusing on underlying mechanisms.</p>
<p>You now have a conceptual map of candidate models and understand why cognitive constraints matter. But verbal descriptions like ‘win-stay-lose-shift’ hide crucial ambiguities: Does ‘stay’ mean always stay or usually stay? How do we handle the first trial? In Chapter 3, you’ll implement these models in code, forcing you to make every assumption explicit. This is where modeling becomes rigorous and often reveals that our verbal intuitions were vaguer than we thought.</p>
<p>The next chapter, “From verbal descriptions to formal models,” tackles exactly this challenge. We will take some of the candidate models discussed here (like Random Choice and WSLS) and translate them into precise mathematical algorithms and R functions. This formalization will force us to be explicit about our assumptions and enable us to simulate agent behavior, setting the stage for fitting these models to data and evaluating their performance in later chapters.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="the-pizza-experiment.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="from-verbal-descriptions-to-formal-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/fusaroli/AdvancedCognitiveModeling/edit/master/02-BuildingModels.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["series.pdf"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
