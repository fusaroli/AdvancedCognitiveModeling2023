<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Building Models of Strategic Decision-Making | Advanced Cognitive Modeling Notes</title>
  <meta name="description" content="My notes for the advanced cognitive modeling course - 2026" />
  <meta name="generator" content="bookdown 0.46 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Building Models of Strategic Decision-Making | Advanced Cognitive Modeling Notes" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="My notes for the advanced cognitive modeling course - 2026" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Building Models of Strategic Decision-Making | Advanced Cognitive Modeling Notes" />
  
  <meta name="twitter:description" content="My notes for the advanced cognitive modeling course - 2026" />
  

<meta name="author" content="Riccardo Fusaroli" />


<meta name="date" content="2026-02-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="the-pizza-experiment.html"/>
<link rel="next" href="from-verbal-descriptions-to-formal-models.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="lib/css/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="lib/css/style.css" type="text/css" />
<link rel="stylesheet" href="lib/css/lesson.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Cognitive Modeling</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Advanced Cognitive Modeling</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#course-philosophy-and-approach"><i class="fa fa-check"></i><b>1.1</b> Course Philosophy and Approach</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#course-structure-and-learning-path"><i class="fa fa-check"></i><b>1.2</b> Course Structure and Learning Path</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#prerequisites-and-preparation"><i class="fa fa-check"></i><b>1.3</b> Prerequisites and Preparation</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#course-resources"><i class="fa fa-check"></i><b>1.4</b> Course Resources</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#about-these-notes"><i class="fa fa-check"></i><b>1.5</b> About These Notes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html"><i class="fa fa-check"></i><b>2</b> The Pizza Experiment</a>
<ul>
<li class="chapter" data-level="2.1" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#from-pizza-to-cognitive-models-an-introduction"><i class="fa fa-check"></i><b>2.1</b> From Pizza to Cognitive Models: An Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#why-start-with-pizza"><i class="fa fa-check"></i><b>2.2</b> Why Start with Pizza?</a></li>
<li class="chapter" data-level="2.3" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#learning-objectives"><i class="fa fa-check"></i><b>2.3</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.4" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#part-1-exploring-the-pizza-stone-temperature-data"><i class="fa fa-check"></i><b>2.4</b> Part 1: Exploring the Pizza Stone Temperature Data</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#initial-data-visualization"><i class="fa fa-check"></i><b>2.4.1</b> Initial Data Visualization</a></li>
<li class="chapter" data-level="2.4.2" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#key-observations"><i class="fa fa-check"></i><b>2.4.2</b> Key Observations</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#part-2-initial-statistical-modeling"><i class="fa fa-check"></i><b>2.5</b> Part 2: Initial Statistical Modeling</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#model-setup-and-priors"><i class="fa fa-check"></i><b>2.5.1</b> Model Setup and Priors</a></li>
<li class="chapter" data-level="2.5.2" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#linear-mixed-effects-model"><i class="fa fa-check"></i><b>2.5.2</b> Linear Mixed-Effects Model</a></li>
<li class="chapter" data-level="2.5.3" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#lognormal-mixed-effects-model"><i class="fa fa-check"></i><b>2.5.3</b> Lognormal Mixed-Effects Model</a></li>
<li class="chapter" data-level="2.5.4" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#model-comparison-and-visualization"><i class="fa fa-check"></i><b>2.5.4</b> Model Comparison and Visualization</a></li>
<li class="chapter" data-level="2.5.5" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#model-assessment"><i class="fa fa-check"></i><b>2.5.5</b> Model Assessment</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#part-3-understanding-the-physics-model"><i class="fa fa-check"></i><b>2.6</b> Part 3: Understanding the Physics Model</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#the-basic-temperature-evolution-equation"><i class="fa fa-check"></i><b>2.6.1</b> The Basic Temperature Evolution Equation</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#part-4-implementing-the-physics-based-model"><i class="fa fa-check"></i><b>2.7</b> Part 4: Implementing the Physics-Based Model</a></li>
<li class="chapter" data-level="2.8" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#part-5-model-analysis-and-practical-applications"><i class="fa fa-check"></i><b>2.8</b> Part 5: Model Analysis and Practical Applications</a></li>
<li class="chapter" data-level="2.9" data-path="the-pizza-experiment.html"><a href="the-pizza-experiment.html#conclusion-from-pizza-to-cognitive-principles"><i class="fa fa-check"></i><b>2.9</b> Conclusion: From Pizza to Cognitive Principles</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html"><i class="fa fa-check"></i><b>3</b> Building Models of Strategic Decision-Making</a>
<ul>
<li class="chapter" data-level="3.1" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#learning-goals"><i class="fa fa-check"></i><b>3.1</b> Learning Goals</a></li>
<li class="chapter" data-level="3.2" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#introduction-observing-behavior-to-theorize-mechanisms"><i class="fa fa-check"></i><b>3.2</b> Introduction: Observing Behavior to Theorize Mechanisms</a></li>
<li class="chapter" data-level="3.3" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#the-matching-pennies-game"><i class="fa fa-check"></i><b>3.3</b> The Matching Pennies Game</a></li>
<li class="chapter" data-level="3.4" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#game-structure"><i class="fa fa-check"></i><b>3.4</b> Game Structure</a></li>
<li class="chapter" data-level="3.5" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#empirical-investigation"><i class="fa fa-check"></i><b>3.5</b> Empirical Investigation</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#data-collection-protocol"><i class="fa fa-check"></i><b>3.5.1</b> Data Collection Protocol</a></li>
<li class="chapter" data-level="3.5.2" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#initial-observations"><i class="fa fa-check"></i><b>3.5.2</b> Initial Observations</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#empirical-explorations"><i class="fa fa-check"></i><b>3.6</b> Empirical explorations</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#from-observation-to-theory-identifying-potential-mechanisms"><i class="fa fa-check"></i><b>3.6.1</b> From Observation to Theory: Identifying Potential Mechanisms</a></li>
<li class="chapter" data-level="3.6.2" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#the-distinction-between-participant-and-researcher-perspectives"><i class="fa fa-check"></i><b>3.6.2</b> The distinction between participant and researcher perspectives</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#candidate-models-a-hierarchy-of-cognitive-complexity"><i class="fa fa-check"></i><b>3.7</b> Candidate Models: A Hierarchy of Cognitive Complexity</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-0-the-static-agent-no-learning"><i class="fa fa-check"></i><b>3.7.1</b> Level 0: The Static Agent (No Learning)</a></li>
<li class="chapter" data-level="3.7.2" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#the-biased-agent-random-choice"><i class="fa fa-check"></i><b>3.7.2</b> The Biased Agent (Random Choice):</a></li>
<li class="chapter" data-level="3.7.3" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-1-heuristics-the-immediate-past"><i class="fa fa-check"></i><b>3.7.3</b> Level 1: Heuristics &amp; The Immediate Past</a></li>
<li class="chapter" data-level="3.7.4" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-2-integrating-history-the-moving-average"><i class="fa fa-check"></i><b>3.7.4</b> Level 2: Integrating History (The Moving Average)</a></li>
<li class="chapter" data-level="3.7.5" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-3-a-more-elegant-memory-decay-mechanism"><i class="fa fa-check"></i><b>3.7.5</b> Level 3: A more elegant memory decay mechanism</a></li>
<li class="chapter" data-level="3.7.6" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-4-the-bayesian-update-static-uncertainty"><i class="fa fa-check"></i><b>3.7.6</b> Level 4: The Bayesian Update (Static Uncertainty)</a></li>
<li class="chapter" data-level="3.7.7" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-5-the-kalman-filter-dynamic-uncertainty"><i class="fa fa-check"></i><b>3.7.7</b> Level 5: The Kalman Filter (Dynamic Uncertainty)</a></li>
<li class="chapter" data-level="3.7.8" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-6-the-hierarchical-gaussian-filter-meta-learning"><i class="fa fa-check"></i><b>3.7.8</b> Level 6: The Hierarchical Gaussian Filter (Meta-Learning)</a></li>
<li class="chapter" data-level="3.7.9" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#level-7-recursive-strategies-theory-of-mind"><i class="fa fa-check"></i><b>3.7.9</b> Level 7: Recursive Strategies (Theory of Mind)</a></li>
<li class="chapter" data-level="3.7.10" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#handling-heterogeneity-mixture-models"><i class="fa fa-check"></i><b>3.7.10</b> Handling Heterogeneity: Mixture Models</a></li>
<li class="chapter" data-level="3.7.11" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#plausibility-check-cognitive-constraints"><i class="fa fa-check"></i><b>3.7.11</b> Plausibility Check: Cognitive Constraints</a></li>
<li class="chapter" data-level="3.7.12" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#relationships-between-models"><i class="fa fa-check"></i><b>3.7.12</b> Relationships Between Models</a></li>
<li class="chapter" data-level="3.7.13" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#handling-heterogeneity-mixture-models-1"><i class="fa fa-check"></i><b>3.7.13</b> Handling Heterogeneity: Mixture Models</a></li>
<li class="chapter" data-level="3.7.14" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#cognitive-modeling-vs.-traditional-statistical-approaches-e.g.-glm"><i class="fa fa-check"></i><b>3.7.14</b> Cognitive Modeling vs. Traditional Statistical Approaches (e.g., GLM)</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="building-models-of-strategic-decision-making.html"><a href="building-models-of-strategic-decision-making.html#conclusion-from-observations-to-verbal-theories"><i class="fa fa-check"></i><b>3.8</b> Conclusion: From Observations to Verbal Theories</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html"><i class="fa fa-check"></i><b>4</b> From verbal descriptions to formal models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#learning-goals-1"><i class="fa fa-check"></i><b>4.1</b> Learning Goals</a></li>
<li class="chapter" data-level="4.2" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#the-value-of-formalization-and-simulation"><i class="fa fa-check"></i><b>4.2</b> The Value of Formalization and Simulation</a></li>
<li class="chapter" data-level="4.3" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#defining-general-conditions"><i class="fa fa-check"></i><b>4.3</b> Defining general conditions</a></li>
<li class="chapter" data-level="4.4" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#implementing-a-random-agent"><i class="fa fa-check"></i><b>4.4</b> Implementing a Random Agent</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#encapsulating-the-agent-in-a-function"><i class="fa fa-check"></i><b>4.4.1</b> Encapsulating the Agent in a Function</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#implementing-a-win-stay-lose-shift-wsls-agent"><i class="fa fa-check"></i><b>4.5</b> Implementing a Win-Stay-Lose-Shift (WSLS) Agent</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#implementing-the-wsls-function"><i class="fa fa-check"></i><b>4.5.1</b> Implementing the WSLS Function</a></li>
<li class="chapter" data-level="4.5.2" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#simulating-wsls-vs.-opponents"><i class="fa fa-check"></i><b>4.5.2</b> Simulating WSLS vs. Opponents</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#scaling-up-the-virtual-experiment"><i class="fa fa-check"></i><b>4.6</b> Scaling Up: The Virtual Experiment</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#visualizing-results"><i class="fa fa-check"></i><b>4.6.1</b> Visualizing Results</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#conclusion-the-forward-model"><i class="fa fa-check"></i><b>4.7</b> Conclusion: The Forward Model</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="from-verbal-descriptions-to-formal-models.html"><a href="from-verbal-descriptions-to-formal-models.html#the-problem-of-inference"><i class="fa fa-check"></i><b>4.7.1</b> The Problem of Inference</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html"><i class="fa fa-check"></i><b>5</b> From simulation to model fitting</a>
<ul>
<li class="chapter" data-level="5.1" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#learning-goals-2"><i class="fa fa-check"></i><b>5.1</b> Learning Goals</a></li>
<li class="chapter" data-level="5.2" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#the-challenge-inferring-latent-parameters"><i class="fa fa-check"></i><b>5.2</b> The Challenge: Inferring Latent Parameters</a></li>
<li class="chapter" data-level="5.3" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#simulating-data"><i class="fa fa-check"></i><b>5.3</b> Simulating data</a></li>
<li class="chapter" data-level="5.4" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#building-our-first-stan-model-inferring-bias-rate"><i class="fa fa-check"></i><b>5.4</b> Building our First Stan Model: Inferring Bias Rate</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#model"><i class="fa fa-check"></i><b>5.4.1</b> Model</a></li>
<li class="chapter" data-level="5.4.2" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#assessing-model-quality"><i class="fa fa-check"></i><b>5.4.2</b> Assessing model quality</a></li>
<li class="chapter" data-level="5.4.3" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#summarizing-the-results"><i class="fa fa-check"></i><b>5.4.3</b> Summarizing the results</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#validating-the-model-parameter-recovery"><i class="fa fa-check"></i><b>5.5</b> Validating the Model: Parameter Recovery</a></li>
<li class="chapter" data-level="5.6" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#moving-beyond-simple-bias-memory-models"><i class="fa fa-check"></i><b>5.6</b> Moving Beyond Simple Bias: Memory Models</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#memory-model-1-glm-like-approach-external-predictor"><i class="fa fa-check"></i><b>5.6.1</b> Memory Model 1: GLM-like Approach (External Predictor)</a></li>
<li class="chapter" data-level="5.6.2" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#summarizing-the-results-1"><i class="fa fa-check"></i><b>5.6.2</b> Summarizing the results</a></li>
<li class="chapter" data-level="5.6.3" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#memory-model-2-internal-state-variable"><i class="fa fa-check"></i><b>5.6.3</b> Memory Model 2: Internal State Variable</a></li>
<li class="chapter" data-level="5.6.4" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#memory-model-3-exponential-forgetting-relation-to-rl"><i class="fa fa-check"></i><b>5.6.4</b> Memory Model 3: Exponential Forgetting (Relation to RL)</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#memory-model-4-bayesian-agent-optimal-updating"><i class="fa fa-check"></i><b>5.7</b> Memory Model 4: Bayesian Agent (Optimal Updating)</a></li>
<li class="chapter" data-level="5.8" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#relationship-to-rescorla-wagner"><i class="fa fa-check"></i><b>5.8</b> Relationship to Rescorla-Wagner</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#connection-to-kalman-filters"><i class="fa fa-check"></i><b>5.8.1</b> Connection to Kalman Filters</a></li>
<li class="chapter" data-level="5.8.2" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#connection-to-hierarchical-gaussian-filter-hgf"><i class="fa fa-check"></i><b>5.8.2</b> Connection to Hierarchical Gaussian Filter (HGF)</a></li>
<li class="chapter" data-level="5.8.3" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#implications-for-model-development"><i class="fa fa-check"></i><b>5.8.3</b> Implications for Model Development</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="from-simulation-to-model-fitting.html"><a href="from-simulation-to-model-fitting.html#conclusion-estimating-parameters-and-exploring-memory"><i class="fa fa-check"></i><b>5.9</b> Conclusion: Estimating Parameters and Exploring Memory</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Cognitive Modeling Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="building-models-of-strategic-decision-making" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Building Models of Strategic Decision-Making<a href="building-models-of-strategic-decision-making.html#building-models-of-strategic-decision-making" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>You’ve just played Matching Pennies and discussed strategies with your classmates. You probably noticed patterns in your opponent’s play, tried to be unpredictable, and maybe even changed your strategy mid-game. This chapter helps you translate those observations and intuitions into the language of cognitive modeling—preparing you to implement formal models in Chapter 3.</p>
<div id="learning-goals" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Learning Goals<a href="building-models-of-strategic-decision-making.html#learning-goals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This chapter bridges the gap between observing behavior and developing testable theories. By the end of this chapter, using the Matching Pennies game as a case study, you will be able to:</p>
<ul>
<li><strong>Identify Key Modeling Steps:</strong> Understand the process of moving from behavioral observations and participant reflections to formulating initial verbal theories of underlying cognitive strategies.</li>
<li><strong>Appreciate Theory Building Challenges:</strong> Recognize common issues in theory development, such as the participant vs. researcher perspective, the need for simplification, and incorporating known cognitive constraints.</li>
<li><strong>Conceptualize Learning Mechanisms:</strong> Propose distinct models (e.g., random choice, heuristics, RL) and organize them into a unified framework based on how they process prediction errors.</li>
<li><strong>Connect to Formalization:</strong> Understand the “Update Rule” (<span class="math inline">\(\text{New} = \text{Old} + \text{Learning Rate} \times \text{Error}\)</span>) as a universal grammar of learning that connects simple heuristics to complex cognitive strategies.</li>
</ul>
</div>
<div id="introduction-observing-behavior-to-theorize-mechanisms" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Introduction: Observing Behavior to Theorize Mechanisms<a href="building-models-of-strategic-decision-making.html#introduction-observing-behavior-to-theorize-mechanisms" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Chapter 1 emphasized the importance of modeling underlying generative mechanisms. To do this for cognition, we first need a behavior to explain. This chapter uses the <strong>Matching Pennies game</strong> as our initial cognitive phenomenon. It’s a simple strategic interaction, yet rich enough to illustrate the process of developing and refining cognitive models.</p>
<p>Our goal here is not yet to build the final computational models, but to practice the crucial preceding steps:</p>
<ol style="list-style-type: decimal">
<li><p>Observing behavior in a specific task (through experiments and data exploration).</p></li>
<li><p>Reflecting on potential cognitive strategies and constraints (drawing on observations, participant reports, and cognitive science principles).</p></li>
<li><p>Formulating initial <em>verbal</em> theories or candidate models that describe the potential underlying mechanisms.</p></li>
</ol>
<p>This process lays the groundwork for Chapter 3, where we will translate these verbal ideas into precise, formal models ready for simulation and testing.</p>
</div>
<div id="the-matching-pennies-game" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> The Matching Pennies Game<a href="building-models-of-strategic-decision-making.html#the-matching-pennies-game" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the matching pennies game, two players engage in a series of choices. One player attempts to match the other’s choice, while the other player aims to achieve a mismatch, and they repeatedly play with each other. This is a prototypical example of interacting behaviors that are usually tackled by game theory, and bring up issues of theory of mind and recursivity.</p>
<p>For an introduction see the paper: Waade, Peter T., et al. “Introducing tomsup: Theory of mind simulations using Python.” Behavior Research Methods 55.5 (2023): 2197-2231.</p>
<p>For fun data involving different kinds of primates playing the game, see: Devaine, M., San-Galli, A., Trapanese, C., Bardino, G., Hano, C., Saint Jalme, M., … &amp; Daunizeau, J. (2017). Reading wild minds: a computational assay of theory of mind sophistication across seven primate species. PLoS computational biology, 13(11), e1005833. The data is available in Assignment 2 (for the students at AU/CogSci).</p>
</div>
<div id="game-structure" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Game Structure<a href="building-models-of-strategic-decision-making.html#game-structure" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The game proceeds as follows:</p>
<ol style="list-style-type: decimal">
<li>Two players sit facing each other</li>
<li>Each round, both players choose either “left” or “right” to indicate where they believe a penny is hidden</li>
<li>The matcher wins by choosing the same hand as their opponent</li>
<li>The hider wins by choosing the opposite hand</li>
<li>Points are awarded: +1 for winning, -1 (or 0, depending on the version) for losing</li>
<li>Repeat</li>
</ol>
<p>This simple structure creates a rich environment for studying decision-making strategies, learning, and adaptation.</p>
</div>
<div id="empirical-investigation" class="section level2 hasAnchor" number="3.5">
<h2><span class="header-section-number">3.5</span> Empirical Investigation<a href="building-models-of-strategic-decision-making.html#empirical-investigation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="data-collection-protocol" class="section level3 hasAnchor" number="3.5.1">
<h3><span class="header-section-number">3.5.1</span> Data Collection Protocol<a href="building-models-of-strategic-decision-making.html#data-collection-protocol" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>[NOTES FOR FUTURE YEARS: MAYBE REPLACE WITH THE PRIMATE DATA?]</p>
<p>If you are attending my class you have been (or will be) asked to participate in a matching pennies game. This game provides the foundation for our modeling efforts. By observing gameplay and collecting data, we can develop models that capture the cognitive processes underlying decision-making in strategic situations.</p>
<p>Participants play 30 rounds as the matcher and 30 rounds as the hider, allowing us to observe behavior in both roles. While playing, participants track their scores, which can provide quantitative data for later analysis. Participants are also asked to reflect on their strategies and the strategies they believe their opponents are using, as that provides valuable materials to build models on.</p>
</div>
<div id="initial-observations" class="section level3 hasAnchor" number="3.5.2">
<h3><span class="header-section-number">3.5.2</span> Initial Observations<a href="building-models-of-strategic-decision-making.html#initial-observations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Through the careful observation and discussion of gameplay we do in class, several patterns typically emerge. For instance, players often demonstrate strategic adaptation, adjusting their choices based on their opponent’s previous moves. They may attempt to identify patterns in their opponent’s behavior while trying to make their own choices less predictable. The tension between exploitation of perceived patterns and maintenance of unpredictability creates fascinating dynamics for modeling.</p>
</div>
</div>
<div id="empirical-explorations" class="section level2 hasAnchor" number="3.6">
<h2><span class="header-section-number">3.6</span> Empirical explorations<a href="building-models-of-strategic-decision-making.html#empirical-explorations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Below you can observe how a previous year of CogSci did against bots (computational agents) playing according to different strategies. Look at the plots below, where the x axes indicate trial, the y axes how many points the CogSci’ers scored (0 being chance, negative means being completely owned by the bots, positive owning the bot) and the different colors indicate different strategies employed by the bots. Strategy “-2” was a Win-Stay-Lose-Shift bot: when it got a +1, it repeated its previous move (e.g. right if it had just played right), otherwise it would perform the opposite move (e.g. left if it had just played right). Strategy “-1” was a biased Nash both, playing “right” 80% of the time. Strategy “0” indicates a reinforcement learning bot; “1” a bot assuming you were playing according to a reinforcement learning strategy and trying to infer your learning and temperature parameters; “2” a bot assuming you were following strategy “1” and trying to accordingly infer your parameters.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="building-models-of-strategic-decision-making.html#cb18-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb18-2"><a href="building-models-of-strategic-decision-making.html#cb18-2" tabindex="-1"></a></span>
<span id="cb18-3"><a href="building-models-of-strategic-decision-making.html#cb18-3" tabindex="-1"></a><span class="co"># --- 1. Data Loading / Generation ---</span></span>
<span id="cb18-4"><a href="building-models-of-strategic-decision-making.html#cb18-4" tabindex="-1"></a>data_path <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;MP_MSc_CogSci22.csv&quot;</span>)</span>
<span id="cb18-5"><a href="building-models-of-strategic-decision-making.html#cb18-5" tabindex="-1"></a></span>
<span id="cb18-6"><a href="building-models-of-strategic-decision-making.html#cb18-6" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">file.exists</span>(data_path)) {</span>
<span id="cb18-7"><a href="building-models-of-strategic-decision-making.html#cb18-7" tabindex="-1"></a>  d <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(data_path)</span>
<span id="cb18-8"><a href="building-models-of-strategic-decision-making.html#cb18-8" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb18-9"><a href="building-models-of-strategic-decision-making.html#cb18-9" tabindex="-1"></a>  <span class="co"># Generate synthetic data if file is missing (Reproducibility check)</span></span>
<span id="cb18-10"><a href="building-models-of-strategic-decision-making.html#cb18-10" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb18-11"><a href="building-models-of-strategic-decision-making.html#cb18-11" tabindex="-1"></a>  n_students <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb18-12"><a href="building-models-of-strategic-decision-making.html#cb18-12" tabindex="-1"></a>  n_trials <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb18-13"><a href="building-models-of-strategic-decision-making.html#cb18-13" tabindex="-1"></a>  strategies <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb18-14"><a href="building-models-of-strategic-decision-making.html#cb18-14" tabindex="-1"></a>  d <span class="ot">&lt;-</span> <span class="fu">expand_grid</span>(</span>
<span id="cb18-15"><a href="building-models-of-strategic-decision-making.html#cb18-15" tabindex="-1"></a>    <span class="at">ID =</span> <span class="fu">factor</span>(<span class="dv">1</span><span class="sc">:</span>n_students),</span>
<span id="cb18-16"><a href="building-models-of-strategic-decision-making.html#cb18-16" tabindex="-1"></a>    <span class="at">BotStrategy =</span> strategies,</span>
<span id="cb18-17"><a href="building-models-of-strategic-decision-making.html#cb18-17" tabindex="-1"></a>    <span class="at">Role =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="co"># 0=Matcher, 1=Hider</span></span>
<span id="cb18-18"><a href="building-models-of-strategic-decision-making.html#cb18-18" tabindex="-1"></a>    <span class="at">Trial =</span> <span class="dv">1</span><span class="sc">:</span>n_trials</span>
<span id="cb18-19"><a href="building-models-of-strategic-decision-making.html#cb18-19" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb18-20"><a href="building-models-of-strategic-decision-making.html#cb18-20" tabindex="-1"></a>    <span class="fu">mutate</span>(</span>
<span id="cb18-21"><a href="building-models-of-strategic-decision-making.html#cb18-21" tabindex="-1"></a>      <span class="co"># Random payoffs for demonstration</span></span>
<span id="cb18-22"><a href="building-models-of-strategic-decision-making.html#cb18-22" tabindex="-1"></a>      <span class="at">Payoff =</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="fu">n</span>(), <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.45</span>, <span class="fl">0.55</span>))</span>
<span id="cb18-23"><a href="building-models-of-strategic-decision-making.html#cb18-23" tabindex="-1"></a>    )</span>
<span id="cb18-24"><a href="building-models-of-strategic-decision-making.html#cb18-24" tabindex="-1"></a>  <span class="fu">warning</span>(<span class="st">&quot;Using synthetic data for demonstration.&quot;</span>)</span>
<span id="cb18-25"><a href="building-models-of-strategic-decision-making.html#cb18-25" tabindex="-1"></a>}</span>
<span id="cb18-26"><a href="building-models-of-strategic-decision-making.html#cb18-26" tabindex="-1"></a></span>
<span id="cb18-27"><a href="building-models-of-strategic-decision-making.html#cb18-27" tabindex="-1"></a><span class="co"># --- 2. Data Cleaning (Crucial Step!) ---</span></span>
<span id="cb18-28"><a href="building-models-of-strategic-decision-making.html#cb18-28" tabindex="-1"></a><span class="co"># Map cryptic codes to human-readable labels</span></span>
<span id="cb18-29"><a href="building-models-of-strategic-decision-making.html#cb18-29" tabindex="-1"></a>bot_labels <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb18-30"><a href="building-models-of-strategic-decision-making.html#cb18-30" tabindex="-1"></a>  <span class="st">&quot;-2&quot;</span> <span class="ot">=</span> <span class="st">&quot;WSLS Bot&quot;</span>,</span>
<span id="cb18-31"><a href="building-models-of-strategic-decision-making.html#cb18-31" tabindex="-1"></a>  <span class="st">&quot;-1&quot;</span> <span class="ot">=</span> <span class="st">&quot;Bias Bot (80%)&quot;</span>,</span>
<span id="cb18-32"><a href="building-models-of-strategic-decision-making.html#cb18-32" tabindex="-1"></a>  <span class="st">&quot;0&quot;</span>  <span class="ot">=</span> <span class="st">&quot;RL Bot&quot;</span>,</span>
<span id="cb18-33"><a href="building-models-of-strategic-decision-making.html#cb18-33" tabindex="-1"></a>  <span class="st">&quot;1&quot;</span>  <span class="ot">=</span> <span class="st">&quot;ToM-1 Bot&quot;</span>,</span>
<span id="cb18-34"><a href="building-models-of-strategic-decision-making.html#cb18-34" tabindex="-1"></a>  <span class="st">&quot;2&quot;</span>  <span class="ot">=</span> <span class="st">&quot;ToM-2 Bot&quot;</span></span>
<span id="cb18-35"><a href="building-models-of-strategic-decision-making.html#cb18-35" tabindex="-1"></a>)</span>
<span id="cb18-36"><a href="building-models-of-strategic-decision-making.html#cb18-36" tabindex="-1"></a></span>
<span id="cb18-37"><a href="building-models-of-strategic-decision-making.html#cb18-37" tabindex="-1"></a>d_clean <span class="ot">&lt;-</span> d <span class="sc">%&gt;%</span></span>
<span id="cb18-38"><a href="building-models-of-strategic-decision-making.html#cb18-38" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb18-39"><a href="building-models-of-strategic-decision-making.html#cb18-39" tabindex="-1"></a>    <span class="co"># Make BotStrategy a factor with meaningful names</span></span>
<span id="cb18-40"><a href="building-models-of-strategic-decision-making.html#cb18-40" tabindex="-1"></a>    <span class="at">BotStrategy =</span> <span class="fu">factor</span>(BotStrategy, </span>
<span id="cb18-41"><a href="building-models-of-strategic-decision-making.html#cb18-41" tabindex="-1"></a>                         <span class="at">levels =</span> <span class="fu">names</span>(bot_labels), </span>
<span id="cb18-42"><a href="building-models-of-strategic-decision-making.html#cb18-42" tabindex="-1"></a>                         <span class="at">labels =</span> bot_labels),</span>
<span id="cb18-43"><a href="building-models-of-strategic-decision-making.html#cb18-43" tabindex="-1"></a>    <span class="co"># Make Role a factor</span></span>
<span id="cb18-44"><a href="building-models-of-strategic-decision-making.html#cb18-44" tabindex="-1"></a>    <span class="at">Role =</span> <span class="fu">factor</span>(Role, <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Matcher&quot;</span>, <span class="st">&quot;Hider&quot;</span>))</span>
<span id="cb18-45"><a href="building-models-of-strategic-decision-making.html#cb18-45" tabindex="-1"></a>  )</span>
<span id="cb18-46"><a href="building-models-of-strategic-decision-making.html#cb18-46" tabindex="-1"></a></span>
<span id="cb18-47"><a href="building-models-of-strategic-decision-making.html#cb18-47" tabindex="-1"></a><span class="co"># --- 3. Plot Collective Performance ---</span></span>
<span id="cb18-48"><a href="building-models-of-strategic-decision-making.html#cb18-48" tabindex="-1"></a><span class="fu">ggplot</span>(d_clean, <span class="fu">aes</span>(<span class="at">x =</span> Trial, <span class="at">y =</span> Payoff, <span class="at">color =</span> BotStrategy)) <span class="sc">+</span></span>
<span id="cb18-49"><a href="building-models-of-strategic-decision-making.html#cb18-49" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="at">span =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb18-50"><a href="building-models-of-strategic-decision-making.html#cb18-50" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb18-51"><a href="building-models-of-strategic-decision-making.html#cb18-51" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>Role) <span class="sc">+</span></span>
<span id="cb18-52"><a href="building-models-of-strategic-decision-making.html#cb18-52" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb18-53"><a href="building-models-of-strategic-decision-making.html#cb18-53" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Human vs. Machine: Average Performance&quot;</span>,</span>
<span id="cb18-54"><a href="building-models-of-strategic-decision-making.html#cb18-54" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">&quot;Positive values indicate humans winning against bots&quot;</span>,</span>
<span id="cb18-55"><a href="building-models-of-strategic-decision-making.html#cb18-55" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Average Payoff&quot;</span>,</span>
<span id="cb18-56"><a href="building-models-of-strategic-decision-making.html#cb18-56" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&quot;Opponent Strategy&quot;</span></span>
<span id="cb18-57"><a href="building-models-of-strategic-decision-making.html#cb18-57" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb18-58"><a href="building-models-of-strategic-decision-making.html#cb18-58" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb18-59"><a href="building-models-of-strategic-decision-making.html#cb18-59" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span></code></pre></div>
<p><img src="series_files/figure-html/02-load-and-clean-data-1.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<p>That doesn’t look too good, ah? What about individual variability? In the plot below we indicate the score of each of the former students, against the different bots.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="building-models-of-strategic-decision-making.html#cb19-1" tabindex="-1"></a><span class="co"># --- Plot 2: Individual Variability in Scores ---</span></span>
<span id="cb19-2"><a href="building-models-of-strategic-decision-making.html#cb19-2" tabindex="-1"></a><span class="co"># Calculate the total score for each student (ID) against each bot strategy.</span></span>
<span id="cb19-3"><a href="building-models-of-strategic-decision-making.html#cb19-3" tabindex="-1"></a>d_summary <span class="ot">&lt;-</span> d <span class="sc">%&gt;%</span></span>
<span id="cb19-4"><a href="building-models-of-strategic-decision-making.html#cb19-4" tabindex="-1"></a>  <span class="fu">group_by</span>(ID, BotStrategy, Role) <span class="sc">%&gt;%</span> <span class="co"># Group by student, bot, and role</span></span>
<span id="cb19-5"><a href="building-models-of-strategic-decision-making.html#cb19-5" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">TotalScore =</span> <span class="fu">sum</span>(Payoff), <span class="at">.groups =</span> <span class="st">&quot;drop&quot;</span>) <span class="co"># Calculate total score</span></span>
<span id="cb19-6"><a href="building-models-of-strategic-decision-making.html#cb19-6" tabindex="-1"></a></span>
<span id="cb19-7"><a href="building-models-of-strategic-decision-making.html#cb19-7" tabindex="-1"></a><span class="co"># Visualize the distribution of total scores for each bot strategy.</span></span>
<span id="cb19-8"><a href="building-models-of-strategic-decision-making.html#cb19-8" tabindex="-1"></a><span class="co"># geom_boxplot shows the distribution, geom_point shows individual student scores.</span></span>
<span id="cb19-9"><a href="building-models-of-strategic-decision-making.html#cb19-9" tabindex="-1"></a><span class="fu">print</span>(</span>
<span id="cb19-10"><a href="building-models-of-strategic-decision-making.html#cb19-10" tabindex="-1"></a>  <span class="fu">ggplot</span>(d_summary, <span class="fu">aes</span>(<span class="at">x =</span> BotStrategy, <span class="at">y =</span> TotalScore)) <span class="sc">+</span></span>
<span id="cb19-11"><a href="building-models-of-strategic-decision-making.html#cb19-11" tabindex="-1"></a>    <span class="fu">geom_boxplot</span>(<span class="fu">aes</span>(<span class="at">fill =</span> Role), <span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">outlier.shape =</span> <span class="cn">NA</span>) <span class="sc">+</span> <span class="co"># Boxplot showing distribution</span></span>
<span id="cb19-12"><a href="building-models-of-strategic-decision-making.html#cb19-12" tabindex="-1"></a>    <span class="fu">geom_jitter</span>(<span class="fu">aes</span>(<span class="at">color =</span> ID), <span class="at">width =</span> <span class="fl">0.2</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span> <span class="co"># Individual student points</span></span>
<span id="cb19-13"><a href="building-models-of-strategic-decision-making.html#cb19-13" tabindex="-1"></a>    <span class="fu">facet_wrap</span>(<span class="sc">~</span>Role) <span class="sc">+</span> <span class="co"># Separate plots for Matcher and Hider</span></span>
<span id="cb19-14"><a href="building-models-of-strategic-decision-making.html#cb19-14" tabindex="-1"></a>    <span class="fu">labs</span>(</span>
<span id="cb19-15"><a href="building-models-of-strategic-decision-making.html#cb19-15" tabindex="-1"></a>      <span class="at">title =</span> <span class="st">&quot;Distribution of Total Scores Against Different Bots&quot;</span>,</span>
<span id="cb19-16"><a href="building-models-of-strategic-decision-making.html#cb19-16" tabindex="-1"></a>      <span class="at">subtitle =</span> <span class="st">&quot;Shows individual student variability&quot;</span>,</span>
<span id="cb19-17"><a href="building-models-of-strategic-decision-making.html#cb19-17" tabindex="-1"></a>      <span class="at">x =</span> <span class="st">&quot;Bot Strategy&quot;</span>,</span>
<span id="cb19-18"><a href="building-models-of-strategic-decision-making.html#cb19-18" tabindex="-1"></a>      <span class="at">y =</span> <span class="st">&quot;Total Score (Sum of Payoffs)&quot;</span>,</span>
<span id="cb19-19"><a href="building-models-of-strategic-decision-making.html#cb19-19" tabindex="-1"></a>      <span class="at">fill =</span> <span class="st">&quot;Player Role&quot;</span></span>
<span id="cb19-20"><a href="building-models-of-strategic-decision-making.html#cb19-20" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb19-21"><a href="building-models-of-strategic-decision-making.html#cb19-21" tabindex="-1"></a>    <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb19-22"><a href="building-models-of-strategic-decision-making.html#cb19-22" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) <span class="co"># Hide legend for individual IDs</span></span>
<span id="cb19-23"><a href="building-models-of-strategic-decision-making.html#cb19-23" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="series_files/figure-html/02%20plot%20individual%20performance%20in%20MP-1.png" alt="" width="80%" style="display: block; margin: auto;" /></p>
<div id="from-observation-to-theory-identifying-potential-mechanisms" class="section level3 hasAnchor" number="3.6.1">
<h3><span class="header-section-number">3.6.1</span> From Observation to Theory: Identifying Potential Mechanisms<a href="building-models-of-strategic-decision-making.html#from-observation-to-theory-identifying-potential-mechanisms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The plots above reveal patterns: average performance changes over time, varies by opponent, and differs across individuals. Gameplay observations and participant reflections (from class discussion or collected data) add qualitative insights – perhaps players mention trying to be unpredictable, guessing opponent biases, or repeating winning moves.</p>
<p>The crucial next step is to distill these rich, complex observations into simplified, plausible <strong>mechanisms</strong> or <strong>strategies</strong>. This involves abstraction:</p>
<ul>
<li><p><strong>Identifying Core Patterns:</strong> What recurring behaviors seem most important? (e.g., reacting to wins/losses, tracking opponent frequencies).</p></li>
<li><p><strong>Simplifying:</strong> Can we capture the essence of a strategy without modeling every detail of a player’s thought process or interaction? (e.g., modeling just previous behaviors as possible inputs, instead of complex patterns in face expressions or movements that real humans likely use when trying to guess which hand has the penny).</p></li>
<li><p><strong>Drawing on Cognitive Principles:</strong> How do known cognitive constraints (like limited memory or processing errors) shape plausible strategies?</p></li>
</ul>
<p>For instance, observing that players often change their choice after a loss might lead us to propose a “If Lose Then Shift” component as part of a candidate model. Observing that performance differs against biased vs. adaptive bots suggests players might be trying to learn or adapt, leading to memory-based or learning models.</p>
<p>This process generates <em>verbal models</em> – initial hypotheses about the strategies at play. Key modeling considerations guide this translation:</p>
<ul>
<li><p>What information do players likely use? (Own past choices? Opponent’s choices? Payoffs?)</p></li>
<li><p>How far back does memory plausibly extend? (Last trial? Last 5 trials? Exponential decay?)</p></li>
<li><p>What is the role of randomness? (True randomness? Exploration? Implementation errors?)</p></li>
<li><p>How might strategies adapt over time or differ between individuals?</p></li>
</ul>
<p>Answering these helps refine our verbal models, paving the way for formalization. The goal isn’t to capture everything, but to propose distinct, testable mechanisms.</p>
</div>
<div id="the-distinction-between-participant-and-researcher-perspectives" class="section level3 hasAnchor" number="3.6.2">
<h3><span class="header-section-number">3.6.2</span> The distinction between participant and researcher perspectives<a href="building-models-of-strategic-decision-making.html#the-distinction-between-participant-and-researcher-perspectives" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As participants we might not be aware of the strategy we use, or we might believe something erroneous. The exercise here is to act as researchers: what are the principles underlying the participants’ behaviors, no matter what the participants know or believe? Note that talking to participants and being participants helps developing ideas, but it’s not the end point of the process. Also note that as cognitive scientists we can rely on what we have learned about cognitive processes (e.g. memory).</p>
<p>Another important component of the distinction is that participants leave in a rich world: they rely on facial expressions and bodily posture, the switch strategies, etc. On the other hand, the researcher is trying to identify one or few at most “simple” strategies. Rich bodily interactions and mixtures or sequences of multiple strategies are not a good place to start modeling. These aspects are a poor starting point for building your first model, and are often pretty difficult to fit to empirical data. Nevertheless, they are important intuitions that the researcher should (eventually?) accommodate.</p>
</div>
</div>
<div id="candidate-models-a-hierarchy-of-cognitive-complexity" class="section level2 hasAnchor" number="3.7">
<h2><span class="header-section-number">3.7</span> Candidate Models: A Hierarchy of Cognitive Complexity<a href="building-models-of-strategic-decision-making.html#candidate-models-a-hierarchy-of-cognitive-complexity" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Based on behavioral observations and cognitive principles, the many discussions in class during the years have advanced a variety of models, which I’m here organizing into a hierarchy based on their conception of learning.
We start with simple agents that ignore history, move to learning agents that track first average outcomes, then also uncertainty and volatility, and conclude with strategic agents that model the opponent’s mind. To make their conceptual continuity more explicit, I couldn’t resist adding some discussion of the math behind the verbal intuitions and pointing to how each model can be recast in terms of an update rule: <span class="math display">\[\text{New Belief} = \text{Old Belief} + \text{Learning Rate} \cdot \text{Predictive Error}\]</span>. This format unifies the different models under a common mathematical framework, making it easier to understand their relationships and differences.</p>
<p>Also note that in the formula below, ‘Belief’ is a placeholder. If we are modeling a coin flipper, the belief is a probability (<span class="math inline">\(\theta\)</span>). If we are modeling betting, it might be an expected reward value (<span class="math inline">\(V\)</span>). If we are modeling playing strategies, it might be a prediction of the opponent’s move. As it should be obvious, those are partially overlapping conceptualizations.</p>
<div id="level-0-the-static-agent-no-learning" class="section level3 hasAnchor" number="3.7.1">
<h3><span class="header-section-number">3.7.1</span> Level 0: The Static Agent (No Learning)<a href="building-models-of-strategic-decision-making.html#level-0-the-static-agent-no-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The simplest assumption is that the agent does not learn or adapt to the opponent at all.
They simply act according to a fixed internal preference.</p>
</div>
<div id="the-biased-agent-random-choice" class="section level3 hasAnchor" number="3.7.2">
<h3><span class="header-section-number">3.7.2</span> The Biased Agent (Random Choice):<a href="building-models-of-strategic-decision-making.html#the-biased-agent-random-choice" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><em>Concept</em>: The agent is a biased coin flipper. They have a static preference (e.g., “I generally prefer Right”) that does not change over time.</p></li>
<li><p><em>Traditional Formulation (Bernoulli Process)</em>: We model the choice <span class="math inline">\(y_t\)</span> at trial <span class="math inline">\(t\)</span> as a draw from a Bernoulli distribution with a fixed rate parameter <span class="math inline">\(\theta\)</span>: <span class="math display">\[y_t \sim \text{Bernoulli}(\theta)\]</span></p></li>
<li><p><em>The “Update” Rule</em>: Because this agent is static, there is no update rule, in other words, a learning of 0. The parameter <span class="math inline">\(\theta\)</span> remains constant regardless of wins or losses. <span class="math display">\[\theta_{t+1} = \theta_{t} + \text{Learning Rate} \cdot \text{Predictive Error}\]</span> where <span class="math inline">\(\text{Learning Rate} = 0\)</span> and therefore the formula reduces to <span class="math display">\[\theta_{t+1} = \theta_{t}\]</span>.</p></li>
<li><p><em>Variable Definitions</em>:</p>
<ul>
<li><span class="math inline">\(y_t \in \{0, 1\}\)</span>: The choice (e.g., Left/Right).</li>
<li><span class="math inline">\(\theta \in [0, 1]\)</span>: The fixed probability of choosing 1 (bias).</li>
</ul></li>
<li><p><em>Looking Ahead</em>: This model might seem too simple to be useful, but never underestimate the power of null models! In a study using k-ToM models (see below), we realized that for k = 6 or above, the model behaved in a way that was practically indistinguishabe from a biased agent. Also, a simple model allows us to build skills in reasonable steps. In the next chapter, we will write code to simulate data according to these models and in the following chapter, we will then learn how to take a sequence of choices and mathematically work backwards to find the most likely value of the model parameters. In all these cases, being able to start with a simple model is crucial to build intuition and skills before moving to more complex models.</p></li>
</ul>
<p>[FIND REF OF PAPER USING THIS]</p>
</div>
<div id="level-1-heuristics-the-immediate-past" class="section level3 hasAnchor" number="3.7.3">
<h3><span class="header-section-number">3.7.3</span> Level 1: Heuristics &amp; The Immediate Past<a href="building-models-of-strategic-decision-making.html#level-1-heuristics-the-immediate-past" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The next step up is an agent that learns minimally: it reacts to feedback but has a “memory” of only one trial.</p>
<div id="deterministic-win-stay-lose-shift-wsls" class="section level4 hasAnchor" number="3.7.3.1">
<h4><span class="header-section-number">3.7.3.1</span> Deterministic Win-Stay-Lose-Shift (WSLS):<a href="building-models-of-strategic-decision-making.html#deterministic-win-stay-lose-shift-wsls" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p><em>Concept</em>: A rigid heuristic: “If I won, I do the same thing. If I lost, I switch.” This can be viewed as an agent with zero memory who effectively “re-learns” the world from scratch after every single feedback.</p></li>
<li><p><em>Traditional Formulation (Conditional Probability)</em>: <span class="math display">\[P(y_t = y_{t-1} | outcome_{t-1}) = \begin{cases} 1 &amp; \text{if } outcome_{t-1} = \text{win} \\ 0 &amp; \text{if } outcome_{t-1} = \text{loss} \end{cases}\]</span></p></li>
<li><p><em>The “Update” Rule</em>: We can treat the “Probability of Staying” (<span class="math inline">\(P_{stay}\)</span>) as a value that is updated trial-by-trial.<span class="math display">\[P_{stay, t+1} = P_{stay, t} + \text{Learning Rate} \cdot (Outcome_t - P_{stay, t})\]</span> Where <span class="math inline">\(\text{Learning Rate} = 1\)</span>. Because the agent learns instantly from the immediate past, the formula reduces to: <span class="math display">\[P_{stay, t+1} = P_{stay, t} + 1 \cdot (Outcome_t - P_{stay, t})\]</span><span class="math display">\[P_{stay, t+1} = Outcome_t\]</span></p>
<ul>
<li>Implication: If the outcome was a Win (<span class="math inline">\(1\)</span>), the probability of staying becomes <span class="math inline">\(1\)</span>. If the outcome was a Loss (<span class="math inline">\(0\)</span>), the probability of staying becomes <span class="math inline">\(0\)</span>. This mathematically formalizes the idea of “instant forgetting.”</li>
</ul></li>
<li><p><em>Variable Definitions</em>:<span class="math inline">\(outcome_{t-1}\)</span>: <span class="math inline">\(outcome_{t-1} \in \{0, 1\}\)</span>: The feedback from the previous trial, where 1 = Win and 0 = Loss</p></li>
<li><p><em>Note: The Physics View (Ising Formulation)</em> [only for nerds]: While we typically code choices as 0/1 for logistic regression, physicists and network theorists often code binary states as “spins”: -1 (Left) and +1 (Right). If we also code the outcome as -1 (Loss) and +1 (Win), the WSLS update rule becomes mathematically elegant: <span class="math display">\[y_t = outcome_{t-1} \cdot y_{t-1}\]</span> Why does this work? If Win (+1): The equation becomes <span class="math inline">\(y_t = 1 \cdot y_{t-1}\)</span>. The sign stays the same (Stay). If Loss (-1): The equation becomes <span class="math inline">\(y_t = -1 \cdot y_{t-1}\)</span>. The sign flips (Shift). This formulation highlights that “shifting” is mathematically equivalent to sign inversion. This connects cognitive shifting to “spin glass” or ising models in physics (e.g., Stephens &amp; Bialek, 2010), and is useful to know of it as it sometimes simplifies the mathematical equations of your models.</p></li>
</ul>
<p>[FIND REF OF PAPERS USING THIS MODES]</p>
</div>
<div id="probabilistic-win-stay-lose-shift-logistic-regression" class="section level4 hasAnchor" number="3.7.3.2">
<h4><span class="header-section-number">3.7.3.2</span> Probabilistic Win-Stay-Lose-Shift (Logistic Regression):<a href="building-models-of-strategic-decision-making.html#probabilistic-win-stay-lose-shift-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p><em>Concept</em>: We relax the strict rule. The agent is more likely to stay after a win and shift after a loss, but real behavior is noisy (stochastic, probabilistic).</p></li>
<li><p><em>Traditional Formulation (GLM)</em>: We define the probability of “staying” (<span class="math inline">\(P_{stay}\)</span>) as a function of the previous outcome using a logistic curve.
<span class="math display">\[P(stay_t) = \text{logit}^{-1}(\beta_0 + \beta_1 \cdot outcome_{t-1})\]</span>.
Note that we can think of the reactions to feedback as symmetric (probability of staying when winning equal to the possibility of shifting when losing), or asymmetric (e.g. the agent might be more sensitive to losses than wins, or vice versa). In the latter case, we’d have an equation like: <span class="math display">\[P(stay_t) = \text{logit}^{-1}(\beta_0 + \beta_1 \cdot win_{t-1} + \beta_2 \cdot loss_{t-1})\]</span></p></li>
<li><p><em>The “Update” Rule</em>: To fit our hierarchy, we treat the agent’s internal Decision Value (<span class="math inline">\(Q\)</span>) as the state being updated.<span class="math display">\[Q_{t+1} = Q_{t} + \text{Learning Rate} \cdot (\text{Target}_t - Q_{t})\]</span>Where <span class="math inline">\(\text{Learning Rate} = 1\)</span> (Instant Update) and the Target is the weighted outcome (<span class="math inline">\(\beta_0 + \beta_1 \cdot outcome_t\)</span>).Reduction:<span class="math display">\[Q_{t+1} = \beta_0 + \beta_1 \cdot outcome_t\]</span>Implication: Just like the Deterministic agent, this agent “forgets” the distant past instantly. However, a “Win” does not guarantee a Stay (<span class="math inline">\(P=1\)</span>); it simply pushes the decision value to a high—but not infinite—number.</p></li>
<li><p><em>Variable Definitions</em>:</p>
<ul>
<li><p><span class="math inline">\(Q\)</span>: The internal log-odds of staying.</p></li>
<li><p><span class="math inline">\(\text{logit}^{-1}(x) = \frac{1}{1+e^{-x}}\)</span>: The sigmoid function mapping value to probability.</p></li>
<li><p><span class="math inline">\(\beta_1\)</span>: Sensitivity to feedback. High <span class="math inline">\(\beta_1\)</span> approximates the deterministic heuristic; <span class="math inline">\(\beta_1 \approx 0\)</span> implies the agent ignores feedback.</p></li>
</ul></li>
</ul>
<p>[FIND REF OF PAPER USING THIS e.g., Zhang &amp; Lee, 2010; Worthy et al., 2013]</p>
</div>
</div>
<div id="level-2-integrating-history-the-moving-average" class="section level3 hasAnchor" number="3.7.4">
<h3><span class="header-section-number">3.7.4</span> Level 2: Integrating History (The Moving Average)<a href="building-models-of-strategic-decision-making.html#level-2-integrating-history-the-moving-average" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Real agents usually care about more than just the last trial. They integrate history over time to form an expectation.</p>
<div id="the-moving-average-windowed-memory" class="section level4 hasAnchor" number="3.7.4.1">
<h4><span class="header-section-number">3.7.4.1</span> The Moving Average (Windowed Memory):<a href="building-models-of-strategic-decision-making.html#the-moving-average-windowed-memory" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p><em>Concept</em>: “I think the future will look like the average of the recent past.”</p></li>
<li><p><em>Traditional Formulation (Batch Average)</em>: <span class="math display">\[V_{t} = \frac{1}{N} \sum_{i=0}^{N-1} Outcome_{t-i}\]</span></p></li>
<li><p><em>Transformation to Update Rule</em>: To avoid recalculating the sum from scratch, we can update the average by adding the new outcome and removing the oldest outcome.<span class="math display">\[V_{t} = V_{t-1} + \frac{1}{N} \cdot (Outcome_{t} - Outcome_{t-N})\]</span></p></li>
<li><p><em>Critique (The Memory Problem)</em>: This formulation reveals a massive cognitive cost. To perform this update, the agent cannot just store the current average (<span class="math inline">\(V_{t-1}\)</span>); they must remember exactly what happened <span class="math inline">\(N\)</span> trials ago (<span class="math inline">\(Outcome_{t-N}\)</span>) to “remove” it from the sum. Further, a memory from 10 trials ago is recalled perfectly, but a memory from 11 trials ago vanishes instantly. This is biologically implausible.</p>
<ul>
<li>The Mismatch: This does not fit the standard “Prediction Error” update rule. It compares the new reality (<span class="math inline">\(Outcome_t\)</span>) to the oldest reality (<span class="math inline">\(Outcome_{t-N}\)</span>), rather than comparing reality to expectation.</li>
</ul></li>
<li><p><em>Variable Definitions</em>:</p>
<ul>
<li><span class="math inline">\(V_t\)</span>: The estimated value (probability of winning/Right) at trial <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(N\)</span>: The window size (e.g., 10 trials).</li>
<li><span class="math inline">\(Outcome_t \in \{0, 1\}\)</span>: The outcome at trial <span class="math inline">\(t\)</span>.</li>
</ul></li>
</ul>
</div>
</div>
<div id="level-3-a-more-elegant-memory-decay-mechanism" class="section level3 hasAnchor" number="3.7.5">
<h3><span class="header-section-number">3.7.5</span> Level 3: A more elegant memory decay mechanism<a href="building-models-of-strategic-decision-making.html#level-3-a-more-elegant-memory-decay-mechanism" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Reinforcement Learning (RL) is mathematically the elegant solution to the Moving Average’s memory problem. It replaces the “perfect memory of <span class="math inline">\(N\)</span> trials” with a “fading memory of everything”.</p>
<div id="from-moving-average-to-rl" class="section level4 hasAnchor" number="3.7.5.1">
<h4><span class="header-section-number">3.7.5.1</span> From Moving Average to RL<a href="building-models-of-strategic-decision-making.html#from-moving-average-to-rl" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>How do we fix the memory problem in Level 2?
The agent cannot remember the specific outcome <span class="math inline">\(Outcome_{t-N}\)</span>. So, they make a guess: “The outcome <span class="math inline">\(N\)</span> trials ago was probably similar to my current average value.”
Mathematically, we substitute <span class="math inline">\(Outcome_{t-N} \approx V_{t-1}\)</span>.
<span class="math display">\[V_{t} = V_{t-1} + \frac{1}{N} (Outcome_{t} - \mathbf{V_{t-1}})\]</span>
If we rename <span class="math inline">\(\frac{1}{N}\)</span> to <span class="math inline">\(\alpha\)</span> (alpha), we get the standard RL rule.</p>
</div>
<div id="reinforcement-learning-rescorla-wagner" class="section level4 hasAnchor" number="3.7.5.2">
<h4><span class="header-section-number">3.7.5.2</span> Reinforcement Learning (Rescorla-Wagner):<a href="building-models-of-strategic-decision-making.html#reinforcement-learning-rescorla-wagner" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p><em>“Traditional Formulation (Exponential Weighted Average)</em>: Instead of a sum over <span class="math inline">\(N\)</span>, value is a weighted sum of all past history, where weights decay geometrically. <span class="math display">\[V_{t} = (1-\alpha) \cdot V_{t-1} + \alpha \cdot Reward_{t}\]</span></p></li>
<li><p><em>Transformation to Update Rule (The Delta Rule)</em>: By rearranging terms, we get the update format I used as template for all models: <span class="math display">\[V_{t} = V_{t-1} + \alpha \cdot (Reward_{t} - V_{t-1})\]</span></p></li>
<li><p><em>Why is this “Learning”?</em> The term <span class="math inline">\((Reward_{t} - V_{t-1})\)</span> is the Prediction Error (PE). The agent compares reality (<span class="math inline">\(Reward\)</span>) to their expectation (<span class="math inline">\(V\)</span>) and nudges their belief by a step size <span class="math inline">\(\alpha\)</span>.</p></li>
<li><p><em>Variable Definitions</em>:</p>
<ul>
<li><span class="math inline">\(V_t\)</span>: The estimated value (e.g., probability of win) at trial <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(\alpha \in [0, 1]\)</span>: The Learning Rate. High <span class="math inline">\(\alpha\)</span> = fast forgetting; Low <span class="math inline">\(\alpha\)</span> = long memory.</li>
<li><span class="math inline">\(PE\)</span>: The difference between what happened and what was expected.</li>
</ul></li>
</ul>
</div>
</div>
<div id="level-4-the-bayesian-update-static-uncertainty" class="section level3 hasAnchor" number="3.7.6">
<h3><span class="header-section-number">3.7.6</span> Level 4: The Bayesian Update (Static Uncertainty)<a href="building-models-of-strategic-decision-making.html#level-4-the-bayesian-update-static-uncertainty" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In RL, the learning rate <span class="math inline">\(\alpha\)</span> is a fixed number. In Bayesian inference, the “learning rate” becomes adaptive based on uncertainty.</p>
<ul>
<li><p><em>Concept</em>: The agent tracks not just the value, but the uncertainty in estimating that value. They weigh new evidence against their prior belief based on how noisy the evidence is versus how solid their prior is.</p></li>
<li><p><em>Traditional Formulation</em>: We combine a Prior distribution (<span class="math inline">\(\mathcal{N}(\mu_{prior}, \sigma^2_{prior})\)</span>) with Likelihood (<span class="math inline">\(\mathcal{N}(Outcome, \sigma^2_{noise})\)</span>) to get a Posterior.<span class="math display">\[\text{Posterior Mean} = \frac{\sigma^2_{noise}\mu_{t-1} + \sigma^2_{t-1}Outcome_t}{\sigma^2_{noise} + \sigma^2_{t-1}}\]</span></p></li>
<li><p><em>Transformation to Update Rule (Kalman Gain)</em>: With some algebra, we can rearrange the posterior mean into our standard “Update + Error” format.<span class="math display">\[\mu_{t} = \mu_{t-1} + K_t \cdot (Outcome_t - \mu_{t-1})\]</span> Here, <span class="math inline">\(K\)</span>, what we called learning rate is often called <span class="math inline">\(Kalman Gain\)</span>: <span class="math display">\[K_t = \frac{\sigma^{2}_{t-1}}{\sigma^{2}_{t-1} + \sigma^{2}_{noise}}\]</span></p></li>
<li><p><em>Variable Definitions</em>:</p>
<ul>
<li><span class="math inline">\(\mu_t\)</span>: The estimated value (mean belief) at trial <span class="math inline">\(t\)</span>.</li>
<li><span class="math inline">\(\sigma^2_{t-1}\)</span>: The uncertainty of the agent’s belief before seeing the outcome (Prior Variance).</li>
<li><span class="math inline">\(\sigma^2_{noise}\)</span>: The uncertainty/noise of the environment (Likelihood Variance).</li>
<li><span class="math inline">\(Outcome_t\)</span>: The observation at trial <span class="math inline">\(t\)</span>.</li>
</ul></li>
<li><p><em>Critique (The Stopping Problem)</em>:</p>
<ul>
<li>The Match: This looks exactly like RL, where <span class="math inline">\(K_t\)</span> replaces <span class="math inline">\(\alpha\)</span>.</li>
<li>The Difference: In this model, the uncertainty <span class="math inline">\(\sigma^2_{t-1}\)</span> decreases after every observation (the agent gets more confident). As <span class="math inline">\(\sigma^2_{t-1} \to 0\)</span>, the gain <span class="math inline">\(K_t \to 0\)</span>.</li>
<li>Implication: The agent eventually stops learning because they become “sure” they know the truth. This is optimal for static worlds, but disastrous if the opponent changes strategy.</li>
</ul></li>
</ul>
</div>
<div id="level-5-the-kalman-filter-dynamic-uncertainty" class="section level3 hasAnchor" number="3.7.7">
<h3><span class="header-section-number">3.7.7</span> Level 5: The Kalman Filter (Dynamic Uncertainty)<a href="building-models-of-strategic-decision-making.html#level-5-the-kalman-filter-dynamic-uncertainty" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Real environments change (volatility). The Kalman Filter extends the Bayesian update by adding a Prediction Step that prevents the agent from becoming “too sure.”</p>
<ul>
<li><p><em>Concept</em>: “The world is not static; it drifts. Even if I was sure yesterday, my knowledge has degraded by today.”</p></li>
<li><p><em>Traditional Formulation (State Space Model)</em>: We assume the true hidden value (<span class="math inline">\(x\)</span>) drifts over time, and that our observations (<span class="math inline">\(y\)</span>) are noisy versions of that drifting value. <span class="math display">\[x_t = x_{t-1} + w_t, \quad w_t \sim \mathcal{N}(0, Q)\]</span><span class="math display">\[y_t = x_t + v_t, \quad v_t \sim \mathcal{N}(0, R)\]</span></p></li>
<li><p><em>Transformation to Update Rule (Two-Step Process)</em>: Unlike the static Bayesian agent, the Kalman agent “inflates” their uncertainty before looking at the data.</p>
<ul>
<li>Predict (Inflate Uncertainty): Before seeing data, the agent assumes the world might have changed. They add Process Noise (<span class="math inline">\(Q\)</span>) to their existing uncertainty. <span class="math display">\[\sigma^2_{prediction} = \sigma^2_{previous} + Q\]</span></li>
<li>Calculate Gain: The “Learning Rate” (<span class="math inline">\(K_t\)</span>) is calculated using this inflated uncertainty.<span class="math display">\[K_{t} = \frac{\sigma^2_{prediction}}{\sigma^2_{prediction} + R}\]</span></li>
<li>Update (The Standard Rule): Finally, we apply the standard error-correction rule. <span class="math display">\[\mu_{t} = \mu_{t-1} + K_t \cdot (Outcome_t - \mu_{t-1})\]</span></li>
</ul></li>
<li><p><em>Variable Definitions</em>:</p>
<ul>
<li><p><span class="math inline">\(Q\)</span>: Process Noise (Volatility). The variance of the drift <span class="math inline">\(w_t\)</span>. High <span class="math inline">\(Q\)</span> means the world changes largely/frequently.</p></li>
<li><p><span class="math inline">\(R\)</span>: Measurement Noise (Observation Uncertainty). Equivalent to <span class="math inline">\(\sigma^2_{noise}\)</span> in Level 4.</p></li>
<li><p><span class="math inline">\(\mu_t\)</span>: The agent’s estimate of the true state <span class="math inline">\(x_t\)</span>.</p></li>
<li><p><span class="math inline">\(\sigma^2_{prediction}\)</span>: The agent’s uncertainty after accounting for volatility but before seeing the new outcome.</p></li>
</ul></li>
<li><p><em>Why this fixes the “Stopping Problem”</em>: In Level 4, <span class="math inline">\(\sigma^2\)</span> shrank to zero, causing learning to stop. Here, because we add <span class="math inline">\(Q\)</span> at every step, <span class="math inline">\(\sigma^2_{prediction}\)</span> never hits zero. Consequently, the learning rate <span class="math inline">\(K_t\)</span> never hits zero. It settles at a dynamic equilibrium—a sweet spot where the agent stays permanently “alert” to changes without over-reacting to noise.</p></li>
</ul>
</div>
<div id="level-6-the-hierarchical-gaussian-filter-meta-learning" class="section level3 hasAnchor" number="3.7.8">
<h3><span class="header-section-number">3.7.8</span> Level 6: The Hierarchical Gaussian Filter (Meta-Learning)<a href="building-models-of-strategic-decision-making.html#level-6-the-hierarchical-gaussian-filter-meta-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Kalman Filter assumes the volatility (<span class="math inline">\(Q\)</span>) is constant. But what if the opponent plays steadily for 20 rounds, then suddenly starts switching wildly? The HGF introduces a hierarchy to track this.</p>
<ul>
<li><p><em>Concept</em>:</p>
<ul>
<li><p>Level 1 (<span class="math inline">\(x_1\)</span>): The value of the stimulus (e.g., probability of “Right”).</p></li>
<li><p>Level 2 (<span class="math inline">\(x_2\)</span>): The volatility of Level 1.</p></li>
<li><p>N.B. we could build more levels (e.g. level 3 would be the meta-volatility, the model belief of how fast to update estimates of volatility)</p></li>
</ul></li>
<li><p><em>Transformation to Update Rule (Volatile Learning Rates)</em>: The update rule for Level 1 looks standard, but the Learning Rate is now a function of Level 2.<span class="math display">\[\mu_{1,t} = \mu_{1,t-1} + K_1 \cdot (Outcome_t - \mu_{1,t-1})\]</span>
Where the Gain <span class="math inline">\(K_1\)</span> depends on the volatility estimate from Level 2:<span class="math display">\[K_1 \approx \frac{\exp(\mu_{2})}{\exp(\mu_{2}) + \sigma^2_{noise}}\]</span></p></li>
<li><p><em>Variable Definitions</em>:</p>
<ul>
<li><span class="math inline">\(\mu_{1}\)</span>: Estimated value (Probability).</li>
<li><span class="math inline">\(\mu_{2}\)</span>: Estimated volatility (Log-volatility).</li>
<li><span class="math inline">\(\exp(\mu_2)\)</span>: The “phasic volatility”—how much the agent expects the world to change right now.</li>
</ul></li>
<li><p><em>Implication</em>:</p>
<ul>
<li>If Level 2 detects high volatility (<span class="math inline">\(x_2 \uparrow\)</span>), the learning rate <span class="math inline">\(K_1\)</span> spikes <span class="math inline">\(\to 1\)</span>.</li>
<li>If Level 2 detects stability (<span class="math inline">\(x_2 \downarrow\)</span>), the learning rate <span class="math inline">\(K_1\)</span> drops <span class="math inline">\(\to 0\)</span>.</li>
<li>Meta-Learning: The agent is not just learning the value; they are learning how fast to learn.</li>
</ul></li>
<li><p><em>Looking Ahead</em>: This model represents the current state-of-the-art in “Ideal Observer” models and has had many interesting applications in cognitive neurosciences (REFS). While the math for inverting this model (Variational Bayes) is complex, the intuition is simple: it is a dynamic learning rate manager. Future chapters (not yet written) might explore the model and its implications and limitations.</p></li>
</ul>
</div>
<div id="level-7-recursive-strategies-theory-of-mind" class="section level3 hasAnchor" number="3.7.9">
<h3><span class="header-section-number">3.7.9</span> Level 7: Recursive Strategies (Theory of Mind)<a href="building-models-of-strategic-decision-making.html#level-7-recursive-strategies-theory-of-mind" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Here is the revised and expanded text for the final sections. I have aligned Level 7 (ToM) with the “Update Rule” framework by clarifying that while the decision is recursive, the learning is a Bayesian update of the opponent’s parameters. I also kept the Mixture Models section as a necessary pedagogical conclusion.</p>
<p>Level 7: Recursive Strategies (Theory of Mind)</p>
<p>Finally, we move from learning about the environment to learning about the agent. This is Theory of Mind (ToM). In our framework, this is formally framed as Recursive Bayesian Learning.</p>
<ul>
<li><p><em>Concept</em>: The agent (<span class="math inline">\(k\)</span>-ToM) does not simply track the pattern of outcomes; they attempt to track the opponent’s hidden strategy.</p>
<ul>
<li>A 0-ToM agent is a simple learner (e.g., the Biased Agent or RL).</li>
<li>A 1-ToM agent simulates a 0-ToM opponent. They ask: “If I were a simple learner observing this history, what would I play next?”</li>
<li>A 2-ToM agent simulates a 1-ToM opponent. They ask: “What does the opponent think I will do?”</li>
</ul></li>
<li><p><em>Traditional Formulation (Recursive Simulation)</em>: The agent holds a “shadow model” of the opponent.
If I am Level <span class="math inline">\(k\)</span>, I assume my opponent is Level <span class="math inline">\(k-1\)</span>. I feed the game history into my internal simulation of them to predict their next move probability (<span class="math inline">\(\hat{p}_{op}\)</span>).</p></li>
<li><p><em>Update Rule (Bayesian Meta-Learning)</em>: Unlike RL, where we update a simple value <span class="math inline">\(V\)</span>, here we update the parameters of the simulated opponent. <span class="math display">\[\text{OpponentModel}_{new} = \text{OpponentModel}_{old} + \text{Learning Rate} \cdot (\text{Prediction Error})\]</span></p>
<ul>
<li><p>Specifics: If I am 1-ToM modeling a 0-ToM opponent (Bias), I use a Bayesian update to refine my estimate of their bias <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>Decision Value: Once the opponent model is updated, the value of my action <span class="math inline">\(a\)</span> is derived from their predicted move: <span class="math display">\[V_{k}(a) \propto P(\text{Opponent plays } \hat{a}_{op} | \text{Opponent is } k-1)\]</span></p></li>
</ul></li>
<li><p><em>Variable Definitions</em>:</p>
<ul>
<li><span class="math inline">\(k\)</span>: The sophistication level. <span class="math inline">\(k=0\)</span> is the baseline; <span class="math inline">\(k=1\)</span> is strategic; <span class="math inline">\(k=2\)</span> is meta-strategic.</li>
<li><span class="math inline">\(\hat{a}_{op}\)</span>: The predicted action of the opponent.(Ref: Devaine, et al., 2014; Waade et al., 2023)</li>
</ul></li>
</ul>
</div>
<div id="handling-heterogeneity-mixture-models" class="section level3 hasAnchor" number="3.7.10">
<h3><span class="header-section-number">3.7.10</span> Handling Heterogeneity: Mixture Models<a href="building-models-of-strategic-decision-making.html#handling-heterogeneity-mixture-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Real behavior is rarely pure. A player might be “Random” when tired but “Strategic” when focused. Or they might switch strategies to confuse the opponent.</p>
<ul>
<li><p><em>Concept</em>: We assume the data is not generated by one single model, but by a probabilistic blend of several.</p></li>
<li><p><em>Traditional Formulation (The Weighted Likelihood)</em>: The likelihood of the observed data <span class="math inline">\(D\)</span> is the weighted sum of the likelihoods from <span class="math inline">\(M\)</span> different candidate strategies. <span class="math display">\[P(D | \Theta) = \sum_{m=1}^{M} w_m \cdot P(D | \text{Model}_m, \theta_m)\]</span></p></li>
<li><p><em>Variable Definitions</em>:<span class="math inline">\(w_m\)</span>: The mixing weight (e.g., 70% RL, 30% Random). Note that <span class="math inline">\(\sum w_m = 1\)</span>.<span class="math inline">\(P(D|\text{Model}_m)\)</span>: How well the specific strategy (e.g., RL) explains the data.</p></li>
<li><p><em>Critique</em> (The Complexity Trap): While realistic, these models are hard to fit. If we allow an agent to switch between 5 different strategies at any moment, the possible combinations of parameter values explaining the same patterns of behavior could explode, making the model underdefined for the data. Sometimes one can be lucky and integrate the “mixed” models into one equation (see an example here: <a href="https://betanalpha.github.io/assets/chapters_html/reading_times.html" class="uri">https://betanalpha.github.io/assets/chapters_html/reading_times.html</a>)</p></li>
</ul>
</div>
<div id="plausibility-check-cognitive-constraints" class="section level3 hasAnchor" number="3.7.11">
<h3><span class="header-section-number">3.7.11</span> Plausibility Check: Cognitive Constraints<a href="building-models-of-strategic-decision-making.html#plausibility-check-cognitive-constraints" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>You probably noticed you couldn’t remember every single move your opponent made. Maybe you lost track of older trials, and recent trials felt more important. These aren’t failures: they’re features of human cognition. Our models should reflect these constraints to be cognitively realistic. Let’s see what difference these constraints make for predictions.</p>
<div id="memory-limitations" class="section level4 hasAnchor" number="3.7.11.1">
<h4><span class="header-section-number">3.7.11.1</span> Memory Limitations<a href="building-models-of-strategic-decision-making.html#memory-limitations" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><em>Constraint:</em> Humans have limited working memory and exhibit forgetting, often approximated by exponential decay. Perfect recall of long trial sequences is unrealistic.</li>
<li><em>Modeling Implication:</em> This favors models incorporating memory decay or finite history windows (like imperfect memory models or RL with a learning rate &lt; 1) over perfect memory models. It suggests that even bias-tracking models should discount older information.</li>
</ul>
</div>
<div id="perseveration-tendencies" class="section level4 hasAnchor" number="3.7.11.2">
<h4><span class="header-section-number">3.7.11.2</span> Perseveration Tendencies<a href="building-models-of-strategic-decision-making.html#perseveration-tendencies" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><em>Constraint:</em> People sometimes exhibit perseveration – repeating a previous action, especially if it was recently successful or chosen, even if a different strategy might suggest otherwise. This can be distinct from rational “win-stay”.</li>
<li><em>Modeling Implication:</em> This might be incorporated as an additional bias parameter influencing the choice probability (e.g., a small added probability of repeating the last action <span class="math inline">\(a_{t-1}\)</span> regardless of outcome) or interact with feedback processing (e.g., strengthening the ‘stay’ tendency after wins).</li>
</ul>
</div>
<div id="noise-and-errors" class="section level4 hasAnchor" number="3.7.11.3">
<h4><span class="header-section-number">3.7.11.3</span> Noise and Errors<a href="building-models-of-strategic-decision-making.html#noise-and-errors" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><em>Constraint:</em> Human behavior is inherently noisy. People make mistakes, have attentional lapses, press the wrong button, or misunderstand feedback. Behavior rarely perfectly matches a deterministic strategy.</li>
<li><em>Modeling Implication:</em> Models should almost always include a “noise” component. This can be implemented in several ways:
<ul>
<li><strong>Lapse Rate:</strong> A probability (e.g., <span class="math inline">\(\epsilon\)</span>) that on any given trial, the agent makes a random choice instead of following their primary strategy (as used in the Mixture Model chapter).</li>
<li><strong>Decision Noise (Softmax):</strong> In models where choices are based on comparing values (like RL), a ‘temperature’ parameter can control the stochasticity. High temperature leads to more random choices, low temperature leads to more deterministic choices based on values.</li>
<li><strong>Imperfect Heuristics:</strong> Parameters within a strategy might reflect imperfect application (e.g., in WSLS, <span class="math inline">\(p_{stay\_win} &lt; 1\)</span> or <span class="math inline">\(p_{shift\_loss} &lt; 1\)</span>). This can also capture asymmetric responses to feedback (e.g., being more likely to shift after a loss than stay after a win).
<ul>
<li><em>Exploration:</em> Note that we talked about noise and errors, but random deviations can also be framed as adaptive exploration, allowing the agent to test actions that their current strategy deems suboptimal.</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="a-note-on-ideal-observers" class="section level4 hasAnchor" number="3.7.11.4">
<h4><span class="header-section-number">3.7.11.4</span> A Note on Ideal Observers<a href="building-models-of-strategic-decision-making.html#a-note-on-ideal-observers" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>It is important to distinguish between <strong>Heuristic Models</strong> (like WSLS) and <strong>Ideal Observer Models</strong> (like the Kalman Filter or HGF). Heuristics attempt to describe the <em>process</em> a human uses. Ideal observers describe the <em>optimal computation</em> given the uncertainty. When we fit models like the HGF to human data, we are effectively asking: “In what specific ways does the human deviate from optimality?” (e.g., do they overestimate how volatile the opponent is?).</p>
</div>
</div>
<div id="relationships-between-models" class="section level3 hasAnchor" number="3.7.12">
<h3><span class="header-section-number">3.7.12</span> Relationships Between Models<a href="building-models-of-strategic-decision-making.html#relationships-between-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>It’s useful to note that these candidate models aren’t always entirely distinct. Often, simpler models emerge as special cases of more complex ones:</p>
<ul>
<li><p>A Random Choice model is like a Memory-Based model where the influence of memory is zero.</p></li>
<li><p>WSLS can be seen as a specific type of RL model with a very high learning rate and sensitivity only to the immediately preceding trial’s outcome.</p></li>
<li><p>A 0-ToM model might resemble a Bias Tracking (moving average or RL model).</p></li>
</ul>
<p>Recognizing these connections can guide a principled modeling approach, starting simple and adding complexity only as needed and justified by data or theory.</p>
<p>This is what we called “model nesting” in a future chapter. It’s very elegant in that it allows to directly compare several models in a non-exclusive fashion, simply based on parameter values. A good example is also provided in Betancourt’s case study on reading times: <a href="https://betanalpha.github.io/assets/chapters_html/reading_times.html" class="uri">https://betanalpha.github.io/assets/chapters_html/reading_times.html</a></p>
</div>
<div id="handling-heterogeneity-mixture-models-1" class="section level3 hasAnchor" number="3.7.13">
<h3><span class="header-section-number">3.7.13</span> Handling Heterogeneity: Mixture Models<a href="building-models-of-strategic-decision-making.html#handling-heterogeneity-mixture-models-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sometimes the models cannot be nested, or we might want to capture the possibility that different participants (or even the same participant at different times) use different strategies. For instance, some players might predominantly use WSLS, while others rely more on bias tracking (moving average or RL). This is where <em>mixture models</em> become relevant (explored in detail in a future chapter).</p>
<ul>
<li><p><em>Concept:</em> Instead of assuming <em>one</em> model generated all the data, a mixture model assumes the data is a probabilistic blend from <em>multiple</em> candidate models (e.g., 70% of choices from WSLS, 30% from Random Bias).</p></li>
<li><p><em>Purpose:</em> Allows capturing heterogeneity within or across individuals without needing to know <em>a priori</em> which strategy was used on which trial or by which person. The model estimates the <em>probability</em> that each data point came from each component strategy.</p></li>
<li><p><em>Challenge:</em> Mixture models often require substantial data to reliably distinguish between components and estimate their mixing proportions.</p></li>
</ul>
</div>
<div id="cognitive-modeling-vs.-traditional-statistical-approaches-e.g.-glm" class="section level3 hasAnchor" number="3.7.14">
<h3><span class="header-section-number">3.7.14</span> Cognitive Modeling vs. Traditional Statistical Approaches (e.g., GLM)<a href="building-models-of-strategic-decision-making.html#cognitive-modeling-vs.-traditional-statistical-approaches-e.g.-glm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>How does this modeling approach differ from standard statistical analyses you might have learned, like ANOVAs or the General Linear Model - GLM?</p>
<ul>
<li><strong>Focus:</strong> GLM approaches typically focus on identifying <em>statistical effects</em>: Does factor X significantly influence outcome Y? (e.g., Does the opponent’s strategy affect the player’s win rate?). Cognitive modeling focuses on identifying the underlying <em>process or mechanism</em>: <em>How</em> does the opponent’s strategy lead to changes in the player’s choices via specific computations (like learning, memory updating, or strategic reasoning)?</li>
<li><strong>Theory:</strong> Cognitive models are usually derived from theories about mental processes. GLMs are more general statistical tools, often used agnostically regarding the specific cognitive mechanism.</li>
<li><strong>Parameters:</strong> Cognitive models estimate parameters that often have direct psychological interpretations (e.g., learning rate, memory decay, decision threshold, bias weight). GLM parameters represent statistical associations (e.g., regression coefficients).</li>
<li><strong>Data Level:</strong> Cognitive models often predict behavior at the trial level (e.g., predicting the choice on trial <em>t</em> based on history up to <em>t-1</em>). GLM analyses often aggregate data (e.g., comparing average win rates across conditions).</li>
<li><strong>Prediction vs. Explanation:</strong> While both aim to explain data, cognitive modeling often places a stronger emphasis on generating the observed behavior pattern from the hypothesized mechanism, allowing for simulation and prediction of fine-grained details.</li>
</ul>
<p><em>Example Revisited:</em> In the Matching Pennies game:
* A GLM approach might test if <code>Payoff ~ BotStrategy * Role + (1|ID)</code> shows a significant effect of <code>BotStrategy</code>.
* A cognitive modeling approach would fit different strategy models (WSLS, RL, etc.) to the choice data and compare them (using methods from Ch 7) to see which <em>mechanism</em> best explains the choices made against different bots, potentially revealing <em>why</em> performance differs (e.g., due to changes in estimated learning rates or strategy weights).</p>
<p>Both approaches are valuable, but cognitive modeling aims for a deeper, mechanistic level of explanation about the underlying cognitive processes.</p>
</div>
</div>
<div id="conclusion-from-observations-to-verbal-theories" class="section level2 hasAnchor" number="3.8">
<h2><span class="header-section-number">3.8</span> Conclusion: From Observations to Verbal Theories<a href="building-models-of-strategic-decision-making.html#conclusion-from-observations-to-verbal-theories" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This chapter took us from observing behavior in a specific task – the Matching Pennies game – to the crucial stage of formulating initial theories about the cognitive processes involved. We explored how analyzing gameplay data, considering participant reports, applying cognitive principles (like memory limits and error proneness), and contrasting different potential strategies (Random, WSLS, Memory-based, RL, k-ToM) helps us generate plausible <em>verbal models</em>.</p>
<p>We saw that the path from raw behavior to a testable model involves significant abstraction and simplification. We also highlighted the importance of distinguishing between the participant’s experience and the researcher’s theoretical stance, and how cognitive modeling differs from traditional statistical approaches by focusing on underlying mechanisms.</p>
<p>You now have a conceptual map of candidate models and understand why cognitive constraints matter. But verbal descriptions like ‘win-stay-lose-shift’ hide crucial ambiguities: Does ‘stay’ mean always stay or usually stay? How do we handle the first trial? In Chapter 3, you’ll implement these models in code, forcing you to make every assumption explicit. This is where modeling becomes rigorous and often reveals that our verbal intuitions were vaguer than we thought.</p>
<p>The next chapter, “From verbal descriptions to formal models,” tackles exactly this challenge. We will take some of the candidate models discussed here (like Random Choice and WSLS) and translate them into precise mathematical algorithms and R functions. This formalization will force us to be explicit about our assumptions and enable us to simulate agent behavior, setting the stage for fitting these models to data and evaluating their performance in later chapters.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="the-pizza-experiment.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="from-verbal-descriptions-to-formal-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/fusaroli/AdvancedCognitiveModeling/edit/master/02-BuildingModels.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["series.pdf"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
