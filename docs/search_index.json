[["index.html", "07-MixtureModels Chapter 1 Advanced Cognitive Modeling 1.1 Course Philosophy and Approach 1.2 Course Structure and Learning Path 1.3 Prerequisites and Preparation 1.4 Course Resources 1.5 About These Notes", " 07-MixtureModels Riccardo Fusaroli 2023-03-13 Chapter 1 Advanced Cognitive Modeling These course notes support the Advanced Cognitive Modeling course taught in the Master’s program in Cognitive Science at Aarhus University. The course represents a journey into how we can understand cognitive processes through the formalization and implementation of hypothesized mechanisms, their testing and validation. 1.1 Course Philosophy and Approach Advanced cognitive modeling focuses on three interrelated objectives that shape how we approach the modeling of cognitive processes: The first objective centers on understanding the thought process behind model development. Rather than simply providing a toolbox of existing scripts, we explore how cognitive models are conceptualized and constructed from the ground up. This approach ensures you develop the skills to create novel models for unique research questions. The second objective emphasizes mastering the Bayesian workflow essential for robust model development. This workflow encompasses simulation design, prior assessment, parameter recovery testing, and thorough model fit evaluation. These skills ensure your models are not just theoretically sound but also practically reliable and generalize way beyond cognitive modeling. The third objective focuses on developing advanced probabilistic modeling capabilities. Through hands-on experience with Stan, you will learn to implement increasingly sophisticated models while maintaining scientific rigor. 1.2 Course Structure and Learning Path The course follows a carefully structured progression that builds your modeling capabilities step by step: After a deepdive into the physics of pizza ovens, we begin with simple scenarios that introduce fundamental modeling concepts. Each subsequent chapter introduces new modeling techniques while building upon previous knowledge. This cumulative approach ensures you develop a deep understanding of both basic principles and advanced applications. The chapters include theoretical discussions paired with practical coding exercises. During practical sessions, we work with real datasets, design models collaboratively, and implement them using modern statistical tools. This hands-on approach provides ample opportunity for questions and exploration. The course schedule maintains flexibility to adapt to the collective learning pace of each cohort. While we have clear learning objectives, we ensure everyone develops a solid foundation before moving to more advanced topics. 1.3 Prerequisites and Preparation To make the most of this course, students should prepare their technical environment and review fundamental concepts: Software Requirements: - R (version 4.4 or above) - RStudio (version 2024.12.0 or above) - brms package with proper configuration - cmdstanr package with complete installation Technical Prerequisites: - Working knowledge of R programming - Basic understanding of Bayesian statistics - Familiarity with cognitive science fundamentals Additional Resources: - Introduction to R and tidyverse: https://r4ds.had.co.nz/ - A condensed Bayesian statistics primer (by Chris Cox and me): https://4ccoxau.github.io/PriorsWorkshop/ 1.4 Course Resources The course materials include: - Lecture notes and presentations - Practical exercise guides - Example code and solutions - Additional readings and references For comprehensive information: - Course syllabus: [TBA] - Lecture videos: [TBA] 1.5 About These Notes These notes represent an evolving resource that builds upon previous iterations of the course while incorporating new developments in the field. They are designed to serve both as a learning guide during the course and as a reference for your future research endeavors. knitr::opts_chunk$set( warning = FALSE, # Suppress warnings message = FALSE, # Suppress package loading messages echo = TRUE, # Show R code fig.width = 8, # Set default figure width fig.height = 5, # Set default figure height fig.align = &#39;center&#39;, # Center figures out.width = &quot;80%&quot;, # Make figures 80% of text width dpi = 300 # Set high resolution for figures ) "],["foundations.html", "Chapter 2 Foundations 2.1 From Pizza to Cognitive Models: An Introduction 2.2 Why Start with Pizza? 2.3 Learning Objectives 2.4 Part 1: Exploring the Pizza Stone Temperature Data 2.5 Part 2: Initial Statistical Modeling 2.6 Part 3: Understanding the Physics Model 2.7 Part 4: Implementing the Physics-Based Model 2.8 Part 5: Model Analysis and Practical Applications 2.9 Conclusion: From Pizza to Principles", " Chapter 2 Foundations 2.1 From Pizza to Cognitive Models: An Introduction This chapter introduces core modeling concepts through an unexpected lens: the physics of pizza stone heating. While this might seem far removed from cognitive science, it provides an insightful introduction to the challenges and methodologies of modeling complex phenomena. 2.2 Why Start with Pizza? Do I even need to answer that question? Because pizza, obviously. In any case, understanding how humans think and make decisions is arguably one of the most complex challenges in science. Rather than diving directly into this complexity, we begin with a more tractable problem: modeling how a pizza stone heats up in an oven. This seemingly simple process introduces us to key modeling concepts: The importance of selecting appropriate levels of analysis The role of prior knowledge in model development The challenge of balancing model complexity with practical utility The necessity of rigorous validation approaches Through this concrete example, we can focus on understanding modeling principles without the added complexity of cognitive theory. 2.3 Learning Objectives This first chpater is a bit odd, in that it pushes you straight into the deep waters of a complex example. I don’t expect you to understand all the technicalities. But, by completing this tutorial, you will be able to better grasp the importance of generative modeling, that is, of modeling that is focused on the underlying mechanisms producing the data. On the side you might learn something about how to * Implement physics-based thermal modeling using R and Stan * Apply Bayesian inference to real-world temperature data * Compare different statistical models using posterior predictions * Create professional visualizations of temperature evolution * Make practical predictions about heating times under various conditions Oh, and you’ll probably get hungry as well! Required Packages required_packages &lt;- c( &quot;tidyverse&quot;, # For data manipulation and visualization &quot;brms&quot;, # For Bayesian regression modeling &quot;bayesplot&quot;, # For visualization of Bayesian models &quot;tidybayes&quot;, # For working with Bayesian samples &quot;cmdstanr&quot; # For Stan implementation ) # Install and load packages for (pkg in required_packages) { if (!require(pkg, character.only = TRUE)) { install.packages(pkg) library(pkg, character.only = TRUE) } } 2.4 Part 1: Exploring the Pizza Stone Temperature Data In this study, we collected temperature measurements from a pizza stone in a gas-fired oven using an infrared temperature gun. Three different raters (N, TR, and R) took measurements over time to track how the stone heated up. Understanding how pizza stones heat up is crucial for achieving the perfect pizza crust, as consistent and sufficient stone temperature is essential for proper baking. The measurements were taken as follows: # Load and examine the data data &lt;- tibble( Order = rep(0:18, 3), Seconds = rep(c(0, 175, 278, 333, 443, 568, 731, 773, 851, 912, 980, 1040, 1074, 1124, 1175, 1237, 1298, 1359, 1394), 3), Temperature = c(15.1, 233, 244, 280, 289, 304, 343, NA, 333, 341, 320, 370, 325, 362, 363, 357, 380, 376, 380, 14.5, 139.9, 153, 36.1, 254, 459, 263, 369, rep(NA, 11), 12.9, 149.5, 159, 179.4, 191.7, 201, 210, NA, 256, 257, 281, 293, 297, 309, 318, 321, rep(NA, 3)), Rater = rep(c(&quot;N&quot;, &quot;TR&quot;, &quot;R&quot;), each = 19) ) # Create summary statistics summary_stats &lt;- data %&gt;% group_by(Rater) %&gt;% summarize( n_measurements = sum(!is.na(Temperature)), mean_temp = mean(Temperature, na.rm = TRUE), sd_temp = sd(Temperature, na.rm = TRUE), min_temp = min(Temperature, na.rm = TRUE), max_temp = max(Temperature, na.rm = TRUE) ) # Display summary statistics knitr::kable(summary_stats, digits = 1) Rater n_measurements mean_temp sd_temp min_temp max_temp N 18 312.0 86.4 15.1 380 R 15 229.0 83.9 12.9 321 TR 8 211.1 155.2 14.5 459 2.4.1 Initial Data Visualization Let’s visualize how the temperature evolves over time for each rater: ggplot(data, aes(x = Seconds/60, y = Temperature, color = Rater)) + geom_point(size = 3, alpha = 0.7) + geom_line(alpha = 0.5) + labs( title = &quot;Pizza Stone Temperature Evolution&quot;, subtitle = &quot;Measurements by three different raters&quot;, x = &quot;Time (minutes)&quot;, y = &quot;Temperature (°C)&quot;, color = &quot;Rater&quot; ) + theme_bw() + scale_color_brewer(palette = &quot;Set1&quot;) 2.4.2 Key Observations Several interesting patterns emerge from our data: Heating Patterns: The temperature generally increases over time, but not uniformly. We observe some fluctuations that might be due to: Variation in gas flame intensity Different measurement locations on the stone Measurement technique differences between raters Measurement Patterns by Rater Rater N maintained consistent measurements throughout the experiment Rater TR shows more variability and fewer total measurements Rater R shows a more gradual temperature increase pattern Missing Data: Some measurements are missing (NA values), particularly in the later time points for Rater TR. This is common in real-world data collection and needs to be considered in our analysis. Let’s examine the rate of temperature change: # Calculate temperature change rate data_with_rate &lt;- data %&gt;% group_by(Rater) %&gt;% arrange(Seconds) %&gt;% mutate( temp_change = (Temperature - lag(Temperature)) / (Seconds - lag(Seconds)) * 60, minutes = Seconds/60 ) %&gt;% filter(!is.na(temp_change)) # Visualize temperature change rate ggplot(data_with_rate, aes(x = minutes, y = temp_change, color = Rater)) + geom_point() + geom_smooth(se = FALSE, span = 0.75) + labs( title = &quot;Rate of Temperature Change Over Time&quot;, subtitle = &quot;Degrees Celsius per minute&quot;, x = &quot;Time (minutes)&quot;, y = &quot;Temperature Change Rate (°C/min)&quot;, color = &quot;Rater&quot; ) + theme_bw() + scale_color_brewer(palette = &quot;Set1&quot;) This visualization reveals that the heating rate is highest in the first few minutes and gradually decreases as the stone temperature approaches the oven temperature. This aligns with Newton’s Law of Cooling/Heating, which we will explore in the next section. 2.5 Part 2: Initial Statistical Modeling Before developing our physics-based model, let’s explore how standard statistical approaches perform in modeling our temperature data. We’ll implement two types of models using the brms package: a linear mixed-effects model and a lognormal mixed-effects model. Both models will account for variations between raters. 2.5.1 Model Setup and Priors First, let’s ensure we have a directory for our models and set up our computational parameters: # Create models directory if it doesn&#39;t exist dir.create(&quot;models&quot;, showWarnings = FALSE) # Define computational parameters mc_settings &lt;- list( chains = 2, iter = 6000, seed = 123, backend = &quot;cmdstanr&quot; ) 2.5.2 Linear Mixed-Effects Model We begin with a linear mixed-effects model, which assumes that temperature increases linearly with time but allows for different patterns across raters. This model includes both fixed effects (overall time trend) and random effects (rater-specific variations). # Define priors for linear model linear_priors &lt;- c( prior(normal(15, 20), class = &quot;Intercept&quot;), # Centered around room temperature prior(normal(0, 1), class = &quot;b&quot;), # Expected temperature change per second prior(normal(0, 100), class = &quot;sigma&quot;), # Residual variation prior(normal(0, 100), class = &quot;sd&quot;), # Random effects variation prior(lkj(3), class = &quot;cor&quot;) # Random effects correlation ) # Fit linear mixed-effects model linear_model &lt;- brm( Temperature ~ Seconds + (1 + Seconds | Rater), data = data, family = gaussian, prior = linear_priors, chains = mc_settings$chains, iter = mc_settings$iter, seed = mc_settings$seed, backend = mc_settings$backend, file = &quot;models/01_pizza_linear_model&quot;, cores = 2, adapt_delta = 0.99, max_treedepth = 20 ) # Display model summary summary(linear_model) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: Temperature ~ Seconds + (1 + Seconds | Rater) ## Data: data (Number of observations: 41) ## Draws: 2 chains, each with iter = 6000; warmup = 3000; thin = 1; ## total post-warmup draws = 6000 ## ## Multilevel Hyperparameters: ## ~Rater (Number of levels: 3) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 88.18 49.29 14.36 210.34 1.00 1804 1750 ## sd(Seconds) 0.70 0.57 0.15 2.34 1.00 1226 1398 ## cor(Intercept,Seconds) -0.03 0.38 -0.71 0.67 1.00 2106 3251 ## ## Regression Coefficients: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 75.42 71.38 -110.73 194.77 1.00 1461 1136 ## Seconds -0.08 0.11 -0.25 0.19 1.00 1406 1133 ## ## Further Distributional Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 58.36 7.51 46.01 75.32 1.00 3735 3662 ## ## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). # Generate predictions linear_preds &lt;- fitted( linear_model, newdata = data, probs = c(0.025, 0.975) ) %&gt;% as_tibble() %&gt;% bind_cols(data) 2.5.3 Lognormal Mixed-Effects Model The lognormal model accounts for the fact that temperature changes might be proportional rather than additive, and ensures predictions cannot go below zero (I don’t bring my oven out in the freezing cold!). # Define priors for lognormal model lognormal_priors &lt;- c( prior(normal(2.7, 1), class = &quot;Intercept&quot;), # Log scale for room temperature prior(normal(0, 0.01), class = &quot;b&quot;), # Expected log-scale change per second prior(normal(0, 1), class = &quot;sigma&quot;), # Log-scale residual variation prior(normal(0, 1), class = &quot;sd&quot;), # Random effects variation prior(lkj(3), class = &quot;cor&quot;) # Random effects correlation ) # Fit lognormal mixed-effects model lognormal_model &lt;- brm( Temperature ~ Seconds + (1 + Seconds | Rater), data = data, family = lognormal, prior = lognormal_priors, chains = mc_settings$chains, cores = 2, adapt_delta = 0.99, max_treedepth = 20, iter = mc_settings$iter, seed = mc_settings$seed, backend = mc_settings$backend, file = &quot;models/01_pizza_lognormal_model&quot; ) # Generate predictions lognormal_preds &lt;- fitted( lognormal_model, newdata = data, probs = c(0.025, 0.975) ) %&gt;% as_tibble() %&gt;% bind_cols(data) 2.5.4 Model Comparison and Visualization Let’s compare how these models fit our data: # Compare models using LOO model_comparison &lt;- loo_compare( loo(linear_model), loo(lognormal_model) ) # Create comparison plot ggplot() + # Raw data points geom_point(data = data, aes(x = Seconds/60, y = Temperature, color = Rater), alpha = 0.5) + # Linear model predictions geom_line(data = linear_preds, aes(x = Seconds/60, y = Estimate, linetype = &quot;Linear&quot;), color = &quot;blue&quot;) + geom_ribbon(data = linear_preds, aes(x = Seconds/60, ymin = Q2.5, ymax = Q97.5), fill = &quot;blue&quot;, alpha = 0.1) + # Lognormal model predictions geom_line(data = lognormal_preds, aes(x = Seconds/60, y = Estimate, linetype = &quot;Lognormal&quot;), color = &quot;red&quot;) + geom_ribbon(data = lognormal_preds, aes(x = Seconds/60, ymin = Q2.5, ymax = Q97.5), fill = &quot;red&quot;, alpha = 0.1) + # Formatting facet_wrap(~Rater) + labs( title = &quot;Comparison of Statistical Models&quot;, subtitle = &quot;Linear vs Lognormal Mixed-Effects Models&quot;, x = &quot;Time (minutes)&quot;, y = &quot;Temperature (°C)&quot;, linetype = &quot;Model Type&quot; ) + theme_bw() # Create comparison plot but capping the y axis ggplot() + # Raw data points geom_point(data = data, aes(x = Seconds/60, y = Temperature, color = Rater), alpha = 0.5) + # Linear model predictions geom_line(data = linear_preds, aes(x = Seconds/60, y = Estimate, linetype = &quot;Linear&quot;), color = &quot;blue&quot;) + geom_ribbon(data = linear_preds, aes(x = Seconds/60, ymin = Q2.5, ymax = Q97.5), fill = &quot;blue&quot;, alpha = 0.1) + # Lognormal model predictions geom_line(data = lognormal_preds, aes(x = Seconds/60, y = Estimate, linetype = &quot;Lognormal&quot;), color = &quot;red&quot;) + geom_ribbon(data = lognormal_preds, aes(x = Seconds/60, ymin = Q2.5, ymax = Q97.5), fill = &quot;red&quot;, alpha = 0.1) + ylim(0, 1000) + # Formatting facet_wrap(~Rater) + labs( title = &quot;Comparison of Statistical Models&quot;, subtitle = &quot;Linear vs Lognormal Mixed-Effects Models&quot;, x = &quot;Time (minutes)&quot;, y = &quot;Temperature (°C)&quot;, linetype = &quot;Model Type&quot; ) + theme_bw() 2.5.5 Model Assessment I have seen worse models in my time, but they do seem to have important issues: The linear mixed-effects model assumes a constant rate of temperature change, which we can see is not at all accurate. The actual temperature increase is fast at the beginning and appears to slow down over time, particularly at higher temperatures. While this model has the advantage of simplicity, it is not likely to produce accurate predictions as it seem to fail to capture the underlying physics of heat transfer. The lognormal mixed-effects model is completely off. Further, the models produce some divergences, which is often a sign that they are not well suited to the data. I suggest that the issue is that neither model incorporates our knowledge of heat transfer physics, which suggests an exponential approach to equilibrium temperature. This limitation motivates our next section, where we’ll develop a physics-based model. 2.6 Part 3: Understanding the Physics Model Temperature evolution in a pizza stone follows Newton’s Law of Cooling/Heating. We’ll start by exploring this physical model before applying it to real data. 2.6.1 The Basic Temperature Evolution Equation The temperature evolution of a pizza stone in a gas-fired oven is governed by the heat diffusion equation, which describes how heat flows through solid materials: \\[\\rho c_p \\frac{\\partial T}{\\partial t} = k\\nabla^2T + Q\\] where: \\(\\rho\\) represents the stone’s density (kg/m³) \\(c_p\\) denotes specific heat capacity (J/kg·K) \\(T\\) is temperature (K) \\(t\\) represents time (s) \\(k\\) is thermal conductivity (W/m·K) \\(\\nabla^2\\) is the Laplacian operator \\(Q\\) represents heat input from the oven (W/m³) While this equation provides a complete description of heat flow, we can significantly simplify our analysis by applying the lumped capacitance model. This simplification assumes that the temperature throughout the pizza stone remains uniform at any given time - not perfect, but a reasonable assumption given the stone’s relatively thin profile and good thermal conductivity. This approach reduces our model to: \\[\\frac{dT}{dt} = \\frac{hA}{mc_p}(T_{\\infty} - T)\\] where: \\(h\\) is the heat transfer coefficient (W/m²·K) \\(A\\) is the surface area exposed to heat (m²) \\(m\\) is the stone’s mass (kg) \\(T_{\\infty}\\) is the oven temperature (K) This simplified equation relates the rate of temperature change to the difference between the current stone temperature T and the flame temperature T∞. The coefficient h represents the heat transfer coefficient between the flame and stone, A is the stone’s surface area exposed to heat, m is its mass, and cp remains the specific heat capacity. To solve this differential equation, we begin by separating variables: \\[\\frac{dT}{T_{\\infty} - T} = \\left(\\frac{hA}{mc_p}\\right)dt\\] Integration of both sides yields: \\[-\\ln|T_{\\infty} - T| = \\left(\\frac{hA}{mc_p}\\right)t + C\\] where C is an integration constant. Using the initial condition \\(T = T_i\\) at \\(t = 0\\), we can determine the integration constant: \\[C = -\\ln|T_{\\infty} - T_i|\\] Substituting this back and solving for temperature gives us: \\[T = T_{\\infty} + (T_i - T_{\\infty})\\exp\\left(-\\frac{hA}{mc_p}t\\right)\\] For practical reasons, we combine physical parameters into a single coefficient \\(\\theta\\): \\[HOT = \\frac{hA}{mc_p}\\] Giving our working equation: \\[T = T_{\\infty} + (T_i - T_{\\infty})\\exp(-HOT * t)\\] This equation retains the essential physics while providing a practical model for analyzing our experimental data. The HOT coefficient encapsulates the combined effects of heat transfer efficiency, stone geometry, and material properties into a single parameter that determines how quickly the stone approaches the flame temperature. 2.7 Part 4: Implementing the Physics-Based Model Having established the theoretical foundation for our heat transfer model, we now move to its practical implementation. We will use Stan to create a Bayesian implementation of our physics-based model, allowing us to account for measurement uncertainty and variation between raters. First, we prepare our data for the Stan model. Our model requires initial temperatures, time measurements, and observed temperatures from each rater: # Create data structure for Stan stan_data &lt;- list( N = nrow(data %&gt;% filter(!is.na(Temperature))), time = data %&gt;% filter(!is.na(Temperature)) %&gt;% pull(Seconds), temp = data %&gt;% filter(!is.na(Temperature)) %&gt;% pull(Temperature), n_raters = 3, rater = as.numeric(factor(data %&gt;% filter(!is.na(Temperature)) %&gt;% pull(Rater))), Ti = c(100, 100, 100), # Initial temperature estimates Tinf = 450 # Flame temperature estimate ) Next, we implement our physics-based model in Stan. The model incorporates our derived equation while allowing for rater-specific heating coefficients: stan_code &lt;- &quot; data { int&lt;lower=0&gt; N; // Number of observations vector[N] time; // Time points vector[N] temp; // Observed temperatures int&lt;lower=0&gt; n_raters; // Number of raters array[N] int&lt;lower=1,upper=n_raters&gt; rater; // Rater indices vector[n_raters] Ti; // Initial temperatures real Tinf; // Flame temperature } parameters { vector&lt;lower=0&gt;[n_raters] HOT; // Heating coefficients vector&lt;lower=0&gt;[n_raters] sigma; // Measurement error } model { vector[N] mu; // Physics-based temperature prediction for (i in 1:N) { mu[i] = Tinf + (Ti[rater[i]] - Tinf) * exp(-HOT[rater[i]] * time[i]); } // Prior distributions target += normal_lpdf(HOT | 0.005, 0.005); // Prior for heating rate target += exponential_lpdf(sigma | 1); // Prior for measurement error // Likelihood target += normal_lpdf(temp | mu, sigma[rater]); } &quot; # Save the model writeLines(stan_code, &quot;models/pizza_physics_model.stan&quot;) # Compile and fit the model mod &lt;- cmdstan_model(&quot;models/pizza_physics_model.stan&quot;) fit &lt;- mod$sample( data = stan_data, seed = 123, chains = 2, parallel_chains = 2 ) ## Running MCMC with 2 parallel chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 0.1 seconds. ## Chain 2 finished in 0.1 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 0.1 seconds. ## Total execution time: 0.3 seconds. The Stan implementation translates our mathematical model into a computational framework. We assign informative priors to our parameters based on physical understanding: the heating coefficient (HOT) is expected to be small but positive, while measurement error (sigma) follows an exponential distribution to ensure positivity while allowing for varying levels of uncertainty between raters. To visualize our model’s predictions and assess its performance, we extract posterior samples and generate predictions across our time range: # Extract draws post &lt;- as_draws_df(fit$draws()) %&gt;% select(starts_with(&quot;HOT&quot;), starts_with(&quot;sigma&quot;)) %&gt;% slice_sample(n = 100) # Create prediction grid pred_data &lt;- crossing( time = seq(0, max(stan_data$time), length.out = 100), rater = 1:stan_data$n_raters ) %&gt;% mutate( Ti = stan_data$Ti[rater], Tinf = stan_data$Tinf ) # Generate predictions pred_matrix &lt;- matrix(NA, nrow = nrow(pred_data), ncol = 100) for (i in 1:nrow(pred_data)) { pred_matrix[i,] &lt;- with(pred_data[i,], Tinf + (Ti - Tinf) * exp(-as.matrix(post)[,rater] * time)) } # Summarize predictions predictions &lt;- pred_data %&gt;% mutate( mean = rowMeans(pred_matrix), lower = apply(pred_matrix, 1, quantile, 0.025), upper = apply(pred_matrix, 1, quantile, 0.975) ) # Create visualization ggplot(predictions, aes(x = time/60)) + geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) + geom_line(aes(y = mean)) + geom_point( data = data %&gt;% filter(!is.na(Temperature)) %&gt;% mutate(rater = case_when( Rater == &quot;N&quot; ~ 1, Rater == &quot;TR&quot; ~ 2, Rater == &quot;R&quot; ~ 3 )), aes(x = Seconds/60, y = Temperature) ) + facet_wrap(~rater, labeller = labeller(rater = c( &quot;1&quot; = &quot;Rater N&quot;, &quot;2&quot; = &quot;Rater TR&quot;, &quot;3&quot; = &quot;Rater R&quot; ))) + labs( title = &quot;Physics-Based Model Predictions&quot;, x = &quot;Time (minutes)&quot;, y = &quot;Temperature (°C)&quot; ) + theme_bw() Our implementation combines the theoretical understanding developed in Part 3 with practical considerations for real-world data analysis. The model accounts for measurement uncertainty while maintaining the fundamental physics of heat transfer, providing a robust framework for understanding pizza stone temperature evolution. 2.8 Part 5: Model Analysis and Practical Applications Having implemented our physics-based model, we can now analyze its predictions and develop practical insights for pizza stone temperature management. A key question for pizza making is how long it takes to reach optimal cooking temperatures under different conditions. We begin by creating a function that calculates the time needed to reach a target temperature: time_to_temp &lt;- function(target_temp, HOT, Ti, Tinf) { # Solve: target = Tinf + (Ti - Tinf) * exp(-HOT * t) # for t t = -1/HOT * log((target_temp - Tinf)/(Ti - Tinf)) return(t/60) # Convert seconds to minutes } To understand heating times across different oven conditions, we examine how varying flame temperatures affect the time needed to reach pizza-making temperatures. We extract the heating coefficients from our fitted model and analyze temperature scenarios: # Extract HOT samples from our posterior hot_samples &lt;- as_draws_df(fit$draws()) %&gt;% select(starts_with(&quot;HOT&quot;)) # Create prediction grid for different flame temperatures pred_data &lt;- crossing( Tinf = seq(450, 1200, by = 50), # Range of flame temperatures rater = 1:3 ) %&gt;% mutate( Ti = stan_data$Ti[rater], target_temp = 400 # Target temperature for pizza cooking ) # Calculate heating times across conditions n_samples &lt;- 100 time_preds &lt;- map_dfr(1:nrow(pred_data), function(i) { times &lt;- sapply(1:n_samples, function(j) { hot &lt;- hot_samples[j, paste0(&quot;HOT[&quot;, pred_data$rater[i], &quot;]&quot;)][[1]] time_to_temp( pred_data$target_temp[i], hot, pred_data$Ti[i], pred_data$Tinf[i] ) }) data.frame( rater = pred_data$rater[i], Tinf = pred_data$Tinf[i], mean_time = mean(times), lower = quantile(times, 0.025), upper = quantile(times, 0.975) ) }) # Visualize heating time predictions ggplot(time_preds, aes(x = Tinf)) + geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) + geom_line(aes(y = mean_time)) + facet_wrap(~rater, labeller = labeller(rater = c( &quot;1&quot; = &quot;Rater N&quot;, &quot;2&quot; = &quot;Rater TR&quot;, &quot;3&quot; = &quot;Rater R&quot; ))) + labs( title = &quot;Time Required to Reach Pizza-Making Temperature&quot;, subtitle = &quot;Target temperature: 400°C&quot;, x = &quot;Flame Temperature (°C)&quot;, y = &quot;Minutes to reach target&quot; ) + theme_bw() Our analysis reveals several important insights for practical pizza making. First, the heating time decreases nonlinearly with flame temperature, showing diminishing returns at very high temperatures. We can also observe differences between raters in their measured heating times. These variations likely stem from differences in measurement technique and location on the stone, highlighting the importance of consistent temperature monitoring practices. For practical application, we can provide specific heating guidelines based on our model. At a typical flame temperature of 800°C, the model predicts it will take approximately 20-30 minutes to reach optimal pizza-making temperature, assuming room temperature start. However, this time can vary significantly based on: Initial stone temperature Flame temperature and consistency Environmental conditions. Can we really wait that long? 2.9 Conclusion: From Pizza to Principles The journey from modeling a heating pizza stone to understanding cognitive processes might seem unusual, but it illustrates fundamental principles that will guide us throughout this course. Through this seemingly simple physics problem, we have encountered the core challenges that cognitive scientists face daily. Just relying on standard statistical models is not enough. We need to understand the underlying generative processes. We discovered how choosing the right level of analysis shapes our understanding - just as we simplified complex heat equations into workable models, cognitive scientists must decide which aspects of the mental processes to model explicitly and which to abstract. We learned that even well-understood physical processes require careful statistical treatment, foreshadowing the challenges we will face with more complex cognitive phenomena. The pizza stone experiment also demonstrated the importance of rigorous methodology. We saw how multiple measurements from different raters revealed variability in our data, leading us to consider measurement error and individual differences - themes that will become crucial when studying human behavior. Our exploration of different statistical approaches, from simple linear models to more sophisticated Bayesian frameworks, established a foundation for the modeling techniques we will develop throughout this course. Perhaps most importantly, this chapter starts showing that successful modeling requires balancing competing demands. We must weigh theoretical complexity against practical utility, statistical sophistication against interpretability, and mathematical elegance against real-world applicability. These trade-offs will become even more prominent as we move into modeling cognitive processes. As we progress through this course, we will encounter increasingly complex cognitive phenomena. The principles we learned here - careful data collection, thoughtful model specification, rigorous validation, and balanced interpretation - will serve as our guide. While human cognition presents challenges far beyond those of heating pizza stones, the fundamental approach remains the same: start with clear observations, build theoretically motivated models, and test them systematically against data. In the next chapter, we will begin applying these principles directly to cognitive processes, starting with simple decision-making tasks. The mathematical tools and statistical frameworks introduced here will provide the foundation for understanding how humans process information and make choices. Finally, I hope you are hungry now. I know I am. Let’s go and make some pizza! "],["building-models-of-strategic-decision-making.html", "Chapter 3 Building Models of Strategic Decision-Making 3.1 Learning goals 3.2 Introduction 3.3 The Matching Pennies Game 3.4 Game Structure 3.5 Empirical Investigation 3.6 Empirical explorations 3.7 Notes from previous years 3.8 Building Formal Models 3.9 Cognitive constraints 3.10 Continuity between models 3.11 Mixture of strategies 3.12 Differences from more traditional (general linear model-based) approaches", " Chapter 3 Building Models of Strategic Decision-Making 3.1 Learning goals Becoming more aware of the issue involved in theory building (and assessment); Identifying a small set of verbal models that we can then formalize in mathematical cognitive models and algorithms for simulations and model fitting. 3.2 Introduction In order to do computational models we need a phenomenon to study (and ideally some data), throughout the course you will be asked undergo several experiments, which provides specific behaviors to model. The matching pennies game provides a fun starting point for exploring cognitive modeling. This simple game allows us to examine how humans make decisions in strategic situations, while introducing fundamental concepts in model development and validation. Through this chapter, we will progress from observing actual gameplay behavior to developing formal models that capture decision-making processes. 3.3 The Matching Pennies Game In the matching pennies game, two players engage in a series of choices. One player attempts to match the other’s choice, while the other player aims to achieve a mismatch, and they repeatedly play with each other. This is a prototypical example of interacting behaviors that are usually tackled by game theory, and bring up issues of theory of mind and recursivity. For an introduction see the paper: Waade, Peter T., et al. “Introducing tomsup: Theory of mind simulations using Python.” Behavior Research Methods 55.5 (2023): 2197-2231. 3.4 Game Structure The game proceeds as follows: Two players sit facing each other Each round, both players choose either “left” or “right” to indicate where they believe a penny is hidden The matcher wins by choosing the same hand as their opponent The hider wins by choosing the opposite hand Points are awarded: +1 for winning, -1 for losing Repeat This simple structure creates a rich environment for studying decision-making strategies, learning, and adaptation. 3.5 Empirical Investigation 3.5.1 Data Collection Protocol If you are attending my class you have been (or will be) asked to participate in a matching pennies game. This game provides the foundation for our modeling efforts. By observing gameplay and collecting data, we can develop models that capture the cognitive processes underlying decision-making in strategic situations. Participants play 30 rounds as the matcher and 30 rounds as the hider, allowing us to observe behavior in both roles. While playing, participants track their scores, which can provide quantitative data for later analysis. Participants are also asked to reflect on their strategies and the strategies they believe their opponents are using, as that provides valuable materials to build models on. 3.5.2 Initial Observations Through the careful observation and discussion of gameplay we do in class, several patterns typically emerge. For instance, players often demonstrate strategic adaptation, adjusting their choices based on their opponent’s previous moves. They may attempt to identify patterns in their opponent’s behavior while trying to make their own choices less predictable. The tension between exploitation of perceived patterns and maintenance of unpredictability creates fascinating dynamics for modeling. 3.6 Empirical explorations Below you can observe how a previous year of CogSci did against bots (computational agents) playing according to different strategies. Look at the plots below, where the x axes indicate trial, the y axes how many points the CogSci’ers scored (0 being chance, negative means being completely owned by the bots, positive owning the bot) and the different colors indicate different strategies employed by the bots. Strategy “-2” was a Win-Stay-Lose-Shift bot: when it got a +1, it repeated its previous move (e.g. right if it had just played right), otherwise it would perform the opposite move (e.g. left if it had just played right). Strategy “-1” was a biased Nash both, playing “right” 80% of the time. Strategy “0” indicates a reinforcement learning bot; “1” a bot assuming you were playing according to a reinforcement learning strategy and trying to infer your learning and temperature parameters; “2” a bot assuming you were following strategy “1” and trying to accordingly infer your parameters. library(tidyverse) d &lt;- read_csv(&quot;data/MP_MSc_CogSci22.csv&quot;) %&gt;% mutate(BotStrategy = as.factor(BotStrategy)) d$Role &lt;- ifelse(d$Role == 0, &quot;Matcher&quot;, &quot;Hider&quot;) ggplot(d, aes(Trial, Payoff, group = BotStrategy, color = BotStrategy)) + geom_smooth(se = F) + theme_classic() + facet_wrap(.~Role) That doesn’t look too good, ah? What about individual variability? In the plot below we indicate the score of each of the former students, against the different bots. d1 &lt;- d %&gt;% group_by(ID, BotStrategy) %&gt;% dplyr::summarize(Score = sum(Payoff)) ggplot(d1, aes(BotStrategy, Score, label = ID)) + geom_point(aes(color = ID)) + geom_boxplot(alpha = 0.3) + theme_classic() Now, let’s take a bit of group discussion. Get together in groups, and discuss which strategies and cognitive processes might underlie your and the agents’ behaviors in the game. One thing to keep in mind is what a model is: a simplification that can help us make sense of the world. In other words, any behavior is incredibly complex and involves many complex cognitive mechanisms. So start simple, and if you think it’s too simple, progressively add simple components. Once your study group has discussed a few (during the PE), let’s discuss them. 3.7 Notes from previous years 3.7.1 From Observation to Theory The transition from observing gameplay to building formal models requires careful consideration of multiple factors. We must identify which aspects of behavior to model explicitly while deciding which details can be abstracted away. 3.7.2 Core Modeling Considerations When developing models of matching pennies behavior, we must address several key questions: What information do players use to make decisions? How do players integrate past experiences with current choices? What role does randomness play in decision-making? How do players adapt their strategies over time? Are there notions and models from previous cognitive science courses that can help us understand the behavior? These questions guide our model development process, helping us move from verbal theories to mathematical formulations. 3.7.3 The distinction between participant and researcher perspectives As participants we might not be aware of the strategy we use, or we might believe something erroneous. The exercise here is to act as researchers: what are the principles underlying the participants’ behaviors, no matter what the participants know or believe? Note that talking to participants and being participants helps developing ideas, but it’s not the end point of the process. Also note that as cognitive scientists we can rely on what we have learned about cognitive processes (e.g. memory). Another important component of the distinction is that participants leave in a rich world: they rely on facial expressions and bodily posture, the switch strategies, etc. On the other hand, the researcher is trying to identify one or few at most “simple” strategies. Rich bodily interactions and mixtures or sequences of multiple strategies are not a good place to start modeling. These aspects are a poor starting point for building your first model, and are often pretty difficult to fit to empirical data. Nevertheless, they are important intuitions that the researcher should (eventually?) accommodate. 3.8 Building Formal Models Based on observed behavior patterns and theoretical considerations, we can develop several candidate models of decision-making in the matching pennies game. 3.8.1 Random Choice Model The simplest model assumes players make choices randomly, independent of history or context. Players might simply be randomly choosing “head” or “tail” independently on the opponent’s choices and of how well they are doing. Choices could be fully at random (50% “head”, 50% “tail”) or biased (e.g. 60% “head”, 40% tail). While this may seem overly simplistic, it provides an important baseline for comparison and introduces key concepts in model specification. 3.8.2 Immediate reaction (Win-Stay-Lose-Shift) Another simple strategy is simply to follow the previous choice: if it was successful keep it, if not change it. This strategy is also called Win-Stay-Lose-Shift (WSLS). The model can be formalized as: \\[P(a_t = a_{t-1}) = \\begin{cases} p_w &amp; \\text{if win at } t-1 \\ 1 - p_l &amp; \\text{if loss at } t-1 \\end{cases}\\] where \\(a_t\\) represents the action at time \\(t\\), and \\(p_w\\) and \\(p_l\\) are the probabilities of staying after wins and losses respectively. Alternatively, one could do the opposite: Win-Shift-Lose-Stay. 3.8.3 Keep track of the bias (perfect memory) A more sophisticated approach considers how players track and respond to their opponent’s choice patterns. This model maintains a running estimate of the opponent’s choice probabilities and updates these estimates based on observed choices. 3.8.4 Keep track of the bias (imperfect memory) A player could not be able to keep in mind all previous trials, or decide to forget old trials, in case the biase shifts over time. So we could use only the last n trials, or do a weighted mean with weigths proportional to temporal closeness (the more recent, the higher the weight). 3.8.5 Reinforcement learning Since there is a lot of leeway in how much memory we should keep of previous trials, we could also use a model that explicitly estimates how much players are learning on a trial by trial basis (high learning, low memory; low learning, high memory). This is the model of reinforcement learning, which we will deal with in future chapters. Shortly described, reinforcement learning assumes that each choice has a possible reward (probability of winning) and at every trial given the feedback received updates the expected value of the choice taken. The update depends on the prediction error (difference between expected and actual reward) and the learning rate. 3.8.6 k-ToM Reinforcement learning is a neat model, but can be problematic when playing against other agents: what the game is really about is not assessing the probability of the opponent choosing “head” generalizing from their past choices, but predicting what they will do. This requires making an explicit model of how the opponent chooses. k-ToM models will be dealt with in future chapters, but can be here anticipated as models assuming that the opponent follows a random bias (0-ToM), or models us as following a random bias (1-ToM), or models us modeling them as following a random bias (2-ToM), etc. 3.8.7 Other possible strategies Many additional strategies can be generated by combining former strategies. Generating random output is hard, so if we want to confuse the opponent, we could act first choosing tail 8 times, and then switching to a WSLS strategy for 4 trials, and then choosing head 4 times. Or implementing any of the previous strategies and doing the opposite “to mess with the opponent”. 3.9 Cognitive constraints As we discuss strategies, we can also identify several cognitive constraints that we know from former studies: in particular, memory, perseveration, and errors. 3.9.1 Memory Humans have limited memory and a tendency to forget that is roughly exponential. Models assuming perfect memory for longer stretches of trials are unrealistic. We could for instance use the exponential decay of memory to create weights following the same curve in the “keeping track of bias” models. Roughly, this is what reinforcement learning is doing via the learning rate parameter. 3.9.2 Perseveration Winning choice is not changed. People tend to have a tendency to perseverate with “good” choices independently of which other strategy they might be using. 3.9.3 Errors Humans make mistakes, get distracted, push the wrong button, forget to check whether they won or lost before. So a realistic model of what happens in these games should contain a certain chance of making a mistake. E.g. a 10% chance that any choice will be perfectly random instead of following the strategy. Such random deviations from the strategy might also be conceptualized as explorations: keeping the door open to the strategy not being optimal and therefore testing other choices. For instance, one could have an imperfect WSLS where the probability of staying if winning (or shifting if losing) is only 80% and not 100%. Further, these deviations could be asymmetric, with the probability of staying if winning is 80% and of shifting if losing is 100%; for instance if negative and positive feedback are perceived asymmetrically. 3.10 Continuity between models Many of these models are simply extreme cases of others. For instance, WSLS is a reinforcement learning model with an extreme learning rate (reward replaces the formerly expected value without any moderation), which is also a memory model with a memory of 1 previous trial. k-ToM builds on reinforcement learning: at level 1 assumes the other is a RL agent. 3.11 Mixture of strategies We discussed that there are techniques to consider the data generated by a mixture of models: estimating the probability that they are generated by model 1 or 2 or n. This probability can then be conditioned, according to our research question, to group (are people w schizophrenia more likely to employ model 1) or ID (are different participants using different models), or condition, or… We discussed that we often need lots of data to disambiguate between models, so conditioning e.g. on trial would in practice almost (?) never work. 3.12 Differences from more traditional (general linear model-based) approaches In a more traditional approach we would carefully set up the experiment to discriminate between hypotheses. For instance, if the hypothesis is that humans deploy ToM only when playing against intentional agents, we can set agents with increasing levels of k-ToM against humans, set up two framings (this is a human playing hide and seek, this is a slot machine), and assess whether humans perform differently. E.g. whether they perform better when thinking it’s a human. We analyze performance e.g. as binary outcome on a trial by trial base and condition its rate on framing and complexity. If framing makes a difference in the expected direction, we are good. If we do this properly, thanks to the clever experimental designs we set up, we can discriminate between hypotheses. And that is good. However, cognitive modeling opens additional opportunities. For instance, we can actually reconstruct which level of recursion the participants are enacting and if it changes over time. This might be very useful in the experimental setup, and crucial in more observational setups. Cognitive modeling also allows us to discriminate between different cognitive components more difficult to assess by looking at performance only. For instance, why are participants performing less optimally when facing a supposedly non-intentional agent? Is their learning rate different? Is their estimate of volatility different? In other setups, e.g. a gambling context, we might observe that some participants (e.g. parkinson’s patients) are gambling away much. Is this due to changes in their risk-seeking propensities, loss aversion, or changes in the ability to actually learn the reward structure? Experimental setups help, but cognitive modeling can provide more nuanced and direct evidence. "],["from-verbal-descriptions-to-formal-models.html", "Chapter 4 From verbal descriptions to formal models 4.1 Learning Goals 4.2 The Value of Formalization 4.3 Defining general conditions 4.4 Implementing a random agent 4.5 Implementing a Win-Stay-Lose-Shift agent 4.6 Now we scale it up 4.7 Conclusion", " Chapter 4 From verbal descriptions to formal models This chapter bridges the gap between verbal theories and computational implementations of cognitive models. Building on our observations of the matching pennies game, we now develop precise mathematical formulations that can generate testable predictions. 4.1 Learning Goals After completing this chapter, you will be able to: Transform verbal descriptions of decision-making strategies into precise mathematical formulations, which implications can be more easily explored and that can be empirically tested Create computational implementations of these mathematical models as agent-based models in R Generate and analyze simulated data to understand model behavior under different conditions 4.2 The Value of Formalization Moving from verbal to formal models represents a crucial step in cognitive science. When we describe behavior in words, ambiguities often remain hidden. For instance, a verbal description might state that players “tend to repeat successful choices.” But what exactly constitutes “tend to”? How strongly should past successes influence future choices? Mathematical formalization forces us to be precise about these specifications. By computationally implementing the our models, we are forced to make them very explicit in their assumptions; we become able to simulate the models in a variety of different situations and therefore better understand their implications So, what we’ll do throughout the chapter is to: choose two of the models and formalize them, that is, produce an algorithm that enacts the strategy, so we can simulate them. implement the algorithms as functions: getting an input and producing an output, so we can more easily implement them across various contexts (e.g. varying amount of trials, input, etc). See R4DataScience, if you need a refresher: https://r4ds.had.co.nz/functions.html implement a Random Bias agent (choosing “head” 70% of the times) and get your agents to play against it for 120 trials (and save the data) implement a Win-Stay-Lose-Shift agent (keeping the same choice if it won, changing it if it lost) and do the same. scale up the simulation: have 100 agents for each of your strategy playing against both Random Bias and Win-Stay-Lose-Shift and save their data. figure out a good way to visualize the data to assess which strategy performs better, whether that changes over time and generally explore what the agents are doing. 4.3 Defining general conditions pacman::p_load(tidyverse, patchwork) # Number of trials per simulation trials &lt;- 120 # Number of agents to simulate agents &lt;- 100 # Optional: Set random seed for reproducibility # set.seed(123) 4.4 Implementing a random agent Remember a random agent is an agent that picks at random between “right” and “left” independently on what the opponent is doing. A random agent might be perfectly random (50% chance of choosing “right”, same for “left”) or biased. The variable “rate” determines the rate of choosing “right”. rate &lt;- 0.5 RandomAgent &lt;- rbinom(trials, 1, rate) # we simply sample randomly from a binomial # Now let&#39;s plot how it&#39;s choosing d1 &lt;- tibble(trial = seq(trials), choice = RandomAgent) p1 &lt;- ggplot(d1, aes(trial, choice)) + geom_line() + labs( title = &quot;Random Agent Behavior (rate 0.5)&quot;, x = &quot;Trial Number&quot;, y = &quot;Choice (0/1)&quot; ) + theme_classic() p1 # What if we were to compare it to an agent being biased? rate &lt;- 0.8 RandomAgent &lt;- rbinom(trials, 1, rate) # we simply sample randomly from a binomial # Now let&#39;s plot how it&#39;s choosing d2 &lt;- tibble(trial = seq(trials), choice = RandomAgent) p2 &lt;- ggplot(d2, aes(trial, choice)) + geom_line() + labs( title = &quot;Biased Random Agent Behavior&quot;, x = &quot;Trial Number&quot;, y = &quot;Choice (0/1)&quot; ) + theme_classic() p1 + p2 print(&quot;This first visualization shows the behavior of a purely random agent - one that chooses between options with equal probability (rate = 0.5). Looking at the jagged line jumping between 0 and 1, we can see that the agent&#39;s choices appear truly random, with no discernible pattern. This represents what we might expect from a player who is deliberately trying to be unpredictable in the matching pennies game. However, this raw choice plot can be hard to interpret. A more informative way to look at the agent&#39;s behavior is to examine how its average rate of choosing option 1 evolves over time:&quot;) ## [1] &quot;This first visualization shows the behavior of a purely random agent - one that chooses between options with equal probability (rate = 0.5). Looking at the jagged line jumping between 0 and 1, we can see that the agent&#39;s choices appear truly random, with no discernible pattern. This represents what we might expect from a player who is deliberately trying to be unpredictable in the matching pennies game.\\nHowever, this raw choice plot can be hard to interpret. A more informative way to look at the agent&#39;s behavior is to examine how its average rate of choosing option 1 evolves over time:&quot; # Tricky to see, let&#39;s try writing the cumulative rate: d1$cumulativerate &lt;- cumsum(d1$choice) / seq_along(d1$choice) d2$cumulativerate &lt;- cumsum(d2$choice) / seq_along(d2$choice) p3 &lt;- ggplot(d1, aes(trial, cumulativerate)) + geom_line() + ylim(0,1) + labs( title = &quot;Random Agent Behavior&quot;, x = &quot;Trial Number&quot;, y = &quot;Cumulative probability of choosing 1 (0-1)&quot; ) + theme_classic() p4 &lt;- ggplot(d2, aes(trial, cumulativerate)) + geom_line() + labs( title = &quot;Random Agent Behavior&quot;, x = &quot;Trial Number&quot;, y = &quot;Cumulative probability of choosing 1 (0-1)&quot; ) + ylim(0,1) + theme_classic() p3 + p4 print(&quot;This cumulative rate plot helps us better understand the agent&#39;s overall tendencies. For a truly random agent, we expect this line to converge toward 0.5 as the number of trials increases. Early fluctuations away from 0.5 are possible due to random chance, but with more trials, these fluctuations tend to even out. When we compare agents with different underlying biases (rate = 0.5 vs rate = 0.8):&quot;) ## [1] &quot;This cumulative rate plot helps us better understand the agent&#39;s overall tendencies. For a truly random agent, we expect this line to converge toward 0.5 as the number of trials increases. Early fluctuations away from 0.5 are possible due to random chance, but with more trials, these fluctuations tend to even out.\\nWhen we compare agents with different underlying biases (rate = 0.5 vs rate = 0.8):&quot; ## Now in the same plot d1$rate &lt;- 0.5 d2$rate &lt;- 0.8 d &lt;- rbind(d1,d2) %&gt;% mutate(rate = as.factor(rate)) p5 &lt;- ggplot(d, aes(trial, cumulativerate, color = rate, group = rate)) + geom_line() + labs( title = &quot;Random Agents Behavior&quot;, x = &quot;Trial Number&quot;, y = &quot;Cumulative probability of choosing 1 (0-1)&quot; ) + ylim(0,1) + theme_classic() p5 print(&quot;We can clearly see how bias affects choice behavior. The unbiased agent (rate = 0.5) stabilizes around choosing each option equally often, while the biased agent (rate = 0.8) shows a strong preference for option 1, choosing it approximately 80% of the time. This comparison helps us understand how we might detect biases in real players&#39; behavior - consistent deviation from 50-50 choice proportions could indicate an underlying preference or strategy.&quot;) ## [1] &quot;We can clearly see how bias affects choice behavior. The unbiased agent (rate = 0.5) stabilizes around choosing each option equally often, while the biased agent (rate = 0.8) shows a strong preference for option 1, choosing it approximately 80% of the time. This comparison helps us understand how we might detect biases in real players&#39; behavior - consistent deviation from 50-50 choice proportions could indicate an underlying preference or strategy.&quot; # Now as a function #&#39; Create a random decision-making agent #&#39; @param input Vector of previous choices (not used but included for API consistency) #&#39; @param rate Probability of choosing option 1 (default: 0.5 for unbiased) #&#39; @return Vector of binary choices #&#39; @examples #&#39; # Create unbiased random agent for 10 trials #&#39; choices &lt;- RandomAgent_f(rep(1,10), 0.5) RandomAgent_f &lt;- function(input, rate = 0.5) { # Input validation if (!is.numeric(rate) || rate &lt; 0 || rate &gt; 1) { stop(&quot;Rate must be a probability between 0 and 1&quot;) } n &lt;- length(input) choice &lt;- rbinom(n, 1, rate) return(choice) } input &lt;- rep(1,trials) # it doesn&#39;t matter, it&#39;s not taken into account choice &lt;- RandomAgent_f(input, rate) d3 &lt;- tibble(trial = seq(trials), choice) ggplot(d3, aes(trial, choice)) + geom_line() + labs( title = &quot;Random Agent Behavior&quot;, x = &quot;Trial Number&quot;, y = &quot;Cumulative probability of choosing 1 (0-1)&quot; ) + theme_classic() ## What if there&#39;s noise? RandomAgentNoise_f &lt;- function(input, rate, noise){ n &lt;- length(input) choice &lt;- rbinom(n, 1, rate) if (rbinom(1, 1, noise) == 1) {choice = rbinom(1,1,0.5)} return(choice) } 4.5 Implementing a Win-Stay-Lose-Shift agent #&#39; Create a Win-Stay-Lose-Shift decision-making agent #&#39; @param prevChoice Previous choice made by the agent (0 or 1) #&#39; @param feedback Success of previous choice (1 for win, 0 for loss) #&#39; @param noise Optional probability of random choice (default: 0) #&#39; @return Next choice (0 or 1) #&#39; @examples #&#39; # Basic WSLS decision after a win #&#39; next_choice &lt;- WSLSAgent_f(prevChoice = 1, feedback = 1) WSLSAgent_f &lt;- function(prevChoice, feedback, noise = 0) { # Input validation if (!is.numeric(prevChoice) || !prevChoice %in% c(0,1)) { stop(&quot;Previous choice must be 0 or 1&quot;) } if (!is.numeric(feedback) || !feedback %in% c(0,1)) { stop(&quot;Feedback must be 0 or 1&quot;) } if (!is.numeric(noise) || noise &lt; 0 || noise &gt; 1) { stop(&quot;Noise must be a probability between 0 and 1&quot;) } # Core WSLS logic choice &lt;- if (feedback == 1) { prevChoice # Stay with previous choice if won } else { 1 - prevChoice # Switch to opposite choice if lost } # Apply noise if specified if (noise &gt; 0 &amp;&amp; runif(1) &lt; noise) { choice &lt;- sample(c(0,1), 1) } return(choice) } WSLSAgentNoise_f &lt;- function(prevChoice, Feedback, noise){ if (Feedback == 1) { choice = prevChoice } else if (Feedback == 0) { choice = 1 - prevChoice } if (rbinom(1, 1, noise) == 1) {choice &lt;- rbinom(1, 1, .5)} return(choice) } WSLSAgent &lt;- WSLSAgent_f(1, 0) # Against a random agent Self &lt;- rep(NA, trials) Other &lt;- rep(NA, trials) Self[1] &lt;- RandomAgent_f(1, 0.5) Other &lt;- RandomAgent_f(seq(trials), rate) for (i in 2:trials) { if (Self[i - 1] == Other[i - 1]) { Feedback = 1 } else {Feedback = 0} Self[i] &lt;- WSLSAgent_f(Self[i - 1], Feedback) } sum(Self == Other) ## [1] 84 df &lt;- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other)) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, Self)) + geom_line(color = &quot;blue&quot;, aes(trial, Other)) + labs( title = &quot;WSLS Agent (red) vs Biased Random Opponent (blue)&quot;, x = &quot;Trial Number&quot;, y = &quot;Choice (0/1)&quot;, color = &quot;Agent Type&quot; ) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, Feedback)) + geom_line(color = &quot;blue&quot;, aes(trial, 1 - Feedback)) + labs( title = &quot;WSLS Agent (red) vs Biased Random Opponent (blue)&quot;, x = &quot;Trial Number&quot;, y = &quot;Feedback received (0/1)&quot;, color = &quot;Agent Type&quot; ) print(&quot;These plots compare how a Win-Stay-Lose-Shift (WSLS) agent performs against different opponents. The red line shows the WSLS agent&#39;s choices, while the blue line shows the opponent&#39;s choices. When playing against a biased random opponent, we can see clearer patterns in the WSLS agent&#39;s behavior as it responds to wins and losses. Against another WSLS agent, the interaction becomes more complex, as each agent is trying to adapt to the other&#39;s adaptations. This kind of visualization helps us understand how different strategies might interact in actual gameplay.&quot;) ## [1] &quot;These plots compare how a Win-Stay-Lose-Shift (WSLS) agent performs against different opponents. The red line shows the WSLS agent&#39;s choices, while the blue line shows the opponent&#39;s choices. When playing against a biased random opponent, we can see clearer patterns in the WSLS agent&#39;s behavior as it responds to wins and losses. Against another WSLS agent, the interaction becomes more complex, as each agent is trying to adapt to the other&#39;s adaptations. This kind of visualization helps us understand how different strategies might interact in actual gameplay.&quot; df$cumulativerateSelf &lt;- cumsum(df$Feedback) / seq_along(df$Feedback) df$cumulativerateOther &lt;- cumsum(1 - df$Feedback) / seq_along(df$Feedback) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, cumulativerateSelf)) + geom_line(color = &quot;blue&quot;, aes(trial, cumulativerateOther)) + labs( title = &quot;WSLS Agent (red) vs Biased Random Opponent (blue)&quot;, x = &quot;Trial Number&quot;, y = &quot;Cumulative probability of choosing 1 (0-1)&quot;, color = &quot;Agent Type&quot; ) # Against a Win-Stay-Lose Shift Self &lt;- rep(NA, trials) Other &lt;- rep(NA, trials) Self[1] &lt;- RandomAgent_f(1, 0.5) Other[1] &lt;- RandomAgent_f(1, 0.5) for (i in 2:trials) { if (Self[i - 1] == Other[i - 1]) { Feedback = 1 } else {Feedback = 0} Self[i] &lt;- WSLSAgent_f(Self[i - 1], Feedback) Other[i] &lt;- WSLSAgent_f(Other[i - 1], 1 - Feedback) } sum(Self == Other) ## [1] 60 df &lt;- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other)) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, Self)) + geom_line(color = &quot;blue&quot;, aes(trial, Other)) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, Feedback)) + geom_line(color = &quot;blue&quot;, aes(trial, 1 - Feedback)) df$cumulativerateSelf &lt;- cumsum(df$Feedback) / seq_along(df$Feedback) df$cumulativerateOther &lt;- cumsum(1 - df$Feedback) / seq_along(df$Feedback) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, cumulativerateSelf)) + geom_line(color = &quot;blue&quot;, aes(trial, cumulativerateOther)) print(&quot;This cumulative performance plot reveals the overall effectiveness of the WSLS strategy. By tracking the running average of successes, we can see whether the strategy leads to above-chance performance in the long run. When playing against a biased random opponent, the WSLS agent can potentially exploit the opponent&#39;s predictable tendencies, though success depends on how strong and consistent the opponent&#39;s bias is. When we pit the WSLS agent against another WSLS agent, the dynamics become more complex. Both agents are now trying to adapt to each other&#39;s adaptations, creating a more sophisticated strategic interaction. The resulting behavior often shows interesting patterns of mutual adaptation, where each agent&#39;s attempts to exploit the other&#39;s strategy leads to evolving patterns of play.&quot;) ## [1] &quot;This cumulative performance plot reveals the overall effectiveness of the WSLS strategy. By tracking the running average of successes, we can see whether the strategy leads to above-chance performance in the long run. When playing against a biased random opponent, the WSLS agent can potentially exploit the opponent&#39;s predictable tendencies, though success depends on how strong and consistent the opponent&#39;s bias is.\\nWhen we pit the WSLS agent against another WSLS agent, the dynamics become more complex. Both agents are now trying to adapt to each other&#39;s adaptations, creating a more sophisticated strategic interaction. The resulting behavior often shows interesting patterns of mutual adaptation, where each agent&#39;s attempts to exploit the other&#39;s strategy leads to evolving patterns of play.&quot; 4.6 Now we scale it up trials = 120 agents = 100 # WSLS vs agents with varying rates for (rate in seq(from = 0.5, to = 1, by = 0.05)) { for (agent in seq(agents)) { Self &lt;- rep(NA, trials) Other &lt;- rep(NA, trials) Self[1] &lt;- RandomAgent_f(1, 0.5) Other &lt;- RandomAgent_f(seq(trials), rate) for (i in 2:trials) { if (Self[i - 1] == Other[i - 1]) { Feedback = 1 } else {Feedback = 0} Self[i] &lt;- WSLSAgent_f(Self[i - 1], Feedback) } temp &lt;- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other), agent, rate) if (agent == 1 &amp; rate == 0.5) {df &lt;- temp} else {df &lt;- bind_rows(df, temp)} } } ## WSLS with another WSLS for (agent in seq(agents)) { Self &lt;- rep(NA, trials) Other &lt;- rep(NA, trials) Self[1] &lt;- RandomAgent_f(1, 0.5) Other[1] &lt;- RandomAgent_f(1, 0.5) for (i in 2:trials) { if (Self[i - 1] == Other[i - 1]) { Feedback = 1 } else {Feedback = 0} Self[i] &lt;- WSLSAgent_f(Self[i - 1], Feedback) Other[i] &lt;- WSLSAgent_f(Other[i - 1], 1 - Feedback) } temp &lt;- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other), agent, rate) if (agent == 1 ) {df1 &lt;- temp} else {df1 &lt;- bind_rows(df1, temp)} } 4.6.1 And we visualize it ggplot(df, aes(trial, Feedback, group = rate, color = rate)) + geom_smooth(se = F) + theme_classic() We can see that the bigger the bias in the random agent, the bigger the performance in the WSLS (the higher the chances the random agent picks the same hand more than once in a row). Now it’s your turn to follow a similar process for your 2 chosen strategies. 4.7 Conclusion Moving from verbal descriptions to formal computational models represents a crucial step in cognitive science. Through our work with the matching pennies game, we have seen how this transformation process requires careful consideration of theoretical assumptions, mathematical precision, and practical implementation details. The development of formal models forces us to be explicit about mechanisms that might remain ambiguous in verbal descriptions. When we state that an agent “learns from experience” or “responds to patterns,” we must specify exactly how these processes work. This precision not only clarifies our theoretical understanding but also enables rigorous empirical testing. Our implementation of different agent types - from simple random choice to more sophisticated strategies - demonstrates how computational modeling can reveal surprising implications of seemingly straightforward theories. Through simulation, we discovered that even basic strategies can produce complex patterns of behavior, especially when agents interact with each other over multiple trials. Perhaps most importantly, this chapter has established a foundational workflow for cognitive modeling: begin with careful observation, think carefully and develop precise mathematical formulations, implement these as computational models, and validate predictions against data. Don’t be afraid to make mistakes, or rethink your strategy and iterate the modeling process. This systematic approach will serve as our template as we progress to more complex cognitive phenomena in subsequent chapters. While our matching pennies models may seem simple compared to the rich complexity of human cognition, they exemplify the essential principles of good modeling practice: clarity of assumptions, precision in implementation, and rigorous validation against empirical data. These principles will guide our exploration of more sophisticated cognitive models throughout this course. For more advanced examples of models that can underly behavior in the Matching Pennies game check: Chapter 12 on reinforcement learning. the paper by Waade et al mentioned at the beginning of the chapter. "],["from-simulation-to-model-fitting.html", "Chapter 5 From simulation to model fitting 5.1 Learning Goals 5.2 The Challenge of Model Fitting 5.3 Simulating data 5.4 Building our basic model in Stan 5.5 Parameter recovery 5.6 The memory model: conditioning theta 5.7 Memory agent with internal parameter 5.8 Relationship to Rescorla-Wagner 5.9 Bayesian memory agent 5.10 Conclusion: From Simple Models to Complex Cognitive Processes", " Chapter 5 From simulation to model fitting This chapter introduces essential techniques for moving from theoretical models to empirical validation. Building on our implementation of decision-making agents, we now tackle the challenge of determining whether these models accurately describe observed behavior. 5.1 Learning Goals After completing this chapter, you will be able to: Design and implement Bayesian parameter estimation for cognitive models using Stan Create and interpret prior and posterior predictive checks to validate model behavior Evaluate model quality through systematic parameter recovery studies 5.2 The Challenge of Model Fitting Understanding human behavior requires more than just implementing plausible models - we must determine whether these models actually capture meaningful empirical patterns. Consider our biased agent model that tends to favor one choice over another. While we can specify different levels of bias in our simulations, real-world application requires determining what bias values best explain observed behavior, and for instance whether a pharmacological manipulation can affect the bias. Bayesian inference provides a powerful framework for this challenge. It allows us to: Express our prior beliefs about reasonable parameter values Update these beliefs based on observed data Quantify uncertainty in our parameter estimates Generate predictions that account for parameter uncertainty 5.3 Simulating data As usual we start with simulated data, where we know the underlying mechanisms and parameter values. Simulated data are rarely enough (empirical data often offer unexpected challenges), but they are a great starting point to stress test your model: does the model reconstruct the right parameter values? Does it reproduce the overall patterns in the data? Here we build a new simulation of random agents with bias and noise. The code and visualization is really nothing different from last chapter. pacman::p_load(tidyverse, here, posterior, cmdstanr, brms, tidybayes) trials &lt;- 120 RandomAgentNoise_f &lt;- function(rate, noise) { choice &lt;- rbinom(1, 1, rate) # generating noiseless choices if (rbinom(1, 1, noise) == 1) { choice = rbinom(1, 1, 0.5) # introducing noise } return(choice) } d &lt;- NULL for (noise in seq(0, 0.5, 0.1)) { # looping through noise levels for (rate in seq(0, 1, 0.1)) { # looping through rate levels randomChoice &lt;- rep(NA, trials) for (t in seq(trials)) { # looping through trials (to make it homologous to more reactive models) randomChoice[t] &lt;- RandomAgentNoise_f(rate, noise) } temp &lt;- tibble(trial = seq(trials), choice = randomChoice, rate, noise) temp$cumulativerate &lt;- cumsum(temp$choice) / seq_along(temp$choice) if (exists(&quot;d&quot;)) { d &lt;- rbind(d, temp) } else{ d &lt;- temp } } } write_csv(d, &quot;simdata/W3_randomnoise.csv&quot;) # Now we visualize it p1 &lt;- ggplot(d, aes(trial, cumulativerate, group = rate, color = rate)) + geom_line() + geom_hline(yintercept = 0.5, linetype = &quot;dashed&quot;) + ylim(0,1) + facet_wrap(.~noise) + theme_classic() p1 5.4 Building our basic model in Stan N.B. Refer to the video and slides for the step by step build-up of the Stan code. Now we subset to a simple case, no noise and rate of 0.8, to focus on the Stan model. We make it into the right format for Stan, build the Stan model, and fit it. 5.4.1 Data Here we define the data and format it for Stan. Stan likes data as a list. Why a list? Well, dataframes (now tibbles) are amazing. But they have a big drawback: they require each variable to have the same length. Lists do not have that limitation, they are more flexible. So, lists. We’ll have to learn how to live with them. d1 &lt;- d %&gt;% subset(noise == 0 &amp; rate == 0.8) ## Create the data. N.B. note the two variables have different lengths: 1 for n, n for h. data &lt;- list( n = 120, # n of trials h = d1$choice # sequence of choices (h stands for hand) ) 5.4.2 Model We write the stan code within the R code (so I can show it to you more easily), then we save it as a stan file, which can be loaded at a later stage in order to compile it. [Missing: more info on compiling etc.] Remember that the minimal Stan model requires 3 chunks, one specifying the data it will need as input; one specifying the parameters to be estimated; one specifying the model within which the parameters appear, and the priors for those parameters. stan_model &lt;- &quot; // This model infers a random bias from a sequences of 1s and 0s (right and left hand choices) // The input (data) for the model. n of trials and the sequence of choices (right as 1, left as 0) data { int&lt;lower=1&gt; n; // n of trials array[n] int h; // sequence of choices (right as 1, left as 0) as long as n } // The parameters that the model needs to estimate (theta) parameters { real&lt;lower=0, upper=1&gt; theta; // rate or theta is a probability and therefore bound between 0 and 1 } // The model to be estimated (a bernoulli, parameter theta, prior on the theta) model { // The prior for theta is a beta distribution alpha of 1, beta of 1, equivalent to a uniform between 0 and 1 target += beta_lpdf(theta | 1, 1); // N.B. you could also define the parameters of the priors as variables to be found in the data // target += beta_lpdf(theta | beta_alpha, beta_beta); BUT remember to add beta_alpha and beta_beta to the data list // The model consists of a bernoulli distribution (binomial w 1 trial only) with a rate theta target += bernoulli_lpmf(h | theta); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W3_SimpleBernoulli.stan&quot;) 5.4.3 Compiling and fitting the model ## Specify where the model is file &lt;- file.path(&quot;stan/W3_SimpleBernoulli.stan&quot;) # Compile the model mod &lt;- cmdstan_model(file, # this specifies we can parallelize the gradient estimations on multiple cores cpp_options = list(stan_threads = TRUE), # this is a trick to make it faster stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, # the data :-) seed = 123, # a seed, so I always get the same results chains = 2, # how many chains should I fit (to check whether they give the same results) parallel_chains = 2, # how many of the chains can be run in parallel? threads_per_chain = 2, # distribute gradient estimations within chain across multiple cores iter_warmup = 1000, # warmup iterations through which hyperparameters (steps and step length) are adjusted iter_sampling = 2000, # total number of iterations refresh = 0, # how often to show that iterations have been run output_dir = &quot;simmodels&quot;, # saves the samples as csv so it can be later loaded max_treedepth = 20, # how many steps in the future to check to avoid u-turns adapt_delta = 0.99, # how high a learning rate to adjust hyperparameters during warmup ) # Same the fitted model samples$save_object(&quot;simmodels/W3_SimpleBernoulli.rds&quot;) 5.4.4 Summarizing the model Now the model is ready to be assessed. First we simply generate a summary of the estimates to have a first idea. samples &lt;- readRDS(&quot;simmodels/W3_SimpleBernoulli.rds&quot;) samples$summary() # summarize the model ## # A tibble: 2 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -54.9 -54.7 0.739 0.324 -56.4 -54.4 1.00 991. 987. ## 2 theta 0.835 0.837 0.0342 0.0340 0.775 0.887 1.00 1117. 1012. 5.4.5 Assessing model quality Then we need to look more in the details at the quality of the estimation: * the markov chains * how the prior and the posterior estimates relate to each other (whether the prior is constraining the posterior estimate) # Extract posterior samples and include sampling of the prior: draws_df &lt;- as_draws_df(samples$draws()) # Checking the model&#39;s chains ggplot(draws_df, aes(.iteration, theta, group = .chain, color = .chain)) + geom_line() + theme_classic() # add a prior for theta (ugly, but we&#39;ll do better soon) draws_df &lt;- draws_df %&gt;% mutate( theta_prior = rbeta(nrow(draws_df), 1, 1) ) # Now let&#39;s plot the density for theta (prior and posterior) ggplot(draws_df) + geom_density(aes(theta), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(theta_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0.8, linetype = &quot;dashed&quot;, color = &quot;black&quot;, linewidth = 1.5) + xlab(&quot;Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() As we can see from the posterior estimates and the prior posterior update check, our model is doing a decent job. It doesn’t exactly reconstruct the rate of 0.8, but 0.755 is pretty close and 0.8 is included within the credible interval. Now we build the same model, but using the log odds scale for the theta parameter, which will become useful later when we condition theta on variables and build multilevel models (as we can do what we want in a log odds space and it will always be bound between 0 and 1). stan_model &lt;- &quot; // This model infers a random bias from a sequences of 1s and 0s (right and left hand choices) // The input (data) for the model. n of trials and the sequence of choices (right as 1, left as 0) data { int&lt;lower=1&gt; n; // n of trials array[n] int h; // sequence of choices (right as 1, left as 0) as long as n } // The parameters that the model needs to estimate (theta) parameters { real theta; // note it is unbounded as we now work on log odds } // The model to be estimated (a bernoulli, parameter theta, prior on the theta) model { // The prior for theta on a log odds scale is a normal distribution with a mean of 0 and a sd of 1. // This covers most of the probability space between 0 and 1, after being converted to probability. target += normal_lpdf(theta | 0, 1); // as before the parameters of the prior could be fed as variables // target += normal_lpdf(theta | normal_mu, normal_sigma); // The model consists of a bernoulli distribution (binomial w 1 trial only) with a rate theta, // note we specify it uses a logit link (theta is in logodds) target += bernoulli_logit_lpmf(h | theta); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W3_SimpleBernoulli_logodds.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W3_SimpleBernoulli_logodds.stan&quot; ## With the logit format ## Specify where the model is file &lt;- file.path(&quot;stan/W3_SimpleBernoulli_logodds.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1000, iter_sampling = 2000, refresh = 0, output_dir = &quot;simmodels&quot;, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 finished in 0.0 seconds. ## Chain 2 finished in 0.1 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 0.0 seconds. ## Total execution time: 0.4 seconds. # Same the fitted model samples$save_object(&quot;simmodels/W3_SimpleBernoulli_logodds.rds&quot;) 5.4.6 Summarizing the results samples &lt;- readRDS(&quot;simmodels/W3_SimpleBernoulli_logodds.rds&quot;) # Diagnostics samples$cmdstan_diagnose() ## Checking sampler transitions treedepth. ## Treedepth satisfactory for all transitions. ## ## Checking sampler transitions for divergences. ## No divergent transitions found. ## ## Checking E-BFMI - sampler transitions HMC potential energy. ## E-BFMI satisfactory. ## ## Rank-normalized split effective sample size satisfactory for all parameters. ## ## Rank-normalized split R-hat values satisfactory for all parameters. ## ## Processing complete, no problems detected. # Extract posterior samples and include sampling of the prior: draws_df &lt;- as_draws_df(samples$draws()) ggplot(draws_df, aes(.iteration, theta, group = .chain, color = .chain)) + geom_line() + theme_classic() # add a prior for theta (ugly, but we&#39;ll do better soon) draws_df &lt;- draws_df %&gt;% mutate( theta_prior = rnorm(nrow(draws_df), 0, 1) ) # Now let&#39;s plot the density for theta (prior and posterior) ggplot(draws_df) + geom_density(aes(theta), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(theta_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 1.38, linetype = &quot;dashed&quot;, color = &quot;black&quot;, size = 1.5) + xlab(&quot;Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() # Summary samples$summary() ## # A tibble: 2 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -59.6 -59.4 0.672 0.319 -60.9 -59.1 1.00 1371. 1245. ## 2 theta 1.42 1.41 0.221 0.230 1.06 1.78 1.00 1088. 1391. We can see that the results are very similar. 5.5 Parameter recovery Now that we see that the model works in one case, we can run it throughout all possible rate and noise levels in the simulation. N.B. here is using loops, parallelized version in the next code chunk. # Now we need to scale it up to all possible rates and noises # recovery_df &lt;- NULL # # for (noiseLvl in unique(d$noise)) { # # for (rateLvl in unique(d$rate)) { # # dd &lt;- d %&gt;% subset( # noise == noiseLvl &amp; rate == rateLvl # ) # # data &lt;- list( # n = 120, # h = dd$choice # ) # # samples &lt;- mod$sample( # data = data, # seed = 123, # chains = 1, # parallel_chains = 1, # threads_per_chain = 1, # iter_warmup = 1000, # iter_sampling = 2000, # refresh = 0, # max_treedepth = 20, # adapt_delta = 0.99, # ) # # draws_df &lt;- as_draws_df(samples$draws()) # temp &lt;- tibble(biasEst = inv_logit_scaled(draws_df$theta), # biasTrue = rateLvl, noise = noiseLvl) # # # if (exists(&quot;recovery_df&quot;)) {recovery_df &lt;- rbind(recovery_df, temp)} else {recovery_df &lt;- temp} # # } # # } # # write_csv(recovery_df, &quot;simdata/W3_recoverydf_simple.csv&quot;) Now we can look at the relation between the “true” bias value we inputted in the simulation and the inferred bias value - the posterior estimates of bias. recovery_df &lt;- read_csv(&quot;simdata/W3_recoverydf_simple.csv&quot;) ggplot(recovery_df, aes(biasTrue, biasEst)) + geom_point(alpha = 0.1) + geom_smooth() + facet_wrap(.~noise) + theme_classic() There’s much to be said about the final plot, but for now let’s just say that it looks good. We can reconstruct in a nice ordered way true rate values. However, our ability to do so decreases with the increase in noise. So far no surprises. Wait, you say, shouldn’t we actually model the generative process, that is, include noise in the Stan model? Gold star, there! But let’s wait a bit before we get there, we’ll need mixture models. One final note before moving to the memory model: what if we parallelized the parameter recovery, so that different models / datasets run on different cores? This was not necessary above (it ran in a few minutes anyway), but will become crucial with more complex models. To parallelize, we rely on furrr, a neat R package that distributes parallel operations across cores. First we need to define the function that will define the operations to be run on each core separately, here we simulate the data according to a seed, a n of trials, a rate and a noise, and then we fit the model to them. Second, we need to create a tibble of the seeds, n of trials, rate and noise values that should be simulated. Third, we use future_pmap_dfr to run the function on each row of the tibble above separately on a different core. Note that I set the system to split across 4 parallel cores (to work on my computer without clogging it). Do change it according to the system you are using. Note that if you have 40 “jobs” (rows of the tibble, sets of parameter values to run), using e.g. 32 cores will not substantially speed things more than using 20. # pacman::p_load(future, purrr, furrr) # # plan(multisession, workers = 4) # # sim_d_and_fit &lt;- function(seed, trials, rateLvl, noiseLvl) { # # for (t in seq(trials)) { # looping through trials (to make it homologous to more reactive models) # randomChoice[t] &lt;- RandomAgentNoise_f(rateLvl, noiseLvl) # } # temp &lt;- tibble(trial = seq(trials), choice = randomChoice, rate, noise) # # data &lt;- list( # n = 120, # h = temp$choice # ) # # samples &lt;- mod$sample( # data = data, # seed = 1000, # chains = 1, # parallel_chains = 1, # threads_per_chain = 1, # iter_warmup = 1000, # iter_sampling = 2000, # refresh = 0, # max_treedepth = 20, # adapt_delta = 0.99, # ) # # draws_df &lt;- as_draws_df(samples$draws()) # temp &lt;- tibble(biasEst = inv_logit_scaled(draws_df$theta), # biasTrue = rateLvl, noise = noiseLvl) # # return(temp) # # } # # # temp &lt;- tibble(unique(d[,c(&quot;rate&quot;, &quot;noise&quot;)])) %&gt;% # mutate(seed = 1000, trials = 120) %&gt;% # rename(rateLvl = rate, noiseLvl = noise) # # recovery_df &lt;- future_pmap_dfr(temp, sim_d_and_fit, .options = furrr_options(seed = TRUE)) # # write_csv(recovery_df, &quot;simdata/W3_recoverydf_parallel.csv&quot;) recovery_df &lt;- read_csv(&quot;simdata/W3_recoverydf_parallel.csv&quot;) And now we load the data and visualize it as before. ggplot(recovery_df, aes(biasTrue, biasEst)) + geom_point(alpha = 0.1) + geom_smooth() + facet_wrap(.~noise) + theme_classic() 5.6 The memory model: conditioning theta Now that we fitted the base model, we can move onto more complex models. For instance a memory model (including all previous trials). Here we rely on a generalized linear model kind of thinking: the theta is the expression of a linear model (bias + b1 * PreviousRate). To make the variable more intuitive we code previous rate - which is bound to a probability 0-1 space - into log-odds via a logit link/transformation. In this way a previous rate with more left than right choices will result in a negative value, thereby decreasing our propensity to choose right; and one with more right than left choices will result in a positive value, thereby increasing our propensity to choose right. # We subset to only include no noise and a specific rate d1 &lt;- d %&gt;% subset(noise == 0 &amp; rate == 0.8) %&gt;% rename(Other = choice) %&gt;% mutate(cumulativerate = lag(cumulativerate, 1)) d1$cumulativerate[1] &lt;- 0.5 # no prior info at first trial d1$cumulativerate[d1$cumulativerate == 0] &lt;- 0.01 d1$cumulativerate[d1$cumulativerate == 1] &lt;- 0.99 # Now we create the memory agent with a coefficient of 1 (in log odds) MemoryAgent_f &lt;- function(bias, beta, cumulativerate){ choice = rbinom(1, 1, inv_logit_scaled(bias + beta * logit_scaled(cumulativerate))) return(choice) } d1$Self[1] &lt;- RandomAgentNoise_f(0.5, 0) for (i in 2:trials) { d1$Self[i] &lt;- MemoryAgent_f(bias = 0, beta = 1, d1$cumulativerate[i]) } ## Create the data data &lt;- list( n = 120, h = d1$Self, memory = d1$cumulativerate # this creates the new parameter: the rate of right hands so far in log-odds ) stan_model &lt;- &quot; // The input (data) for the model. n of trials and h for (right and left) hand data { int&lt;lower=1&gt; n; array[n] int h; vector[n] memory; // here we add the new variable between 0.01 and .99 } // The parameters accepted by the model. parameters { real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)? real beta; // how strongly is previous rate impacting the decision? } // The model to be estimated. model { // priors target += normal_lpdf(bias | 0, .3); target += normal_lpdf(beta | 0, .5); // model target += bernoulli_logit_lpmf(h | bias + beta * logit(memory)); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W3_MemoryBernoulli.stan&quot;) ## Specify where the model is file &lt;- file.path(&quot;stan/W3_MemoryBernoulli.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1000, iter_sampling = 1000, refresh = 0, output_dir = &quot;simmodels&quot;, max_treedepth = 20, adapt_delta = 0.99, ) # Same the fitted model samples$save_object(&quot;simmodels/W3_MemoryBernoulli.rds&quot;) 5.6.1 Summarizing the results samples &lt;- readRDS(&quot;simmodels/W3_MemoryBernoulli.rds&quot;) # Diagnostics samples$cmdstan_diagnose() ## Checking sampler transitions treedepth. ## Treedepth satisfactory for all transitions. ## ## Checking sampler transitions for divergences. ## No divergent transitions found. ## ## Checking E-BFMI - sampler transitions HMC potential energy. ## E-BFMI satisfactory. ## ## Rank-normalized split effective sample size satisfactory for all parameters. ## ## Rank-normalized split R-hat values satisfactory for all parameters. ## ## Processing complete, no problems detected. # Extract posterior samples and include sampling of the prior: draws_df &lt;- as_draws_df(samples$draws()) ggplot(draws_df, aes(.iteration, bias, group = .chain, color = .chain)) + geom_line() + theme_classic() ggplot(draws_df, aes(.iteration, beta, group = .chain, color = .chain)) + geom_line() + theme_classic() # add a prior for theta (ugly, but we&#39;ll do better soon) draws_df &lt;- draws_df %&gt;% mutate( bias_prior = rnorm(nrow(draws_df), 0, .3), beta_prior = rnorm(nrow(draws_df), 0, .5), ) # Now let&#39;s plot the density for theta (prior and posterior) ggplot(draws_df) + geom_density(aes(bias), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(bias_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;black&quot;, size = 1.5) + xlab(&quot;Bias&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_density(aes(beta), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(beta_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 1, linetype = &quot;dashed&quot;, color = &quot;black&quot;, size = 1.5) + xlab(&quot;Beta&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() samples$summary() ## # A tibble: 3 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -47.4 -47.1 0.964 0.706 -49.4 -46.5 1.01 719. 918. ## 2 bias 0.230 0.222 0.270 0.268 -0.202 0.682 1.00 610. 904. ## 3 beta 0.926 0.920 0.203 0.201 0.597 1.26 1.00 567. 763. We can see that the model has now estimated both the bias and the role of previous memory. Bias should reflect the bias in the setup (0.5 which in log odds is 0), and the beta coefficient for memory (roughly 1). More on the quality checks of the models in the next chapter. 5.7 Memory agent with internal parameter So far we behaved like in GLM: we keep feeding to the model an external variable of memory, but what if we coded memory as an internal parameter? This opens up to further possibilities to model how long memory is kept and weighted by distance from the current moment, etc. ## Create the data data &lt;- list( n = 120, h = d1$Self, other = d1$Other ) stan_model &lt;- &quot; // Memory-based choice model with prior and posterior predictions data { int&lt;lower=1&gt; n; array[n] int h; array[n] int other; } parameters { real bias; real beta; } transformed parameters { vector[n] memory; for (trial in 1:n) { if (trial == 1) { memory[trial] = 0.5; } if (trial &lt; n) { memory[trial + 1] = memory[trial] + ((other[trial] - memory[trial]) / (trial + 1)); if (memory[trial + 1] == 0) { memory[trial + 1] = 0.01; } if (memory[trial + 1] == 1) { memory[trial + 1] = 0.99; } } } } model { // Priors target += normal_lpdf(bias | 0, .3); target += normal_lpdf(beta | 0, .5); // Likelihood for (trial in 1:n) { target += bernoulli_logit_lpmf(h[trial] | bias + beta * logit(memory[trial])); } } generated quantities { // Generate prior samples real bias_prior = normal_rng(0, .3); real beta_prior = normal_rng(0, .5); // Variables for predictions array[n] int prior_preds; array[n] int posterior_preds; vector[n] memory_prior; vector[n] log_lik; // Generate predictions at different memory levels array[3] real memory_levels = {0.2, 0.5, 0.8}; // Low, neutral, and high memory array[3] int prior_preds_memory; array[3] int posterior_preds_memory; // Generate predictions from prior for each memory level for (i in 1:3) { real logit_memory = logit(memory_levels[i]); prior_preds_memory[i] = bernoulli_logit_rng(bias_prior + beta_prior * logit_memory); posterior_preds_memory[i] = bernoulli_logit_rng(bias + beta * logit_memory); } // Generate predictions from prior memory_prior[1] = 0.5; for (trial in 1:n) { if (trial == 1) { prior_preds[trial] = bernoulli_logit_rng(bias_prior + beta_prior * logit(memory_prior[trial])); } else { memory_prior[trial] = memory_prior[trial-1] + ((other[trial-1] - memory_prior[trial-1]) / trial); if (memory_prior[trial] == 0) { memory_prior[trial] = 0.01; } if (memory_prior[trial] == 1) { memory_prior[trial] = 0.99; } prior_preds[trial] = bernoulli_logit_rng(bias_prior + beta_prior * logit(memory_prior[trial])); } } // Generate predictions from posterior for (trial in 1:n) { posterior_preds[trial] = bernoulli_logit_rng(bias + beta * logit(memory[trial])); log_lik[trial] = bernoulli_logit_lpmf(h[trial] | bias + beta * logit(memory[trial])); } } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W3_InternalMemory.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W3_InternalMemory.stan&quot; ## Specify where the model is file &lt;- file.path(&quot;stan/W3_InternalMemory.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 1, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1000, iter_sampling = 1000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 1 chain, with 2 thread(s) per chain... ## ## Chain 1 finished in 0.6 seconds. samples$summary() ## # A tibble: 614 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -52.7 -52.3 1.14 0.763 -55.0 -51.7 1.01 224. 259. ## 2 bias 0.320 0.312 0.281 0.280 -0.152 0.803 1.00 271. 219. ## 3 beta 0.945 0.945 0.240 0.222 0.551 1.33 1.01 265. 339. ## 4 memory[1] 0.5 0.5 0 0 0.5 0.5 NA NA NA ## 5 memory[2] 0.75 0.75 0 0 0.75 0.75 NA NA NA ## 6 memory[3] 0.5 0.5 0 0 0.5 0.5 NA NA NA ## 7 memory[4] 0.625 0.625 0 0 0.625 0.625 NA NA NA ## 8 memory[5] 0.5 0.5 0 0 0.5 0.5 NA NA NA ## 9 memory[6] 0.417 0.417 0 0 0.417 0.417 NA NA NA ## 10 memory[7] 0.5 0.5 0 0 0.5 0.5 NA NA NA ## # ℹ 604 more rows library(tidyverse) library(bayesplot) draws_df &lt;- as_draws_df(samples$draws()) # 1. Check chain convergence # Plot traces for main parameters mcmc_trace(draws_df, pars = c(&quot;bias&quot;, &quot;beta&quot;)) + theme_minimal() + ggtitle(&quot;Parameter Traces Across Chains&quot;) # Plot rank histograms to check mixing mcmc_rank_hist(draws_df, pars = c(&quot;bias&quot;, &quot;beta&quot;)) # 2. Prior-Posterior Update Check p1 &lt;- ggplot() + geom_density(data = draws_df, aes(bias, fill = &quot;Posterior&quot;), alpha = 0.5) + geom_density(data = draws_df, aes(bias_prior, fill = &quot;Prior&quot;), alpha = 0.5) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;) + scale_fill_manual(values = c(&quot;Prior&quot; = &quot;red&quot;, &quot;Posterior&quot; = &quot;blue&quot;)) + theme_minimal() + ggtitle(&quot;Prior-Posterior Update: Bias Parameter&quot;) p2 &lt;- ggplot() + geom_density(data = draws_df, aes(beta, fill = &quot;Posterior&quot;), alpha = 0.5) + geom_density(data = draws_df, aes(beta_prior, fill = &quot;Prior&quot;), alpha = 0.5) + geom_vline(xintercept = 1, linetype = &quot;dashed&quot;) + scale_fill_manual(values = c(&quot;Prior&quot; = &quot;red&quot;, &quot;Posterior&quot; = &quot;blue&quot;)) + theme_minimal() + ggtitle(&quot;Prior-Posterior Update: Beta Parameter&quot;) p3 &lt;- ggplot() + geom_point(data = draws_df, aes(bias, beta), alpha = 0.5) + theme_minimal() + ggtitle(&quot;Correlation&quot;) p1 + p2 + p3 # First let&#39;s properly extract and organize our posterior predictions posterior_predictions &lt;- draws_df %&gt;% select(starts_with(&quot;posterior_preds[&quot;)) %&gt;% # Select all posterior prediction columns pivot_longer(everything(), names_to = &quot;trial&quot;, values_to = &quot;prediction&quot;) %&gt;% # Clean up the trial number from the Stan array notation mutate(trial = as.numeric(str_extract(trial, &quot;\\\\d+&quot;))) # Calculate summary statistics for posterior predictions posterior_summary &lt;- posterior_predictions %&gt;% group_by(trial) %&gt;% summarise( mean = mean(prediction), lower = quantile(prediction, 0.025), upper = quantile(prediction, 0.975) ) # Do the same for prior predictions prior_predictions &lt;- draws_df %&gt;% select(starts_with(&quot;prior_preds[&quot;)) %&gt;% pivot_longer(everything(), names_to = &quot;trial&quot;, values_to = &quot;prediction&quot;) %&gt;% mutate(trial = as.numeric(str_extract(trial, &quot;\\\\d+&quot;))) prior_summary &lt;- prior_predictions %&gt;% group_by(trial) %&gt;% summarise( mean = mean(prediction), lower = quantile(prediction, 0.025), upper = quantile(prediction, 0.975) ) # Now let&#39;s create our visualization # First the prior predictive check p4 &lt;- ggplot() + # Add prior prediction interval geom_ribbon(data = prior_summary, aes(x = trial, ymin = lower, ymax = upper), alpha = 0.2, fill = &quot;red&quot;) + # Add mean prior prediction geom_line(data = prior_summary, aes(x = trial, y = mean), color = &quot;red&quot;) + # Add actual data points geom_point(data = tibble(trial = 1:length(data$h), choice = data$h), aes(x = trial, y = choice), alpha = 0.5) + labs(title = &quot;Prior Predictive Check&quot;, x = &quot;Trial&quot;, y = &quot;Choice (0/1)&quot;) + theme_minimal() # Then the posterior predictive check p5 &lt;- ggplot() + # Add posterior prediction interval geom_ribbon(data = posterior_summary, aes(x = trial, ymin = lower, ymax = upper), alpha = 0.2, fill = &quot;blue&quot;) + # Add mean posterior prediction geom_line(data = posterior_summary, aes(x = trial, y = mean), color = &quot;blue&quot;) + # Add actual data points geom_point(data = tibble(trial = 1:length(data$h), choice = data$h), aes(x = trial, y = choice), alpha = 0.5) + labs(title = &quot;Posterior Predictive Check&quot;, x = &quot;Trial&quot;, y = &quot;Choice (0/1)&quot;) + theme_minimal() # Display plots side by side library(patchwork) p4 + p5 # First, let&#39;s calculate the total number of 1s predicted in each posterior sample posterior_totals &lt;- draws_df %&gt;% select(starts_with(&quot;posterior_preds[&quot;)) %&gt;% # Sum across rows to get total 1s per sample mutate(total_ones = rowSums(.)) # Do the same for prior predictions prior_totals &lt;- draws_df %&gt;% select(starts_with(&quot;prior_preds[&quot;)) %&gt;% mutate(total_ones = rowSums(.)) # Calculate actual number of 1s in the data actual_ones &lt;- sum(data$h) # Create visualization comparing distributions ggplot() + # Prior predictive distribution geom_histogram(data = prior_totals, aes(x = total_ones, fill = &quot;Prior&quot;), alpha = 0.3) + # Posterior predictive distribution geom_histogram(data = posterior_totals, aes(x = total_ones, fill = &quot;Posterior&quot;), alpha = 0.3) + # Vertical line for actual data geom_vline(xintercept = actual_ones, linetype = &quot;dashed&quot;, color = &quot;black&quot;, size = 1) + # Aesthetics scale_fill_manual(values = c(&quot;Prior&quot; = &quot;red&quot;, &quot;Posterior&quot; = &quot;blue&quot;), name = &quot;Distribution&quot;) + labs(title = &quot;Distribution of Predicted Successes (1s) out of 120 Trials&quot;, subtitle = &quot;Comparing Prior, Posterior and Actual Data&quot;, x = &quot;Number of 1s&quot;, y = &quot;Density&quot;) + theme_minimal() + # Add annotation for actual value annotate(&quot;text&quot;, x = actual_ones, y = 0, label = paste(&quot;Actual:&quot;, actual_ones), vjust = -0.5) # Let&#39;s also print summary statistics prior_summary &lt;- prior_totals %&gt;% summarise( mean = mean(total_ones), sd = sd(total_ones), q025 = quantile(total_ones, 0.025), q975 = quantile(total_ones, 0.975) ) posterior_summary &lt;- posterior_totals %&gt;% summarise( mean = mean(total_ones), sd = sd(total_ones), q025 = quantile(total_ones, 0.025), q975 = quantile(total_ones, 0.975) ) print(&quot;Prior predictive summary:&quot;) ## [1] &quot;Prior predictive summary:&quot; print(prior_summary) ## # A tibble: 1 × 4 ## mean sd q025 q975 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 60.0 20.0 23 98.0 print(&quot;Posterior predictive summary:&quot;) ## [1] &quot;Posterior predictive summary:&quot; print(posterior_summary) ## # A tibble: 1 × 4 ## mean sd q025 q975 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 98.6 5.40 87 108. # First let&#39;s calculate predicted probabilities for each draw and memory level predicted_probs &lt;- draws_df %&gt;% mutate( # Calculate probability of choosing right for each memory level # using the logistic function on our parameter estimates prob_low = inv_logit_scaled(bias + beta * logit_scaled(0.2)), prob_mid = inv_logit_scaled(bias + beta * logit_scaled(0.5)), prob_high = inv_logit_scaled(bias + beta * logit_scaled(0.8)) ) %&gt;% # Reshape to long format for easier plotting pivot_longer( cols = starts_with(&quot;prob_&quot;), names_to = &quot;memory_level&quot;, values_to = &quot;probability&quot; ) %&gt;% mutate( memory_value = case_when( memory_level == &quot;prob_low&quot; ~ 0.2, memory_level == &quot;prob_mid&quot; ~ 0.5, memory_level == &quot;prob_high&quot; ~ 0.8 ) ) # Do the same for prior predictions prior_probs &lt;- draws_df %&gt;% mutate( prob_low = inv_logit_scaled(bias_prior + beta_prior * logit_scaled(0.2)), prob_mid = inv_logit_scaled(bias_prior + beta_prior * logit_scaled(0.5)), prob_high = inv_logit_scaled(bias_prior + beta_prior * logit_scaled(0.8)) ) %&gt;% pivot_longer( cols = starts_with(&quot;prob_&quot;), names_to = &quot;memory_level&quot;, values_to = &quot;probability&quot; ) %&gt;% mutate( memory_value = case_when( memory_level == &quot;prob_low&quot; ~ 0.2, memory_level == &quot;prob_mid&quot; ~ 0.5, memory_level == &quot;prob_high&quot; ~ 0.8 ) ) # Create visualization with density plots p1 &lt;- ggplot() + # Add prior distributions geom_density(data = prior_probs, aes(x = probability, fill = &quot;Prior&quot;), alpha = 0.3) + # Add posterior distributions geom_density(data = predicted_probs, aes(x = probability, fill = &quot;Posterior&quot;), alpha = 0.3) + # Separate by memory level facet_wrap(~memory_value, labeller = labeller(memory_value = c( &quot;0.2&quot; = &quot;Low Memory (20% Right)&quot;, &quot;0.5&quot; = &quot;Neutral Memory (50% Right)&quot;, &quot;0.8&quot; = &quot;High Memory (80% Right)&quot; ))) + # Aesthetics scale_fill_manual(values = c(&quot;Prior&quot; = &quot;red&quot;, &quot;Posterior&quot; = &quot;blue&quot;), name = &quot;Distribution&quot;) + labs(title = &quot;Distribution of Predicted Probabilities at Different Memory Levels&quot;, x = &quot;Probability of Choosing Right&quot;, y = &quot;Density&quot;) + theme_minimal() # Alternative visualization using violin plots p2 &lt;- ggplot() + # Add prior distributions geom_violin(data = prior_probs, aes(x = factor(memory_value), y = probability, fill = &quot;Prior&quot;), alpha = 0.3, position = position_dodge(width = 0.5)) + # Add posterior distributions geom_violin(data = predicted_probs, aes(x = factor(memory_value), y = probability, fill = &quot;Posterior&quot;), alpha = 0.3, position = position_dodge(width = 0.5)) + # Aesthetics scale_fill_manual(values = c(&quot;Prior&quot; = &quot;red&quot;, &quot;Posterior&quot; = &quot;blue&quot;), name = &quot;Distribution&quot;) + scale_x_discrete(labels = c(&quot;Low\\n(20% Right)&quot;, &quot;Neutral\\n(50% Right)&quot;, &quot;High\\n(80% Right)&quot;)) + labs(title = &quot;Distribution of Predicted Probabilities by Memory Level&quot;, x = &quot;Memory Level&quot;, y = &quot;Probability of Choosing Right&quot;) + theme_minimal() # Display both visualizations library(patchwork) p1 / p2 # 4. Check for divergences # Extract divergent transitions n_div &lt;- sum(draws_df$.divergent) print(paste(&quot;Number of divergent transitions:&quot;, n_div)) ## [1] &quot;Number of divergent transitions: 0&quot; # Plot divergent transitions in parameter space # ggplot(draws_df, aes(bias, beta)) + # geom_point(aes(color = factor(.divergent)), alpha = 0.5) + # scale_color_manual(values = c(&quot;black&quot;, &quot;red&quot;)) + # theme_minimal() + # ggtitle(&quot;Divergent Transitions in Parameter Space&quot;) Now that we know how to model memory as an internal state, we can play with making the update discount the past, setting a parameter that indicates after how many trials memory is lost, etc. 5.7.1 Trying out a more complex memory model, with a rate of forgetting that exponentially discounts the past stan_model &lt;- &quot; // The input (data) for the model. n of trials and h for (right and left) hand data { int&lt;lower=1&gt; n; array[n] int h; array[n] int other; } // The parameters accepted by the model. parameters { real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)? real beta; // how strongly is previous rate impacting the decision? real&lt;lower=0, upper=1&gt; forgetting; } // The model to be estimated. model { vector[n] memory; // Priors target += beta_lpdf(forgetting | 1, 1); target += normal_lpdf(bias | 0, .3); target += normal_lpdf(beta | 0, .5); // Model, looping to keep track of memory for (trial in 1:n) { if (trial == 1) { memory[trial] = 0.5; } target += bernoulli_logit_lpmf(h[trial] | bias + beta * logit(memory[trial])); if (trial &lt; n){ memory[trial + 1] = (1 - forgetting) * memory[trial] + forgetting * other[trial]; if (memory[trial + 1] == 0){memory[trial + 1] = 0.01;} if (memory[trial + 1] == 1){memory[trial + 1] = 0.99;} } } } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W3_InternalMemory2.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W3_InternalMemory2.stan&quot; ## Specify where the model is file &lt;- file.path(&quot;stan/W3_InternalMemory2.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 1, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1000, iter_sampling = 1000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 1 chain, with 2 thread(s) per chain... ## ## Chain 1 finished in 0.7 seconds. samples$summary() ## # A tibble: 4 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -58.0 -57.7 1.28 0.943 -60.6 -56.7 0.999 297. 374. ## 2 bias 0.479 0.475 0.246 0.249 0.0792 0.879 1.00 363. 489. ## 3 beta 0.810 0.804 0.270 0.253 0.361 1.24 1.00 425. 455. ## 4 forgetting 0.0660 0.0536 0.0515 0.0288 0.0221 0.147 0.999 557. 411. The memory model we’ve implemented can be seen as part of a broader family of models that track and update beliefs based on incoming evidence. Let’s explore how it relates to some key frameworks. 5.7.2 Connection to Kalman Filters Our memory model updates beliefs about the probability of right-hand choices using a weighted average of past observations. This is conceptually similar to how a Kalman filter works, though simpler: Kalman filters maintain both an estimate and uncertainty about that estimate They optimally weight new evidence based on relative uncertainty Our model uses a fixed weighting scheme (1/trial or the forgetting parameter) The key difference is that Kalman filters dynamically adjust how much they learn from new evidence based on uncertainty, while our model uses a fixed learning scheme. 5.8 Relationship to Rescorla-Wagner The Rescorla-Wagner model of learning follows the form: V(t+1) = V(t) + α(λ - V(t)) where: V(t) is the current estimate α is the learning rate λ is the observed outcome (λ - V(t)) is the prediction error Our memory model with forgetting parameter follows a very similar structure: memory(t+1) = (1-forgetting) * memory(t) + forgetting * outcome(t) This can be rewritten as: memory(t+1) = memory(t) + forgetting * (outcome(t) - memory(t)) Making the parallel clear: our forgetting parameter acts as the learning rate α in Rescorla-Wagner. 5.8.1 Connection to Hierarchical Gaussian Filter (HGF) The HGF extends these ideas by: Tracking beliefs at multiple levels Allowing learning rates to vary over time Explicitly modeling environmental volatility Our model could be seen as the simplest case of an HGF where: We only track one level (probability of right-hand choice) Have a fixed learning rate (forgetting parameter) Don’t explicitly model environmental volatility 5.8.2 Implications for Model Development Understanding these relationships helps us think about how models relate to each other and to extend our model: We could add uncertainty estimates to get Kalman-like behavior We could make the forgetting parameter dynamic to capture changing learning rates We could add multiple levels to track both immediate probabilities and longer-term trends Each extension would make the model more flexible but also more complex to fit to data. The choice depends on our specific research questions and available data. 5.9 Bayesian memory agent We can also model the memory agent in a Bayesian framework. This allows us to model the agent as (optimally) estimating a possible distribution of rates from the other’s behavior and keep all the uncertainty. stan_model &lt;- &quot; data { int&lt;lower=1&gt; n; // number of trials array[n] int h; // agent&#39;s choices (0 or 1) array[n] int other; // other player&#39;s choices (0 or 1) } parameters { real&lt;lower=0&gt; alpha_prior; // Prior alpha parameter real&lt;lower=0&gt; beta_prior; // Prior beta parameter } transformed parameters { vector[n] alpha; // Alpha parameter at each trial vector[n] beta; // Beta parameter at each trial vector[n] rate; // Expected rate at each trial // Initialize with prior alpha[1] = alpha_prior; beta[1] = beta_prior; rate[1] = alpha[1] / (alpha[1] + beta[1]); // Sequential updating of Beta distribution for(t in 2:n) { // Update Beta parameters based on previous observation alpha[t] = alpha[t-1] + other[t-1]; beta[t] = beta[t-1] + (1 - other[t-1]); // Calculate expected rate rate[t] = alpha[t] / (alpha[t] + beta[t]); } } model { // Priors on hyperparameters target += gamma_lpdf(alpha_prior | 2, 1); target += gamma_lpdf(beta_prior | 2, 1); // Agent&#39;s choices follow current rate estimates for(t in 1:n) { target += bernoulli_lpmf(h[t] | rate[t]); } } generated quantities { array[n] int prior_preds; array[n] int posterior_preds; real initial_rate = alpha_prior / (alpha_prior + beta_prior); // Prior predictions use initial rate for(t in 1:n) { prior_preds[t] = bernoulli_rng(initial_rate); } // Posterior predictions use sequentially updated rates for(t in 1:n) { posterior_preds[t] = bernoulli_rng(rate[t]); } } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W3_BayesianMemory.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W3_BayesianMemory.stan&quot; ## Specify where the model is file &lt;- file.path(&quot;stan/W3_BayesianMemory.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 1, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1000, iter_sampling = 1000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 1 chain, with 2 thread(s) per chain... ## ## Chain 1 finished in 0.3 seconds. samples$summary() ## # A tibble: 604 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -53.0 -52.7 0.993 0.760 -55.0 -52.0 1.00 306. 442. ## 2 alpha_prior 2.67 2.32 1.65 1.43 0.675 5.83 1.01 280. 456. ## 3 beta_prior 0.916 0.783 0.641 0.559 0.174 2.13 1.00 365. 379. ## 4 alpha[1] 2.67 2.32 1.65 1.43 0.675 5.83 1.01 280. 456. ## 5 alpha[2] 3.67 3.32 1.65 1.43 1.68 6.83 1.01 280. 456. ## 6 alpha[3] 3.67 3.32 1.65 1.43 1.68 6.83 1.01 280. 456. ## 7 alpha[4] 4.67 4.32 1.65 1.43 2.68 7.83 1.01 280. 456. ## 8 alpha[5] 4.67 4.32 1.65 1.43 2.68 7.83 1.01 280. 456. ## 9 alpha[6] 4.67 4.32 1.65 1.43 2.68 7.83 1.01 280. 456. ## 10 alpha[7] 5.67 5.32 1.65 1.43 3.68 8.83 1.01 280. 456. ## # ℹ 594 more rows library(posterior) library(bayesplot) # Extract draws draws_df &lt;- as_draws_df(samples$draws()) # First let&#39;s look at the priors ggplot(draws_df) + geom_density(aes(alpha_prior), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(beta_prior), fill = &quot;red&quot;, alpha = 0.3) + theme_classic() + labs(title = &quot;Prior Distributions&quot;, x = &quot;Parameter Value&quot;, y = &quot;Density&quot;) # Now let&#39;s look at how the rate evolves over trials # First melt the rate values across trials into long format rate_df &lt;- draws_df %&gt;% select(starts_with(&quot;rate[&quot;)) %&gt;% pivot_longer(everything(), names_to = &quot;trial&quot;, values_to = &quot;rate&quot;, names_pattern = &quot;rate\\\\[(\\\\d+)\\\\]&quot;) %&gt;% mutate(trial = as.numeric(trial)) # Calculate summary statistics for each trial rate_summary &lt;- rate_df %&gt;% group_by(trial) %&gt;% summarise( mean_rate = mean(rate), lower = quantile(rate, 0.025), upper = quantile(rate, 0.975) ) plot_data &lt;- tibble(trial = seq(120), choices = data$other) # Plot the evolution of rate estimates ggplot(rate_summary, aes(x = trial)) + geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) + geom_line(aes(y = mean_rate), color = &quot;blue&quot;) + # Add true data points geom_line(data = plot_data, aes(x = trial, y = choices), color = &quot;orange&quot;, alpha = 0.5) + theme_classic() + labs(title = &quot;Evolution of Rate Estimates&quot;, x = &quot;Trial&quot;, y = &quot;Rate&quot;, subtitle = &quot;Blue line: posterior mean, Gray band: 95% CI&quot;) + ylim(0, 1) # Let&#39;s also look at the correlation between alpha and beta parameters ggplot(draws_df) + geom_point(aes(alpha_prior, beta_prior), alpha = 0.1) + theme_classic() + labs(title = &quot;Correlation between Alpha and Beta Parameters&quot;, x = &quot;Alpha&quot;, y = &quot;Beta&quot;) 5.10 Conclusion: From Simple Models to Complex Cognitive Processes Throughout this chapter, we’ve progressed from basic parameter estimation to increasingly sophisticated models of decision-making. We began with a simple biased agent model, demonstrating how Bayesian inference allows us to recover underlying parameters from observed behavior. We saw how we can transform parameters from one scale to another - here from probability-scale to log-odds parameterizations -, thus gaining flexibility that will prove valuable for more complex models. The transition to memory-based models illustrated how we can incorporate psychological theory into our statistical framework. We explored different approaches to modeling memory - from treating it as an external predictor to implementing it as an internal state variable that evolves over time. The final exploration of exponential forgetting demonstrated how we can capture more nuanced cognitive processes while maintaining mathematical tractability. This progression sets the stage for Chapter 12, where we’ll explore how these memory updating mechanisms relate to reinforcement learning models. The exponential discounting of past events we implemented here represents a simplified version of the learning mechanisms we’ll encounter in reinforcement learning. Several key principles emerged that will guide our future modeling work: The importance of systematic model validation through parameter recovery studies and prior-posterior checks. These techniques help ensure our models can meaningfully capture the processes we aim to study. The value of starting simple and gradually adding complexity. Each model we implemented built upon previous ones, allowing us to understand the impact of new components while maintaining a solid foundation. This principle will become particularly important when we tackle reinforcement learning models, where multiple parameters interact in complex ways to produce learning behavior. The relationship between mathematical convenience and psychological reality. The log-odds transformation, for instance, provides both computational benefits and psychological insights about how humans might represent probabilities. Similarly, the memory updating rules we explored here foreshadow the prediction error calculations central to reinforcement learning and relates very tightly to other popular models like the Kalman filter and the Hierarchical Gaussian Filter. In the next chapters, we will build upon these foundations to tackle even more sophisticated cognitive models. Chapter 5 will introduce multilevel modeling, allowing us to capture individual differences while maintaining population-level insights. This will set the stage for exploring how different individuals might employ different strategies or show varying levels of memory decay in their decision-making processes. These individual differences become again relevant in future models where parameters like learning rate, or bias for social information can vary substantially across individuals. "],["model-quality-assessment.html", "Chapter 6 Model Quality Assessment 6.1 Introduction 6.2 Generating and plotting additional variables 6.3 Assessing priors 6.4 Prior Predictive Checks 6.5 Posterior Predictive Checks 6.6 Prior sensitivity analysis 6.7 The memory model 6.8 Prior sensitivity check for the memory model 6.9 Conclusion", " Chapter 6 Model Quality Assessment 6.1 Introduction Building computational models is only the first step in understanding cognitive processes. We must rigorously evaluate whether our models actually capture meaningful patterns in behavior and provide reliable insights. This chapter introduces systematic approaches for assessing model quality, focusing on techniques that help us understand both the strengths and limitations of our cognitive models. This document covers: - generating and plotting priors (against posteriors) - generating and plotting predictive checks (prior and posterior ones) - prior sensitivity checks [I SHOULD RESTRUCTURE THE DOCUMENT SO THAT PRIOR PREDICTIVE CHECKS COME BEFORE PRIOR / POSTERIOR UPDATE CHECKS] 6.2 Generating and plotting additional variables As we try to understand our model, we might want to plot how the prior relates to the posterior, or - in other words, what has the model learned from looking at the data? We can do so by overlaying the prior and the posterior distributions, what is also called a “prior - posterior update check”. Stan does not automatically save the prior distribution, so we need to tell it to generate and save prior distributions in a convenient place so we can easily plot or use them at will from R. Luckily, Stan gives us a dedicated code chunk to do that: the generated quantities chunk. As before, we need to define the kind of variable we want to save, and then how to generate it. If we take the example of the random agent (with a bias), we have one parameter: theta. We can then generate theta according to the prior in generated quantities. While we are at this, we can also generate a nicer version of the posterior estimate for the theta parameter, now in probability scale (instead of log odds). However, prior and posterior estimates are not always the most immediate thing to understand. For instance, we might have trouble having a good grasp for how the uncertainty in the estimate will play out on 120 trials, or 6 trials, or however many trials we are planning for our experiment. Luckily, we can ask Stan to run predictions from either priors or posteriors, or both: given the priors how many trials will have “right hand” choice? and given the posterior estimates? As we use complex models, the relation between prior/posterior estimates and predictions becomes less and less intuitive. Simulating their implications for the outcomes - also called prior/posterior predictive checks - becomes a very useful tool to adjust our priors and their uncertainty so that they reflect what we know of the outcome scale; as well as to assess whether the model (and its posterior estimates) can appropriately describe the data we observe, or there’s some bias there. More discussion of this can be found at https://4ccoxau.github.io/PriorsWorkshop/. pacman::p_load(tidyverse, here, posterior, cmdstanr, brms, tidybayes) d &lt;- read_csv(&quot;simdata/W3_randomnoise.csv&quot;) stan_model &lt;- &quot; // This model infers a random bias from a sequences of 1s and 0s (right and left hand choices) // The input (data) for the model. n of trials and the sequence of choices (right as 1, left as 0) data { int&lt;lower=1&gt; n; // n of trials array[n] int h; // sequence of choices (right as 1, left as 0) as long as n } // The parameters that the model needs to estimate (theta) parameters { real theta; // note it is unbounded as we now work on log odds } // The model to be estimated (a bernoulli, parameter theta, prior on the theta) model { // The prior for theta on a log odds scale is a normal distribution with a mean of 0 and a sd of 1. // This covers most of the probability space between 0 and 1, after being converted to probability. target += normal_lpdf(theta | 0, 1); // The model consists of a bernoulli distribution (binomial w 1 trial only) with a rate theta, // note we specify it uses a logit link (theta is in logodds) target += bernoulli_logit_lpmf(h | theta); } generated quantities{ real&lt;lower=0, upper=1&gt; theta_prior; // theta prior parameter, on a prob scale (0-1) real&lt;lower=0, upper=1&gt; theta_posterior; // theta posterior parameter, on a prob scale (0-1) int&lt;lower=0, upper=n&gt; prior_preds; // distribution of right hand choices according to the prior int&lt;lower=0, upper=n&gt; posterior_preds; // distribution of right hand choices according to the posterior theta_prior = inv_logit(normal_rng(0,1)); // generating the prior on a log odds scale and converting theta_posterior = inv_logit(theta); // converting the posterior estimate from log odds to prob. prior_preds = binomial_rng(n, theta_prior); posterior_preds = binomial_rng(n, inv_logit(theta)); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W4_SimpleBernoulli_logodds.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W4_SimpleBernoulli_logodds.stan&quot; ## With the logit format ## Specify where the model is file &lt;- file.path(&quot;stan/W4_SimpleBernoulli_logodds.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) d1 &lt;- d %&gt;% subset(noise == 0 &amp; rate == 0.8) ## Create the data. N.B. note the two variables have different lengths: 1 for n, n for h. data &lt;- list( n = 120, # n of trials h = d1$choice # sequence of choices (h stands for hand) ) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1000, iter_sampling = 2000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 finished in 0.0 seconds. ## Chain 2 finished in 0.0 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 0.0 seconds. ## Total execution time: 0.4 seconds. draws_df &lt;- as_draws_df(samples$draws()) 6.3 Assessing priors # Now let&#39;s plot the density for theta (prior and posterior) ggplot(draws_df) + geom_density(aes(theta_posterior), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(theta_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0.8, linetype = &quot;dashed&quot;, color = &quot;black&quot;, size = 1.5) + xlab(&quot;Rate&quot;) + ylab(&quot;Estimate Densities&quot;) + theme_classic() 6.4 Prior Predictive Checks Prior predictive checks involve simulating data from our model using only the prior distributions, before seeing any actual data. This helps us understand what kinds of patterns our model assumes are possible before we begin fitting to real observations. These predictions should be assessed for: Plausible ranges of behavior Appropriate levels of uncertainty Preservation of known constraints Coverage of theoretically important patterns 6.5 Posterior Predictive Checks After fitting our models, posterior predictive checks help us determine whether the fitted model can reproduce key patterns in our observed data. We generate new data using parameters sampled from the posterior distribution and compare these simulations to our actual observations. For decision-making models, important patterns to check include: Overall choice proportions Sequential dependencies in choices Learning curves Response to feedback Individual differences in strategies ggplot(draws_df) + geom_histogram(aes(prior_preds), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3) + xlab(&quot;Predicted heads out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_histogram(aes(posterior_preds), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3, bins = 90) + geom_point(x = sum(data$h), y = 0, color = &quot;red&quot;, shape = 17, size = 5) + xlab(&quot;Predicted heads out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_histogram(aes(prior_preds), color = &quot;lightblue&quot;, fill = &quot;blue&quot;, alpha = 0.3, bins = 90) + geom_histogram(aes(posterior_preds), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3, bins = 90) + geom_point(x = sum(data$h), y = 0, color = &quot;red&quot;, shape = 17, size = 5) + xlab(&quot;Predicted heads out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() 6.6 Prior sensitivity analysis ## Now we adding different priors for theta prior_mean &lt;- seq(-3, 3, .5) prior_sd &lt;- seq(0.1, 1, 0.1) priors &lt;- expand.grid(prior_mean, prior_sd) priors &lt;- tibble(prior_mean = priors$Var1, prior_sd = priors$Var2) stan_model &lt;- &quot; // The input (data) for the model data { int&lt;lower=1&gt; n; array[n] int h; real prior_mean; real&lt;lower=0&gt; prior_sd; } // The parameters accepted by the model. parameters { real theta; } // The model to be estimated. model { // Prior target += normal_lpdf(theta | prior_mean, prior_sd); // Model target += bernoulli_logit_lpmf(h | theta); } generated quantities{ real&lt;lower=0, upper=1&gt; theta_prior; real&lt;lower=0, upper=1&gt; theta_posterior; int&lt;lower=0, upper=n&gt; prior_preds; int&lt;lower=0, upper=n&gt; posterior_preds; theta_prior = inv_logit(normal_rng(0,1)); theta_posterior = inv_logit(theta); prior_preds = binomial_rng(n, theta_prior); posterior_preds = binomial_rng(n, inv_logit(theta)); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W4_PriorBernoulli.stan&quot;) file &lt;- file.path(&quot;stan/W4_PriorBernoulli.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) dd &lt;- d %&gt;% subset(noise == 0.1 &amp; rate == 0.8) pacman::p_load(future, purrr, furrr) plan(multisession, workers = 4) sim_d_and_fit &lt;- function(prior_mean, prior_sd) { data &lt;- list( n = nrow(dd), h = dd$choice, prior_mean = prior_mean, prior_sd = prior_sd ) samples &lt;- mod$sample( data = data, seed = 1000, chains = 1, parallel_chains = 1, threads_per_chain = 1, iter_warmup = 1000, iter_sampling = 2000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) draws_df &lt;- as_draws_df(samples$draws()) temp &lt;- tibble(theta_prior = draws_df$theta_prior, theta_posterior = draws_df$theta_posterior, prior_preds = draws_df$prior_preds, posterior_preds = draws_df$posterior_preds, prior_mean = prior_mean, prior_sd = prior_sd) return(temp) } # Commenting this out to ensure faster compiling time for the book. Uncomment to run the code # recovery_df &lt;- future_pmap_dfr(priors, sim_d_and_fit, .options = furrr_options(seed = TRUE)) # write_csv(recovery_df, &quot;simdata/W4_priorSensitivityRecovery.csv&quot;) Now we load the data and plot it recovery_df &lt;- read_csv(&quot;simdata/W4_priorSensitivityRecovery.csv&quot;) ggplot(recovery_df, aes(prior_mean, theta_posterior)) + geom_point(alpha = 0.1) + geom_hline(yintercept = 0.8, color = &quot;red&quot;) + geom_smooth() + facet_wrap(.~prior_sd) + theme_classic() 6.7 The memory model We can do the same for the memory model: generate prior distributions to overlay to the posteriors (prior-posterior update checks), generate predicted outcomes based on the priors (prior predictive checks) and on the posteriors (posterior predictive checks). N.B. prior and posterior predictions now depend on the value on memory. I identified 3 meaningful values for the memory value (e.g. 0.5, 0.7, 0.9) and used those to generate 3 prior and posterior predictive checks. # We subset to only include no noise and a specific rate d1 &lt;- d %&gt;% subset(noise == 0 &amp; rate == 0.8) %&gt;% rename(Other = choice) %&gt;% mutate(cumulativerate = lag(cumulativerate, 1)) d1$cumulativerate[1] &lt;- 0.5 # no prior info at first trial d1$cumulativerate[d1$cumulativerate == 0] &lt;- 0.01 d1$cumulativerate[d1$cumulativerate == 1] &lt;- 0.99 # Now we create the memory agent with a coefficient of 0.9 bias = 0 beta = 0.9 MemoryAgent_f &lt;- function(bias, beta, cumulativerate){ choice = rbinom(1, 1, inv_logit_scaled(bias + beta * logit_scaled(cumulativerate))) return(choice) } for (i in 1:trials) { d1$Self[i] &lt;- MemoryAgent_f(bias, beta, d1$cumulativerate[i]) } ## Create the data. data &lt;- list( n = 120, h = d1$Self, other = d1$Other ) stan_model &lt;- &quot; // The input (data) for the model. n of trials and h for (right and left) hand data { int&lt;lower=1&gt; n; array[n] int h; array[n] int other; } // The parameters accepted by the model. parameters { real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)? real beta; // how strongly is previous rate impacting the decision? } transformed parameters{ vector[n] memory; for (trial in 1:n){ if (trial == 1) { memory[trial] = 0.5; } if (trial &lt; n){ memory[trial + 1] = memory[trial] + ((other[trial] - memory[trial]) / trial); if (memory[trial + 1] == 0){memory[trial + 1] = 0.01;} if (memory[trial + 1] == 1){memory[trial + 1] = 0.99;} } } } // The model to be estimated. model { // Priors target += normal_lpdf(bias | 0, .3); target += normal_lpdf(beta | 0, .5); // Model, looping to keep track of memory for (trial in 1:n) { target += bernoulli_logit_lpmf(h[trial] | bias + beta * logit(memory[trial])); } } generated quantities{ real bias_prior; real beta_prior; int&lt;lower=0, upper=n&gt; prior_preds5; int&lt;lower=0, upper=n&gt; post_preds5; int&lt;lower=0, upper=n&gt; prior_preds7; int&lt;lower=0, upper=n&gt; post_preds7; int&lt;lower=0, upper=n&gt; prior_preds9; int&lt;lower=0, upper=n&gt; post_preds9; bias_prior = normal_rng(0, 0.3); beta_prior = normal_rng(0, 0.5); prior_preds5 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.5))); prior_preds7 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.7))); prior_preds9 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.9))); post_preds5 = binomial_rng(n, inv_logit(bias + beta * logit(0.5))); post_preds7 = binomial_rng(n, inv_logit(bias + beta * logit(0.7))); post_preds9 = binomial_rng(n, inv_logit(bias + beta * logit(0.9))); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W4_MemoryBernoulli.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W4_MemoryBernoulli.stan&quot; ## Specify where the model is file &lt;- file.path(&quot;stan/W4_MemoryBernoulli.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 1, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1000, iter_sampling = 1000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 1 chain, with 2 thread(s) per chain... ## ## Chain 1 finished in 0.6 seconds. samples$summary() ## # A tibble: 131 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -65.6 -65.3 1.01 0.771 -67.7 -64.7 1.00 429. 504. ## 2 bias -0.0116 -0.0169 0.239 0.222 -0.405 0.391 1.00 283. 503. ## 3 beta 0.815 0.809 0.204 0.227 0.477 1.15 1.00 265. 540. ## 4 memory[1] 0.5 0.5 0 0 0.5 0.5 NA NA NA ## 5 memory[2] 0.99 0.99 0 0 0.99 0.99 NA NA NA ## 6 memory[3] 0.495 0.495 0 0 0.495 0.495 NA NA NA ## 7 memory[4] 0.663 0.663 0 0 0.663 0.663 NA NA NA ## 8 memory[5] 0.498 0.498 0 0 0.498 0.498 NA NA NA ## 9 memory[6] 0.398 0.398 0 0 0.398 0.398 NA NA NA ## 10 memory[7] 0.498 0.498 0 0 0.498 0.498 NA NA NA ## # ℹ 121 more rows # Extract posterior samples and include sampling of the prior: draws_df &lt;- as_draws_df(samples$draws()) # Now let&#39;s plot the density for bias (prior and posterior) ggplot(draws_df) + geom_density(aes(bias), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(bias_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0, size = 2) + xlab(&quot;Bias&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_density(aes(beta), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(beta_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0.9, size = 2) + xlab(&quot;MemoryBeta&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_histogram(aes(`prior_preds5`), color = &quot;yellow&quot;, fill = &quot;lightyellow&quot;, alpha = 0.2) + geom_histogram(aes(`prior_preds7`), color = &quot;green&quot;, fill = &quot;lightgreen&quot;, alpha = 0.2) + geom_histogram(aes(`prior_preds9`), color = &quot;blue&quot;, fill = &quot;lightblue&quot;, alpha = 0.2) + xlab(&quot;Predicted heads out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_histogram(aes(`post_preds5`), color = &quot;yellow&quot;, fill = &quot;lightyellow&quot;, alpha = 0.3, bins = 90) + geom_histogram(aes(`post_preds7`), color = &quot;green&quot;, fill = &quot;lightgreen&quot;, alpha = 0.3, bins = 90) + geom_histogram(aes(`post_preds9`), color = &quot;blue&quot;, fill = &quot;lightblue&quot;, alpha = 0.3, bins = 90) + #geom_point(x = sum(data$h), y = 0, color = &quot;red&quot;, shape = 17, size = 5) + xlab(&quot;Predicted heads out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_histogram(aes(`prior_preds5`), color = &quot;lightblue&quot;, fill = &quot;blue&quot;, alpha = 0.3, bins = 90) + geom_histogram(aes(`post_preds5`), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3, bins = 90) + xlab(&quot;Predicted heads out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() 6.8 Prior sensitivity check for the memory model ## Now we adding different priors for theta prior_mean_bias &lt;- 0 prior_sd_bias &lt;- seq(0.1, 0.5, 0.1) prior_mean_beta &lt;- 0 prior_sd_beta &lt;- seq(0.1, 0.5, 0.1) priors &lt;- tibble(expand.grid(tibble(prior_mean_bias, prior_sd_bias, prior_mean_beta, prior_sd_beta))) stan_model &lt;- &quot; // The input (data) for the model data { int&lt;lower=1&gt; n; array[n] int h; array[n] int other; real prior_mean_bias; real&lt;lower=0&gt; prior_sd_bias; real prior_mean_beta; real&lt;lower=0&gt; prior_sd_beta; } // The parameters accepted by the model. parameters { real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)? real beta; // how strongly is previous rate impacting the decision? } transformed parameters{ vector[n] memory; for (trial in 1:n){ if (trial == 1) { memory[trial] = 0.5; } if (trial &lt; n){ memory[trial + 1] = memory[trial] + ((other[trial] - memory[trial]) / trial); if (memory[trial + 1] == 0){memory[trial + 1] = 0.01;} if (memory[trial + 1] == 1){memory[trial + 1] = 0.99;} } } } // The model to be estimated. model { // The priors target += normal_lpdf(bias | prior_mean_bias, prior_sd_bias); target += normal_lpdf(beta | prior_mean_beta, prior_sd_beta); // The model target += bernoulli_logit_lpmf(h | bias + beta * logit(memory)); } generated quantities{ real bias_prior; real beta_prior; int&lt;lower=0, upper=n&gt; prior_preds5; int&lt;lower=0, upper=n&gt; post_preds5; int&lt;lower=0, upper=n&gt; prior_preds7; int&lt;lower=0, upper=n&gt; post_preds7; int&lt;lower=0, upper=n&gt; prior_preds9; int&lt;lower=0, upper=n&gt; post_preds9; bias_prior = normal_rng(prior_mean_bias, prior_sd_bias); beta_prior = normal_rng(prior_mean_beta, prior_sd_beta); prior_preds5 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.5))); prior_preds7 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.7))); prior_preds9 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.9))); post_preds5 = binomial_rng(n, inv_logit(bias + beta * logit(0.5))); post_preds7 = binomial_rng(n, inv_logit(bias + beta * logit(0.7))); post_preds9 = binomial_rng(n, inv_logit(bias + beta * logit(0.9))); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W4_PriorMemory.stan&quot;) file &lt;- file.path(&quot;stan/W4_PriorMemory.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE)) dd &lt;- d %&gt;% subset(noise == 0.1 &amp; rate == 0.8) %&gt;% mutate(memory = lag(cumulativerate, 1)) dd$memory[1] &lt;- 0.5 pacman::p_load(future, purrr, furrr) plan(multisession, workers = 4) sim_d_and_fit &lt;- function(prior_mean_bias, prior_sd_bias, prior_mean_beta, prior_sd_beta) { data &lt;- list( n = nrow(dd), h = dd$choice, memory = dd$memory, prior_mean_bias = prior_mean_bias, prior_sd_bias = prior_sd_bias, prior_mean_beta = prior_mean_beta, prior_sd_beta = prior_sd_beta ) samples &lt;- mod$sample( data = data, seed = 1000, chains = 1, parallel_chains = 1, threads_per_chain = 1, iter_warmup = 1000, iter_sampling = 2000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) draws_df &lt;- as_draws_df(samples$draws()) temp &lt;- tibble(bias_prior = draws_df$bias_prior, beta_prior = draws_df$beta_prior, bias_posterior = draws_df$bias, beta_posterior = draws_df$beta, prior_preds5 = draws_df$prior_preds5, prior_preds7 = draws_df$prior_preds7, prior_preds9 = draws_df$prior_preds9, posterior_preds5 = draws_df$post_preds5, posterior_preds7 = draws_df$post_preds7, posterior_preds9 = draws_df$post_preds9, prior_mean_bias = prior_mean_bias, prior_sd_bias = prior_sd_bias, prior_mean_beta = prior_mean_beta, prior_sd_beta = prior_sd_beta) return(temp) } # Commenting this out to ensure the book compiles faster. Uncomment to run the code. #recovery_df &lt;- future_pmap_dfr(priors, sim_d_and_fit, .options = furrr_options(seed = TRUE)) #write_csv(recovery_df, &quot;simdata/W4_MemoryPriorSensitivity.csv&quot;) recovery_df &lt;- read_csv(&quot;simdata/W4_MemoryPriorSensitivity.csv&quot;) ggplot(recovery_df, aes(prior_sd_beta, beta_posterior)) + geom_point(alpha = 0.1) + geom_hline(yintercept = 0.8, color = &quot;red&quot;) + geom_smooth(method = lm) + facet_wrap(.~prior_sd_bias) + theme_classic() 6.9 Conclusion Rigorous model assessment is essential for developing reliable insights into cognitive processes. The techniques covered in this chapter provide a systematic framework for validating our models and understanding their limitations. As we move forward to more complex models incorporating individual differences and learning mechanisms, these quality checks become increasingly important for ensuring our conclusions are well-supported by the evidence. In the next chapter, we’ll build on these foundations as we explore multilevel modeling approaches that can capture individual differences while maintaining population-level insights. "],["individual-differences-in-cognitive-strategies-multilevel-modeling.html", "Chapter 7 Individual Differences in Cognitive Strategies (Multilevel modeling) 7.1 Introduction 7.2 Learning Objectives 7.3 The Value of Multilevel Modeling 7.4 Graphical Model Visualization 7.5 Generating the agents 7.6 Plotting the agents 7.7 Coding the multilevel agents 7.8 Multilevel Random Agent Model 7.9 Let’s look at individuals 7.10 Prior sensitivity checks 7.11 Parameter recovery 7.12 Multilevel Memory Agent Model 7.13 Comparing Pooling Approaches 7.14 Comparing Pooling Approaches 7.15 Multilevel Modeling Cheatsheet 7.16 Conclusion: The Power and Challenges of Multilevel Modeling 7.17 Exercises (just some ideas)", " Chapter 7 Individual Differences in Cognitive Strategies (Multilevel modeling) 7.1 Introduction Our exploration of decision-making models has so far focused on single agents or averaged behavior across many agents. However, cognitive science consistentlyreveals that individuals differ systematically in how they approach tasks and process information. Some people may be more risk-averse, have better memory, learn faster, or employ entirely different strategies than others. This chapter introduces multilevel modeling as a powerful framework for capturing these individual differences while still identifying population-level patterns. Multilevel modeling (also called hierarchical modeling) provides a powerful framework for addressing this challenge. It allows us to simultaneously: Capture individual differences across participants Identify population-level patterns that generalize across individuals Improve estimates for individuals with limited data by leveraging information from the group Consider our matching pennies game: different players might vary in their strategic sophistication, memory capacity, or learning rates. Some may show strong biases toward particular choices while others adapt more flexibly to their opponents. Multilevel modeling allows us to capture these variations while still understanding what patterns hold across the population. Consider our matching pennies game: players might vary in their strategic sophistication, memory capacity, or learning rates. Some may show strong biases toward particular choices while others adapt more flexibly to their opponents. Multilevel modeling allows us to quantify these variations while still understanding what patterns hold across the population. 7.2 Learning Objectives After completing this chapter, you will be able to: Understand how multilevel modeling balances individual and group-level information Distinguish between complete pooling, no pooling, and partial pooling approaches to modeling group and individual variation Use different parameterizations to improve model efficiency Evaluate model quality through systematic parameter recovery studies Apply multilevel modeling techniques to cognitive science questions 7.3 The Value of Multilevel Modeling Traditional approaches to handling individual differences often force a choice between two extremes: 7.3.1 Complete Pooling Treats all participants as identical by averaging or combining their data Estimates a single set of parameters for the entire group Ignores individual differences entirely Example: Fitting a single model to all participants’ data combined 7.3.2 No Pooling Analyzes each participant completely separately Estimates separate parameters for each individual Fails to leverage information shared across participants and can lead to unstable estimates Example: Fitting separate models to each participant’s data Multilevel modeling offers a middle ground through partial pooling. Individual estimates are informed by both individual-level data and the overall population distribution. 7.3.3 Partial Pooling (Multilevel Modeling) Individual parameters are treated as coming from a group-level distribution Estimates are informed by both individual data and the population distribution Creates a balance between individual and group information Example: Hierarchical Bayesian model with parameters at both individual and group levels This partial pooling approach is particularly valuable when: Data per individual is limited (e.g., few trials per participant) Individual differences are meaningful but not completely independent We want to make predictions about new individuals from the same population 7.4 Graphical Model Visualization Before diving into code, let’s understand the structure of our multilevel models using graphical model notation. These diagrams help visualize how parameters relate to each other and to the observed data. 7.4.1 Biased Agent Model In this model, each agent has an individual bias parameter (θ) that determines their probability of choosing “right” (1) versus “left” (0). We are now conceptualizing our agents as being part of (sampled from) a more general population. This general population is characterized by a population level average parameter value (e.g. a general bias of 0.8 as we all like right hands more) and a certain variation in the population (e.g. a standard deviation of 0.1, as we are all a bit different from each other). Each biased agent’s bias is then sampled from that distribution. The key elements are: Population parameters: μ_θ (mean bias) and σ_θ (standard deviation of bias) Individual parameters: θ_i (bias for agent i) Observed data: y_it (choice for agent i on trial t) 7.4.2 Memory Agent Model This model is more complex, with each agent having two parameters: a baseline bias (α) and a memory sensitivity parameter (β). The key elements are: Population parameters: μ_α, σ_α, μ_β, σ_β (means and standard deviations) Individual parameters: α_i (bias for agent i), β_i (memory sensitivity for agent i) Transformed variables: m_it (memory state for agent i on trial t) Observed data: y_it (choice for agent i on trial t) These graphical models help us understand how information flows in our models and guide our implementation in Stan. Again, it’s practical to work in log odds. Why? Well, it’s not unconceivable that an agent would be 3 sd from the mean. So a biased agent could have a rate of 0.8 + 3 * 0.1, which gives a rate of 1.1. It’s kinda impossible to choose 110% of the time the right hand. We want an easy way to avoid these situations without too carefully tweaking our parameters, or including exception statements (e.g. if rate &gt; 1, then rate = 1). Conversion to log odds is again a wonderful way to work in a boundless space, and in the last step shrinking everything back to 0-1 probability space. N.B. we model all agents with some added noise as we assume it cannot be eliminated from empirical studies. pacman::p_load(tidyverse, here, posterior, cmdstanr, brms, tidybayes, patchwork, bayesplot, furrr, LaplacesDemon) # Population-level parameters agents &lt;- 100 # Number of agents to simulate trials &lt;- 120 # Number of trials per agent noise &lt;- 0 # Base noise level (probability of random choice) # Biased agent population parameters rateM &lt;- 1.386 # Population mean of bias (log-odds scale, ~0.8 in probability) rateSD &lt;- 0.65 # Population SD of bias (log-odds scale, ~0.1 in probability) # Memory agent population parameters biasM &lt;- 0 # Population mean of baseline bias (log-odds scale) biasSD &lt;- 0.1 # Population SD of baseline bias (log-odds scale) betaM &lt;- 1.5 # Population mean of memory sensitivity (log-odds scale) betaSD &lt;- 0.3 # Population SD of memory sensitivity (log-odds scale) # For reference, convert log-odds parameters to probability scale cat(&quot;Biased agent population mean (probability scale):&quot;, round(plogis(rateM), 2), &quot;\\n&quot;) ## Biased agent population mean (probability scale): 0.8 cat(&quot;Approximate biased agent population SD (probability scale):&quot;, round(0.1, 2), &quot;\\n&quot;) ## Approximate biased agent population SD (probability scale): 0.1 # Random agent function: makes choices based on bias parameter # Parameters: # rate: log-odds of choosing option 1 (&quot;right&quot;) # noise: probability of making a random choice # Returns: binary choice (0 or 1) RandomAgentNoise_f &lt;- function(rate, noise) { # Generate choice based on agent&#39;s bias parameter (on log-odds scale) choice &lt;- rbinom(1, 1, plogis(rate)) # With probability &#39;noise&#39;, override choice with random 50/50 selection if (rbinom(1, 1, noise) == 1) { choice = rbinom(1, 1, 0.5) } return(choice) } # Memory agent function: makes choices based on opponent&#39;s historical choices # Parameters: # bias: baseline tendency to choose option 1 (log-odds scale) # beta: sensitivity to memory (how strongly past choices affect decisions) # otherRate: opponent&#39;s observed rate of choosing option 1 (probability scale) # noise: probability of making a random choice # Returns: binary choice (0 or 1) MemoryAgentNoise_f &lt;- function(bias, beta, otherRate, noise) { # Calculate choice probability based on memory of opponent&#39;s choices # Higher beta means agent responds more strongly to opponent&#39;s pattern choice_prob &lt;- inv_logit_scaled(bias + beta * logit_scaled(otherRate)) # Generate choice choice &lt;- rbinom(1, 1, choice_prob) # With probability &#39;noise&#39;, override choice with random 50/50 selection if (rbinom(1, 1, noise) == 1) { choice = rbinom(1, 1, 0.5) } return(choice) } 7.5 Generating the agents [MISSING: PARALLELIZE] # Function to simulate one agent&#39;s behavior simulate_agent &lt;- function(agent_id, population_params, n_trials, noise_level) { # Sample agent-specific parameters from population distributions rate &lt;- rnorm(1, population_params$rateM, population_params$rateSD) bias &lt;- rnorm(1, population_params$biasM, population_params$biasSD) beta &lt;- rnorm(1, population_params$betaM, population_params$betaSD) # Initialize choice vectors randomChoice &lt;- rep(NA, n_trials) memoryChoice &lt;- rep(NA, n_trials) # Generate choices for each trial for (trial in 1:n_trials) { # Random agent makes choice based on bias parameter randomChoice[trial] &lt;- RandomAgentNoise_f(rate, noise_level) # Memory agent uses history of random agent&#39;s choices if (trial == 1) { # First trial: no history, so use 50/50 chance memoryChoice[trial] &lt;- rbinom(1, 1, 0.5) } else { # Later trials: use memory of previous random agent choices memoryChoice[trial] &lt;- MemoryAgentNoise_f( bias, beta, mean(randomChoice[1:trial], na.rm = TRUE), # Current memory noise_level ) } } # Create tibble with all agent data return(tibble( agent = agent_id, trial = seq(n_trials), randomChoice, trueRate = rate, # Store true parameter values for later validation memoryChoice, noise = noise_level, rateM = population_params$rateM, rateSD = population_params$rateSD, bias = bias, beta = beta, biasM = population_params$biasM, biasSD = population_params$biasSD, betaM = population_params$betaM, betaSD = population_params$betaSD )) } # Population parameters bundled in a list population_params &lt;- list( rateM = rateM, rateSD = rateSD, biasM = biasM, biasSD = biasSD, betaM = betaM, betaSD = betaSD ) # Simulate all agents (in a real application, consider using purrr::map functions) d &lt;- NULL for (agent_id in 1:agents) { agent_data &lt;- simulate_agent(agent_id, population_params, trials, noise) if (agent_id == 1) { d &lt;- agent_data } else { d &lt;- rbind(d, agent_data) } } # Calculate running statistics for each agent d &lt;- d %&gt;% group_by(agent) %&gt;% mutate( # Cumulative proportions of choices (shows learning/strategy over time) randomRate = cumsum(randomChoice) / seq_along(randomChoice), memoryRate = cumsum(memoryChoice) / seq_along(memoryChoice) ) # Display information about the simulated dataset cat(&quot;Generated data for&quot;, agents, &quot;agents with&quot;, trials, &quot;trials each\\n&quot;) ## Generated data for 100 agents with 120 trials each cat(&quot;Total observations:&quot;, nrow(d), &quot;\\n&quot;) ## Total observations: 12000 # Show a small sample of the data head(d, 5) ## # A tibble: 5 × 16 ## # Groups: agent [1] ## agent trial randomChoice trueRate memoryChoice noise rateM rateSD bias beta biasM biasSD betaM betaSD ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 1 0.920 1 0 1.39 0.65 0.0859 0.792 0 0.1 1.5 0.3 ## 2 1 2 0 0.920 0 0 1.39 0.65 0.0859 0.792 0 0.1 1.5 0.3 ## 3 1 3 1 0.920 0 0 1.39 0.65 0.0859 0.792 0 0.1 1.5 0.3 ## 4 1 4 0 0.920 1 0 1.39 0.65 0.0859 0.792 0 0.1 1.5 0.3 ## 5 1 5 1 0.920 0 0 1.39 0.65 0.0859 0.792 0 0.1 1.5 0.3 ## # ℹ 2 more variables: randomRate &lt;dbl&gt;, memoryRate &lt;dbl&gt; 7.6 Plotting the agents # Create plot themes that we&#39;ll reuse custom_theme &lt;- theme_classic() + theme( legend.position = &quot;top&quot;, plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5, size = 9) ) # Plot 1: Trajectories of randomRate for all agents p1 &lt;- ggplot(d, aes(x = trial, y = randomRate)) + geom_line(aes(group = agent, color = &quot;Individual Agents&quot;), alpha = 0.25) + # Individual agents geom_smooth(aes(color = &quot;Average&quot;), se = TRUE, size = 1.2) + # Group average geom_hline(yintercept = 0.5, linetype = &quot;dashed&quot;) + ylim(0, 1) + labs( title = &quot;Random Agent Behavior&quot;, subtitle = &quot;Cumulative proportion of &#39;right&#39; choices over trials&quot;, x = &quot;Trial Number&quot;, y = &quot;Proportion of Right Choices&quot;, color = NULL ) + scale_color_manual(values = c(&quot;Individual Agents&quot; = &quot;gray50&quot;, &quot;Average&quot; = &quot;blue&quot;)) + custom_theme # Plot 2: Trajectories of memoryRate for all agents p2 &lt;- ggplot(d, aes(x = trial, y = memoryRate)) + geom_line(alpha = 0.15, aes(color = &quot;Individual Agents&quot;, group = agent)) + # Individual agents geom_smooth(aes(color = &quot;Average&quot;), se = TRUE, size = 1.2) + # Group average geom_hline(yintercept = 0.5, linetype = &quot;dashed&quot;) + ylim(0, 1) + labs( title = &quot;Memory Agent Behavior&quot;, subtitle = &quot;Cumulative proportion of &#39;right&#39; choices over trials&quot;, x = &quot;Trial Number&quot;, y = &quot;Proportion of Right Choices&quot;, color = NULL ) + scale_color_manual(values = c(&quot;Individual Agents&quot; = &quot;gray50&quot;, &quot;Average&quot; = &quot;darkred&quot;)) + custom_theme # Display plots side by side p1 + p2 # Plot 3-5: Correlation between random and memory agent behavior at different timepoints # These show how well memory agents track random agents&#39; behavior over time p3 &lt;- d %&gt;% filter(trial == 10) %&gt;% ggplot(aes(randomRate, memoryRate)) + geom_point(alpha = 0.6) + geom_smooth(method = &quot;lm&quot;, color = &quot;blue&quot;) + geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + coord_fixed(xlim = c(0, 1), ylim = c(0, 1)) + labs( title = &quot;After 10 Trials&quot;, x = &quot;Random Agent Rate&quot;, y = &quot;Memory Agent Rate&quot; ) + custom_theme p4 &lt;- d %&gt;% filter(trial == 60) %&gt;% ggplot(aes(randomRate, memoryRate)) + geom_point(alpha = 0.6) + geom_smooth(method = &quot;lm&quot;, color = &quot;blue&quot;) + geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + coord_fixed(xlim = c(0, 1), ylim = c(0, 1)) + labs( title = &quot;After 60 Trials&quot;, x = &quot;Random Agent Rate&quot;, y = &quot;Memory Agent Rate&quot; ) + custom_theme p5 &lt;- d %&gt;% filter(trial == 120) %&gt;% ggplot(aes(randomRate, memoryRate)) + geom_point(alpha = 0.6) + geom_smooth(method = &quot;lm&quot;, color = &quot;blue&quot;) + geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + coord_fixed(xlim = c(0, 1), ylim = c(0, 1)) + labs( title = &quot;After 120 Trials&quot;, x = &quot;Random Agent Rate&quot;, y = &quot;Memory Agent Rate&quot; ) + custom_theme # Display plots in a single row p3 + p4 + p5 + plot_layout(guides = &quot;collect&quot;) + plot_annotation( title = &quot;Memory Agents&#39; Adaptation to Random Agents Over Time&quot;, subtitle = &quot;Red line: perfect tracking; Blue line: actual relationship&quot;, theme = theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5)) ) # Plot 6-8: Correlation between true rate parameter and observed rate # These show how well we can recover the underlying rate parameter p6 &lt;- d %&gt;% filter(trial == 10) %&gt;% ggplot(aes(inv_logit_scaled(trueRate), randomRate)) + geom_point(alpha = 0.6) + geom_smooth(method = &quot;lm&quot;, color = &quot;blue&quot;) + geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + coord_fixed(xlim = c(0, 1), ylim = c(0, 1)) + labs( title = &quot;After 10 Trials&quot;, x = &quot;True Rate Parameter&quot;, y = &quot;Observed Rate&quot; ) + custom_theme p7 &lt;- d %&gt;% filter(trial == 60) %&gt;% ggplot(aes(inv_logit_scaled(trueRate), randomRate)) + geom_point(alpha = 0.6) + geom_smooth(method = &quot;lm&quot;, color = &quot;blue&quot;) + geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + coord_fixed(xlim = c(0, 1), ylim = c(0, 1)) + labs( title = &quot;After 60 Trials&quot;, x = &quot;True Rate Parameter&quot;, y = &quot;Observed Rate&quot; ) + custom_theme p8 &lt;- d %&gt;% filter(trial == 120) %&gt;% ggplot(aes(inv_logit_scaled(trueRate), randomRate)) + geom_point(alpha = 0.6) + geom_smooth(method = &quot;lm&quot;, color = &quot;blue&quot;) + geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + coord_fixed(xlim = c(0, 1), ylim = c(0, 1)) + labs( title = &quot;After 120 Trials&quot;, x = &quot;True Rate Parameter&quot;, y = &quot;Observed Rate&quot; ) + custom_theme # Display plots in a single row p6 + p7 + p8 + plot_layout(guides = &quot;collect&quot;) + plot_annotation( title = &quot;Parameter Recovery: True vs. Observed Rates Over Time&quot;, subtitle = &quot;Red line: perfect recovery; Blue line: actual relationship&quot;, theme = theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5)) ) Note that as the n of trials increases, the memory model matches the random model better and better 7.7 Coding the multilevel agents 7.7.1 Multilevel random Remember that the simulated parameters are: * biasM &lt;- 0 * biasSD &lt;- 0.1 * betaM &lt;- 1.5 * betaSD &lt;- 0.3 Prep the data # For multilevel models, we need to reshape our data into matrices # where rows are trials and columns are agents # Function to create matrices from our long-format data create_stan_data &lt;- function(data, agent_type) { # Select relevant choice column based on agent type choice_col &lt;- ifelse(agent_type == &quot;random&quot;, &quot;randomChoice&quot;, &quot;memoryChoice&quot;) other_col &lt;- ifelse(agent_type == &quot;random&quot;, &quot;memoryChoice&quot;, &quot;randomChoice&quot;) # Create choice matrix choice_data &lt;- data %&gt;% select(agent, trial, all_of(choice_col)) %&gt;% pivot_wider( names_from = agent, values_from = all_of(choice_col), names_prefix = &quot;agent_&quot; ) %&gt;% select(-trial) %&gt;% as.matrix() # Create other-choice matrix (used for memory agent) other_data &lt;- data %&gt;% select(agent, trial, all_of(other_col)) %&gt;% pivot_wider( names_from = agent, values_from = all_of(other_col), names_prefix = &quot;agent_&quot; ) %&gt;% select(-trial) %&gt;% as.matrix() # Return data as a list ready for Stan return(list( trials = trials, agents = agents, h = choice_data, other = other_data )) } # Create data for random agent model data_random &lt;- create_stan_data(d, &quot;random&quot;) # Create data for memory agent model data_memory &lt;- create_stan_data(d, &quot;memory&quot;) # Display dimensions of our data matrices cat(&quot;Random agent matrix dimensions:&quot;, dim(data_random$h), &quot;\\n&quot;) ## Random agent matrix dimensions: 120 100 cat(&quot;Memory agent matrix dimensions:&quot;, dim(data_memory$h), &quot;\\n&quot;) ## Memory agent matrix dimensions: 120 100 7.8 Multilevel Random Agent Model Our first multilevel model focuses on the biased random agent. For each agent, we’ll estimate an individual bias parameter (theta) that determines their probability of choosing “right” versus “left”. These individual parameters will be modeled as coming from a population distribution with mean thetaM and standard deviation thetaSD. This approach balances two sources of information: 1. The agent’s individual choice patterns 2. The overall population distribution of bias parameters The model implements the following hierarchical structure: Population level: θᵐ ~ Normal(0, 1), θˢᵈ ~ Normal⁺(0, 0.3) Individual level: θᵢ ~ Normal(θᵐ, θˢᵈ) Data level: yᵢₜ ~ Bernoulli(logit⁻¹(θᵢ)) Let’s implement this in Stan: # Stan model for multilevel random agent stan_model &lt;- &quot; /* Multilevel Bernoulli Model * This model infers agent-specific choice biases from sequences of binary choices (0/1) * The model assumes each agent has their own bias (theta) drawn from a population distribution */ functions { // Generate random numbers from truncated normal distribution real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } data { int&lt;lower=1&gt; trials; // Number of trials per agent int&lt;lower=1&gt; agents; // Number of agents array[trials, agents] int&lt;lower=0, upper=1&gt; h; // Choice data: 0 or 1 for each trial/agent } parameters { real thetaM; // Population-level mean bias (log-odds scale) real&lt;lower=0&gt; thetaSD; // Population-level SD of bias array[agents] real theta; // Agent-specific biases (log-odds scale) } model { // Population-level priors target += normal_lpdf(thetaM | 0, 1); // Prior for population mean target += normal_lpdf(thetaSD | 0, 0.3) // Half-normal prior for population SD - normal_lccdf(0 | 0, 0.3); // Adjustment for truncation at 0 // Agent-level model target += normal_lpdf(theta | thetaM, thetaSD); // Agent biases drawn from population // Likelihood for observed choices for (i in 1:agents) { target += bernoulli_logit_lpmf(h[,i] | theta[i]); // Choice likelihood } } generated quantities { // Prior predictive samples real thetaM_prior = normal_rng(0, 1); real&lt;lower=0&gt; thetaSD_prior = normal_lb_rng(0, 0.3, 0); real&lt;lower=0, upper=1&gt; theta_prior = inv_logit(normal_rng(thetaM_prior, thetaSD_prior)); // Posterior predictive samples real&lt;lower=0, upper=1&gt; theta_posterior = inv_logit(normal_rng(thetaM, thetaSD)); // Predictive simulations int&lt;lower=0, upper=trials&gt; prior_preds = binomial_rng(trials, inv_logit(thetaM_prior)); int&lt;lower=0, upper=trials&gt; posterior_preds = binomial_rng(trials, inv_logit(thetaM)); // Convert parameters to probability scale for easier interpretation real&lt;lower=0, upper=1&gt; thetaM_prob = inv_logit(thetaM); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W5_MultilevelBias.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W5_MultilevelBias.stan&quot; # File path for saved model model_file &lt;- &quot;simmodels/W5_MultilevelBias.RDS&quot; # Check if we need to rerun the simulation if (regenerate_simulations || !file.exists(model_file)) { file &lt;- file.path(&quot;stan/W5_MultilevelBias.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # Check if we need to rerun the simulation samples &lt;- mod$sample( data = data_random, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99, ) samples$save_object(file = model_file) cat(&quot;Generated new model fit and saved to&quot;, model_file, &quot;\\n&quot;) } else { # Load existing results samples &lt;- readRDS(model_file) cat(&quot;Loaded existing model fit from&quot;, model_file, &quot;\\n&quot;) } ## Loaded existing model fit from simmodels/W5_MultilevelBias.RDS 7.8.1 Assessing multilevel random agents Besides the usual prior predictive checks, prior posterior update checks, posterior predictive checks, based on the population level estimates; we also want to plot at least a few of the single agents to assess how well the model is doing for them. [MISSING: PLOT MODEL ESTIMATES AGAINST N OF HEADS BY PARTICIPANT] # Load the model results samples &lt;- readRDS(&quot;simmodels/W5_MultilevelBias.RDS&quot;) # Display summary statistics for key parameters samples$summary(c(&quot;thetaM&quot;, &quot;thetaSD&quot;, &quot;thetaM_prob&quot;)) ## # A tibble: 3 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 thetaM 1.59 1.59 0.0755 0.0749 1.46 1.71 1.00 6911. 3378. ## 2 thetaSD 0.706 0.704 0.0549 0.0537 0.621 0.799 1.00 4255. 3514. ## 3 thetaM_prob 0.830 0.830 0.0106 0.0105 0.812 0.847 1.00 6911. 3378. # Extract posterior draws for analysis draws_df &lt;- as_draws_df(samples$draws()) # Create a function for standard diagnostic plots plot_diagnostics &lt;- function(parameter_name, true_value = NULL, prior_name = paste0(parameter_name, &quot;_prior&quot;)) { # Trace plot to check mixing and convergence p1 &lt;- ggplot(draws_df, aes(.iteration, .data[[parameter_name]], group = .chain, color = as.factor(.chain))) + geom_line(alpha = 0.5) + labs(title = paste(&quot;Trace Plot for&quot;, parameter_name), x = &quot;Iteration&quot;, y = parameter_name, color = &quot;Chain&quot;) + theme_classic() # Prior-posterior update plot p2 &lt;- ggplot(draws_df) + geom_histogram(aes(.data[[parameter_name]]), fill = &quot;blue&quot;, alpha = 0.3) + geom_histogram(aes(.data[[prior_name]]), fill = &quot;red&quot;, alpha = 0.3) # Add true value if provided if (!is.null(true_value)) { p2 &lt;- p2 + geom_vline(xintercept = true_value, linetype = &quot;dashed&quot;, size = 1) } p2 &lt;- p2 + labs(title = paste(&quot;Prior-Posterior Update for&quot;, parameter_name), subtitle = &quot;Blue: posterior, Red: prior, Dashed: true value&quot;, x = parameter_name, y = &quot;Density&quot;) + theme_classic() # Return both plots return(p1 + p2) } # Plot diagnostics for population mean pop_mean_plots &lt;- plot_diagnostics(&quot;thetaM&quot;, rateM) # Plot diagnostics for population SD pop_sd_plots &lt;- plot_diagnostics(&quot;thetaSD&quot;, rateSD) # Display diagnostic plots pop_mean_plots pop_sd_plots # Create predictive check plots # Prior predictive check p1 &lt;- ggplot(draws_df) + geom_histogram(aes(prior_preds), bins = 30, fill = &quot;blue&quot;, alpha = 0.3, color = &quot;darkblue&quot;) + labs(title = &quot;Prior Predictive Check&quot;, subtitle = &quot;Distribution of predicted &#39;right&#39; choices out of 120 trials&quot;, x = &quot;Number of Right Choices&quot;, y = &quot;Count&quot;) + theme_classic() # Posterior predictive check p2 &lt;- ggplot(draws_df) + geom_histogram(aes(posterior_preds), bins = 30, fill = &quot;green&quot;, alpha = 0.3, color = &quot;darkgreen&quot;) + geom_histogram(aes(prior_preds), bins = 30, fill = &quot;blue&quot;, alpha = 0.1, color = &quot;darkblue&quot;) + labs(title = &quot;Prior vs Posterior Predictive Check&quot;, subtitle = &quot;Green: posterior predictions, Blue: prior predictions&quot;, x = &quot;Number of Right Choices&quot;, y = &quot;Count&quot;) + theme_classic() # Average observed choices per agent agent_means &lt;- colMeans(data_random$h) observed_counts &lt;- agent_means * trials # Add observed counts to posterior predictive plot p3 &lt;- ggplot(draws_df) + geom_histogram(aes(posterior_preds), bins = 30, fill = &quot;green&quot;, alpha = 0.3, color = &quot;darkgreen&quot;) + geom_histogram(data = tibble(observed = observed_counts), aes(observed), bins = 30, fill = &quot;red&quot;, alpha = 0.3, color = &quot;darkred&quot;) + labs(title = &quot;Posterior Predictions vs Observed Data&quot;, subtitle = &quot;Green: posterior predictions, Red: actual observed counts&quot;, x = &quot;Number of Right Choices&quot;, y = &quot;Count&quot;) + theme_classic() # Display predictive check plots p1 + p2 + p3 7.9 Let’s look at individuals # Extract individual parameter estimates # Sample 10 random agents to examine more closely sample_agents &lt;- sample(1:agents, 10) # Extract posterior samples for each agent&#39;s theta parameter theta_samples &lt;- matrix(NA, nrow = nrow(draws_df), ncol = agents) for (a in 1:agents) { # Convert from log-odds to probability scale for ease of interpretation theta_samples[, a] &lt;- inv_logit_scaled(draws_df[[paste0(&quot;theta[&quot;, a, &quot;]&quot;)]]) } # Calculate true rates dddd &lt;- unique(d[,c(&quot;agent&quot;, &quot;trueRate&quot;)]) %&gt;% mutate(trueRate = inv_logit_scaled(trueRate)) # Create a dataframe with the true rates and empirical rates agent_comparison &lt;- tibble( agent = 1:agents, true_rate = dddd$trueRate, # True rate used in simulation empirical_rate = colMeans(data_random$h) # Observed proportion of right choices ) # Calculate summary statistics for posterior estimates theta_summaries &lt;- tibble( agent = 1:agents, mean = colMeans(theta_samples), lower_95 = apply(theta_samples, 2, quantile, 0.025), upper_95 = apply(theta_samples, 2, quantile, 0.975) ) %&gt;% # Join with true values for comparison left_join(agent_comparison, by = &quot;agent&quot;) %&gt;% # Calculate error metrics mutate( abs_error = abs(mean - true_rate), in_interval = true_rate &gt;= lower_95 &amp; true_rate &lt;= upper_95, rel_error = abs_error / true_rate ) # Plot 1: Posterior distributions for sample agents posterior_samples &lt;- tibble( agent = rep(sample_agents, each = nrow(draws_df)), sample_idx = rep(1:nrow(draws_df), times = length(sample_agents)), estimated_rate = as.vector(theta_samples[, sample_agents]) ) p1 &lt;- ggplot() + # Add density plot for posterior distribution of rates geom_density(data = posterior_samples, aes(x = estimated_rate, group = agent), fill = &quot;skyblue&quot;, alpha = 0.5) + # Add vertical line for true rate geom_vline(data = agent_comparison %&gt;% filter(agent %in% sample_agents), aes(xintercept = true_rate), color = &quot;red&quot;, size = 1) + # Add vertical line for empirical rate geom_vline(data = agent_comparison %&gt;% filter(agent %in% sample_agents), aes(xintercept = empirical_rate), color = &quot;green4&quot;, size = 1, linetype = &quot;dashed&quot;) + # Facet by agent facet_wrap(~agent, scales = &quot;free_y&quot;) + # Add formatting labs(title = &quot;Individual Agent Parameter Estimation&quot;, subtitle = &quot;Blue density: Posterior distribution\\nRed line: True rate\\nGreen dashed line: Empirical rate&quot;, x = &quot;Rate Parameter (Probability Scale)&quot;, y = &quot;Density&quot;) + theme_classic() + theme(strip.background = element_rect(fill = &quot;white&quot;), strip.text = element_text(face = &quot;bold&quot;)) + xlim(0, 1) # Plot 2: Parameter recovery for all agents p2 &lt;- ggplot(theta_summaries, aes(x = true_rate, y = mean)) + geom_point(aes(color = in_interval), size = 3, alpha = 0.7) + geom_errorbar(aes(ymin = lower_95, ymax = upper_95, color = in_interval), width = 0.01, alpha = 0.3) + geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;, color = &quot;black&quot;) + geom_smooth(method = &quot;lm&quot;, color = &quot;blue&quot;, se = FALSE, linetype = &quot;dotted&quot;) + scale_color_manual(values = c(&quot;TRUE&quot; = &quot;darkgreen&quot;, &quot;FALSE&quot; = &quot;red&quot;)) + labs(title = &quot;Parameter Recovery Performance&quot;, subtitle = &quot;Each point represents one agent; error bars show 95% credible intervals&quot;, x = &quot;True Rate&quot;, y = &quot;Estimated Rate&quot;, color = &quot;True Value in\\n95% Interval&quot;) + theme_classic() + xlim(0, 1) + ylim(0, 1) # Calculate parameter estimation metrics error_metrics &lt;- tibble( agent = 1:agents, true_rate = dddd$trueRate, empirical_rate = colMeans(data_random$h), estimated_rate = colMeans(theta_samples), lower_95 = apply(theta_samples, 2, quantile, 0.025), upper_95 = apply(theta_samples, 2, quantile, 0.975), absolute_error = abs(estimated_rate - true_rate), relative_error = absolute_error / true_rate, in_interval = true_rate &gt;= lower_95 &amp; true_rate &lt;= upper_95 ) # Create direct comparison plot p3 &lt;- ggplot(error_metrics, aes(x = agent)) + geom_errorbar(aes(ymin = lower_95, ymax = upper_95), width = 0.2, color = &quot;blue&quot;, alpha = 0.5) + geom_point(aes(y = estimated_rate), color = &quot;blue&quot;, size = 3) + geom_point(aes(y = true_rate), color = &quot;red&quot;, shape = 4, size = 3, stroke = 2, alpha = 0.3) + geom_point(aes(y = empirical_rate), color = &quot;green4&quot;, shape = 1, size = 3, stroke = 2, alpha = 0.3) + labs(title = &quot;Parameter Estimation Accuracy by Agent&quot;, subtitle = &quot;Blue points and bars: Estimated rate with 95% credible interval\\nRed X: True rate used in simulation\\nGreen circle: Empirical rate from observed data&quot;, x = &quot;Agent ID&quot;, y = &quot;Rate&quot;) + theme_classic() # Plot 4: Shrinkage visualization # Calculate population mean estimate pop_mean &lt;- mean(draws_df$thetaM_prob) # Add shrinkage information to the data shrinkage_data &lt;- theta_summaries %&gt;% mutate( # Distance from empirical to population mean (shows shrinkage direction) empirical_to_pop = empirical_rate - pop_mean, # Distance from estimate to empirical (shows amount of shrinkage) estimate_to_empirical = mean - empirical_rate, # Ratio of distances (shrinkage proportion) shrinkage_ratio = 1 - (abs(mean - pop_mean) / abs(empirical_rate - pop_mean)), # Define number of trials for sizing points n_trials = trials ) p4 &lt;- ggplot(shrinkage_data, aes(x = empirical_rate, y = mean)) + # Reference line for no shrinkage geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;, color = &quot;gray50&quot;) + # Horizontal line for population mean geom_hline(yintercept = pop_mean, linetype = &quot;dotted&quot;, color = &quot;blue&quot;) + # Points for each agent geom_point(aes(size = n_trials, color = abs(shrinkage_ratio)), alpha = 0.7) + # Connect points to their empirical values to show shrinkage geom_segment(aes(xend = empirical_rate, yend = empirical_rate, color = abs(shrinkage_ratio)), alpha = 0.3) + scale_color_gradient(low = &quot;yellow&quot;, high = &quot;red&quot;) + labs(title = &quot;Shrinkage Effects in Multilevel Modeling&quot;, subtitle = &quot;Points above diagonal shrink down, points below shrink up;\\nBlue dotted line: population mean estimate&quot;, x = &quot;Empirical Rate (Observed Proportion)&quot;, y = &quot;Posterior Mean Estimate&quot;, color = &quot;Shrinkage\\nMagnitude&quot;, size = &quot;Number of\\nTrials&quot;) + theme_classic() + xlim(0, 1) + ylim(0, 1) # Display plots p1 p2 + p3 p4 7.10 Prior sensitivity checks # File path for saved sensitivity results sensitivity_results_file &lt;- &quot;simdata/W5_sensitivity_results.csv&quot; # Check if we need to rerun the analysis if (regenerate_simulations || !file.exists(sensitivity_results_file)) { # Define a range of prior specifications to test prior_settings &lt;- expand_grid( prior_mean_theta = c(-1, 0, 1), # Different prior means for population rate prior_sd_theta = c(0.5, 1, 2), # Different prior SDs for population rate prior_scale_theta_sd = c(0.1, 0.3, 0.5, 1) # Different scales for the SD hyperprior ) # First, create a single Stan model that accepts prior hyperparameters as data stan_code &lt;- &quot; functions { real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; } } data { int&lt;lower=1&gt; trials; int&lt;lower=1&gt; agents; array[trials, agents] int&lt;lower=0, upper=1&gt; h; real prior_mean_theta; real&lt;lower=0&gt; prior_sd_theta; real&lt;lower=0&gt; prior_scale_theta_sd; } parameters { real thetaM; real&lt;lower=0&gt; thetaSD; array[agents] real theta; } model { // Population-level priors with specified hyperparameters target += normal_lpdf(thetaM | prior_mean_theta, prior_sd_theta); target += normal_lpdf(thetaSD | 0, prior_scale_theta_sd) - normal_lccdf(0 | 0, prior_scale_theta_sd); // Agent-level model target += normal_lpdf(theta | thetaM, thetaSD); // Likelihood for (i in 1:agents) { target += bernoulli_logit_lpmf(h[,i] | theta[i]); } } generated quantities { real thetaM_prob = inv_logit(thetaM); } &quot; # Write model to file writeLines(stan_code, &quot;stan/sensitivity_model.stan&quot;) # Compile the model once mod_sensitivity &lt;- cmdstan_model(&quot;stan/sensitivity_model.stan&quot;, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # Function to fit model with specified priors fit_with_priors &lt;- function(prior_mean_theta, prior_sd_theta, prior_scale_theta_sd) { # Create data with prior specifications data_with_priors &lt;- c(data, list( prior_mean_theta = prior_mean_theta, prior_sd_theta = prior_sd_theta, prior_scale_theta_sd = prior_scale_theta_sd )) # Fit model fit &lt;- mod_sensitivity$sample( data = data_with_priors, seed = 123, chains = 1, parallel_chains = 1, threads_per_chain = 1, iter_warmup = 1000, iter_sampling = 1000, refresh = 0 ) # Extract posterior summaries summary_df &lt;- fit$summary(c(&quot;thetaM&quot;, &quot;thetaSD&quot;, &quot;thetaM_prob&quot;)) # Return results return(tibble( prior_mean_theta = prior_mean_theta, prior_sd_theta = prior_sd_theta, prior_scale_theta_sd = prior_scale_theta_sd, est_thetaM = summary_df$mean[summary_df$variable == &quot;thetaM&quot;], est_thetaSD = summary_df$mean[summary_df$variable == &quot;thetaSD&quot;], est_thetaM_prob = summary_df$mean[summary_df$variable == &quot;thetaM_prob&quot;] )) } # Run parallel analysis library(furrr) plan(multisession, workers = 2) # Using fewer workers to reduce resource use sensitivity_results &lt;- future_pmap_dfr( prior_settings, function(prior_mean_theta, prior_sd_theta, prior_scale_theta_sd) { fit_with_priors(prior_mean_theta, prior_sd_theta, prior_scale_theta_sd) }, .options = furrr_options(seed = TRUE) ) # Save results for future use write_csv(sensitivity_results, sensitivity_results_file) cat(&quot;Generated new sensitivity analysis results and saved to&quot;, sensitivity_results_file, &quot;\\n&quot;) } else { # Load existing results sensitivity_results &lt;- read_csv(sensitivity_results_file) cat(&quot;Loaded existing sensitivity analysis results from&quot;, sensitivity_results_file, &quot;\\n&quot;) } ## Loaded existing sensitivity analysis results from simdata/W5_sensitivity_results.csv # Plot for population mean estimate p1 &lt;- ggplot(sensitivity_results, aes(x = prior_mean_theta, y = est_thetaM_prob, color = factor(prior_scale_theta_sd))) + geom_point(size = 3) + geom_hline(yintercept = inv_logit_scaled(d$rateM), linetype = &quot;dashed&quot;) + labs(title = &quot;Sensitivity of Population Mean Parameter&quot;, subtitle = &quot;Dashed line shows average empirical rate across participants&quot;, x = &quot;Prior Mean, SD for Population Parameter&quot;, y = &quot;Estimated Population Mean (probability scale)&quot;, color = &quot;Prior Scale for\\nPopulation SD&quot;) + theme_classic() + ylim(0.7, 0.9) + facet_wrap(.~prior_sd_theta) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Plot for population SD parameter p2 &lt;- ggplot(sensitivity_results, aes(x = prior_mean_theta, y = est_thetaSD, color = factor(prior_scale_theta_sd))) + geom_point(size = 3) + geom_hline(yintercept = d$rateSD, linetype = &quot;dashed&quot;) + labs(title = &quot;Sensitivity of Population Variance Parameter&quot;, x = &quot;Prior Mean, SD for Population Parameter&quot;, y = &quot;Estimated Population SD&quot;, color = &quot;Prior Scale for\\nPopulation SD&quot;) + theme_classic() + ylim(0.5, 0.7) + facet_wrap(.~prior_sd_theta) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Display plots p1 / p2 7.11 Parameter recovery # File path for saved recovery results recovery_results_file &lt;- &quot;simdata/W5_recovery_results.csv&quot; # Check if we need to rerun the analysis if (regenerate_simulations || !file.exists(recovery_results_file)) { # Function to simulate data and recover parameters recover_parameters &lt;- function(true_thetaM, true_thetaSD, n_agents, n_trials) { # Generate agent-specific true rates agent_thetas &lt;- rnorm(n_agents, true_thetaM, true_thetaSD) # Generate choice data sim_data &lt;- matrix(NA, nrow = n_trials, ncol = n_agents) for (a in 1:n_agents) { sim_data[,a] &lt;- rbinom(n_trials, 1, inv_logit_scaled(agent_thetas[a])) } # Prepare data for Stan stan_data &lt;- list( trials = n_trials, agents = n_agents, h = sim_data, prior_mean_theta = 0, # Using neutral priors prior_sd_theta = 1, prior_scale_theta_sd = 0.3 ) # Compile the model once mod_sensitivity &lt;- cmdstan_model(&quot;stan/sensitivity_model.stan&quot;, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # Fit model fit &lt;- mod_sensitivity$sample( data = stan_data, seed = 123, chains = 1, parallel_chains = 1, threads_per_chain = 1, iter_warmup = 1000, iter_sampling = 1000, refresh = 0 ) # Extract estimates summary_df &lt;- fit$summary(c(&quot;thetaM&quot;, &quot;thetaSD&quot;)) # Return comparison of true vs. estimated parameters return(tibble( true_thetaM = true_thetaM, true_thetaSD = true_thetaSD, n_agents = n_agents, n_trials = n_trials, est_thetaM = summary_df$mean[summary_df$variable == &quot;thetaM&quot;], est_thetaSD = summary_df$mean[summary_df$variable == &quot;thetaSD&quot;] )) } # Create parameter grid for recovery study recovery_settings &lt;- expand_grid( true_thetaM = c(-1, 0, 1), true_thetaSD = c(0.1, 0.3, 0.5, 0.7), n_agents = c(20, 50), n_trials = c(60, 120) ) # Run parameter recovery study (this can be very time-consuming) recovery_results &lt;- pmap_dfr( recovery_settings, function(true_thetaM, true_thetaSD, n_agents, n_trials) { recover_parameters(true_thetaM, true_thetaSD, n_agents, n_trials) } ) # Save results for future use write_csv(recovery_results, recovery_results_file) cat(&quot;Generated new parameter recovery results and saved to&quot;, recovery_results_file, &quot;\\n&quot;) } else { # Load existing results recovery_results &lt;- read_csv(recovery_results_file) cat(&quot;Loaded existing parameter recovery results from&quot;, recovery_results_file, &quot;\\n&quot;) } ## Loaded existing parameter recovery results from simdata/W5_recovery_results.csv # Visualize parameter recovery results p1 &lt;- ggplot(recovery_results, aes(x = true_thetaM, y = est_thetaM, color = factor(true_thetaSD))) + geom_point(size = 3) + geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;) + facet_grid(n_agents ~ n_trials, labeller = labeller( n_agents = function(x) paste0(&quot;Agents: &quot;, x), n_trials = function(x) paste0(&quot;Trials: &quot;, x) )) + labs(title = &quot;Recovery of Population Mean Parameter&quot;, x = &quot;True Value&quot;, y = &quot;Estimated Value&quot;, color = &quot;True Population SD&quot;) + theme_classic() p2 &lt;- ggplot(recovery_results, aes(x = true_thetaSD, y = est_thetaSD, color = factor(true_thetaM))) + geom_point(size = 3) + geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;) + facet_grid(n_agents ~ n_trials, labeller = labeller( n_agents = function(x) paste0(&quot;Agents: &quot;, x), n_trials = function(x) paste0(&quot;Trials: &quot;, x) )) + labs(title = &quot;Recovery of Population SD Parameter&quot;, x = &quot;True Value&quot;, y = &quot;Estimated Value&quot;, color = &quot;True Population Mean&quot;) + theme_classic() # Display parameter recovery plots p1 / p2 7.12 Multilevel Memory Agent Model Now we’ll implement a more complex model for the memory agent. This model has two parameters per agent: bias: baseline tendency to choose “right” (log-odds scale) beta: sensitivity to the memory of opponent’s past choices Like the random agent model, we’ll use a multilevel structure where individual parameters come from population distributions. However, this model presents some additional challenges: We need to handle two parameters per agent We need to track and update memory states during the model The hierarchical structure is more complex The hierarchical structure for this model is: Population level: μ_bias ~ Normal(0, 1), σ_bias ~ Normal⁺(0, 0.3) μ_beta ~ Normal(0, 0.3), σ_beta ~ Normal⁺(0, 0.3) Individual level: bias_i ~ Normal(μ_bias, σ_bias) beta_i ~ Normal(μ_beta, σ_beta) Transformed variables: memory_it = updated based on opponent’s choices Data level: y_it ~ Bernoulli(logit⁻¹(bias_i + beta_i * logit(memory_it))) Let’s implement this model. [MISSING: DAGS] Code, compile and fit the model # Stan model for multilevel memory agent with centered parameterization stan_model &lt;- &quot; // Multilevel Memory Agent Model (Centered Parameterization) // functions{ real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input data for the model data { int&lt;lower = 1&gt; trials; // Number of trials per agent int&lt;lower = 1&gt; agents; // Number of agents array[trials, agents] int h; // Memory agent choices array[trials, agents] int other; // Opponent (random agent) choices } // Parameters to be estimated parameters { // Population-level parameters real biasM; // Mean of baseline bias real&lt;lower = 0&gt; biasSD; // SD of baseline bias real betaM; // Mean of memory sensitivity real&lt;lower = 0&gt; betaSD; // SD of memory sensitivity // Individual-level parameters array[agents] real bias; // Individual baseline bias parameters array[agents] real beta; // Individual memory sensitivity parameters } // Transformed parameters (derived quantities) transformed parameters { // Memory state for each agent and trial array[trials, agents] real memory; // Calculate memory states based on opponent&#39;s choices for (agent in 1:agents){ // Initial memory state (no prior information) memory[1, agent] = 0.5; for (trial in 1:trials){ // Update memory based on opponent&#39;s choices if (trial &lt; trials){ // Simple averaging memory update memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); // Handle edge cases to avoid numerical issues if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;} if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;} } } } } // Model definition model { // Population-level priors target += normal_lpdf(biasM | 0, 1); target += normal_lpdf(biasSD | 0, .3) - normal_lccdf(0 | 0, .3); // Half-normal target += normal_lpdf(betaM | 0, .3); target += normal_lpdf(betaSD | 0, .3) - normal_lccdf(0 | 0, .3); // Half-normal // Individual-level priors target += normal_lpdf(bias | biasM, biasSD); target += normal_lpdf(beta | betaM, betaSD); // Likelihood for (agent in 1:agents) { for (trial in 1:trials) { target += bernoulli_logit_lpmf(h[trial,agent] | bias[agent] + logit(memory[trial, agent]) * beta[agent]); } } } // Generated quantities for model checking and predictions generated quantities{ // Prior samples for checking real biasM_prior; real&lt;lower=0&gt; biasSD_prior; real betaM_prior; real&lt;lower=0&gt; betaSD_prior; real bias_prior; real beta_prior; // Predictive simulations with different memory values int&lt;lower=0, upper = trials&gt; prior_preds0; // No memory effect (memory=0) int&lt;lower=0, upper = trials&gt; prior_preds1; // Neutral memory (memory=0.5) int&lt;lower=0, upper = trials&gt; prior_preds2; // Strong memory (memory=1) int&lt;lower=0, upper = trials&gt; posterior_preds0; int&lt;lower=0, upper = trials&gt; posterior_preds1; int&lt;lower=0, upper = trials&gt; posterior_preds2; // Individual-level predictions (for each agent) array[agents] int&lt;lower=0, upper = trials&gt; posterior_predsID0; array[agents] int&lt;lower=0, upper = trials&gt; posterior_predsID1; array[agents] int&lt;lower=0, upper = trials&gt; posterior_predsID2; // Generate prior samples biasM_prior = normal_rng(0,1); biasSD_prior = normal_lb_rng(0,0.3,0); betaM_prior = normal_rng(0,1); betaSD_prior = normal_lb_rng(0,0.3,0); bias_prior = normal_rng(biasM_prior, biasSD_prior); beta_prior = normal_rng(betaM_prior, betaSD_prior); // Prior predictive checks with different memory values prior_preds0 = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior)); prior_preds1 = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior)); prior_preds2 = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior)); // Posterior predictive checks with different memory values posterior_preds0 = binomial_rng(trials, inv_logit(biasM + 0 * betaM)); posterior_preds1 = binomial_rng(trials, inv_logit(biasM + 1 * betaM)); posterior_preds2 = binomial_rng(trials, inv_logit(biasM + 2 * betaM)); // Individual-level predictions for (agent in 1:agents){ posterior_predsID0[agent] = binomial_rng(trials, inv_logit(bias[agent] + 0 * beta[agent])); posterior_predsID1[agent] = binomial_rng(trials, inv_logit(bias[agent] + 1 * beta[agent])); posterior_predsID2[agent] = binomial_rng(trials, inv_logit(bias[agent] + 2 * beta[agent])); } } &quot; # File path for saved model model_file &lt;- &quot;simmodels/W5_MultilevelMemory_centered.RDS&quot; # Check if we need to rerun the simulation if (regenerate_simulations || !file.exists(model_file)) { file &lt;- file.path(&quot;stan/W5_MultilevelMemory.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # Sample from the posterior distribution samples &lt;- mod$sample( data = data_memory, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99 ) # Save the model results samples$save_object(file = model_file) cat(&quot;Generated new model fit and saved to&quot;, model_file, &quot;\\n&quot;) } else { # Load existing results samples &lt;- readRDS(model_file) cat(&quot;Loaded existing model fit from&quot;, model_file, &quot;\\n&quot;) } 7.12.1 Assessing multilevel memory # Load the model results samples &lt;- readRDS(&quot;simmodels/W5_MultilevelMemory_centered.RDS&quot;) # Show summary statistics for key parameters print(samples$summary(c(&quot;biasM&quot;, &quot;betaM&quot;, &quot;biasSD&quot;, &quot;betaSD&quot;))) ## # A tibble: 4 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 biasM 0.521 0.518 0.0969 0.101 0.363 0.682 1.02 184. 399. ## 2 betaM 1.09 1.09 0.0666 0.0684 0.983 1.20 1.02 213. 387. ## 3 biasSD 0.315 0.317 0.0709 0.0714 0.197 0.430 1.03 196. 324. ## 4 betaSD 0.288 0.286 0.0465 0.0456 0.213 0.366 1.01 526. 916. # Extract posterior draws for analysis draws_df &lt;- as_draws_df(samples$draws()) # Create trace plots to check convergence p1 &lt;- mcmc_trace(draws_df, pars = c(&quot;biasM&quot;, &quot;biasSD&quot;, &quot;betaM&quot;, &quot;betaSD&quot;)) + theme_classic() + ggtitle(&quot;Trace Plots for Population Parameters&quot;) # Show trace plots p1 # Create prior-posterior update plots create_density_plot &lt;- function(param, true_value, title) { prior_name &lt;- paste0(param, &quot;_prior&quot;) ggplot(draws_df) + geom_histogram(aes(get(param)), fill = &quot;blue&quot;, alpha = 0.3) + geom_histogram(aes(get(prior_name)), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = true_value, linetype = &quot;dashed&quot;) + labs(title = title, subtitle = &quot;Blue: posterior, Red: prior, Dashed: true value&quot;, x = param, y = &quot;Density&quot;) + theme_classic() } # Create individual plots p_biasM &lt;- create_density_plot(&quot;biasM&quot;, biasM, &quot;Population Mean Bias&quot;) p_biasSD &lt;- create_density_plot(&quot;biasSD&quot;, biasSD, &quot;Population SD of Bias&quot;) p_betaM &lt;- create_density_plot(&quot;betaM&quot;, betaM, &quot;Population Mean Beta&quot;) p_betaSD &lt;- create_density_plot(&quot;betaSD&quot;, betaSD, &quot;Population SD of Beta&quot;) # Show them in a grid (p_biasM + p_biasSD) / (p_betaM + p_betaSD) # Show correlations p1 &lt;- ggplot(draws_df, aes(biasM, biasSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p2 &lt;- ggplot(draws_df, aes(betaM, betaSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p3 &lt;- ggplot(draws_df, aes(biasM, betaM, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p4 &lt;- ggplot(draws_df, aes(biasSD, betaSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p1 + p2 + p3 + p4 # Create posterior predictive check plots p1 &lt;- ggplot(draws_df) + geom_histogram(aes(prior_preds0), fill = &quot;red&quot;, alpha = 0.3, bins = 30) + geom_histogram(aes(posterior_preds0), fill = &quot;blue&quot;, alpha = 0.3, bins = 30) + geom_histogram(aes(posterior_preds1), fill = &quot;green&quot;, alpha = 0.3, bins = 30) + geom_histogram(aes(posterior_preds2), fill = &quot;purple&quot;, alpha = 0.3, bins = 30) + labs(title = &quot;Prior and Posterior Predictive Distributions&quot;, subtitle = &quot;Red: prior, Blue: no memory effect, Green: neutral memory, Purple: strong memory&quot;, x = &quot;Predicted Right Choices (out of 120)&quot;, y = &quot;Count&quot;) + theme_classic() # Display plots p1 # Individual-level parameter recovery # Extract individual parameters for a sample of agents sample_agents &lt;- sample(1:agents, 100) sample_data &lt;- d %&gt;% filter(agent %in% sample_agents, trial == 1) %&gt;% select(agent, bias, beta) # Extract posterior means for individual agents bias_means &lt;- c() beta_means &lt;- c() for (i in sample_agents) { bias_means[i] &lt;- mean(draws_df[[paste0(&quot;bias[&quot;, i, &quot;]&quot;)]]) beta_means[i] &lt;- mean(draws_df[[paste0(&quot;beta[&quot;, i, &quot;]&quot;)]]) } # Create comparison data comparison_data &lt;- tibble( agent = sample_agents, true_bias = sample_data$bias, est_bias = bias_means[sample_agents], true_beta = sample_data$beta, est_beta = beta_means[sample_agents] ) # Plot comparison p1 &lt;- ggplot(comparison_data, aes(true_bias, est_bias)) + geom_point(size = 3) + geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;) + geom_smooth(method = lm) + ylim(-0.2, 1.1) + xlim(-0.2, 1.1) + labs(title = &quot;Bias Parameter Recovery&quot;, x = &quot;True Bias&quot;, y = &quot;Estimated Bias&quot;) + theme_classic() p2 &lt;- ggplot(comparison_data, aes(true_beta, est_beta)) + geom_point(size = 3) + geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;) + ylim(0.6, 2.4) + xlim(0.6, 2.4) + labs(title = &quot;Beta Parameter Recovery&quot;, x = &quot;True Beta&quot;, y = &quot;Estimated Beta&quot;) + theme_classic() # Display parameter recovery plots p1 + p2 7.12.2 Diagnosing the issue with bias and beta # First, let&#39;s examine the individual bias parameters distribution bias_params &lt;- draws_df %&gt;% select(starts_with(&quot;bias[&quot;)) %&gt;% pivot_longer(everything(), names_to = &quot;parameter&quot;, values_to = &quot;value&quot;) # Plot distribution of all individual bias parameters ggplot(bias_params, aes(x = value)) + geom_histogram(bins = 30) + labs(title = &quot;Distribution of Individual Bias Parameters&quot;, x = &quot;Bias Value (log-odds scale)&quot;, y = &quot;Count&quot;) + theme_classic() # Check for correlation between bias and beta parameters # For a few sample agents cors &lt;- NULL for (i in sample(1:agents)) { cors[i] &lt;- (cor(draws_df[[paste0(&quot;bias[&quot;, i, &quot;]&quot;)]], draws_df[[paste0(&quot;beta[&quot;, i, &quot;]&quot;)]])) } corr_data &lt;- tibble( agent = seq_along(cors), correlation = cors ) %&gt;% filter(!is.na(correlation)) # Calculate summary statistics mean_cor &lt;- mean(corr_data$correlation) median_cor &lt;- median(corr_data$correlation) min_cor &lt;- min(corr_data$correlation) max_cor &lt;- max(corr_data$correlation) # Create correlation strength categories corr_data &lt;- corr_data %&gt;% mutate( strength = case_when( correlation &lt;= -0.7 ~ &quot;Strong negative&quot;, correlation &lt;= -0.5 ~ &quot;Moderate negative&quot;, correlation &lt;= -0.3 ~ &quot;Weak negative&quot;, correlation &lt; 0 ~ &quot;Negligible negative&quot;, correlation &gt;= 0 &amp; correlation &lt; 0.3 ~ &quot;Negligible positive&quot;, correlation &gt;= 0.3 &amp; correlation &lt; 0.5 ~ &quot;Weak positive&quot;, correlation &gt;= 0.5 &amp; correlation &lt; 0.7 ~ &quot;Moderate positive&quot;, TRUE ~ &quot;Strong positive&quot; ), strength = factor(strength, levels = c( &quot;Strong negative&quot;, &quot;Moderate negative&quot;, &quot;Weak negative&quot;, &quot;Negligible negative&quot;, &quot;Negligible positive&quot;, &quot;Weak positive&quot;, &quot;Moderate positive&quot;, &quot;Strong positive&quot; )) ) # Create the plot ggplot(corr_data, aes(x = correlation)) + # Histogram colored by correlation strength geom_histogram(aes(fill = strength), bins = 30, alpha = 0.8, color = &quot;white&quot;) + # Density curve geom_density(color = &quot;black&quot;, linewidth = 1, alpha = 0.3) + # Reference lines geom_vline(xintercept = median_cor, linewidth = 1, linetype = &quot;dotted&quot;, color = &quot;black&quot;) + geom_vline(xintercept = 0, linewidth = 0.5, color = &quot;gray50&quot;) + # Annotations annotate(&quot;label&quot;, x = median_cor, y = Inf, label = paste(&quot;Median:&quot;, round(median_cor, 2)), vjust = 3, size = 4, fill = &quot;lightblue&quot;, alpha = 0.8) + # Colors for correlation strength scale_fill_manual(values = c( &quot;Strong negative&quot; = &quot;#d73027&quot;, &quot;Moderate negative&quot; = &quot;#fc8d59&quot;, &quot;Weak negative&quot; = &quot;#fee090&quot;, &quot;Negligible negative&quot; = &quot;#ffffbf&quot;, &quot;Negligible positive&quot; = &quot;#e0f3f8&quot;, &quot;Weak positive&quot; = &quot;#91bfdb&quot;, &quot;Moderate positive&quot; = &quot;#4575b4&quot;, &quot;Strong positive&quot; = &quot;#313695&quot; )) + # Titles and labels labs( title = &quot;Distribution of Bias-Beta Parameter Correlations&quot;, subtitle = paste0( &quot;Analysis of &quot;, nrow(corr_data), &quot; agents shows consistent negative correlation\\n&quot;, &quot;Range: [&quot;, round(min_cor, 2), &quot;, &quot;, round(max_cor, 2), &quot;]&quot; ), x = &quot;Correlation Coefficient&quot;, y = &quot;Count&quot;, fill = &quot;Correlation Strength&quot; ) + # Set axis limits and theme xlim(-1, 1) + theme_minimal() 7.12.3 Multilevel memory with non centered parameterization When implementing multilevel models, we sometimes encounter sampling efficiency issues, especially when group-level variance parameters are small or data is limited. This creates a “funnel” in the posterior distribution that’s difficult for the sampler to navigate efficiently. Non-centered parameterization addresses this by reparameterizing individual parameters as standardized deviations from the group mean: Instead of: θᵢ ~ Normal(μ, σ) We use: θᵢ = μ + σ · zᵢ, where zᵢ ~ Normal(0, 1) This is conceptually similar to when we z-score variables in regression models. This approach separates the sampling of the standardized individual parameters (zᵢ) from the group-level parameters (μ and σ), improving sampling efficiency. The transformation between these parameterizations is invertible, so the models are equivalent, but the non-centered version often performs better computationally. In our code, we implement this by: Sampling standardized individual parameters (biasID_z, betaID_z) Multiplying by group SD and adding group mean to get individual parameters # Stan model for multilevel memory agent with non-centered parameterization stan_model_nc &lt;- &quot; // Multilevel Memory Agent Model (Non-Centered Parameterization) // functions{ real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input data for the model data { int&lt;lower = 1&gt; trials; // Number of trials per agent int&lt;lower = 1&gt; agents; // Number of agents array[trials, agents] int h; // Memory agent choices array[trials, agents] int other; // Opponent (random agent) choices } // Parameters to be estimated parameters { // Population-level parameters real biasM; // Mean of baseline bias real&lt;lower = 0&gt; biasSD; // SD of baseline bias real betaM; // Mean of memory sensitivity real&lt;lower = 0&gt; betaSD; // SD of memory sensitivity // Standardized individual parameters (non-centered parameterization) vector[agents] biasID_z; // Standardized individual bias parameters vector[agents] betaID_z; // Standardized individual beta parameters } // Transformed parameters (derived quantities) transformed parameters { // Memory state for each agent and trial array[trials, agents] real memory; // Individual parameters (constructed from non-centered parameterization) vector[agents] biasID; vector[agents] betaID; // Calculate memory states based on opponent&#39;s choices for (agent in 1:agents){ for (trial in 1:trials){ // Initial memory state (no prior information) if (trial == 1) { memory[trial, agent] = 0.5; } // Update memory based on opponent&#39;s choices if (trial &lt; trials){ // Simple averaging memory update memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); // Handle edge cases to avoid numerical issues if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;} if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;} } } } // Construct individual parameters from non-centered parameterization biasID = biasM + biasID_z * biasSD; betaID = betaM + betaID_z * betaSD; } // Model definition model { // Population-level priors target += normal_lpdf(biasM | 0, 1); target += normal_lpdf(biasSD | 0, .3) - normal_lccdf(0 | 0, .3); // Half-normal target += normal_lpdf(betaM | 0, .3); target += normal_lpdf(betaSD | 0, .3) - normal_lccdf(0 | 0, .3); // Half-normal // Standardized individual parameters (non-centered parameterization) target += std_normal_lpdf(biasID_z); // Standard normal prior for z-scores target += std_normal_lpdf(betaID_z); // Standard normal prior for z-scores // Likelihood for (agent in 1:agents){ for (trial in 1:trials){ target += bernoulli_logit_lpmf(h[trial,agent] | biasID[agent] + logit(memory[trial, agent]) * betaID[agent]); } } } // Generated quantities for model checking and predictions generated quantities{ // Prior samples for checking real biasM_prior; real&lt;lower=0&gt; biasSD_prior; real betaM_prior; real&lt;lower=0&gt; betaSD_prior; real bias_prior; real beta_prior; // Predictive simulations with different memory values (individual level) array[agents] int&lt;lower=0, upper = trials&gt; prior_preds0; // No memory effect (memory=0) array[agents] int&lt;lower=0, upper = trials&gt; prior_preds1; // Neutral memory (memory=0.5) array[agents] int&lt;lower=0, upper = trials&gt; prior_preds2; // Strong memory (memory=1) array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds2; // Generate prior samples biasM_prior = normal_rng(0,1); biasSD_prior = normal_lb_rng(0,0.3,0); betaM_prior = normal_rng(0,1); betaSD_prior = normal_lb_rng(0,0.3,0); bias_prior = normal_rng(biasM_prior, biasSD_prior); beta_prior = normal_rng(betaM_prior, betaSD_prior); // Generate predictions for each agent for (agent in 1:agents){ // Prior predictive checks prior_preds0[agent] = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior)); prior_preds1[agent] = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior)); prior_preds2[agent] = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior)); // Posterior predictive checks posterior_preds0[agent] = binomial_rng(trials, inv_logit(biasM + biasID[agent] + 0 * (betaM + betaID[agent]))); posterior_preds1[agent] = binomial_rng(trials, inv_logit(biasM + biasID[agent] + 1 * (betaM + betaID[agent]))); posterior_preds2[agent] = binomial_rng(trials, inv_logit(biasM + biasID[agent] + 2 * (betaM + betaID[agent]))); } } &quot; # Write the Stan model to a file write_stan_file( stan_model_nc, dir = &quot;stan/&quot;, basename = &quot;W5_MultilevelMemory_nc.stan&quot; ) # File path for saved model model_file &lt;- &quot;simmodels/W5_MultilevelMemory_noncentered.RDS&quot; # Check if we need to rerun the simulation if (regenerate_simulations || !file.exists(model_file)) { # Compile the model file &lt;- file.path(&quot;stan/W5_MultilevelMemory_nc.stan&quot;) mod_nc &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # Sample from the posterior distribution samples &lt;- mod_nc$sample( data = data_memory, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99 ) # Save the model results samples$save_object(file = model_file) cat(&quot;Generated new model fit and saved to&quot;, model_file, &quot;\\n&quot;) } else { # Load existing results samples &lt;- readRDS(model_file) cat(&quot;Loaded existing model fit from&quot;, model_file, &quot;\\n&quot;) } 7.12.4 Assessing multilevel memory samples &lt;- readRDS(&quot;simmodels/W5_MultilevelMemory_noncentered.RDS&quot;) # Show summary statistics for key parameters print(samples$summary(c(&quot;biasM&quot;, &quot;betaM&quot;, &quot;biasSD&quot;, &quot;betaSD&quot;))) ## # A tibble: 4 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 biasM 0.538 0.537 0.0870 0.0875 0.397 0.683 1.00 1315. 2025. ## 2 betaM 1.02 1.02 0.0726 0.0732 0.901 1.14 1.00 1187. 2168. ## 3 biasSD 0.281 0.281 0.0702 0.0698 0.168 0.401 1.00 630. 956. ## 4 betaSD 0.411 0.409 0.0497 0.0493 0.333 0.499 1.00 1394. 2137. # Extract posterior draws for analysis draws_df &lt;- as_draws_df(samples$draws()) # Create trace plots to check convergence p1 &lt;- mcmc_trace(draws_df, pars = c(&quot;biasM&quot;, &quot;biasSD&quot;, &quot;betaM&quot;, &quot;betaSD&quot;)) + theme_classic() + ggtitle(&quot;Trace Plots for Population Parameters&quot;) # Show trace plots p1 # Create prior-posterior update plots create_density_plot &lt;- function(param, true_value, title) { prior_name &lt;- paste0(param, &quot;_prior&quot;) ggplot(draws_df) + geom_histogram(aes(get(param)), fill = &quot;blue&quot;, alpha = 0.3) + geom_histogram(aes(get(prior_name)), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = true_value, linetype = &quot;dashed&quot;) + labs(title = title, subtitle = &quot;Blue: posterior, Red: prior, Dashed: true value&quot;, x = param, y = &quot;Density&quot;) + theme_classic() } # Create individual plots p_biasM &lt;- create_density_plot(&quot;biasM&quot;, biasM, &quot;Population Mean Bias&quot;) p_biasSD &lt;- create_density_plot(&quot;biasSD&quot;, biasSD, &quot;Population SD of Bias&quot;) p_betaM &lt;- create_density_plot(&quot;betaM&quot;, betaM, &quot;Population Mean Beta&quot;) p_betaSD &lt;- create_density_plot(&quot;betaSD&quot;, betaSD, &quot;Population SD of Beta&quot;) # Show them in a grid (p_biasM + p_biasSD) / (p_betaM + p_betaSD) # Show correlations p1 &lt;- ggplot(draws_df, aes(biasM, biasSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p2 &lt;- ggplot(draws_df, aes(betaM, betaSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p3 &lt;- ggplot(draws_df, aes(biasM, betaM, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p4 &lt;- ggplot(draws_df, aes(biasSD, betaSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p1 + p2 + p3 + p4 # Create posterior predictive check plots p1 &lt;- ggplot(draws_df) + geom_histogram(aes(`prior_preds0[1]`), fill = &quot;red&quot;, alpha = 0.3, bins = 30) + geom_histogram(aes(`posterior_preds0[1]`), fill = &quot;blue&quot;, alpha = 0.3, bins = 30) + geom_histogram(aes(`posterior_preds1[1]`), fill = &quot;green&quot;, alpha = 0.3, bins = 30) + geom_histogram(aes(`posterior_preds2[1]`), fill = &quot;purple&quot;, alpha = 0.3, bins = 30) + labs(title = &quot;Prior and Posterior Predictive Distributions&quot;, subtitle = &quot;Red: prior, Blue: no memory effect, Green: neutral memory, Purple: strong memory&quot;, x = &quot;Predicted Right Choices (out of 120)&quot;, y = &quot;Count&quot;) + theme_classic() # Display plots p1 # Individual-level parameter recovery # Extract individual parameters for a sample of agents sample_agents &lt;- sample(1:agents, 100) sample_data &lt;- d %&gt;% filter(agent %in% sample_agents, trial == 1) %&gt;% select(agent, bias, beta) # Extract posterior means for individual agents bias_means &lt;- c() beta_means &lt;- c() for (i in sample_agents) { bias_means[i] &lt;- mean(draws_df[[paste0(&quot;biasID[&quot;, i, &quot;]&quot;)]]) beta_means[i] &lt;- mean(draws_df[[paste0(&quot;betaID[&quot;, i, &quot;]&quot;)]]) } # Create comparison data comparison_data &lt;- tibble( agent = sample_agents, true_bias = sample_data$bias, est_bias = bias_means[sample_agents], true_beta = sample_data$beta, est_beta = beta_means[sample_agents] ) # Plot comparison p1 &lt;- ggplot(comparison_data, aes(true_bias, est_bias)) + geom_point(size = 3) + geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;) + geom_smooth(method = lm) + labs(title = &quot;Bias Parameter Recovery&quot;, x = &quot;True Bias&quot;, y = &quot;Estimated Bias&quot;) + theme_classic() p2 &lt;- ggplot(comparison_data, aes(true_beta, est_beta)) + geom_point(size = 3) + geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;) + geom_smooth(method = lm) + labs(title = &quot;Beta Parameter Recovery&quot;, x = &quot;True Beta&quot;, y = &quot;Estimated Beta&quot;) + theme_classic() # Display parameter recovery plots p1 + p2 7.12.5 Multilevel memory with correlation between parameters stan_model_nc_cor &lt;- &quot; // // This STAN model infers a random bias from a sequences of 1s and 0s (heads and tails) // functions{ real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; array[trials, agents] int other; } // The parameters accepted by the model. parameters { real biasM; real betaM; vector&lt;lower = 0&gt;[2] tau; matrix[2, agents] z_IDs; cholesky_factor_corr[2] L_u; } transformed parameters { array[trials, agents] real memory; matrix[agents,2] IDs; IDs = (diag_pre_multiply(tau, L_u) * z_IDs)&#39;; for (agent in 1:agents){ for (trial in 1:trials){ if (trial == 1) { memory[trial, agent] = 0.5; } if (trial &lt; trials){ memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;} if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;} } } } } // The model to be estimated. model { target += normal_lpdf(biasM | 0, 1); target += normal_lpdf(tau[1] | 0, .3) - normal_lccdf(0 | 0, .3); target += normal_lpdf(betaM | 0, .3); target += normal_lpdf(tau[2] | 0, .3) - normal_lccdf(0 | 0, .3); target += lkj_corr_cholesky_lpdf(L_u | 2); target += std_normal_lpdf(to_vector(z_IDs)); for (agent in 1:agents){ for (trial in 1:trials){ target += bernoulli_logit_lpmf(h[trial, agent] | biasM + IDs[agent, 1] + memory[trial, agent] * (betaM + IDs[agent, 2])); } } } generated quantities{ real biasM_prior; real&lt;lower=0&gt; biasSD_prior; real betaM_prior; real&lt;lower=0&gt; betaSD_prior; real bias_prior; real beta_prior; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds2; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds2; biasM_prior = normal_rng(0,1); biasSD_prior = normal_lb_rng(0,0.3,0); betaM_prior = normal_rng(0,1); betaSD_prior = normal_lb_rng(0,0.3,0); bias_prior = normal_rng(biasM_prior, biasSD_prior); beta_prior = normal_rng(betaM_prior, betaSD_prior); for (i in 1:agents){ prior_preds0[i] = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior)); prior_preds1[i] = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior)); prior_preds2[i] = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior)); posterior_preds0[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 0 * (betaM + IDs[i,2]))); posterior_preds1[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 1 * (betaM + IDs[i,2]))); posterior_preds2[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 2 * (betaM + IDs[i,2]))); } } &quot; write_stan_file( stan_model_nc_cor, dir = &quot;stan/&quot;, basename = &quot;W5_MultilevelMemory_nc_cor.stan&quot;) model_file &lt;- &quot;simmodels/W5_MultilevelMemory_noncentered_cor.RDS&quot; # Check if we need to rerun the simulation if (regenerate_simulations || !file.exists(model_file)) { # Compile the model file &lt;- file.path(&quot;stan/W5_MultilevelMemory_nc_cor.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # Sample from the posterior distribution samples &lt;- mod$sample( data = data_memory, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99 ) # Save the model results samples$save_object(file = model_file) cat(&quot;Generated new model fit and saved to&quot;, model_file, &quot;\\n&quot;) } else { # Load existing results samples &lt;- readRDS(model_file) cat(&quot;Loaded existing model fit from&quot;, model_file, &quot;\\n&quot;) } 7.12.6 Assessing multilevel memory [MISSING LOTS OF EVALUATION] samples &lt;- readRDS(&quot;simmodels/W5_MultilevelMemory_noncentered_cor.RDS&quot;) # Show summary statistics for key parameters print(samples$summary(c(&quot;biasM&quot;, &quot;betaM&quot;, &quot;tau[1]&quot;, &quot;tau[2]&quot;, &quot;L_u[2,2]&quot;))) ## # A tibble: 5 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 biasM -0.199 -0.195 0.219 0.215 -0.561 0.159 1.00 1510. 2256. ## 2 betaM 3.05 3.05 0.232 0.227 2.67 3.44 1.00 2222. 2196. ## 3 tau[1] 0.721 0.722 0.120 0.111 0.526 0.923 1.00 1828. 1838. ## 4 tau[2] 0.336 0.295 0.234 0.243 0.0269 0.775 1.00 196. 562. ## 5 L_u[2,2] 0.898 0.944 0.120 0.0773 0.657 1.00 1.00 2235. 1869. # Extract posterior draws for analysis draws_df &lt;- as_draws_df(samples$draws()) # Create trace plots to check convergence p1 &lt;- mcmc_trace(draws_df, pars = c(&quot;biasM&quot;, &quot;betaM&quot;, &quot;tau[1]&quot;, &quot;tau[2]&quot;, &quot;L_u[2,2]&quot;)) + theme_classic() + ggtitle(&quot;Trace Plots for Population Parameters&quot;) # Show trace plots p1 # Create prior-posterior update plots create_density_plot &lt;- function(param, true_value, title) { prior_name &lt;- paste0(param, &quot;_prior&quot;) param &lt;- case_when( param == &quot;biasSD&quot; ~ &quot;tau[1]&quot;, param == &quot;betaSD&quot; ~ &quot;tau[2]&quot;, TRUE ~ param ) ggplot(draws_df) + geom_histogram(aes(get(param)), fill = &quot;blue&quot;, alpha = 0.3) + geom_histogram(aes(get(prior_name)), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = true_value, linetype = &quot;dashed&quot;) + labs(title = title, subtitle = &quot;Blue: posterior, Red: prior, Dashed: true value&quot;, x = param, y = &quot;Density&quot;) + theme_classic() } # Create individual plots p_biasM &lt;- create_density_plot(&quot;biasM&quot;, biasM, &quot;Population Mean Bias&quot;) p_biasSD &lt;- create_density_plot(&quot;biasSD&quot;, biasSD, &quot;Population SD of Bias&quot;) p_betaM &lt;- create_density_plot(&quot;betaM&quot;, betaM, &quot;Population Mean Beta&quot;) p_betaSD &lt;- create_density_plot(&quot;betaSD&quot;, betaSD, &quot;Population SD of Beta&quot;) # Show them in a grid (p_biasM + p_biasSD) / (p_betaM + p_betaSD) # Show correlations between pop level parameters p1 &lt;- ggplot(draws_df, aes(biasM, biasSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p2 &lt;- ggplot(draws_df, aes(betaM, betaSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p3 &lt;- ggplot(draws_df, aes(biasM, betaM, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p4 &lt;- ggplot(draws_df, aes(biasSD, betaSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p1 + p2 + p3 + p4 # Show correlation between individual level parameters # Function to convert Cholesky factor to correlation matrix chol_to_corr &lt;- function(L) { # L is lower triangular cholesky factor # For 2x2 matrix, correlation is L[2,1] # We assume the input is a 2x2 cholesky factor where L[1,1] and L[2,2] are ignored L_full &lt;- matrix(0, 2, 2) L_full[1,1] &lt;- 1 L_full[2,1] &lt;- L[1] L_full[2,2] &lt;- sqrt(1 - L[1]^2) # Correlation = L * L^T corr &lt;- L_full %*% t(L_full) return(corr[1,2]) # Return correlation between dimension 1 and 2 } # Extract the Cholesky factor from posterior samples posterior_L &lt;- draws_df %&gt;% select(starts_with(&quot;L_u[2,1]&quot;)) # This is the cholesky factor element for correlation # Convert to correlation values posterior_corr &lt;- posterior_L %&gt;% mutate(correlation = `L_u[2,1]`) # For 2×2 case, directly using the parameter works # Generate prior samples from LKJ distribution (approximated via a beta) n_prior_samples &lt;- nrow(posterior_corr) prior_corr &lt;- tibble( correlation = 2 * rbeta(n_prior_samples, 2, 2) - 1 # Scale beta to [-1,1] ) # Combine for plotting plot_data &lt;- bind_rows( mutate(posterior_corr, type = &quot;Posterior&quot;), mutate(prior_corr, type = &quot;Prior&quot;) ) # Create the visualization ggplot(plot_data, aes(x = correlation, fill = type)) + geom_density(alpha = 0.5) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;gray50&quot;) + scale_fill_manual(values = c(&quot;Prior&quot; = &quot;red&quot;, &quot;Posterior&quot; = &quot;blue&quot;)) + labs( title = &quot;Prior vs Posterior: Correlation Between Bias and Beta Parameters&quot;, subtitle = &quot;LKJ(2) prior vs posterior correlation distribution&quot;, x = &quot;Correlation Coefficient&quot;, y = &quot;Density&quot;, fill = &quot;Distribution&quot; ) + coord_cartesian(xlim = c(-1, 1)) + theme_minimal() + annotate(&quot;text&quot;, x = 0.2, y = Inf, label = &quot;Negative correlation suggests\\ntradeoff between bias and\\nmemory sensitivity parameters&quot;, vjust = 2, hjust = 0, size = 3.5) # Create posterior predictive check plots p1 &lt;- ggplot(draws_df) + geom_histogram(aes(`prior_preds0[1]`), fill = &quot;red&quot;, alpha = 0.3, bins = 30) + geom_histogram(aes(`posterior_preds0[1]`), fill = &quot;blue&quot;, alpha = 0.3, bins = 30) + geom_histogram(aes(`posterior_preds1[1]`), fill = &quot;green&quot;, alpha = 0.3, bins = 30) + geom_histogram(aes(`posterior_preds2[1]`), fill = &quot;purple&quot;, alpha = 0.3, bins = 30) + labs(title = &quot;Prior and Posterior Predictive Distributions&quot;, subtitle = &quot;Red: prior, Blue: no memory effect, Green: neutral memory, Purple: strong memory&quot;, x = &quot;Predicted Right Choices (out of 120)&quot;, y = &quot;Count&quot;) + theme_classic() # Display plots p1 # Individual-level parameter recovery # Extract individual parameters for a sample of agents sample_agents &lt;- sample(1:agents, 100) sample_data &lt;- d %&gt;% filter(agent %in% sample_agents, trial == 1) %&gt;% select(agent, bias, beta) # Extract posterior means for individual agents bias_means &lt;- c() beta_means &lt;- c() for (i in sample_agents) { bias_means[i] &lt;- mean(draws_df[[paste0(&quot;z_IDs[1,&quot;, i, &quot;]&quot;)]]) beta_means[i] &lt;- mean(draws_df[[paste0(&quot;z_IDs[2,&quot;, i, &quot;]&quot;)]]) } # Create comparison data comparison_data &lt;- tibble( agent = sample_agents, true_bias = scale(sample_data$bias), est_bias = scale(bias_means[sample_agents]), true_beta = scale(sample_data$beta), est_beta = scale(beta_means[sample_agents]) ) # Plot comparison p1 &lt;- ggplot(comparison_data, aes(true_bias, est_bias)) + geom_point(size = 3) + geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;) + geom_smooth(method = lm) + labs(title = &quot;Bias Parameter Recovery&quot;, x = &quot;Standardized True Bias&quot;, y = &quot;Standardized Estimated Bias&quot;) + theme_classic() p2 &lt;- ggplot(comparison_data, aes(true_beta, est_beta)) + geom_point(size = 3) + geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;) + geom_smooth(method = lm) + labs(title = &quot;Beta Parameter Recovery&quot;, x = &quot;Standardized True Beta&quot;, y = &quot;Standardized Estimated Beta&quot;) + theme_classic() # Display parameter recovery plots p1 + p2 7.12.7 # Load both models centered_model &lt;- readRDS(&quot;simmodels/W5_MultilevelMemory_centered.RDS&quot;) noncentered_model &lt;- readRDS(&quot;simmodels/W5_MultilevelMemory_noncentered.RDS&quot;) # Function to extract divergences and tree depths extract_diagnostics &lt;- function(model_fit) { draws &lt;- as_draws_df(model_fit$draws()) # Extract diagnostic information diagnostics &lt;- tibble( model = model_fit$metadata()$id, divergent = sum(draws$.divergent), max_treedepth = sum(draws$.treedepth &gt;= 10), n_draws = nrow(draws) ) return(diagnostics) } # Get diagnostics for both models centered_diag &lt;- extract_diagnostics(centered_model) noncentered_diag &lt;- extract_diagnostics(noncentered_model) # Combine diagnostics diagnostics &lt;- bind_rows(centered_diag, noncentered_diag) # Create diagnostic summary table diagnostics_table &lt;- diagnostics %&gt;% mutate( divergent_pct = round(divergent / n_draws * 100, 2), max_treedepth_pct = round(max_treedepth / n_draws * 100, 2) ) %&gt;% select(model, divergent, divergent_pct, max_treedepth, max_treedepth_pct) # Display diagnostics table knitr::kable(diagnostics_table, caption = &quot;Sampling Diagnostics Comparison: Centered vs. Non-Centered&quot;, col.names = c(&quot;Model&quot;, &quot;Divergent Transitions&quot;, &quot;% Divergent&quot;, &quot;Max Tree Depth&quot;, &quot;% Max Tree&quot;)) (#tab:compare_parameterizations)Sampling Diagnostics Comparison: Centered vs. Non-Centered Model Divergent Transitions % Divergent Max Tree Depth % Max Tree 1 0 0 0 0 2 0 0 0 0 1 0 0 0 0 2 0 0 0 0 # Extract summary statistics for key parameters from both models centered_summary &lt;- centered_model$summary(c(&quot;biasM&quot;, &quot;biasSD&quot;, &quot;betaM&quot;, &quot;betaSD&quot;)) noncentered_summary &lt;- noncentered_model$summary(c(&quot;biasM&quot;, &quot;biasSD&quot;, &quot;betaM&quot;, &quot;betaSD&quot;)) # Combine and format for comparison parameter_comparison &lt;- bind_rows( mutate(centered_summary, model = &quot;Centered&quot;), mutate(noncentered_summary, model = &quot;Non-Centered&quot;) ) # Display parameter comparison knitr::kable(parameter_comparison %&gt;% select(model, variable, mean, q5, q95), caption = &quot;Parameter Estimates: Centered vs. Non-Centered&quot;, col.names = c(&quot;Model&quot;, &quot;Parameter&quot;, &quot;Mean&quot;, &quot;5% Quantile&quot;, &quot;95% Quantile&quot;)) (#tab:compare_parameterizations)Parameter Estimates: Centered vs. Non-Centered Model Parameter Mean 5% Quantile 95% Quantile Centered biasM 0.5207274 0.3632372 0.6819521 Centered biasSD 0.3149875 0.1967087 0.4295062 Centered betaM 1.0912498 0.9825970 1.2015955 Centered betaSD 0.2880511 0.2132505 0.3661757 Non-Centered biasM 0.5375237 0.3969487 0.6831376 Non-Centered biasSD 0.2812996 0.1683787 0.4006906 Non-Centered betaM 1.0209935 0.9014366 1.1430440 Non-Centered betaSD 0.4113402 0.3330174 0.4987831 # Visual comparison of posterior distributions # Extract draws from both models centered_draws &lt;- as_draws_df(centered_model$draws()) %&gt;% select(biasM, biasSD, betaM, betaSD) %&gt;% mutate(model = &quot;Centered&quot;) noncentered_draws &lt;- as_draws_df(noncentered_model$draws()) %&gt;% select(biasM, biasSD, betaM, betaSD) %&gt;% mutate(model = &quot;Non-Centered&quot;) # Combine draws combined_draws &lt;- bind_rows(centered_draws, noncentered_draws) # Create comparison plots compare_density &lt;- function(param, true_value) { ggplot(combined_draws, aes(x = .data[[param]], fill = model)) + geom_histogram(alpha = 0.5) + geom_vline(xintercept = true_value, linetype = &quot;dashed&quot;) + labs( title = paste(&quot;Posterior Distribution Comparison:&quot;, param), subtitle = &quot;Centered vs. Non-Centered Parameterization&quot;, x = param, y = &quot;Density&quot; ) + theme_classic() } # Create comparison plots for each parameter p1 &lt;- compare_density(&quot;biasM&quot;, biasM) p2 &lt;- compare_density(&quot;biasSD&quot;, biasSD) p3 &lt;- compare_density(&quot;betaM&quot;, betaM) p4 &lt;- compare_density(&quot;betaSD&quot;, betaSD) # Display comparison plots p1 + p2 p3 + p4 7.13 Comparing Pooling Approaches To better understand the trade-offs between different modeling approaches, let’s implement and compare three ways of handling individual differences: No Pooling: Separate models for each agent with no sharing of information Complete Pooling: A single model with identical parameters for all agents Partial Pooling: Our multilevel approach that balances individual and group information Each approach has advantages and disadvantages: Approach Advantages Disadvantages No Pooling Captures all individual differences Unstable for agents with little data; Can’t generalize Complete Pooling Stable estimates; Simple Ignores individual differences Partial Pooling Balances individual vs. group data; Better for small samples More complex; Requires careful implementation Let’s compare how these approaches perform with our memory agent data # First we&#39;ll implement the no-pooling model stan_model_nopooling &lt;- &quot; // Memory Agent Model - No Pooling Approach // (Separate parameters for each agent, no sharing of information) data { int&lt;lower = 1&gt; trials; // Number of trials per agent int&lt;lower = 1&gt; agents; // Number of agents array[trials, agents] int h; // Memory agent choices array[trials, agents] int other; // Opponent (random agent) choices } parameters { // Individual parameters for each agent (no population structure) array[agents] real bias; // Individual bias parameters array[agents] real beta; // Individual beta parameters } transformed parameters { // Memory state for each agent and trial array[trials, agents] real memory; // Calculate memory states for (agent in 1:agents){ for (trial in 1:trials){ if (trial == 1) { memory[trial, agent] = 0.5; } if (trial &lt; trials){ memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;} if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;} } } } } model { // Separate priors for each agent (no pooling) for (agent in 1:agents) { target += normal_lpdf(bias[agent] | 0, 1); target += normal_lpdf(beta[agent] | 0, 1); } // Likelihood for (agent in 1:agents){ for (trial in 1:trials){ target += bernoulli_logit_lpmf(h[trial, agent] | bias[agent] + memory[trial, agent] * beta[agent]); } } } generated quantities{ // Predictions with different memory values array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds2; // Generate predictions for (agent in 1:agents){ posterior_preds0[agent] = binomial_rng(trials, inv_logit(bias[agent] + 0 * beta[agent])); posterior_preds1[agent] = binomial_rng(trials, inv_logit(bias[agent] + 1 * beta[agent])); posterior_preds2[agent] = binomial_rng(trials, inv_logit(bias[agent] + 2 * beta[agent])); } } &quot; # Now implement the complete pooling model stan_model_fullpooling &lt;- &quot; // Memory Agent Model - Complete Pooling Approach // (Single set of parameters shared by all agents) data { int&lt;lower = 1&gt; trials; // Number of trials per agent int&lt;lower = 1&gt; agents; // Number of agents array[trials, agents] int h; // Memory agent choices array[trials, agents] int other; // Opponent (random agent) choices } parameters { // Single set of parameters shared by all agents real bias; // Shared bias parameter real beta; // Shared beta parameter } transformed parameters { // Memory state for each agent and trial array[trials, agents] real memory; // Calculate memory states for (agent in 1:agents){ for (trial in 1:trials){ if (trial == 1) { memory[trial, agent] = 0.5; } if (trial &lt; trials){ memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;} if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;} } } } } model { // Priors for shared parameters target += normal_lpdf(bias | 0, 1); target += normal_lpdf(beta | 0, 1); // Likelihood (same parameters for all agents) for (agent in 1:agents){ for (trial in 1:trials){ target += bernoulli_logit_lpmf(h[trial, agent] | bias + memory[trial, agent] * beta); } } } generated quantities{ // Single set of predictions for all agents int&lt;lower=0, upper = trials&gt; posterior_preds0; int&lt;lower=0, upper = trials&gt; posterior_preds1; int&lt;lower=0, upper = trials&gt; posterior_preds2; // Generate predictions posterior_preds0 = binomial_rng(trials, inv_logit(bias + 0 * beta)); posterior_preds1 = binomial_rng(trials, inv_logit(bias + 1 * beta)); posterior_preds2 = binomial_rng(trials, inv_logit(bias + 2 * beta)); } &quot; # Write the models to files write_stan_file(stan_model_nopooling, dir = &quot;stan/&quot;, basename = &quot;W5_MultilevelMemory_nopooling.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W5_MultilevelMemory_nopooling.stan&quot; write_stan_file(stan_model_fullpooling, dir = &quot;stan/&quot;, basename = &quot;W5_MultilevelMemory_fullpooling.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W5_MultilevelMemory_fullpooling.stan&quot; # Define file paths for saved models file_nopooling_results &lt;- &quot;simmodels/W5_MultilevelMemory_nopooling.RDS&quot; file_fullpooling_results &lt;- &quot;simmodels/W5_MultilevelMemory_fullpooling.RDS&quot; # Fit no pooling model if needed if (regenerate_simulations || !file.exists(file_nopooling_results)) { # Compile the models file_nopooling &lt;- file.path(&quot;stan/W5_MultilevelMemory_nopooling.stan&quot;) mod_nopooling &lt;- cmdstan_model(file_nopooling, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) samples_nopooling &lt;- mod_nopooling$sample( data = data_memory, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99 ) samples_nopooling$save_object(file = file_nopooling_results) cat(&quot;Generated new no-pooling model fit\\n&quot;) } else { cat(&quot;Loading existing no-pooling model fit\\n&quot;) } ## Loading existing no-pooling model fit # Fit full pooling model if needed if (regenerate_simulations || !file.exists(file_fullpooling_results)) { file_fullpooling &lt;- file.path(&quot;stan/W5_MultilevelMemory_fullpooling.stan&quot;) mod_fullpooling &lt;- cmdstan_model(file_fullpooling, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) samples_fullpooling &lt;- mod_fullpooling$sample( data = data_memory, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99 ) samples_fullpooling$save_object(file = file_fullpooling_results) cat(&quot;Generated new full-pooling model fit\\n&quot;) } else { cat(&quot;Loading existing full-pooling model fit\\n&quot;) } ## Loading existing full-pooling model fit 7.14 Comparing Pooling Approaches # Load required packages # Function to simulate and visualize shrinkage from different pooling approaches visualize_pooling_approaches &lt;- function() { # First, simulate some data for demonstration set.seed(42) n_groups &lt;- 20 n_per_group &lt;- c(5, 10, 20, 50) # Different group sizes # True group means (population distribution) true_pop_mean &lt;- 0 true_pop_sd &lt;- 1 true_group_means &lt;- rnorm(n_groups, true_pop_mean, true_pop_sd) # Function to simulate data and estimates for one scenario simulate_one_scenario &lt;- function(n_per_group) { # Create data frame results &lt;- tibble( group_id = factor(1:n_groups), true_mean = true_group_means, n_obs = n_per_group ) # Simulate observed data observed_data &lt;- map2_dfr(1:n_groups, n_per_group, function(group, n) { tibble( group_id = factor(group), value = rnorm(n, true_group_means[group], 1) # Within-group SD = 1 ) }) # Calculate no-pooling estimates (just the group means) no_pooling &lt;- observed_data %&gt;% group_by(group_id) %&gt;% summarize(estimate = mean(value)) %&gt;% pull(estimate) # Calculate full-pooling estimate (grand mean) full_pooling &lt;- mean(observed_data$value) # Calculate partial-pooling estimates (empirical Bayes approach) # This is a simplified version of what happens in a multilevel model grand_mean &lt;- mean(observed_data$value) group_means &lt;- observed_data %&gt;% group_by(group_id) %&gt;% summarize(mean = mean(value), n = n()) # Calculate group variances and total variance components group_var &lt;- var(group_means$mean) within_var &lt;- mean((observed_data %&gt;% group_by(group_id) %&gt;% summarize(var = var(value)) %&gt;% pull(var))) # Calculate shrinkage factor for each group partial_pooling &lt;- map_dbl(1:n_groups, function(i) { group_mean &lt;- group_means$mean[i] group_size &lt;- group_means$n[i] # Optimal shrinkage factor lambda &lt;- within_var / (within_var + group_var * group_size) # Shrunk estimate lambda * grand_mean + (1 - lambda) * group_mean }) # Add estimates to results results &lt;- results %&gt;% mutate( no_pooling = no_pooling, full_pooling = full_pooling, partial_pooling = partial_pooling, # Calculate absolute errors no_pooling_error = abs(no_pooling - true_mean), full_pooling_error = abs(full_pooling - true_mean), partial_pooling_error = abs(partial_pooling - true_mean), scenario = paste(n_per_group, &quot;observations per group&quot;) ) return(results) } # Simulate all scenarios all_results &lt;- map_dfr(n_per_group, simulate_one_scenario) # Convert to long format for plotting results_long &lt;- all_results %&gt;% pivot_longer( cols = c(no_pooling, full_pooling, partial_pooling), names_to = &quot;method&quot;, values_to = &quot;estimate&quot; ) %&gt;% mutate( method = factor(method, levels = c(&quot;no_pooling&quot;, &quot;partial_pooling&quot;, &quot;full_pooling&quot;), labels = c(&quot;No Pooling&quot;, &quot;Partial Pooling&quot;, &quot;Full Pooling&quot;)) ) # Plot 1: Shrinkage visualization p1 &lt;- ggplot(results_long, aes(x = true_mean, y = estimate, color = method)) + geom_point(alpha = 0.7) + geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;) + geom_hline(yintercept = true_pop_mean, linetype = &quot;dotted&quot;) + facet_wrap(~scenario) + scale_color_manual(values = c(&quot;No Pooling&quot; = &quot;red&quot;, &quot;Partial Pooling&quot; = &quot;green&quot;, &quot;Full Pooling&quot; = &quot;blue&quot;)) + labs( title = &quot;Shrinkage Effects in Different Pooling Approaches&quot;, subtitle = &quot;Dashed line: perfect recovery; Dotted line: population mean&quot;, x = &quot;True Group Mean&quot;, y = &quot;Estimated Mean&quot;, color = &quot;Method&quot; ) + theme_minimal() # Calculate error metrics for each scenario and method error_summary &lt;- all_results %&gt;% group_by(scenario) %&gt;% summarize( No_Pooling_MSE = mean(no_pooling_error^2), Full_Pooling_MSE = mean(full_pooling_error^2), Partial_Pooling_MSE = mean(partial_pooling_error^2) ) %&gt;% pivot_longer( cols = contains(&quot;_MSE&quot;), names_to = &quot;method&quot;, values_to = &quot;mse&quot; ) %&gt;% mutate( method = gsub(&quot;_MSE&quot;, &quot;&quot;, method), method = gsub(&quot;_&quot;, &quot; &quot;, method) ) # Plot 2: Error comparison p2 &lt;- ggplot(error_summary, aes(x = scenario, y = mse, fill = method)) + geom_col(position = &quot;dodge&quot;) + scale_fill_manual(values = c(&quot;No Pooling&quot; = &quot;red&quot;, &quot;Partial Pooling&quot; = &quot;green&quot;, &quot;Full Pooling&quot; = &quot;blue&quot;)) + labs( title = &quot;Mean Squared Error by Pooling Approach&quot;, subtitle = &quot;Lower values indicate better parameter recovery&quot;, x = &quot;Scenario&quot;, y = &quot;Mean Squared Error&quot;, fill = &quot;Method&quot; ) + theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Plot 3: Shrinkage as a function of group size and distance from mean # Calculate shrinkage ratio shrinkage_data &lt;- all_results %&gt;% mutate( dist_from_mean = true_mean - true_pop_mean, # Shrinkage ratio: how much of the distance from population mean is preserved # 1 = no shrinkage, 0 = complete shrinkage to mean no_pool_shrinkage = (no_pooling - true_pop_mean) / dist_from_mean, full_pool_shrinkage = (full_pooling - true_pop_mean) / dist_from_mean, partial_pool_shrinkage = (partial_pooling - true_pop_mean) / dist_from_mean ) %&gt;% # Filter out cases where dist_from_mean is too close to zero filter(abs(dist_from_mean) &gt; 0.1) # Convert to long format shrinkage_long &lt;- shrinkage_data %&gt;% select(group_id, scenario, n_obs, dist_from_mean, contains(&quot;_shrinkage&quot;)) %&gt;% pivot_longer( cols = contains(&quot;_shrinkage&quot;), names_to = &quot;method&quot;, values_to = &quot;shrinkage_ratio&quot; ) %&gt;% mutate( method = gsub(&quot;_shrinkage&quot;, &quot;&quot;, method), method = gsub(&quot;_&quot;, &quot; &quot;, method), method = factor(method, levels = c(&quot;no pool&quot;, &quot;partial pool&quot;, &quot;full pool&quot;), labels = c(&quot;No Pooling&quot;, &quot;Partial Pooling&quot;, &quot;Full Pooling&quot;)), # Clip extreme values for visualization shrinkage_ratio = pmin(pmax(shrinkage_ratio, -0.5), 1.5) ) # Plot shrinkage ratio p3 &lt;- ggplot(shrinkage_long, aes(x = abs(dist_from_mean), y = shrinkage_ratio, color = method)) + geom_point(alpha = 0.7) + geom_smooth(method = &quot;loess&quot;, se = FALSE) + geom_hline(yintercept = 1, linetype = &quot;dashed&quot;) + geom_hline(yintercept = 0, linetype = &quot;dotted&quot;) + facet_wrap(~scenario) + scale_color_manual(values = c(&quot;No Pooling&quot; = &quot;red&quot;, &quot;Partial Pooling&quot; = &quot;green&quot;, &quot;Full Pooling&quot; = &quot;blue&quot;)) + labs( title = &quot;Shrinkage Ratio by Distance from Population Mean&quot;, subtitle = &quot;1.0 = No shrinkage; 0.0 = Complete shrinkage to population mean&quot;, x = &quot;Distance from Population Mean&quot;, y = &quot;Shrinkage Ratio&quot;, color = &quot;Method&quot; ) + theme_minimal() # Return all plots together return(list( main_plot = p1, error_plot = p2, shrinkage_plot = p3 )) } # Generate the visualizations plots &lt;- visualize_pooling_approaches() # Display the plots plots$main_plot plots$error_plot plots$shrinkage_plot # Create combined visualization for conceptual understanding set.seed(123) # Generate data for a single example n_groups &lt;- 8 true_pop_mean &lt;- 0 true_pop_sd &lt;- 1 true_means &lt;- rnorm(n_groups, true_pop_mean, true_pop_sd) group_sizes &lt;- sample(c(3, 5, 10, 20, 30), n_groups, replace = TRUE) # Generate observations generate_group_data &lt;- function(group_id, true_mean, n_obs) { tibble( group = factor(group_id), true_mean = true_mean, n_obs = n_obs, value = rnorm(n_obs, true_mean, 1) ) } sim_data &lt;- map_dfr(1:n_groups, ~generate_group_data( ., true_means[.], group_sizes[.] )) # Calculate estimates estimates &lt;- sim_data %&gt;% group_by(group) %&gt;% summarize( n = n(), true_mean = first(true_mean), no_pooling = mean(value), full_pooling = mean(sim_data$value) ) %&gt;% mutate( # Simplified partial pooling calculation reliability = n / (n + 10), # 10 is arbitrary scaling factor for demonstration partial_pooling = reliability * no_pooling + (1 - reliability) * full_pooling ) # Convert to long format for visualization est_long &lt;- estimates %&gt;% pivot_longer( cols = c(no_pooling, partial_pooling, full_pooling), names_to = &quot;method&quot;, values_to = &quot;estimate&quot; ) %&gt;% mutate( method = factor(method, levels = c(&quot;no_pooling&quot;, &quot;partial_pooling&quot;, &quot;full_pooling&quot;), labels = c(&quot;No Pooling&quot;, &quot;Partial Pooling&quot;, &quot;Full Pooling&quot;)) ) # Create conceptual visualization conceptual_plot &lt;- ggplot(est_long, aes(x = reorder(group, true_mean), y = estimate, color = method)) + # Draw vertical lines showing shrinkage #geom_segment(data = est_long %&gt;% filter(method == &quot;No Pooling&quot;), # aes(xend = group, y = estimate, yend = full_pooling), # color = &quot;gray&quot;, linetype = &quot;dotted&quot;) + # Draw points for estimates geom_point(aes(size = n), alpha = 0.8) + # Draw true means geom_point(aes(y = true_mean), shape = 4, size = 3, color = &quot;black&quot;) + # Draw horizontal line for population mean geom_hline(yintercept = mean(sim_data$value), linetype = &quot;dashed&quot;, color = &quot;gray&quot;) + # Formatting scale_color_manual(values = c(&quot;No Pooling&quot; = &quot;red&quot;, &quot;Partial Pooling&quot; = &quot;green&quot;, &quot;Full Pooling&quot; = &quot;blue&quot;)) + labs( title = &quot;Conceptual Visualization of Shrinkage in Multilevel Modeling&quot;, subtitle = &quot;X = True group mean; Dotted lines show shrinkage; Point size = group sample size&quot;, x = &quot;Group&quot;, y = &quot;Estimate&quot;, color = &quot;Pooling Method&quot;, size = &quot;Group Size&quot; ) + theme_minimal() # Display conceptual plot conceptual_plot [MISSING: PARAMETER RECOVERY IN A MULTILEVEL FRAMEWORK (IND VS POP)] 7.15 Multilevel Modeling Cheatsheet Multilevel Model Visualization 7.15.1 When to Use Each Pooling Approach: Approach When to Use Advantages Disadvantages No Pooling Many observations per group; groups truly independent • Simple to implement• Captures all individual differences • Unstable with small sample sizes• Can’t predict for new individuals Full Pooling Few observations per group; minimal individual differences • Stable estimates• Simple model • Ignores individual differences• Can lead to poor predictions for outliers Partial Pooling Moderate observations per group; meaningful individual differences • Balances individual and group data• More accurate for small groups• Can predict for new individuals • More complex model• Requires careful implementation 7.15.2 Parameter Recovery Rules of Thumb: Group-level means (e.g., biasM) typically require fewer observations for good recovery than group-level variances (e.g., biasSD) Individual parameters undergo more shrinkage when: Group-level variance is small Individual data is limited Individual estimates are far from the group mean 7.16 Conclusion: The Power and Challenges of Multilevel Modeling In this chapter, we’ve explored how multilevel modeling provides a principled approach to analyzing data with hierarchical structure. By implementing models for both biased agents and memory agents, we’ve seen how to: Represent population-level distributions of parameters Allow for individual variations while maintaining population constraints Implement different parameterizations to improve sampling efficiency Assess model quality through various diagnostic techniques Multilevel modeling offers several key advantages for cognitive modeling (only some of which have been exemplified here): - Improved parameter estimation for individuals with limited data - Detection of population-level patterns while respecting individual differences - More efficient use of data through partial pooling of information - Capacity to model correlations between different cognitive parameters The practical implementation challenges we’ve encountered—such as sampling difficulties with correlated parameters and the need for non-centered parameterization—are common in cognitive modeling applications. Developing familiarity with these techniques prepares you for implementing more complex models in your own research. 7.17 Exercises (just some ideas) Parameter Recovery Analysis Simulate data with different levels of individual variability (try biasSD values of 0.05, 0.3, and 0.8). Fit the multilevel model to each dataset and assess how well individual and population parameters are recovered. How does the amount of individual variability affect the benefits of partial pooling? Model Comparison Challenge For the memory agent model, compare the predictive performance of: Full pooling (single parameters for all agents) No pooling (separate parameters for each agent) Partial pooling (hierarchical model) Use different amounts of data (20, 60, and 120 trials) to determine when each approach works best. Create a plot showing the relative advantage of each approach as data quantity changes. Extend the Model Modify the memory agent model to include a “forgetting rate” parameter that weights recent observations more heavily. Implement this as a multilevel parameter (varying across individuals). Does this additional parameter improve model fit? How does it correlate with the other parameters? Applied Modeling [MISSING] The file cognitive_data.csv contains real data from a sequential decision-making experiment. Apply the multilevel memory model to this dataset. Interpret the population-level parameters and identify any interesting individual differences. Create visualizations that communicate your findings effectively. Debugging Challenge [MISSING] The file problematic_model.stan contains a multilevel model with several implementation issues. Identify and fix the problems to get the model running efficiently. Common issues include poor parameterization, inefficient computation, or misspecified priors. "],["model-comparison-in-cognitive-science.html", "Chapter 8 Model Comparison in Cognitive Science 8.1 Learning Objectives 8.2 Why Compare Models? 8.3 Define parameters 8.4 Define biased and memory agents 8.5 Generating the agents 8.6 Prep the data 8.7 Log posterior likelihood 8.8 Create the models: multilevel biased agents 8.9 Multilevel memory model 8.10 Fitting the models to the data 8.11 Calculating the expected log predictive density of a model 8.12 Implementing Cross-Validation 8.13 Calculating elpd and comparing 8.14 Limitations of model comparison techniques", " Chapter 8 Model Comparison in Cognitive Science Understanding human cognition often involves choosing between competing theoretical explanations. When faced with behavioral data - whether from matching pennies games, learning tasks, or decision-making scenarios - we can implement different theories of the underlying cognitive processes, or switch on and off specific cognitive components. Model comparison is the set of procedure that allows allows us to determine which cognitive model best explains the observed patterns. But remember, model comparison is not a fail-safe procedure to determine which model embodies the truth, as always we need to be careful, tentative and open about the probabilistic and fallible nature of our inference. 8.1 Learning Objectives After completing this chapter, you will be able to: Implement cross-validation techniques for comparing cognitive models using Stan Calculate and interpret expected log predictive density (ELPD) scores Assess model predictions through posterior and prior predictive checks Understand the strengths and limitations of different model comparison approaches Apply these techniques to compare competing cognitive models using real data 8.2 Why Compare Models? Model comparison serves multiple purposes in cognitive science. Some examples: Theory Testing: Different models often represent competing theoretical accounts of cognitive processes. Comparing their fit to data helps evaluate these theories. Parsimony: When multiple models can explain the data, one of the reason to prefer more complex models is if they are justified by better predictive performance. Generalization: By assessing how well different models predict new data, we can evaluate their ability to capture general patterns rather than just fitting to specific samples. Individual Differences: Model comparison can reveal whether different individuals or groups are better described by different cognitive strategies. This chapter demonstrates these principles using our matching pennies models as concrete examples. We’ll compare simple random choice models against more sophisticated memory-based approaches, showing how to rigorously evaluate which better explains observed behavior. Imagine having several models of what might be going on and want to know which is the best explanation of the data. E.g. Are people more likely to use a memory strategy, or a win stay lose shift strategy? Or are we justified in assuming that people react differently to losses than to wins (e.g. by being more likely to shift when losing, than to stay when winning)? Or would we be justified in assuming that capuchin monkeys and cognitive science students use the same model? Model comparison defines a broad range of practices aimed at identifying among a set of models the best model for a given data set. What “best” means is, however, a non-trivial question. Ideally, “best” would mean the model describing the mechanism that actually generated the data. However, as we will see that is a tricky proposition and we analysts tend to rely on proxies. There are many of such proxies in the literature. For instance, Nicenboim et al (2023) suggests employing either Bayes Factors or cross-validation (https://vasishth.github.io/bayescogsci/book/ch-comparison.html). In this course, we rely on cross-validation based predictive performance (this chapter) and mixture models (next chapter). In other words, this chapter will assess models in terms of their (estimated) ability to predict new (test) data. Remember that predictive performance is a very useful tool, but not a magical solution. It allows us to combat overfitting to the training sample (your model snuggling to your data so much that it fits both signal and noise), but it has key limitations, which we will discuss at the end of the chapter. To learn how to make model comparison, in this chapter, we rely on our usual simulation based approach to ensure that the method is doing what we want. We simulate the behavior of biased agents playing against the memory agents. This provides us with data generated according to two different mechanisms: biased agents and memory agents. We can fit both models separately on each of the two sets of agents, so we can compare the relative performance of the two models: can we identify the true model generating the data (in a setup where truth is known)? This is what is usually called “model recovery” and complements nicely “parameter recovery”. In model recovery we assess whether we can identify the correct model, in parameter recovery we assess whether - once we know the correct model - we can identify the correct parameter values. Let’s get going. 8.3 Define parameters pacman::p_load(tidyverse, here, posterior, cmdstanr, brms, tidybayes, loo, job) # Shared parameters agents &lt;- 100 trials &lt;- 120 noise &lt;- 0 # Biased agents parameters rateM &lt;- 1.386 # roughly 0.8 once inv_logit scaled rateSD &lt;- 0.65 # roughly giving a sd of 0.1 in prob scale # Memory agents parameters biasM &lt;- 0 biasSD &lt;- 0.1 betaM &lt;- 1.5 betaSD &lt;- 0.3 8.4 Define biased and memory agents # Functions of the agents RandomAgentNoise_f &lt;- function(rate, noise) { choice &lt;- rbinom(1, 1, inv_logit_scaled(rate)) if (rbinom(1, 1, noise) == 1) { choice = rbinom(1, 1, 0.5) } return(choice) } MemoryAgentNoise_f &lt;- function(bias, beta, otherRate, noise) { rate &lt;- inv_logit_scaled(bias + beta * logit_scaled(otherRate)) choice &lt;- rbinom(1, 1, rate) if (rbinom(1, 1, noise) == 1) { choice = rbinom(1, 1, 0.5) } return(choice) } 8.5 Generating the agents [MISSING: PARALLELIZE] # Looping through all the agents to generate the data. d &lt;- NULL for (agent in 1:agents) { rate &lt;- rnorm(1, rateM, rateSD) bias &lt;- rnorm(1, biasM, biasSD) beta &lt;- rnorm(1, betaM, betaSD) randomChoice &lt;- rep(NA, trials) memoryChoice &lt;- rep(NA, trials) memoryRate &lt;- rep(NA, trials) for (trial in 1:trials) { randomChoice[trial] &lt;- RandomAgentNoise_f(rate, noise) if (trial == 1) { memoryChoice[trial] &lt;- rbinom(1,1,0.5) } else { memoryChoice[trial] &lt;- MemoryAgentNoise_f(bias, beta, mean(randomChoice[1:trial], na.rm = T), noise) } } temp &lt;- tibble(agent, trial = seq(trials), randomChoice, randomRate = rate, memoryChoice, memoryRate, noise, rateM, rateSD, bias, beta, biasM, biasSD, betaM, betaSD) if (agent &gt; 1) { d &lt;- rbind(d, temp) } else{ d &lt;- temp } } d &lt;- d %&gt;% group_by(agent) %&gt;% mutate( randomRate = cumsum(randomChoice) / seq_along(randomChoice), memoryRate = cumsum(memoryChoice) / seq_along(memoryChoice) ) 8.6 Prep the data d1 &lt;- d %&gt;% subset(select = c(agent, randomChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = randomChoice) d2 &lt;- d %&gt;% subset(select = c(agent, memoryChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = memoryChoice) ## Create the data data_biased &lt;- list( trials = trials, agents = agents, h = as.matrix(d1[,2:101]), other = as.matrix(d2[,2:101]) ) data_memory &lt;- list( trials = trials, agents = agents, h = as.matrix(d2[,2:101]), other = as.matrix(d1[,2:101]) ) 8.7 Log posterior likelihood While the previous sections did not present any new materials (and therefore weren’t much commented), as we create our Stan models to fit to the data, we need to (re)introduce the notion of log-likelihood, or even better, log posterior likelihood. Given certain values for our parameters (let’s say a bias of 0 and beta for memory of 1) and for our variables (let’s say the vector of memory values estimated by the agent on a trial by trial basis), the model will predict a certain distribution of outcomes, that is, a certain distribution of choices (n times right, m times left hand). Comparing this to the actual data, we can identify how likely the model is to produce it. In other words, the probability that the model will actually generate the data we observed out of all its possible outcomes. Remember that we are doing Bayesian statistics, so this probability needs to be combined with the probability of the parameter values given the priors on those parameters. This would give us a posterior likelihood of the model’s parameter values given the data. The last step is that we need to work on a log scale. Working on a log scale is very useful because it avoids low probabilities (close to 0) being rounded down to exactly 0. [MISSING A LINK TO A LENGTHIER EXPLANATION]. By log-transforming the posterior likelihood, we now have the log-posterior likelihood. Now, remember that our agent’s memory varies on a trial by trial level. In other words, for each data point, for each agent we can calculate separate values of log-posterior likelihood for each of the possible values of the parameters. That is, we can have a distribution of log-posterior likelihood for each data point. Luckily for us telling Stan to calculate and such distributions is extremely easy: we just need to add to the generated quantities block the same log probability density/mass statement that we use in the model block, but here we specify it should be saved (replacing target += with an actual variable to be filled). N.B. Some of you might be wandering: if Stan is already using the log-posterior probability in the sampling process, why do we need to tell it to calculate and save it? Fair enough point. But Stan does not save by default (to avoid clogging your computer with endless data) and we need the log posterior likelihood saved as “log_lik” in order to be able to use more automated functions later on. 8.8 Create the models: multilevel biased agents Remember to add the log_lik part in the generated quantities block! stan_biased_model &lt;- &quot; functions{ real normal_lb_rng(real mu, real sigma, real lb) { // normal distribution with a lower bound real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. n of trials and h of hands data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; } // The parameters accepted by the model. parameters { real thetaM; real&lt;lower = 0&gt; thetaSD; array[agents] real theta; } // The model to be estimated. model { target += normal_lpdf(thetaM | 0, 1); target += normal_lpdf(thetaSD | 0, .3) - normal_lccdf(0 | 0, .3); // The prior for theta is a uniform distribution between 0 and 1 target += normal_lpdf(theta | thetaM, thetaSD); for (i in 1:agents) target += bernoulli_logit_lpmf(h[,i] | theta[i]); } generated quantities{ real thetaM_prior; real&lt;lower=0&gt; thetaSD_prior; real&lt;lower=0, upper=1&gt; theta_prior; real&lt;lower=0, upper=1&gt; theta_posterior; int&lt;lower=0, upper = trials&gt; prior_preds; int&lt;lower=0, upper = trials&gt; posterior_preds; array[trials, agents] real log_lik; thetaM_prior = normal_rng(0,1); thetaSD_prior = normal_lb_rng(0,0.3,0); theta_prior = inv_logit(normal_rng(thetaM_prior, thetaSD_prior)); theta_posterior = inv_logit(normal_rng(thetaM, thetaSD)); prior_preds = binomial_rng(trials, inv_logit(thetaM_prior)); posterior_preds = binomial_rng(trials, inv_logit(thetaM)); for (i in 1:agents){ for (t in 1:trials){ log_lik[t,i] = bernoulli_logit_lpmf(h[t,i] | theta[i]); } } } &quot; write_stan_file( stan_biased_model, dir = &quot;stan/&quot;, basename = &quot;W6_MultilevelBias.stan&quot;) file &lt;- file.path(&quot;stan/W6_MultilevelBias.stan&quot;) mod_biased &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) 8.9 Multilevel memory model stan_memory_model &lt;- &quot; functions{ real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; array[trials, agents] int other; } // The parameters accepted by the model. parameters { real biasM; real betaM; vector&lt;lower = 0&gt;[2] tau; matrix[2, agents] z_IDs; cholesky_factor_corr[2] L_u; } transformed parameters { array[trials, agents] real memory; matrix[agents,2] IDs; IDs = (diag_pre_multiply(tau, L_u) * z_IDs)&#39;; for (agent in 1:agents){ for (trial in 1:trials){ if (trial == 1) { memory[trial, agent] = 0.5; } if (trial &lt; trials){ memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;} if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;} } } } } // The model to be estimated. model { target += normal_lpdf(biasM | 0, 1); target += normal_lpdf(tau[1] | 0, .3) - normal_lccdf(0 | 0, .3); target += normal_lpdf(betaM | 0, .3); target += normal_lpdf(tau[2] | 0, .3) - normal_lccdf(0 | 0, .3); target += lkj_corr_cholesky_lpdf(L_u | 2); target += std_normal_lpdf(to_vector(z_IDs)); for (agent in 1:agents){ for (trial in 1:trials){ target += bernoulli_logit_lpmf(h[trial, agent] | biasM + IDs[agent, 1] + memory[trial, agent] * (betaM + IDs[agent, 2])); } } } generated quantities{ real biasM_prior; real&lt;lower=0&gt; biasSD_prior; real betaM_prior; real&lt;lower=0&gt; betaSD_prior; real bias_prior; real beta_prior; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds2; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds2; array[trials, agents] real log_lik; biasM_prior = normal_rng(0,1); biasSD_prior = normal_lb_rng(0,0.3,0); betaM_prior = normal_rng(0,1); betaSD_prior = normal_lb_rng(0,0.3,0); bias_prior = normal_rng(biasM_prior, biasSD_prior); beta_prior = normal_rng(betaM_prior, betaSD_prior); for (i in 1:agents){ prior_preds0[i] = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior)); prior_preds1[i] = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior)); prior_preds2[i] = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior)); posterior_preds0[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 0 * (betaM + IDs[i,2]))); posterior_preds1[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 1 * (betaM + IDs[i,2]))); posterior_preds2[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 2 * (betaM + IDs[i,2]))); for (t in 1:trials){ log_lik[t,i] = bernoulli_logit_lpmf(h[t, i] | biasM + IDs[i, 1] + memory[t, i] * (betaM + IDs[i, 2])); } } } &quot; write_stan_file( stan_memory_model, dir = &quot;stan/&quot;, basename = &quot;W6_MultilevelMemory.stan&quot;) file &lt;- file.path(&quot;stan/W6_MultilevelMemory.stan&quot;) mod_memory &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) 8.10 Fitting the models to the data # # Fitting biased agent model to biased agent data # fit_biased2biased &lt;- mod_biased$sample( # data = data_biased, # seed = 123, # chains = 1, # parallel_chains = 1, # threads_per_chain = 1, # iter_warmup = 2000, # iter_sampling = 2000, # refresh = 0, # output_dir = &quot;simmodels&quot;, # max_treedepth = 20, # adapt_delta = 0.99 # ) # # fit_biased2biased$save_object(file = &quot;simmodels/W6_fit_biased2biased.RDS&quot;) # # # # Fitting biased agent model to memory agent data # fit_biased2memory &lt;- mod_biased$sample( # data = data_memory, # seed = 123, # chains = 1, # parallel_chains = 1, # threads_per_chain = 1, # iter_warmup = 2000, # iter_sampling = 2000, # refresh = 0, # output_dir = &quot;simmodels&quot;, # max_treedepth = 20, # adapt_delta = 0.99 # ) # # fit_biased2memory$save_object(file = &quot;simmodels/W6_fit_biased2memory.RDS&quot;) # # fit_memory2biased &lt;- mod_memory$sample( # data = data_biased, # seed = 123, # chains = 1, # parallel_chains = 1, # threads_per_chain = 4, # iter_warmup = 2000, # iter_sampling = 2000, # refresh = 0, # output_dir = &quot;simmodels&quot;, # max_treedepth = 20, # adapt_delta = 0.99 # ) # # fit_memory2biased$save_object(file = &quot;simmodels/W6_fit_memory2biased.RDS&quot;) # # fit_memory2memory &lt;- mod_memory$sample( # data = data_memory, # seed = 123, # chains = 1, # parallel_chains = 1, # threads_per_chain = 4, # iter_warmup = 2000, # iter_sampling = 2000, # refresh = 0, # output_dir = &quot;simmodels&quot;, # max_treedepth = 20, # adapt_delta = 0.99 # ) # # fit_memory2memory$save_object(file = &quot;simmodels/W6_fit_memory2memory.RDS&quot;) 8.11 Calculating the expected log predictive density of a model In the previous section, we fitted each model (biased and memory) to each dataset (biased and memory), and calculated and saved the log-posterior likelihood distributions for each data point. However, as we know from previous courses, calculating the goodness of fit of a model on the actual data it has been trained/fitted on is a bad idea. Models - expecially complex models - tend to overfit to the data. The multilevel implementation we have used is a bit skeptical of the data (it pools information across agents and combines it with the data from any given agent, thus de facto regularizing the estimates). Still overfitting is a serious risk. Machine learning has made common practices of validation, that is, of keeping parts of the dataset out of the training/fitting process, in order to then see how well the trained model can predict those untouched data, and get an out of sample error. 8.11.1 Rant on internal vs external validity However, we need to think carefully about what we mean by “out of sample.” There are actually two distinct types of test sets we might consider: internal and external. Internal test sets come from the same data collection effort as our training data - for example, we might randomly set aside 20% of our matching pennies games to test on. While this approach helps us detect overfitting to specific participants or trials, it cannot tell us how well our model generalizes to truly new contexts. Our test set participants were recruited from the same population, played the game under the same conditions, and were influenced by the same experimental setup as our training participants. External test sets, in contrast, come from genuinely different contexts. For our matching pennies model, this might mean testing on games played: In different cultures or age groups Under time pressure versus relaxed conditions For real money versus just for fun Against human opponents versus computer agents In laboratory versus online settings The distinction matters because cognitive models often capture not just universal mental processes, but also specific strategies that people adopt in particular contexts. A model that perfectly predicts behavior in laboratory matching pennies games might fail entirely when applied to high-stakes poker games, even though both involve similar strategic thinking. This raises deeper questions about what kind of generalization we want our models to achieve. Are we trying to build models that capture universal cognitive processes, or are we content with models that work well within specific contexts? The answer affects not just how we evaluate our models, but how we design them in the first place. In practice, truly external test sets are rare in cognitive science - they require additional data collection under different conditions, which is often impractical. This means we must be humble about our claims of generalization. When we talk about a model’s predictive accuracy, we should be clear that we’re usually measuring its ability to generalize within a specific experimental context, not its ability to capture human cognition in all its diversity. This limitation of internal test sets is one reason why cognitive scientists often complement predictive accuracy metrics with other forms of model evaluation, such as testing theoretical predictions on new tasks or examining whether model parameters correlate sensibly with individual differences. These approaches help us build confidence that our models capture meaningful cognitive processes rather than just statistical patterns specific to our experimental setup. *** When the datasets are small, as it is often the case in cognitive science, keeping a substantial portion of the data out - substantial enough to be representative of a more general population - is problematic as it risks starving the model of data: there might not be enough data for reliable estimation of the parameter values. This is where the notion of cross-validation comes in: we can split the dataset in k folds, let’s say k = 10. Then each fold is in turn kept aside as validation set, the model is fitted on the other folds, and its predictive performance tested on the validation set. Repeat this operation of each of the folds. This operation ensures that all the data can be used for training as well as for validation, and is in its own terms quite genial. However, this does not mean it is free of shortcomings. First, small validation folds might not be representative of the diversity of true out-of-sample populations - and there is a tendency to set k equal to the number of datapoints (leave-one-out cross validation). Second, there are many ways in which information could leak or contaminate across folds if the pipeline is not very careful (e.g. via data preprocessing scaling the full dataset, or hyper-parameter estimation). Third, and crucial for our case here, cross validation implies refitting the model k times, which for Bayesian models might be very cumbersome (I once had a model that took 6 weeks to run). The elpd (expected log predictive density) is an attempt at estimating the out-of-sample error without actually re-running the model. To understand elpd we need to decompose it in several steps. Log pointwise predictive density (lppd) is the sum of the logarithm of the average log posterior likelihood of each observation ( Pr(yi) ) A penalty is given according to the sum of the variance in log posterior likelihood per each observation. The more unstable (varying) the higher the penalty. This is all still fully based on the training sample. Elpd moves it one step forward by weighting the lppd according to the frequency of the observation in the dataset excluding that observation. The more frequent, the more it matters. N.B. elpd only keeps one datapoint out, meaning that dependencies within larger clusters (e.g. repeated measures by participants) confound the measure. Let’s calculate this, and then we will implement a more properly cross-validated version. fit_biased2biased &lt;- readRDS(&quot;simmodels/W6_fit_memory2memory.RDS&quot;) Loo_biased2biased &lt;- fit_biased2biased$loo(save_psis = TRUE, cores = 4) p1 &lt;- plot(Loo_biased2biased) p1 &lt;- p1 + ylim(-0.4, 0.4) fit_biased2memory &lt;- readRDS(&quot;simmodels/W6_fit_biased2memory.RDS&quot;) Loo_biased2memory &lt;- fit_biased2memory$loo(save_psis = TRUE, cores = 4) plot(Loo_biased2memory) fit_memory2biased &lt;- readRDS(&quot;simmodels/W6_fit_memory2biased.RDS&quot;) Loo_memory2biased &lt;- fit_memory2biased$loo(save_psis = TRUE, cores = 4) plot(Loo_memory2biased) fit_memory2memory &lt;- readRDS(&quot;simmodels/W6_fit_memory2memory.RDS&quot;) Loo_memory2memory &lt;- fit_memory2memory$loo(save_psis = TRUE, cores = 4) plot(Loo_memory2memory) elpd &lt;- tibble( n = seq(12000), biased_diff_elpd = Loo_biased2biased$pointwise[, &quot;elpd_loo&quot;] - Loo_memory2biased$pointwise[, &quot;elpd_loo&quot;], memory_diff_elpd = Loo_memory2memory$pointwise[, &quot;elpd_loo&quot;] - Loo_biased2memory$pointwise[, &quot;elpd_loo&quot;]) p1 &lt;- ggplot(elpd, aes(x = n, y = biased_diff_elpd)) + geom_point(alpha = .1) + #xlim(.5,1.01) + #ylim(-1.5,1.5) + geom_hline(yintercept = 0, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + theme_bw() p2 &lt;- ggplot(elpd, aes(x = n, y = memory_diff_elpd)) + geom_point(alpha = .1) + #xlim(.5,1.01) + #ylim(-1.5,1.5) + geom_hline(yintercept = 0, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + theme_bw() library(patchwork) p1 + p2 loo_compare(Loo_biased2biased, Loo_memory2biased) ## elpd_diff se_diff ## model1 0.0 0.0 ## model2 -1414.1 83.1 loo_compare(Loo_biased2memory, Loo_memory2memory) ## elpd_diff se_diff ## model2 0.0 0.0 ## model1 -95.8 91.3 loo_model_weights(list(Loo_biased2biased, Loo_memory2biased)) ## Method: stacking ## ------ ## weight ## model1 0.768 ## model2 0.232 loo_model_weights(list(Loo_biased2memory, Loo_memory2memory)) ## Method: stacking ## ------ ## weight ## model1 0.488 ## model2 0.512 8.12 Implementing Cross-Validation As we mentioned, elpd per se is only an approximation of the cross-validated performance and it only leaves one datapoint out at a time. [MISSING: VERSION W TRANSFORMED DATA] 8.12.1 Create cross-validation ready stan model for biased agents N.B. compared to before we also need to include specifics for test data stan_biased_cv_model &lt;- &quot; // // This STAN model infers a random bias from a sequences of 1s and 0s (right and left). Now multilevel // functions{ real normal_lb_rng(real mu, real sigma, real lb) { // normal distribution with a lower bound real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. n of trials and h of hands data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; int&lt;lower = 1&gt; agents_test; array[trials, agents_test] int h_test; } // The parameters accepted by the model. parameters { real thetaM; real&lt;lower = 0&gt; thetaSD; array[agents] real theta; } // The model to be estimated. model { target += normal_lpdf(thetaM | 0, 1); target += normal_lpdf(thetaSD | 0, .3) - normal_lccdf(0 | 0, .3); // The prior for theta is a uniform distribution between 0 and 1 target += normal_lpdf(theta | thetaM, thetaSD); for (i in 1:agents) target += bernoulli_logit_lpmf(h[,i] | theta[i]); } generated quantities{ real thetaM_prior; real&lt;lower=0&gt; thetaSD_prior; real&lt;lower=0, upper=1&gt; theta_prior; real&lt;lower=0, upper=1&gt; theta_posterior; int&lt;lower=0, upper = trials&gt; prior_preds; int&lt;lower=0, upper = trials&gt; posterior_preds; array[trials, agents] real log_lik; array[trials, agents_test] real log_lik_test; thetaM_prior = normal_rng(0,1); thetaSD_prior = normal_lb_rng(0,0.3,0); theta_prior = inv_logit(normal_rng(thetaM_prior, thetaSD_prior)); theta_posterior = inv_logit(normal_rng(thetaM, thetaSD)); prior_preds = binomial_rng(trials, inv_logit(thetaM_prior)); posterior_preds = binomial_rng(trials, inv_logit(thetaM)); for (i in 1:agents){ for (t in 1:trials){ log_lik[t,i] = bernoulli_logit_lpmf(h[t,i] | theta[i]); } } for (i in 1:agents_test){ for (t in 1:trials){ log_lik_test[t,i] = bernoulli_lpmf(h_test[t,i] | theta_posterior); } } } &quot; write_stan_file( stan_biased_cv_model, dir = &quot;stan/&quot;, basename = &quot;W6_MultilevelBias_cv.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W6_MultilevelBias_cv.stan&quot; file &lt;- file.path(&quot;stan/W6_MultilevelBias_cv.stan&quot;) mod_biased_cv &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) 8.12.2 Create cross-validation ready stan model for memory agents stan_memory_cv_model &lt;- &quot; // // This STAN model infers a random bias from a sequences of 1s and 0s (heads and tails) // functions{ real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; array[trials, agents] int other; int&lt;lower = 1&gt; agents_test; array[trials, agents_test] int h_test; array[trials, agents_test] int other_test; } // The parameters accepted by the model. parameters { real biasM; real betaM; vector&lt;lower = 0&gt;[2] tau; matrix[2, agents] z_IDs; cholesky_factor_corr[2] L_u; } transformed parameters { array[trials, agents] real memory; array[trials, agents_test] real memory_test; matrix[agents,2] IDs; IDs = (diag_pre_multiply(tau, L_u) * z_IDs)&#39;; for (agent in 1:agents){ for (trial in 1:trials){ if (trial == 1) { memory[trial, agent] = 0.5; } if (trial &lt; trials){ memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;} if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;} } } } for (agent in 1:agents_test){ for (trial in 1:trials){ if (trial == 1) { memory_test[trial, agent] = 0.5; } if (trial &lt; trials){ memory_test[trial + 1, agent] = memory_test[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); if (memory_test[trial + 1, agent] == 0){memory_test[trial + 1, agent] = 0.01;} if (memory_test[trial + 1, agent] == 1){memory_test[trial + 1, agent] = 0.99;} } } } } // The model to be estimated. model { target += normal_lpdf(biasM | 0, 1); target += normal_lpdf(tau[1] | 0, .3) - normal_lccdf(0 | 0, .3); target += normal_lpdf(betaM | 0, .3); target += normal_lpdf(tau[2] | 0, .3) - normal_lccdf(0 | 0, .3); target += lkj_corr_cholesky_lpdf(L_u | 2); target += std_normal_lpdf(to_vector(z_IDs)); for (agent in 1:agents){ for (trial in 1:trials){ target += bernoulli_logit_lpmf(h[trial, agent] | biasM + IDs[agent, 1] + memory[trial, agent] * (betaM + IDs[agent, 2])); } } } generated quantities{ real biasM_prior; real&lt;lower=0&gt; biasSD_prior; real betaM_prior; real&lt;lower=0&gt; betaSD_prior; real bias_prior; real beta_prior; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds2; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds2; array[trials, agents] real log_lik; array[trials, agents_test] real log_lik_test; biasM_prior = normal_rng(0,1); biasSD_prior = normal_lb_rng(0,0.3,0); betaM_prior = normal_rng(0,1); betaSD_prior = normal_lb_rng(0,0.3,0); bias_prior = normal_rng(biasM_prior, biasSD_prior); beta_prior = normal_rng(betaM_prior, betaSD_prior); for (i in 1:agents){ prior_preds0[i] = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior)); prior_preds1[i] = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior)); prior_preds2[i] = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior)); posterior_preds0[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 0 * (betaM + IDs[i,2]))); posterior_preds1[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 1 * (betaM + IDs[i,2]))); posterior_preds2[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 2 * (betaM + IDs[i,2]))); for (t in 1:trials){ log_lik[t,i] = bernoulli_logit_lpmf(h[t, i] | biasM + IDs[i, 1] + memory[t, i] * (betaM + IDs[i, 2])); } } for (i in 1:agents_test){ for (t in 1:trials){ log_lik_test[t,i] = bernoulli_logit_lpmf(h_test[t,i] | biasM + memory_test[t, i] * betaM); } } } &quot; write_stan_file( stan_memory_cv_model, dir = &quot;stan/&quot;, basename = &quot;W6_MultilevelMemory_cv.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W6_MultilevelMemory_cv.stan&quot; file &lt;- file.path(&quot;stan/W6_MultilevelMemory_cv.stan&quot;) mod_memory_cv &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) [MISSING: PARALLELIZE] d$fold &lt;- kfold_split_grouped(K = 10, x = d$agent) log_pd_biased_kfold &lt;- matrix(nrow = 1000, ncol = 12000) log_pd_memory_kfold &lt;- matrix(nrow = 1000, ncol = 12000) for (k in unique(d$fold)) { # Training set for k d_train &lt;- d %&gt;% filter(fold != k) ## Create the data d_memory1_train &lt;- d_train %&gt;% subset(select = c(agent, memoryChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = memoryChoice) d_memory2_train &lt;- d_train %&gt;% subset(select = c(agent, randomChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = randomChoice) agents_n &lt;- length(unique(d_train$agent)) d_test &lt;- d %&gt;% filter(fold == k) d_memory1_test &lt;- d_test %&gt;% subset(select = c(agent, memoryChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = memoryChoice) d_memory2_test &lt;- d_test %&gt;% subset(select = c(agent, randomChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = randomChoice) agents_test_n &lt;- length(unique(d_test$agent)) data_memory &lt;- list( trials = trials, agents = agents_n, agents_test = agents_test_n, h = as.matrix(d_memory1_train[,2:(agents_n + 1)]), other = as.matrix(d_memory2_train[,2:(agents_n + 1)]), h_test = as.matrix(d_memory1_test[,2:(agents_test_n + 1)]), other_test = as.matrix(d_memory2_test[,2:(agents_test_n + 1)])) # Train the models fit_random &lt;- mod_biased_cv$sample( data = data_memory, seed = 123, chains = 1, threads_per_chain = 4, iter_warmup = 1000, iter_sampling = 1000, refresh = 1000, max_treedepth = 20, adapt_delta = 0.99 ) fit_memory &lt;- mod_memory_cv$sample( data = data_memory, seed = 123, chains = 1, threads_per_chain = 4, iter_warmup = 1000, iter_sampling = 1000, refresh = 1000, max_treedepth = 20, adapt_delta = 0.99 ) # Extract log likelihood which represents # the pointwise predictive density. # n.b. the matrix has 1000 row, and 12000 columns. # d$fold==k yields 12000 logical values, of which 1200 TRUEs, identifying 1200 columns ## the fit blabla yields 1000 obs (samples) and 1190 variables instead of 1200 log_pd_biased_kfold[, d$fold == k] &lt;- fit_random$draws(&quot;log_lik_test&quot;, format = &quot;matrix&quot;) log_pd_memory_kfold[, d$fold == k] &lt;- fit_memory$draws(&quot;log_lik_test&quot;, format = &quot;matrix&quot;) } save(log_pd_biased_kfold, log_pd_memory_kfold, file = &quot;simmodels/W6_CV_Biased&amp;Memory.RData&quot;) 8.13 Calculating elpd and comparing load(&quot;simmodels/W6_CV_Biased&amp;Memory.RData&quot;) elpd_biased_kfold &lt;- elpd(log_pd_biased_kfold) elpd_memory_kfold &lt;- elpd(log_pd_memory_kfold) loo_compare(elpd_biased_kfold, elpd_memory_kfold) ## elpd_diff se_diff ## model1 0.0 0.0 ## model2 -437.3 23.9 #loo_model_weights(elpd_biased_kfold, elpd_memory_kfold) 8.14 Limitations of model comparison techniques it might be overfitting to the training population, that is, to the "],["mixture-models.html", "Chapter 9 Mixture models 9.1 Stan model mixing biased and noise 9.2 Fitting and assessing the model 9.3 Basic evaluation 9.4 Multilevel mixture model", " Chapter 9 Mixture models Mixture models are another powerful tool to compare the fit of different models to the data or to different portions of the data. This feature makes mixture models also a great tool to explore the possibility of multiple strategies involved in the mechanisms generating the data. Indeed, human behaviors rarely follow a single, simple strategy. People may switch between different approaches, combine multiple strategies, or show inconsistent behavior due to factors like attention and fatigue. This creates a significant challenge for cognitive modeling - how can we account for this complexity while maintaining models that are tractable and interpretable? Mixture models offer a powerful solution to this challenge. Rather than assuming behavior follows a single process, mixture models allow us to combine multiple cognitive strategies within a unified framework. For example, a participant in a decision-making task might sometimes respond based on careful deliberation and other times rely on quick heuristics or even random guessing; or different participants might be using different strategies. Mixture models let us estimate not only the parameters of these different strategies but also their relative frequencies. In this chapter, we’ll explore how to implement mixture models using Stan, beginning with a simple case that combines a biased choice strategy with random responses. We’ll then extend this to more sophisticated models that can capture multiple cognitive strategies. Through this process, we’ll learn: How to formally specify mixture models in Stan Techniques for estimating mixture proportions and component parameters Methods for validating mixture models through posterior predictive checks Approaches for comparing different mixture specifications Understanding mixture models is crucial for cognitive modeling as they bridge the gap between simplified theoretical models and the messy reality of human behavior. Let’s begin by examining how we can combine two simple decision strategies in a mixture model framework. 9.0.1 Load the dataset We load the data set from chapter NN, where we loop through possible rates and noise levels, and pick one agent to build up the model progressively. d &lt;- read_csv(&quot;simdata/W3_randomnoise.csv&quot;) dd &lt;- d %&gt;% subset(rate == 0.8 &amp; noise == 0.1) data &lt;- list( n = 120, h = dd$choice ) 9.1 Stan model mixing biased and noise We then build a Stan model with the noise parameter stan_mixture_model &lt;- &quot; // This Stan model defines a mixture of bernoulli (random bias + noise) // // The input (data) for the model. n of trials and h of heads data { int&lt;lower=1&gt; n; array[n] int h; } // The parameters accepted by the model. parameters { real bias; real noise; } // The model to be estimated. model { // The prior for theta is a uniform distribution between 0 and 1 target += normal_lpdf(bias | 0, 1); target += normal_lpdf(noise | 0, 1); // The model consists of a binomial distributions with a rate theta target += log_sum_exp(log(inv_logit(noise)) + bernoulli_logit_lpmf(h | 0), log1m(inv_logit(noise)) + bernoulli_logit_lpmf(h | bias)); } generated quantities{ real&lt;lower=0, upper=1&gt; noise_p; real&lt;lower=0, upper=1&gt; bias_p; noise_p = inv_logit(noise); bias_p = inv_logit(bias); } &quot; write_stan_file( stan_mixture_model, dir = &quot;stan/&quot;, basename = &quot;W6_MixtureSingle.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W6_MixtureSingle.stan&quot; file &lt;- file.path(&quot;stan/W6_MixtureSingle.stan&quot;) mod_mixture &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) 9.2 Fitting and assessing the model samples &lt;- mod_mixture$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 1 Iteration: 500 / 4000 [ 12%] (Warmup) ## Chain 1 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 1 Iteration: 1500 / 4000 [ 37%] (Warmup) ## Chain 1 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 1 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 1 Iteration: 2500 / 4000 [ 62%] (Sampling) ## Chain 1 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 2 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 2 Iteration: 500 / 4000 [ 12%] (Warmup) ## Chain 2 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 2 Iteration: 1500 / 4000 [ 37%] (Warmup) ## Chain 2 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 2 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 2 Iteration: 2500 / 4000 [ 62%] (Sampling) ## Chain 1 Iteration: 3500 / 4000 [ 87%] (Sampling) ## Chain 1 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 2 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 2 Iteration: 3500 / 4000 [ 87%] (Sampling) ## Chain 2 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 1 finished in 0.2 seconds. ## Chain 2 finished in 0.2 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 0.2 seconds. ## Total execution time: 0.4 seconds. save(samples, data, file = &quot;simmodels/W7_singlemixture.RData&quot;) samples$save_object(file = &quot;simmodels/W7_singlemixture.RDS&quot;) samples$save_output_files(dir = &quot;simmodels&quot;, basename = &quot;W7_singlemixture&quot;) [MISSING: EVALUATION] 9.3 Basic evaluation samples$summary() ## # A tibble: 5 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -65.7 -65.4 1.03 0.713 -67.7 -64.7 1.00 1396. 1708. ## 2 bias 1.28 1.28 0.216 0.212 0.942 1.65 1.00 1990. 1860. ## 3 noise -0.400 -0.408 0.928 0.941 -1.92 1.11 1.00 2054. 2137. ## 4 noise_p 0.416 0.399 0.193 0.218 0.128 0.753 1.00 2054. 2137. ## 5 bias_p 0.781 0.782 0.0364 0.0361 0.719 0.839 1.00 1990. 1860. 9.4 Multilevel mixture model ### Multilevel mixture stan_multilevelMixture_model &lt;- &quot; // // This Stan model defines a mixture of bernoulli (random bias + noise) // functions{ real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. n of trials and h of heads data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; } // The parameters accepted by the model. parameters { real thetaM; real noiseM; // p of noise vector&lt;lower = 0&gt;[2] tau; matrix[2, agents] z_IDs; cholesky_factor_corr[2] L_u; } transformed parameters { matrix[agents,2] IDs; IDs = (diag_pre_multiply(tau, L_u) * z_IDs)&#39;; } // The model to be estimated. model { target += normal_lpdf(thetaM | 0, 1); target += normal_lpdf(tau[1] | 0, .3) - normal_lccdf(0 | 0, .3); target += normal_lpdf(noiseM | -1, .5); target += normal_lpdf(tau[2] | 0, .3) - normal_lccdf(0 | 0, .3); target += lkj_corr_cholesky_lpdf(L_u | 2); target += std_normal_lpdf(to_vector(z_IDs)); for (i in 1:agents) target += log_sum_exp( log(inv_logit(noiseM + IDs[i,2])) + // p of noise bernoulli_logit_lpmf(h[,i] | 0), // times post likelihood of the noise model log1m(inv_logit(noiseM + IDs[i,2])) + // 1 - p of noise bernoulli_logit_lpmf(h[,i] | thetaM + IDs[i,1])); // times post likelihood of the bias model } generated quantities{ real thetaM_prior; real&lt;lower=0&gt; thetaSD_prior; real noiseM_prior; real&lt;lower=0&gt; noiseSD_prior; real&lt;lower=0, upper=1&gt; theta_prior; real&lt;lower=0, upper=1&gt; noise_prior; real&lt;lower=0, upper=1&gt; theta_posterior; real&lt;lower=0, upper=1&gt; noise_posterior; array[trials,agents] int&lt;lower=0, upper = trials&gt; prior_noise; array[trials,agents] int&lt;lower=0, upper = trials&gt; posterior_noise; array[trials,agents] int&lt;lower=0, upper = trials&gt; prior_preds; array[trials,agents] int&lt;lower=0, upper = trials&gt; posterior_preds; array[trials, agents] real log_lik; thetaM_prior = normal_rng(0,1); thetaSD_prior = normal_lb_rng(0,0.3,0); theta_prior = inv_logit(normal_rng(thetaM_prior, thetaSD_prior)); noiseM_prior = normal_rng(-1,.5); noiseSD_prior = normal_lb_rng(0,0.3,0); noise_prior = inv_logit(normal_rng(noiseM_prior, noiseSD_prior)); theta_posterior = inv_logit(normal_rng(thetaM, tau[1])); noise_posterior = inv_logit(normal_rng(noiseM, tau[2])); for (i in 1:agents){ for (t in 1:trials){ prior_noise[t,i] = bernoulli_rng(noise_prior); posterior_noise[t,i] = bernoulli_rng(inv_logit(noiseM + IDs[i,2])); if(prior_noise[t,i]==1){ prior_preds[t,i] = bernoulli_rng(theta_prior); } else{ prior_preds[t,i] = bernoulli_rng(0.5); } if(posterior_noise[t,i]==1){ posterior_preds[t,i] = bernoulli_rng(inv_logit(thetaM + IDs[i,1])); } else{ posterior_preds[t,i] = bernoulli_rng(0.5); } log_lik[t,i] = log_sum_exp( log(inv_logit(noiseM + IDs[i,2])) + // p of noise bernoulli_logit_lpmf(h[t,i] | 0), // times post likelihood of the noise model log1m(inv_logit(noiseM + IDs[i,2])) + // 1 - p of noise bernoulli_logit_lpmf(h[t,i] | thetaM + IDs[i,1])); // times post likelihood of the bias model } } } &quot; write_stan_file( stan_multilevelMixture_model, dir = &quot;stan/&quot;, basename = &quot;W6_MixtureMultilevel.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W6_MixtureMultilevel.stan&quot; file &lt;- file.path(&quot;stan/W6_MixtureMultilevel.stan&quot;) mod_mixture &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # samples &lt;- mod_mixture$sample( # data = data_biased, # seed = 123, # chains = 2, # parallel_chains = 2, # threads_per_chain = 2, # iter_warmup = 2000, # iter_sampling = 2000, # refresh = 500, # max_treedepth = 20, # adapt_delta = 0.99, # ) # # save(samples, data, # file = &quot;simmodels/W7_multimixture.RData&quot;) # samples$save_object(file = &quot;simmodels/W7_multimixture.RDS&quot;) # samples$save_output_files(dir = &quot;simmodels&quot;, basename = &quot;W7_multimixture&quot;) [MISSING: EVALUATION] samples &lt;- readRDS(&quot;simmodels/W7_multimixture.RDS&quot;) samples$summary() ## # A tibble: 60,417 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -6282. -6281. 13.2 13.1 -6305. -6260. 1.00 737. 1528. ## 2 thetaM 1.41 1.41 0.0650 0.0637 1.31 1.52 1.00 1497. 2051. ## 3 noiseM -2.34 -2.34 0.315 0.308 -2.86 -1.84 1.00 3639. 2055. ## 4 tau[1] 0.568 0.565 0.0530 0.0522 0.484 0.659 1.00 1077. 2007. ## 5 tau[2] 0.204 0.173 0.151 0.150 0.0193 0.497 1.00 3862. 2391. ## 6 z_IDs[1,1] 0.143 0.138 0.380 0.375 -0.473 0.786 1.00 6420. 2779. ## 7 z_IDs[2,1] -0.0209 -0.0159 1.01 1.03 -1.69 1.64 1.00 10804. 2755. ## 8 z_IDs[1,2] 0.228 0.225 0.407 0.397 -0.442 0.896 1.00 7772. 2630. ## 9 z_IDs[2,2] -0.0185 -0.0375 0.982 0.986 -1.65 1.58 1.00 9849. 2787. ## 10 z_IDs[1,3] 1.93 1.91 0.527 0.521 1.11 2.83 1.00 7475. 2623. ## # ℹ 60,407 more rows samples$loo() ## ## Computed from 4000 by 12000 log-likelihood matrix. ## ## Estimate SE ## elpd_loo -6150.3 53.4 ## p_loo 131.8 2.9 ## looic 12300.5 106.8 ## ------ ## MCSE of elpd_loo is NA. ## MCSE and ESS estimates assume MCMC draws (r_eff in [0.2, 3.0]). ## ## Pareto k diagnostic values: ## Count Pct. Min. ESS ## (-Inf, 0.7] (good) 11909 99.2% 659 ## (0.7, 1] (bad) 91 0.8% &lt;NA&gt; ## (1, Inf) (very bad) 0 0.0% &lt;NA&gt; ## See help(&#39;pareto-k-diagnostic&#39;) for details. [MISSING: PARAMETER RECOVERY] [MISSING: BIASED VS. MEMORY?] Mixture models represent a crucial step forward in our cognitive modeling toolkit, allowing us to capture the complexity and variability inherent in human behavior. Through this chapter, we’ve seen how combining multiple cognitive strategies within a single model can provide richer and more realistic accounts of decision-making processes. Several key insights emerge from our exploration of mixture models: First, mixture models allow us to move beyond the false choice between oversimplified single-strategy models and intractably complex specifications. By combining a small number of interpretable components, we can capture substantial behavioral complexity while maintaining mathematical and computational tractability. Second, the Bayesian implementation of mixture models in Stan provides powerful tools for inference. We can estimate not only the parameters of different cognitive strategies but also their relative contributions to behavior. This allows us to quantify the importance of different processes and how they might vary across individuals or conditions. Third, mixture models require careful attention to identifiability and validation. Through parameter recovery studies and posterior predictive checks, we’ve seen how to verify that our mixture specifications can reliably recover true parameter values and generate realistic behavioral patterns. As we move forward in the course, mixture models will continue to play an important role in our modeling toolkit. They provide a bridge between simple theoretical models and complex empirical data, allowing us to build increasingly sophisticated accounts of cognitive processes while maintaining scientific rigor and interpretability. The next chapters will build on these foundations as we explore hierarchical models that can capture individual differences, and more complex cognitive architectures that combine multiple processing stages. The principles we’ve learned about specifying, fitting, and validating mixture models will serve as essential tools in these more advanced applications. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
