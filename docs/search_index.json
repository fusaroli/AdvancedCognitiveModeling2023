[["index.html", "11 - Reinforcement Learning Chapter 1 Advanced Cognitive Modeling 1.1 The goal of the course 1.2 List of lectures and practical exercises 1.3 Preparation before the course", " 11 - Reinforcement Learning Riccardo Fusaroli 2024-02-14 Chapter 1 Advanced Cognitive Modeling These are the teaching notes for Advanced Cognitive Modeling - taught in 2023 at the M.Sc. in Cognitive Science at Aarhus University. The syllabus is available at https://docs.google.com/document/d/1D8NTG0o4nD86AUdyyTp1hZIybg4ZEt9kdJ6mvfa_IQo/edit?usp=sharing The videos are available at https://youtube.com/playlist?list=PL_f3yDs5oZx6bfywYiGitMJPdJv6gZfXu 1.1 The goal of the course Advanced cognitive modeling is a course on how to think through, formalize and validate models of cognitive processes. In other words, we will be thinking about how people learn, and make decisions both in the lab and in the real world, and to robustly assess our hypothesized mechanisms. The course has 3 interrelated aims: to guide you through how models of cognitive processes are thought through and built (more than a toolbox of existing scripts); to provide (or reinforce) a good Bayesian workflow (simulation, prior assessment, parameter/model recovery, model fit assessment) to build robust and reliable models; to develop your probabilistic modeling skills (we will be dealing with brms, and also directly with stan). At the end of the course, you should be able to start thinking about how to use your own theoretical knowledge in cognitive science to build your own models, as well as to robustly evaluate existing models and their applicability. The course will be very hands-on. The main goal of the course is not just for you to understand how cognitive modeling works, but to build and use your own models. The lectures will include conceptual discussions of cognitive modeling and the specific models we will be dealing with, but also introduction to the coding exercises in the practical exercises (e.g. how to code in Stan). During the practical exercises, we will collect some data or explore existing datasets, design models together, and code them up: simulating how a person using those processes would perform, inferring parameters from simulated and real data, assessing model quality. We will take the time to do this together, and there will be time for lots of questions. The schedule for the course will therefore be somewhat flexible, and adaptive to your collective learning speed. See the planned schedule below. 1.2 List of lectures and practical exercises 1.3 Preparation before the course Before starting the course, you need to get your computers and brains in ship-shape so we can focus on modeling! In terms of computers, you need to make sure you have the following software installed and working: * up-to-date R (version 4 or above) and Rstudio (version 1.3 or above) installed and working. See here for a more detailed instruction on how to install R and Rstudio: https://happygitwithr.com/install-r-rstudio.html * the “brms” package installed: https://github.com/paul-buerkner/brms N.B. it’s not always as simple as doing an install.packages(“brms”), so do follow the linked guide! * the “cmdstanr” package: https://mc-stan.org/cmdstanr/articles/cmdstanr.html N.B. it’s not always as simple as doing an install.packages(“cmdstanr”), so do follow the linked guide! N.B. technically you can run all our exercises without cmdstanr if it turns to be too demanding, but your computer will be much slower. Without these packages working, you will not be able to tackle the practical exercises, so install them before you move to the next section and make sure there are no errors or worrying warnings. Once your computer is ready, you should also get your brain ready. This workshop focuses on how to do Bayesian data analysis and does not go into the details of Bayes’ theorem. If you are not familiar with the theorem or need a quick refresh, we strongly recommend you give this 15 min video a watch before the workshop. This should make talk of priors and posteriors much easier to parse. https://www.youtube.com/watch?v=HZGCoVF3YvM This workshop does not cover basic R coding and basic statistical modeling, they are taken for granted. I know not everybody comes from the Bsc in Cognitive Science, so if you feel you need some practice: * An amazing intro to R and the tidyverse (free online): https://r4ds.had.co.nz/ (I know some of you have also been referred to swirl and datacamp, I don’t know those resources, so have a look at the one above to check you know enough) * A intro to Bayesian statistics in brms (summarizing key points from methods 4 in the bachelor): https://4ccoxau.github.io/PriorsWorkshop/ videos + exercises. "],["building-verbal-models-of-the-matching-pennies-game.html", "Chapter 2 Building verbal models of the matching pennies game 2.1 Trying out the game and collecting your own data 2.2 Start Theorizing 2.3 The distinction between participant and researcher perspectives 2.4 Strategies 2.5 Cognitive constraints 2.6 Continuity between models 2.7 Mixture of strategies 2.8 Differences from more traditional (general linear model-based) approaches", " Chapter 2 Building verbal models of the matching pennies game 2.1 Trying out the game and collecting your own data Today’s practical exercise is structured as follows: In order to do computational models we need a phenomenon to study (and ideally some data), you will therefore undergo an experiment, which will provide you with two specific cognitive domains to describe (one for now, one for later), and data from yourselves. You will now have to play the Matching Pennies Game against each other. In the Matching Pennies Game you and your opponent have to choose either “left” or “right” to indicate the hand in which the penny is hidded. If you are the matcher, you win by choosing the same as your opponent. If you are the capitalist with the penny, you win by choosing the opposite as your opponent. You should run 30 rounds with one of you being the capitalist and the other the matcher and then exchange roles for 30 more rounds. When you are the matcher, keep track of your score: every time you guess right you get +1, every time you don’t you get -1. The capitalist gets exactly the opposite, so if the matcher ends with a negative score, the capitalist has won and vice versa. Given you play many trials the game can take a while. If you want to take a break or do it in two sessions, feel free! Try to pay attention and aim at winning. As you play also try to figure out what kind of strategies might be at play for you and for the opponents. How are you deciding whether to choose left or right? Feel free to take notes. 2.2 Start Theorizing The goal of today’s assignment is to build models of the strategies and cognitive processes underlying behavior in the matching pennies game. In other words, to build hypotheses as to how the data is generated. The goal is to: 1) get you more aware of the issue of theory building (and assessment); 2) identify a small set of verbal models that we can then formalize in mathematical cognitive models and algorithms for simulations and model fitting. First, let’s take a little free discussion: Did you enjoy the game? What was the game about? What do you think your opponent was doing? Below you can observe how a previous year of CogSci did against bots (computational agents) playing according to different strategies. Look at the plots below, where the x axes indicate trial, the y axes how many points the CogSci’ers scored (0 being chance, negative means being completely owned by the bots, positive owning the bot) and the different colors indicate different strategies employed by the bots. Strategy “-2” was a Win-Stay-Lose-Shift bot: when it got a +1, it repeated its previous move (e.g. right if it had just played right), otherwise it would perform the opposite move (e.g. left if it had just played right). Strategy “-1” was a biased Nash both, playing “right” 80% of the time. Strategy “0” indicates a reinforcement learning bot; “1” a bot assuming you were playing according to a reinforcement learning strategy and trying to infer your learning and temperature parameters; “2” a bot assuming you were following strategy “1” and trying to accordingly infer your parameters. library(tidyverse) d &lt;- read_csv(&quot;data/MP_MSc_CogSci22.csv&quot;) %&gt;% mutate(BotStrategy = as.factor(BotStrategy)) ## Rows: 4400 Columns: 11 ## ── Column specification ──────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): ID, BotParameters ## dbl (9): BotStrategyN, Role, player.tom_role, Choice, BotChoice, Payoff, BotPayoff, ... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. d$Role &lt;- ifelse(d$Role == 0, &quot;Matcher&quot;, &quot;Mismatcher&quot;) ggplot(d, aes(Trial, Payoff, group = BotStrategy, color = BotStrategy)) + geom_smooth(se = F) + theme_classic() + facet_wrap(.~Role) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; That doesn’t look too good, ah? What about individual variability? In the plot below we indicate the score of each of the former students, against the different bots. d1 &lt;- d %&gt;% group_by(ID, BotStrategy) %&gt;% dplyr::summarize(Score = sum(Payoff)) ## `summarise()` has grouped output by &#39;ID&#39;. You can override using the `.groups` ## argument. ggplot(d1, aes(BotStrategy, Score, label = ID)) + geom_point(aes(color = ID)) + geom_boxplot(alpha = 0.3) + theme_classic() ## Warning: The following aesthetics were dropped during statistical transformation: label ## ℹ This can happen when ggplot fails to infer the correct grouping structure in the ## data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical variable into ## a factor? Now, let’s take a bit of group discussion. Get together in groups, and discuss which strategies and cognitive processes might underlie your and the agents’ behaviors in the game. One thing to keep in mind is what a model is: a simplification that can help us make sense of the world. In other words, any behavior is incredibly complex and involves many complex cognitive mechanisms. So start simple, and if you think it’s too simple, progressively add simple components. Once your study group has discussed a few (during the PE), add them here: https://docs.google.com/document/d/13OZL3CF9qM0744Y81BBKtvlu9k5E0F_tuuuU9DILRMU/edit?usp=sharing (shorturl.at/nrAKV) 2.3 The distinction between participant and researcher perspectives As participants we might not be aware of the strategy we use, or we might believe something erroneous. The exercise here is to act as researchers: what are the principles underlying the participants’ behaviors, no matter what the participants know or believe? Note that talking to participants and being participants helps developing ideas, but it’s not the end point of the process. Also note that as cognitive scientists we can rely on what we have learned about cognitive processes (e.g. memory). Another important component of the distinction is that participants leave in a rich world: they rely on facial expressions and bodily posture, the switch strategies, etc. On the other hand, the researcher is trying to identify one or few at most “simple” strategies. Rich bodily interactions and mixtures or sequences of multiple strategies are not a good place to start modeling. These aspects are a poor starting point for building your first model, and are often pretty difficult to fit to empirical data. Nevertheless, they are important intuitions that the researcher should (eventually?) accommodate. 2.4 Strategies 2.4.1 Random strategies Players might simply be randomly choosing “head” or “tail” independently on the opponent’s choices and of how well they are doing. Choices could be fully at random (50% “head”, 50% “tail”) or biased (e.g. 60% “head”, 40% tail). 2.4.2 Immediate reaction Another simple strategy is simply to follow the previous choice: if it was successful keep it, if not change it. This strategy is also called Win-Stay-Lose-Shift (WSLS). Alternatively, one could do the opposite: Win-Shift-Lose-Stay. 2.4.3 Keep track of the bias (perfect memory) A player could keep track of biases in the opponent: count the proportion of “head” on the total trials so far and choose whichever choice has been made most often by the opponent. 2.4.4 Keep track of the bias (imperfect memory) A player could not be able to keep in mind all previous trials, or decide to forget old trials, in case the biase shifts over time. So we could use only the last n trials, or do a weighted mean with weigths proportional to temporal closeness (the more recent, the higher the weight). 2.4.5 Reinforcement learning Since there is a lot of leeway in how much memory we should keep of previous trials, we could also use a model that explicitly estimates how much players are learning on a trial by trial basis (high learning, low memory; low learning, high memory). This is the model of reinforcement learning, which we will deal with in future chapters. Shortly described, reinforcement learning assumes that each choice has a possible reward (probability of winning) and at every trial given the feedback received updates the expected value of the choice taken. The update depends on the prediction error (difference between expected and actual reward) and the learning rate. 2.4.6 k-ToM Reinforcement learning is a neat model, but can be problematic when playing against other agents: what the game is really about is not assessing the probability of the opponent choosing “head” generalizing from their past choices, but predicting what they will do. This requires making an explicit model of how the opponent chooses. k-ToM models will be dealt with in future chapters, but can be here anticipated as models assuming that the opponent follows a random bias (0-ToM), or models us as following a random bias (1-ToM), or models us modeling them as following a random bias (2-ToM), etc. 2.4.7 Other possible strategies Many additional strategies can be generated by combining former strategies. Generating random output is hard, so if we want to confuse the opponent, we could act first choosing tail 8 times, and then switching to a WSLS strategy for 4 trials, and then choosing head 4 times. Or implementing any of the previous strategies and doing the opposite “to mess with the opponent”. 2.5 Cognitive constraints As we discuss strategies, we can also identify several cognitive constraints that we know from former studies: in particular, memory, perseveration, and errors. 2.5.1 Memory Humans have limited memory and a tendency to forget that is roughly exponential. Models assuming perfect memory for longer stretches of trials are unrealistic. We could for instance use the exponential decay of memory to create weights following the same curve in the “keeping track of bias” models. Roughly, this is what reinforcement learning is doing via the learning rate parameter. 2.5.2 Perseveration Winning choice is not changed. People tend to have a tendency to perseverate with “good” choices independently of which other strategy they might be using. 2.5.3 Errors Humans make mistakes, get distracted, push the wrong button, forget to check whether they won or lost before. So a realistic model of what happens in these games should contain a certain chance of making a mistake. E.g. a 10% chance that any choice will be perfectly random instead of following the strategy. Such random deviations from the strategy might also be conceptualized as explorations: keeping the door open to the strategy not being optimal and therefore testing other choices. For instance, one could have an imperfect WSLS where the probability of staying if winning (or shifting if losing) is only 80% and not 100%. Further, these deviations could be asymmetric, with the probability of staying if winning is 80% and of shifting if losing is 100%; for instance if negative and positive feedback are perceived asymmetrically. 2.6 Continuity between models Many of these models are simply extreme cases of others. For instance, WSLS is a reinforcement learning model with an extreme learning rate (reward replaces the formerly expected value without any moderation), which is also a memory model with a memory of 1 previous trial. k-ToM builds on reinforcement learning: at level 1 assumes the other is a RL agent. 2.7 Mixture of strategies We discussed that there are techniques to consider the data generated by a mixture of models: estimating the probability that they are generated by model 1 or 2 or n. This probability can then be conditioned, according to our research question, to group (are people w schizophrenia more likely to employ model 1) or ID (are different participants using different models), or condition, or… We discussed that we often need lots of data to disambiguate between models, so conditioning e.g. on trial would in practice almost (?) never work. 2.8 Differences from more traditional (general linear model-based) approaches In a more traditional approach we would carefully set up the experiment to discriminate between hypotheses. For instance, if the hypothesis is that humans deploy ToM only when playing against intentional agents, we can set agents with increasing levels of k-ToM against humans, set up two framings (this is a human playing hide and seek, this is a slot machine), and assess whether humans perform differently. E.g. whether they perform better when thinking it’s a human. We analyze performance e.g. as binary outcome on a trial by trial base and condition its rate on framing and complexity. If framing makes a difference in the expected direction, we are good. If we do this properly, thanks to the clever experimental designs we set up, we can discriminate between hypotheses. And that is good. However, cognitive modeling opens additional opportunities. For instance, we can actually reconstruct which level of recursion the participants are enacting and if it changes over time. This might be very useful in the experimental setup, and crucial in more observational setups. Cognitive modeling also allows us to discriminate between different cognitive components more difficult to assess by looking at performance only. For instance, why are participants performing less optimally when facing a supposedly non-intentional agent? Is their learning rate different? Is their estimate of volatility different? In other setups, e.g. a gambling context, we might observe that some participants (e.g. parkinson’s patients) are gambling away much. Is this due to changes in their risk-seeking propensities, loss aversion, or changes in the ability to actually learn the reward structure? Experimental setups help, but cognitive modeling can provide more nuanced and direct evidence. "],["from-verbal-to-formal-models.html", "Chapter 3 From verbal to formal models 3.1 Defining general conditions 3.2 Implementing a random agent 3.3 Implementing a Win-Stay-Lose-Shift agent 3.4 Now we scale it up", " Chapter 3 From verbal to formal models We will now discuss how to go from verbal to formal models. We will not just write a formula, we will implement these models as algorithms in R. By implementing the models of algorithms, we are forced to make them very explicit in their assumptions; we become able to simulate the models in a variety of different situations and therefore better understand their implications So, the steps for today’s exercise are: choose two of the models and formalize them, that is, produce an algorithm that enacts the strategy, so we can simulate them. implement the algorithms as functions: getting an input and producing an output, so we can more easily implement them across various contexts (e.g. varying amount of trials, input, etc). See R4DataScience, if you need a refresher: https://r4ds.had.co.nz/functions.html implement a Random Bias agent (choosing “head” 70% of the times) and get your agents to play against it for 120 trials (and save the data) implement a Win-Stay-Lose-Shift agent (keeping the same choice if it won, changing it if it lost) and do the same. Now scale up the simulation: have 100 agents for each of your strategy playing against both Random Bias and Win-Stay-Lose-Shift and save their data. Figure out a good way to visualize the data to assess which strategy performs better, whether that changes over time and generally explore what the agents are doing. 3.1 Defining general conditions pacman::p_load(tidyverse, patchwork) trials &lt;- 120 agents &lt;- 100 3.2 Implementing a random agent Remember a random agent is an agent that picks at random between “right” and “left” independently on what the opponent is doing. A random agent might be perfectly random (50% chance of choosing “right”, same for “left”) or biased. The variable “rate” determines the rate of choosing “right”. rate &lt;- 0.5 RandomAgent &lt;- rbinom(trials, 1, rate) # we simply sample randomly from a binomial # Now let&#39;s plot how it&#39;s choosing d1 &lt;- tibble(trial = seq(trials), choice = RandomAgent) p1 &lt;- ggplot(d1, aes(trial, choice)) + geom_line() + theme_classic() p1 # What if we were to compare it to an agent being biased? rate &lt;- 0.8 RandomAgent &lt;- rbinom(trials, 1, rate) # we simply sample randomly from a binomial # Now let&#39;s plot how it&#39;s choosing d2 &lt;- tibble(trial = seq(trials), choice = RandomAgent) p2 &lt;- ggplot(d2, aes(trial, choice)) + geom_line() + theme_classic() p1 + p2 # Tricky to see, let&#39;s try writing the cumulative rate: d1$cumulativerate &lt;- cumsum(d1$choice) / seq_along(d1$choice) d2$cumulativerate &lt;- cumsum(d2$choice) / seq_along(d2$choice) p3 &lt;- ggplot(d1, aes(trial, cumulativerate)) + geom_line() + ylim(0,1) + theme_classic() p4 &lt;- ggplot(d2, aes(trial, cumulativerate)) + geom_line() + ylim(0,1) + theme_classic() p3 + p4 ## Now in the same plot d1$rate &lt;- 0.5 d2$rate &lt;- 0.8 d &lt;- rbind(d1,d2) p5 &lt;- ggplot(d, aes(trial, cumulativerate, color = rate, group = rate)) + geom_line() + ylim(0,1) + theme_classic() p5 # now as a function RandomAgent_f &lt;- function(input, rate){ n &lt;- length(input) choice &lt;- rbinom(n, 1, rate) return(choice) } input &lt;- rep(1,trials) # it doesn&#39;t matter, it&#39;s not taken into account choice &lt;- RandomAgent_f(input, rate) d3 &lt;- tibble(trial = seq(trials), choice) ggplot(d3, aes(trial, choice)) + geom_line() + theme_classic() ## What if there&#39;s noise? RandomAgentNoise_f &lt;- function(input, rate, noise){ n &lt;- length(input) choice &lt;- rbinom(n, 1, rate) if (rbinom(1, 1, noise) == 1) {choice = rbinom(1,1,0.5)} return(choice) } 3.3 Implementing a Win-Stay-Lose-Shift agent # as a function WSLSAgent_f &lt;- function(prevChoice, Feedback){ if (Feedback == 1) { choice = prevChoice } else if (Feedback == 0) { choice = 1 - prevChoice } return(choice) } WSLSAgentNoise_f &lt;- function(prevChoice, Feedback, noise){ if (Feedback == 1) { choice = prevChoice } else if (Feedback == 0) { choice = 1 - prevChoice } if (rbinom(1, 1, noise) == 1) {choice &lt;- rbinom(1, 1, .5)} return(choice) } WSLSAgent &lt;- WSLSAgent_f(1, 0) # Against a random agent Self &lt;- rep(NA, trials) Other &lt;- rep(NA, trials) Self[1] &lt;- RandomAgent_f(1, 0.5) Other &lt;- RandomAgent_f(seq(trials), rate) for (i in 2:trials) { if (Self[i - 1] == Other[i - 1]) { Feedback = 1 } else {Feedback = 0} Self[i] &lt;- WSLSAgent_f(Self[i - 1], Feedback) } sum(Self == Other) ## [1] 71 df &lt;- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other)) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, Self)) + geom_line(color = &quot;blue&quot;, aes(trial, Other)) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, Feedback)) + geom_line(color = &quot;blue&quot;, aes(trial, 1 - Feedback)) df$cumulativerateSelf &lt;- cumsum(df$Feedback) / seq_along(df$Feedback) df$cumulativerateOther &lt;- cumsum(1 - df$Feedback) / seq_along(df$Feedback) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, cumulativerateSelf)) + geom_line(color = &quot;blue&quot;, aes(trial, cumulativerateOther)) # Against a Win-Stay-Lose Shift Self &lt;- rep(NA, trials) Other &lt;- rep(NA, trials) Self[1] &lt;- RandomAgent_f(1, 0.5) Other[1] &lt;- RandomAgent_f(1, 0.5) for (i in 2:trials) { if (Self[i - 1] == Other[i - 1]) { Feedback = 1 } else {Feedback = 0} Self[i] &lt;- WSLSAgent_f(Self[i - 1], Feedback) Other[i] &lt;- WSLSAgent_f(Other[i - 1], 1 - Feedback) } sum(Self == Other) ## [1] 60 df &lt;- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other)) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, Self)) + geom_line(color = &quot;blue&quot;, aes(trial, Other)) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, Feedback)) + geom_line(color = &quot;blue&quot;, aes(trial, 1 - Feedback)) df$cumulativerateSelf &lt;- cumsum(df$Feedback) / seq_along(df$Feedback) df$cumulativerateOther &lt;- cumsum(1 - df$Feedback) / seq_along(df$Feedback) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, cumulativerateSelf)) + geom_line(color = &quot;blue&quot;, aes(trial, cumulativerateOther)) 3.4 Now we scale it up trials = 120 agents = 100 # WSLS vs agents with varying rates for (rate in seq(from = 0.5, to = 1, by = 0.05)) { for (agent in seq(agents)) { Self &lt;- rep(NA, trials) Other &lt;- rep(NA, trials) Self[1] &lt;- RandomAgent_f(1, 0.5) Other &lt;- RandomAgent_f(seq(trials), rate) for (i in 2:trials) { if (Self[i - 1] == Other[i - 1]) { Feedback = 1 } else {Feedback = 0} Self[i] &lt;- WSLSAgent_f(Self[i - 1], Feedback) } temp &lt;- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other), agent, rate) if (agent == 1 &amp; rate == 0.5) {df &lt;- temp} else {df &lt;- bind_rows(df, temp)} } } ## WSLS with another WSLS for (agent in seq(agents)) { Self &lt;- rep(NA, trials) Other &lt;- rep(NA, trials) Self[1] &lt;- RandomAgent_f(1, 0.5) Other[1] &lt;- RandomAgent_f(1, 0.5) for (i in 2:trials) { if (Self[i - 1] == Other[i - 1]) { Feedback = 1 } else {Feedback = 0} Self[i] &lt;- WSLSAgent_f(Self[i - 1], Feedback) Other[i] &lt;- WSLSAgent_f(Other[i - 1], 1 - Feedback) } temp &lt;- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other), agent, rate) if (agent == 1 ) {df1 &lt;- temp} else {df1 &lt;- bind_rows(df1, temp)} } 3.4.1 And we visualize it ggplot(df, aes(trial, Feedback, group = rate, color = rate)) + geom_smooth(se = F) + theme_classic() ## `geom_smooth()` using method = &#39;gam&#39; and formula = &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; We can see that the bigger the bias in the random agent, the bigger the performance in the WSLS (the higher the chances the random agent picks the same hand more than once in a row). Now it’s your turn to follow a similar process for your 2 chosen strategies. "],["practical-exercise-3---getting-into-stan.html", "Chapter 4 Practical exercise 3 - Getting into Stan 4.1 Overview 4.2 Simulating data 4.3 Building our basic model in Stan 4.4 Parameter recovery 4.5 The memory model: conditioning theta 4.6 Memory agent with internal parameter", " Chapter 4 Practical exercise 3 - Getting into Stan 4.1 Overview The goal of the practical exercise is to build on the simulated data from Practical Exercise 2 to construct our Stan models of the generative processes of the data. Here we know the truth: we simulated the data ourselves, so we can assess how accurate the model is in reconstructing, e.g. the bias of the agents. 4.2 Simulating data Here we build a new simulation of random agents with bias and noise. The code and visualization is really nothing different from last week’s exercise. pacman::p_load(tidyverse, here, posterior, cmdstanr, brms, tidybayes) trials &lt;- 120 RandomAgentNoise_f &lt;- function(rate, noise) { choice &lt;- rbinom(1, 1, rate) # generating noiseless choices if (rbinom(1, 1, noise) == 1) { choice = rbinom(1, 1, 0.5) # introducing noise } return(choice) } d &lt;- NULL for (noise in seq(0, 0.5, 0.1)) { # looping through noise levels for (rate in seq(0, 1, 0.1)) { # looping through rate levels randomChoice &lt;- rep(NA, trials) for (t in seq(trials)) { # looping through trials (to make it homologous to more reactive models) randomChoice[t] &lt;- RandomAgentNoise_f(rate, noise) } temp &lt;- tibble(trial = seq(trials), choice = randomChoice, rate, noise) temp$cumulativerate &lt;- cumsum(temp$choice) / seq_along(temp$choice) if (exists(&quot;d&quot;)) { d &lt;- rbind(d, temp) } else{ d &lt;- temp } } } write_csv(d, &quot;simdata/W3_randomnoise.csv&quot;) # Now we visualize it p1 &lt;- ggplot(d, aes(trial, cumulativerate, group = rate, color = rate)) + geom_line() + geom_hline(yintercept = 0.5, linetype = &quot;dashed&quot;) + ylim(0,1) + facet_wrap(.~noise) + theme_classic() p1 4.3 Building our basic model in Stan N.B. Refer to the video and slides for the step by step build-up of the Stan code. Now we subset to a simple case, no noise and rate of 0.8, to focus on the Stan model. We make it into the right format for Stan, build the Stan model, and fit it. 4.3.1 Data Here we define the data and format it for Stan. Stan likes data as a list. Why a list? Well, dataframes (now tibbles) are amazing. But they have a big drawback: they require each variable to have the same length. Lists do not have that limitation, they are more flexible. So, lists. We’ll have to learn how to live with them. d1 &lt;- d %&gt;% subset(noise == 0 &amp; rate == 0.8) ## Create the data. N.B. note the two variables have different lengths: 1 for n, n for h. data &lt;- list( n = 120, # n of trials h = d1$choice # sequence of choices (h stands for hand) ) 4.3.2 Model We write the stan code within the R code (so I can show it to you more easily), then we save it as a stan file, which can be loaded at a later stage in order to compile it. [Missing: more info on compiling etc.] Remember that the minimal Stan model requires 3 chunks, one specifying the data it will need as input; one specifying the parameters to be estimated; one specifying the model within which the parameters appear, and the priors for those parameters. stan_model &lt;- &quot; // This model infers a random bias from a sequences of 1s and 0s (right and left hand choices) // The input (data) for the model. n of trials and the sequence of choices (right as 1, left as 0) data { int&lt;lower=1&gt; n; // n of trials array[n] int h; // sequence of choices (right as 1, left as 0) as long as n } // The parameters that the model needs to estimate (theta) parameters { real&lt;lower=0, upper=1&gt; theta; // rate or theta is a probability and therefore bound between 0 and 1 } // The model to be estimated (a bernoulli, parameter theta, prior on the theta) model { // The prior for theta is a beta distribution alpha of 1, beta of 1, equivalent to a uniform between 0 and 1 target += beta_lpdf(theta | 1, 1); // N.B. you could also define the parameters of the priors as variables to be found in the data // target += beta_lpdf(theta | beta_alpha, beta_beta); BUT remember to add beta_alpha and beta_beta to the data list // The model consists of a bernoulli distribution (binomial w 1 trial only) with a rate theta target += bernoulli_lpmf(h | theta); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W3_SimpleBernoulli.stan&quot;) 4.3.3 Compiling and fitting the model ## Specify where the model is file &lt;- file.path(&quot;stan/W3_SimpleBernoulli.stan&quot;) # Compile the model mod &lt;- cmdstan_model(file, # this specifies we can parallelize the gradient estimations on multiple cores cpp_options = list(stan_threads = TRUE), # this is a trick to make it faster stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, # the data :-) seed = 123, # a seed, so I always get the same results chains = 2, # how many chains should I fit (to check whether they give the same results) parallel_chains = 2, # how many of the chains can be run in parallel? threads_per_chain = 2, # distribute gradient estimations within chain across multiple cores iter_warmup = 1000, # warmup iterations through which hyperparameters (steps and step length) are adjusted iter_sampling = 2000, # total number of iterations refresh = 0, # how often to show that iterations have been run output_dir = &quot;simmodels&quot;, # saves the samples as csv so it can be later loaded max_treedepth = 20, # how many steps in the future to check to avoid u-turns adapt_delta = 0.99, # how high a learning rate to adjust hyperparameters during warmup ) # Same the fitted model samples$save_object(&quot;simmodels/W3_SimpleBernoulli.rds&quot;) 4.3.4 Summarizing the model Now the model is ready to be assessed. First we simply generate a summary of the estimates to have a first idea. samples &lt;- readRDS(&quot;simmodels/W3_SimpleBernoulli.rds&quot;) samples$summary() # summarize the model ## # A tibble: 2 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -70.7 -70.4 0.711 0.320 -72.2 -70.2 1.00 1066. 1106. ## 2 theta 0.739 0.740 0.0396 0.0400 0.672 0.802 1.00 938. 1077. 4.3.5 Assessing model quality Then we need to look more in the details at the quality of the estimation: * the markov chains * how the prior and the posterior estimates relate to each other (whether the prior is constraining the posterior estimate) # Extract posterior samples and include sampling of the prior: draws_df &lt;- as_draws_df(samples$draws()) # Checking the model&#39;s chains ggplot(draws_df, aes(.iteration, theta, group = .chain, color = .chain)) + geom_line() + theme_classic() # add a prior for theta (ugly, but we&#39;ll do better soon) draws_df &lt;- draws_df %&gt;% mutate( theta_prior = rbeta(nrow(draws_df), 1, 1) ) # Now let&#39;s plot the density for theta (prior and posterior) ggplot(draws_df) + geom_density(aes(theta), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(theta_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0.8, linetype = &quot;dashed&quot;, color = &quot;black&quot;, size = 1.5) + xlab(&quot;Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. As we can see from the posterior estimates and the prior posterior update check, our model is doing a decent job. It doesn’t exactly reconstruct the rate of 0.8, but 0.755 is pretty close and 0.8 is included within the credible interval. Now we build the same model, but using the log odds scale for the theta parameter, which will become useful later when we condition theta on variables and build multilevel models (as we can do what we want in a log odds space and it will always be bound between 0 and 1). stan_model &lt;- &quot; // This model infers a random bias from a sequences of 1s and 0s (right and left hand choices) // The input (data) for the model. n of trials and the sequence of choices (right as 1, left as 0) data { int&lt;lower=1&gt; n; // n of trials array[n] int h; // sequence of choices (right as 1, left as 0) as long as n } // The parameters that the model needs to estimate (theta) parameters { real theta; // note it is unbounded as we now work on log odds } // The model to be estimated (a bernoulli, parameter theta, prior on the theta) model { // The prior for theta on a log odds scale is a normal distribution with a mean of 0 and a sd of 1. // This covers most of the probability space between 0 and 1, after being converted to probability. target += normal_lpdf(theta | 0, 1); // as before the parameters of the prior could be fed as variables // target += normal_lpdf(theta | normal_mu, normal_sigma); // The model consists of a bernoulli distribution (binomial w 1 trial only) with a rate theta, // note we specify it uses a logit link (theta is in logodds) target += bernoulli_logit_lpmf(h | theta); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W3_SimpleBernoulli_logodds.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W3_SimpleBernoulli_logodds.stan&quot; ## With the logit format ## Specify where the model is file &lt;- file.path(&quot;stan/W3_SimpleBernoulli_logodds.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1000, iter_sampling = 2000, refresh = 0, output_dir = &quot;simmodels&quot;, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 finished in 0.1 seconds. ## Chain 2 finished in 0.0 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 0.1 seconds. ## Total execution time: 0.2 seconds. # Same the fitted model samples$save_object(&quot;simmodels/W3_SimpleBernoulli_logodds.rds&quot;) 4.3.6 Summarizing the results samples &lt;- readRDS(&quot;simmodels/W3_SimpleBernoulli_logodds.rds&quot;) # Diagnostics samples$cmdstan_diagnose() ## Processing csv files: /Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/simmodels/W3_SimpleBernoulli_logodds-202402142305-1-6daa99.csv, /Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/simmodels/W3_SimpleBernoulli_logodds-202402142305-2-6daa99.csv ## ## Checking sampler transitions treedepth. ## Treedepth satisfactory for all transitions. ## ## Checking sampler transitions for divergences. ## No divergent transitions found. ## ## Checking E-BFMI - sampler transitions HMC potential energy. ## E-BFMI satisfactory. ## ## Effective sample size satisfactory. ## ## Split R-hat values satisfactory all parameters. ## ## Processing complete, no problems detected. # Extract posterior samples and include sampling of the prior: draws_df &lt;- as_draws_df(samples$draws()) ggplot(draws_df, aes(.iteration, theta, group = .chain, color = .chain)) + geom_line() + theme_classic() # add a prior for theta (ugly, but we&#39;ll do better soon) draws_df &lt;- draws_df %&gt;% mutate( theta_prior = rnorm(nrow(draws_df), 0, 1) ) # Now let&#39;s plot the density for theta (prior and posterior) ggplot(draws_df) + geom_density(aes(theta), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(theta_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0.8, linetype = &quot;dashed&quot;, color = &quot;black&quot;, size = 1.5) + xlab(&quot;Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() # Summary samples$summary() ## # A tibble: 2 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -65.0 -64.6 0.797 0.298 -66.6 -64.4 1.00 927. 718. ## 2 theta 1.25 1.25 0.220 0.209 0.903 1.62 1.00 1112. 785. We can see that the results are very similar. 4.4 Parameter recovery Now that we see that the model works in one case, we can run it throughout all possible rate and noise levels in the simulation. N.B. here is using loops, parallelized version in the next code chunk. # Now we need to scale it up to all possible rates and noises recovery_df &lt;- NULL for (noiseLvl in unique(d$noise)) { for (rateLvl in unique(d$rate)) { dd &lt;- d %&gt;% subset( noise == noiseLvl &amp; rate == rateLvl ) data &lt;- list( n = 120, h = dd$choice ) samples &lt;- mod$sample( data = data, seed = 123, chains = 1, parallel_chains = 1, threads_per_chain = 1, iter_warmup = 1000, iter_sampling = 2000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) draws_df &lt;- as_draws_df(samples$draws()) temp &lt;- tibble(biasEst = inv_logit_scaled(draws_df$theta), biasTrue = rateLvl, noise = noiseLvl) if (exists(&quot;recovery_df&quot;)) {recovery_df &lt;- rbind(recovery_df, temp)} else {recovery_df &lt;- temp} } } write_csv(recovery_df, &quot;simdata/W3_recoverydf_simple.csv&quot;) Now we can look at the relation between the “true” bias value we inputted in the simulation and the inferred bias value - the posterior estimates of bias. recovery_df &lt;- read_csv(&quot;simdata/W3_recoverydf_simple.csv&quot;) ## Rows: 132000 Columns: 3 ## ── Column specification ──────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## dbl (3): biasEst, biasTrue, noise ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ggplot(recovery_df, aes(biasTrue, biasEst)) + geom_point(alpha = 0.1) + geom_smooth() + facet_wrap(.~noise) + theme_classic() ## `geom_smooth()` using method = &#39;gam&#39; and formula = &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; There’s much to be said about the final plot, but for now let’s just say that it looks good. We can reconstruct in a nice ordered way true rate values. However, our ability to do so decreases with the increase in noise. So far no surprises. Wait, you say, shouldn’t we actually model the generative process, that is, include noise in the Stan model? Gold star, there! But let’s wait a bit before we get there, we’ll need mixture models. One final note before moving to the memory model: what if we parallelized the parameter recovery, so that different models / datasets run on different cores? This was not necessary above (it ran in a few minutes anyway), but will become crucial with more complex models. To parallelize, we rely on furrr, a neat R package that distributes parallel operations across cores. First we need to define the function that will define the operations to be run on each core separately, here we simulate the data according to a seed, a n of trials, a rate and a noise, and then we fit the model to them. Second, we need to create a tibble of the seeds, n of trials, rate and noise values that should be simulated. Third, we use future_pmap_dfr to run the function on each row of the tibble above separately on a different core. Note that I set the system to split across 4 parallel cores (to work on my computer without clogging it). Do change it according to the system you are using. Note that if you have 40 “jobs” (rows of the tibble, sets of parameter values to run), using e.g. 32 cores will not substantially speed things more than using 20. pacman::p_load(future, purrr, furrr) plan(multisession, workers = 4) sim_d_and_fit &lt;- function(seed, trials, rateLvl, noiseLvl) { for (t in seq(trials)) { # looping through trials (to make it homologous to more reactive models) randomChoice[t] &lt;- RandomAgentNoise_f(rateLvl, noiseLvl) } temp &lt;- tibble(trial = seq(trials), choice = randomChoice, rate, noise) data &lt;- list( n = 120, h = temp$choice ) samples &lt;- mod$sample( data = data, seed = 1000, chains = 1, parallel_chains = 1, threads_per_chain = 1, iter_warmup = 1000, iter_sampling = 2000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) draws_df &lt;- as_draws_df(samples$draws()) temp &lt;- tibble(biasEst = inv_logit_scaled(draws_df$theta), biasTrue = rateLvl, noise = noiseLvl) return(temp) } temp &lt;- tibble(unique(d[,c(&quot;rate&quot;, &quot;noise&quot;)])) %&gt;% mutate(seed = 1000, trials = 120) %&gt;% rename(rateLvl = rate, noiseLvl = noise) recovery_df &lt;- future_pmap_dfr(temp, sim_d_and_fit, .options = furrr_options(seed = TRUE)) write_csv(recovery_df, &quot;simdata/W3_recoverydf_parallel.csv&quot;) And now we load the data and visualize it as before. recovery_df &lt;- read_csv(&quot;simdata/W3_recoverydf_parallel.csv&quot;) ## Rows: 132000 Columns: 3 ## ── Column specification ──────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## dbl (3): biasEst, biasTrue, noise ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ggplot(recovery_df, aes(biasTrue, biasEst)) + geom_point(alpha = 0.1) + geom_smooth() + facet_wrap(.~noise) + theme_classic() ## `geom_smooth()` using method = &#39;gam&#39; and formula = &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 4.5 The memory model: conditioning theta Now that we fitted the base model, we can move onto more complex models. For instance a memory model (including all previous trials). Here we rely on a generalized linear model kind of thinking: the theta is the expression of a linear model (bias + b1 * PreviousRate). To make the variable more intuitive we code previous rate - which is bound to a probability 0-1 space - into log-odds via a logit link/transformation. In this way a previous rate with more left than right choices will result in a negative value, thereby decreasing our propensity to choose right; and one with more right than left choices will result in a positive value, thereby increasing our propensity to choose right. # We subset to only include no noise and a specific rate d1 &lt;- d %&gt;% subset(noise == 0 &amp; rate == 0.8) %&gt;% rename(Other = choice) %&gt;% mutate(cumulativerate = lag(cumulativerate, 1)) d1$cumulativerate[1] &lt;- 0.5 # no prior info at first trial d1$cumulativerate[d1$cumulativerate == 0] &lt;- 0.01 d1$cumulativerate[d1$cumulativerate == 1] &lt;- 0.99 # Now we create the memory agent with a coefficient of 0.9 MemoryAgent_f &lt;- function(bias, beta, cumulativerate){ choice = rbinom(1, 1, inv_logit_scaled(bias + beta * cumulativerate)) return(choice) } d1$Self[1] &lt;- RandomAgentNoise_f(0.5, 0) ## Warning: Unknown or uninitialised column: `Self`. for (i in 2:trials) { d1$Self[i] &lt;- MemoryAgent_f(bias = 0, beta = 0.8, d1$cumulativerate[i]) } ## Create the data data &lt;- list( n = 120, h = d1$Self, memory = d1$cumulativerate # this creates the new parameter: the rate of right hands so far in log-odds ) stan_model &lt;- &quot; // The input (data) for the model. n of trials and h for (right and left) hand data { int&lt;lower=1&gt; n; array[n] int h; vector[n] memory; // here we add the new parameter. N.B. Log odds } // The parameters accepted by the model. parameters { real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)? real beta; // how strongly is previous rate impacting the decision? } // The model to be estimated. model { // priors target += normal_lpdf(bias | 0, .3); target += normal_lpdf(beta | 0, .5); // model target += bernoulli_logit_lpmf(h | bias + beta * logit(memory)); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W3_MemoryBernoulli.stan&quot;) ## Specify where the model is file &lt;- file.path(&quot;stan/W3_MemoryBernoulli.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1000, iter_sampling = 1000, refresh = 0, output_dir = &quot;simmodels&quot;, max_treedepth = 20, adapt_delta = 0.99, ) # Same the fitted model samples$save_object(&quot;simmodels/W3_MemoryBernoulli.rds&quot;) 4.5.1 Summarizing the results samples &lt;- readRDS(&quot;simmodels/W3_MemoryBernoulli.rds&quot;) # Diagnostics samples$cmdstan_diagnose() ## Processing csv files: /Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/simmodels/W3_MemoryBernoulli-202303231303-1-3e8206.csv, /Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/simmodels/W3_MemoryBernoulli-202303231303-2-3e8206.csv ## ## Checking sampler transitions treedepth. ## Treedepth satisfactory for all transitions. ## ## Checking sampler transitions for divergences. ## No divergent transitions found. ## ## Checking E-BFMI - sampler transitions HMC potential energy. ## E-BFMI satisfactory. ## ## Effective sample size satisfactory. ## ## Split R-hat values satisfactory all parameters. ## ## Processing complete, no problems detected. # Extract posterior samples and include sampling of the prior: draws_df &lt;- as_draws_df(samples$draws()) ggplot(draws_df, aes(.iteration, bias, group = .chain, color = .chain)) + geom_line() + theme_classic() ggplot(draws_df, aes(.iteration, beta, group = .chain, color = .chain)) + geom_line() + theme_classic() # add a prior for theta (ugly, but we&#39;ll do better soon) draws_df &lt;- draws_df %&gt;% mutate( bias_prior = rnorm(nrow(draws_df), 0, .3), beta_prior = rnorm(nrow(draws_df), 0, .5), ) # Now let&#39;s plot the density for theta (prior and posterior) ggplot(draws_df) + geom_density(aes(bias), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(bias_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0, linetype = &quot;dashed&quot;, color = &quot;black&quot;, size = 1.5) + xlab(&quot;Bias&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_density(aes(beta), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(beta_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0.8, linetype = &quot;dashed&quot;, color = &quot;black&quot;, size = 1.5) + xlab(&quot;Beta&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() samples$summary() ## # A tibble: 3 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -78.7 -78.4 1.02 0.734 -80.7 -77.8 1.01 564. 634. ## 2 bias 0.239 0.235 0.230 0.236 -0.130 0.616 1.00 528. 526. ## 3 beta 0.318 0.321 0.239 0.234 -0.0679 0.719 1.00 600. 656. We can see that the model has now estimated both the bias and the role of previous memory. Bias should reflect the bias in the setup (0.5 which in log odds is 0), and the beta coefficient for memory (roughly 0.8). More on the quality checks of the models in the next chapter. 4.6 Memory agent with internal parameter So far we behaved like in GLM: we keep feeding to the model an external variable of memory, but what if we coded memory as an internal parameter? This opens up to further possibilities to model how long memory is kept and weighted by distance from the current moment, etc. [Missing: discussion of the equation of the model, how it relates to Kalman filters, Rescorla-Wagner, and hierarchical gaussian filters] ## Create the data data &lt;- list( n = 120, h = d1$Self, other = d1$Other ) stan_model &lt;- &quot; // The input (data) for the model. n of trials and h for (right and left) hand data { int&lt;lower=1&gt; n; array[n] int h; array[n] int other; } // The parameters accepted by the model. parameters { real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)? real beta; // how strongly is previous rate impacting the decision? } transformed parameters{ vector[n] memory; for (trial in 1:n){ if (trial == 1) { memory[trial] = 0.5; } if (trial &lt; n){ memory[trial + 1] = memory[trial] + ((other[trial] - memory[trial]) / trial); if (memory[trial + 1] == 0){memory[trial + 1] = 0.01;} if (memory[trial + 1] == 1){memory[trial + 1] = 0.99;} } } } // The model to be estimated. model { // Priors target += normal_lpdf(bias | 0, .3); target += normal_lpdf(beta | 0, .5); // Model, looping to keep track of memory for (trial in 1:n) { target += bernoulli_logit_lpmf(h[trial] | bias + beta * logit(memory[trial])); } } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W3_InternalMemory.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W3_InternalMemory.stan&quot; ## Specify where the model is file &lt;- file.path(&quot;stan/W3_InternalMemory.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 1, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1000, iter_sampling = 1000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 1 chain, with 2 thread(s) per chain... ## ## Chain 1 finished in 0.5 seconds. samples$summary() ## # A tibble: 123 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -81.3 -80.9 1.03 0.720 -83.3 -80.3 1.00 306. 441. ## 2 bias 0.279 0.273 0.226 0.222 -0.0817 0.669 0.999 359. 299. ## 3 beta 0.126 0.126 0.217 0.211 -0.229 0.487 1.00 368. 346. ## 4 memory[1] 0.5 0.5 0 0 0.5 0.5 NA NA NA ## 5 memory[2] 0.01 0.01 0 0 0.01 0.01 NA NA NA ## 6 memory[3] 0.505 0.505 0 0 0.505 0.505 NA NA NA ## 7 memory[4] 0.67 0.67 0 0 0.67 0.67 NA NA NA ## 8 memory[5] 0.752 0.752 0 0 0.752 0.752 NA NA NA ## 9 memory[6] 0.802 0.802 0 0 0.802 0.802 NA NA NA ## 10 memory[7] 0.668 0.668 0 0 0.668 0.668 NA NA NA ## # ℹ 113 more rows Now that we know how to model memory as an internal state, we can play with making the update discount the past, setting a parameter that indicates after how many trials memory is lost, etc. 4.6.1 Trying out a more complex memory model, with a rate of forgetting that exponentially discounts the past stan_model &lt;- &quot; // The input (data) for the model. n of trials and h for (right and left) hand data { int&lt;lower=1&gt; n; array[n] int h; array[n] int other; } // The parameters accepted by the model. parameters { real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)? real beta; // how strongly is previous rate impacting the decision? real&lt;lower=0, upper=1&gt; forgetting; } // The model to be estimated. model { vector[n] memory; // Priors target += beta_lpdf(forgetting | 1, 1); target += normal_lpdf(bias | 0, .3); target += normal_lpdf(beta | 0, .5); // Model, looping to keep track of memory for (trial in 1:n) { if (trial == 1) { memory[trial] = 0.5; } target += bernoulli_logit_lpmf(h[trial] | bias + beta * logit(memory[trial])); if (trial &lt; n){ memory[trial + 1] = (1 - forgetting) * memory[trial] + forgetting * other[trial]; if (memory[trial + 1] == 0){memory[trial + 1] = 0.01;} if (memory[trial + 1] == 1){memory[trial + 1] = 0.99;} } } } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W3_InternalMemory2.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W3_InternalMemory2.stan&quot; ## Specify where the model is file &lt;- file.path(&quot;stan/W3_InternalMemory2.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 1, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1000, iter_sampling = 1000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 1 chain, with 2 thread(s) per chain... ## ## Chain 1 finished in 1.2 seconds. samples$summary() ## # A tibble: 4 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -83.2 -83.0 1.15 1.06 -85.5 -81.9 0.999 305. 379. ## 2 bias 0.270 0.273 0.207 0.205 -0.0810 0.595 1.01 266. 266. ## 3 beta 0.110 0.0682 0.170 0.131 -0.0977 0.440 1.00 224. 236. ## 4 forgetting 0.262 0.200 0.221 0.204 0.0160 0.730 1.01 194. 321. knitr::opts_chunk$set(echo = TRUE) "],["practical-exercise-4---model-quality-checks.html", "Chapter 5 Practical exercise 4 - Model quality checks 5.1 Generating and plotting additional variables 5.2 Assessing priors 5.3 Assessing prior and posterior predictions 5.4 Prior sensitivity analysis 5.5 The memory model 5.6 Prior sensitivity check for the memory model", " Chapter 5 Practical exercise 4 - Model quality checks This document covers: - generating and plotting priors (against posteriors) - generating and plotting predictive checks (prior and posterior ones) - prior sensitivity checks 5.1 Generating and plotting additional variables As we try to understand our model, we might want to plot how the prior relates to the posterior, or - in other words, what has the model learned from looking at the data? We can do so by overlaying the prior and the posterior distributions, what is also called a “prior - posterior update check”. Stan does not automatically save the prior distribution, so we need to tell it to generate and save prior distributions in a convenient place so we can easily plot or use them at will from R. Luckily, Stan gives us a dedicated code chunk to do that: the generated quantities chunk. As before, we need to define the kind of variable we want to save, and then how to generate it. If we take the example of the random agent (with a bias), we have one parameter: theta. We can then generate theta according to the prior in generated quantities. While we are at this, we can also generate a nicer version of the posterior estimate for the theta parameter, now in probability scale (instead of log odds). However, prior and posterior estimates are not always the most immediate thing to understand. For instance, we might have trouble having a good grasp for how the uncertainty in the estimate will play out on 120 trials, or 6 trials, or however many trials we are planning for our experiment. Luckily, we can ask Stan to run predictions from either priors or posteriors, or both: given the priors how many trials will have “right hand” choice? and given the posterior estimates? As we use complex models, the relation between prior/posterior estimates and predictions becomes less and less intuitive. Simulating their implications for the outcomes - also called prior/posterior predictive checks - becomes a very useful tool to adjust our priors and their uncertainty so that they reflect what we know of the outcome scale; as well as to assess whether the model (and its posterior estimates) can appropriately describe the data we observe, or there’s some bias there. More discussion of this can be found at https://4ccoxau.github.io/PriorsWorkshop/. pacman::p_load(tidyverse, here, posterior, cmdstanr, brms, tidybayes) d &lt;- read_csv(&quot;simdata/W3_randomnoise.csv&quot;) stan_model &lt;- &quot; // This model infers a random bias from a sequences of 1s and 0s (right and left hand choices) // The input (data) for the model. n of trials and the sequence of choices (right as 1, left as 0) data { int&lt;lower=1&gt; n; // n of trials array[n] int h; // sequence of choices (right as 1, left as 0) as long as n } // The parameters that the model needs to estimate (theta) parameters { real theta; // note it is unbounded as we now work on log odds } // The model to be estimated (a bernoulli, parameter theta, prior on the theta) model { // The prior for theta on a log odds scale is a normal distribution with a mean of 0 and a sd of 1. // This covers most of the probability space between 0 and 1, after being converted to probability. target += normal_lpdf(theta | 0, 1); // The model consists of a bernoulli distribution (binomial w 1 trial only) with a rate theta, // note we specify it uses a logit link (theta is in logodds) target += bernoulli_logit_lpmf(h | theta); } generated quantities{ real&lt;lower=0, upper=1&gt; theta_prior; // theta prior parameter, on a prob scale (0-1) real&lt;lower=0, upper=1&gt; theta_posterior; // theta posterior parameter, on a prob scale (0-1) int&lt;lower=0, upper=n&gt; prior_preds; // distribution of right hand choices according to the prior int&lt;lower=0, upper=n&gt; posterior_preds; // distribution of right hand choices according to the posterior theta_prior = inv_logit(normal_rng(0,1)); // generating the prior on a log odds scale and converting theta_posterior = inv_logit(theta); // converting the posterior estimate from log odds to prob. prior_preds = binomial_rng(n, theta_prior); posterior_preds = binomial_rng(n, inv_logit(theta)); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W4_SimpleBernoulli_logodds.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W4_SimpleBernoulli_logodds.stan&quot; ## With the logit format ## Specify where the model is file &lt;- file.path(&quot;stan/W4_SimpleBernoulli_logodds.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) d1 &lt;- d %&gt;% subset(noise == 0 &amp; rate == 0.8) ## Create the data. N.B. note the two variables have different lengths: 1 for n, n for h. data &lt;- list( n = 120, # n of trials h = d1$choice # sequence of choices (h stands for hand) ) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1000, iter_sampling = 2000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 finished in 0.1 seconds. ## Chain 2 finished in 0.1 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 0.1 seconds. ## Total execution time: 0.2 seconds. draws_df &lt;- as_draws_df(samples$draws()) 5.2 Assessing priors # Now let&#39;s plot the density for theta (prior and posterior) ggplot(draws_df) + geom_density(aes(theta_posterior), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(theta_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0.8, linetype = &quot;dashed&quot;, color = &quot;black&quot;, size = 1.5) + xlab(&quot;Rate&quot;) + ylab(&quot;Estimate Densities&quot;) + theme_classic() 5.3 Assessing prior and posterior predictions ggplot(draws_df) + geom_histogram(aes(prior_preds), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3) + xlab(&quot;Predicted heads out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_histogram(aes(posterior_preds), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3, bins = 90) + geom_point(x = sum(data$h), y = 0, color = &quot;red&quot;, shape = 17, size = 5) + xlab(&quot;Predicted heads out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_histogram(aes(prior_preds), color = &quot;lightblue&quot;, fill = &quot;blue&quot;, alpha = 0.3, bins = 90) + geom_histogram(aes(posterior_preds), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3, bins = 90) + geom_point(x = sum(data$h), y = 0, color = &quot;red&quot;, shape = 17, size = 5) + xlab(&quot;Predicted heads out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() 5.4 Prior sensitivity analysis ## Now we adding different priors for theta prior_mean &lt;- seq(-3, 3, .5) prior_sd &lt;- seq(0.1, 1, 0.1) priors &lt;- expand.grid(prior_mean, prior_sd) priors &lt;- tibble(prior_mean = priors$Var1, prior_sd = priors$Var2) stan_model &lt;- &quot; // The input (data) for the model data { int&lt;lower=1&gt; n; array[n] int h; real prior_mean; real&lt;lower=0&gt; prior_sd; } // The parameters accepted by the model. parameters { real theta; } // The model to be estimated. model { // Prior target += normal_lpdf(theta | prior_mean, prior_sd); // Model target += bernoulli_logit_lpmf(h | theta); } generated quantities{ real&lt;lower=0, upper=1&gt; theta_prior; real&lt;lower=0, upper=1&gt; theta_posterior; int&lt;lower=0, upper=n&gt; prior_preds; int&lt;lower=0, upper=n&gt; posterior_preds; theta_prior = inv_logit(normal_rng(0,1)); theta_posterior = inv_logit(theta); prior_preds = binomial_rng(n, theta_prior); posterior_preds = binomial_rng(n, inv_logit(theta)); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W4_PriorBernoulli.stan&quot;) file &lt;- file.path(&quot;stan/W4_PriorBernoulli.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) dd &lt;- d %&gt;% subset(noise == 0.1 &amp; rate == 0.8) pacman::p_load(future, purrr, furrr) plan(multisession, workers = 4) sim_d_and_fit &lt;- function(prior_mean, prior_sd) { data &lt;- list( n = nrow(dd), h = dd$choice, prior_mean = prior_mean, prior_sd = prior_sd ) samples &lt;- mod$sample( data = data, seed = 1000, chains = 1, parallel_chains = 1, threads_per_chain = 1, iter_warmup = 1000, iter_sampling = 2000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) draws_df &lt;- as_draws_df(samples$draws()) temp &lt;- tibble(theta_prior = draws_df$theta_prior, theta_posterior = draws_df$theta_posterior, prior_preds = draws_df$prior_preds, posterior_preds = draws_df$posterior_preds, prior_mean = prior_mean, prior_sd = prior_sd) return(temp) } recovery_df &lt;- future_pmap_dfr(priors, sim_d_and_fit, .options = furrr_options(seed = TRUE)) write_csv(recovery_df, &quot;simdata/W4_priorSensitivityRecovery.csv&quot;) Now we load the data and plot it recovery_df &lt;- read_csv(&quot;simdata/W4_priorSensitivityRecovery.csv&quot;) ## Rows: 260000 Columns: 6 ## ── Column specification ──────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## dbl (6): theta_prior, theta_posterior, prior_preds, posterior_preds, prior_mean, pri... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ggplot(recovery_df, aes(prior_mean, theta_posterior)) + geom_point(alpha = 0.1) + geom_hline(yintercept = 0.8, color = &quot;red&quot;) + geom_smooth() + facet_wrap(.~prior_sd) + theme_classic() ## `geom_smooth()` using method = &#39;gam&#39; and formula = &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; 5.5 The memory model We can do the same for the memory model: generate prior distributions to overlay to the posteriors (prior-posterior update checks), generate predicted outcomes based on the priors (prior predictive checks) and on the posteriors (posterior predictive checks). N.B. prior and posterior predictions now depend on the value on memory. I identified 3 meaningful values for the memory value (e.g. 0.5, 0.7, 0.9) and used those to generate 3 prior and posterior predictive checks. # We subset to only include no noise and a specific rate d1 &lt;- d %&gt;% subset(noise == 0 &amp; rate == 0.8) %&gt;% rename(Other = choice) %&gt;% mutate(cumulativerate = lag(cumulativerate, 1)) d1$cumulativerate[1] &lt;- 0.5 # no prior info at first trial d1$cumulativerate[d1$cumulativerate == 0] &lt;- 0.01 d1$cumulativerate[d1$cumulativerate == 1] &lt;- 0.99 # Now we create the memory agent with a coefficient of 0.9 bias = 0 beta = 0.9 MemoryAgent_f &lt;- function(bias, beta, cumulativerate){ choice = rbinom(1, 1, inv_logit_scaled(bias + beta * logit_scaled(cumulativerate))) return(choice) } for (i in 1:trials) { d1$Self[i] &lt;- MemoryAgent_f(bias, beta, d1$cumulativerate[i]) } ## Create the data. data &lt;- list( n = 120, h = d1$Self, other = d1$Other ) stan_model &lt;- &quot; // The input (data) for the model. n of trials and h for (right and left) hand data { int&lt;lower=1&gt; n; array[n] int h; array[n] int other; } // The parameters accepted by the model. parameters { real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)? real beta; // how strongly is previous rate impacting the decision? } transformed parameters{ vector[n] memory; for (trial in 1:n){ if (trial == 1) { memory[trial] = 0.5; } if (trial &lt; n){ memory[trial + 1] = memory[trial] + ((other[trial] - memory[trial]) / trial); if (memory[trial + 1] == 0){memory[trial + 1] = 0.01;} if (memory[trial + 1] == 1){memory[trial + 1] = 0.99;} } } } // The model to be estimated. model { // Priors target += normal_lpdf(bias | 0, .3); target += normal_lpdf(beta | 0, .5); // Model, looping to keep track of memory for (trial in 1:n) { target += bernoulli_logit_lpmf(h[trial] | bias + beta * logit(memory[trial])); } } generated quantities{ real bias_prior; real beta_prior; int&lt;lower=0, upper=n&gt; prior_preds5; int&lt;lower=0, upper=n&gt; post_preds5; int&lt;lower=0, upper=n&gt; prior_preds7; int&lt;lower=0, upper=n&gt; post_preds7; int&lt;lower=0, upper=n&gt; prior_preds9; int&lt;lower=0, upper=n&gt; post_preds9; bias_prior = normal_rng(0, 0.3); beta_prior = normal_rng(0, 0.5); prior_preds5 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.5))); prior_preds7 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.7))); prior_preds9 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.9))); post_preds5 = binomial_rng(n, inv_logit(bias + beta * logit(0.5))); post_preds7 = binomial_rng(n, inv_logit(bias + beta * logit(0.7))); post_preds9 = binomial_rng(n, inv_logit(bias + beta * logit(0.9))); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W4_MemoryBernoulli.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W4_MemoryBernoulli.stan&quot; ## Specify where the model is file &lt;- file.path(&quot;stan/W4_MemoryBernoulli.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 1, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1000, iter_sampling = 1000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 1 chain, with 2 thread(s) per chain... ## ## Chain 1 finished in 0.6 seconds. samples$summary() ## # A tibble: 131 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -71.2 -70.9 1.21 0.658 -73.6 -70.3 1.02 300. 194. ## 2 bias 0.128 0.126 0.239 0.233 -0.267 0.504 1.01 326. 236. ## 3 beta 0.723 0.737 0.251 0.224 0.312 1.12 1.00 412. 307. ## 4 memory[1] 0.5 0.5 0 0 0.5 0.5 NA NA NA ## 5 memory[2] 0.01 0.01 0 0 0.01 0.01 NA NA NA ## 6 memory[3] 0.505 0.505 0 0 0.505 0.505 NA NA NA ## 7 memory[4] 0.67 0.67 0 0 0.67 0.67 NA NA NA ## 8 memory[5] 0.752 0.752 0 0 0.752 0.752 NA NA NA ## 9 memory[6] 0.802 0.802 0 0 0.802 0.802 NA NA NA ## 10 memory[7] 0.668 0.668 0 0 0.668 0.668 NA NA NA ## # ℹ 121 more rows # Extract posterior samples and include sampling of the prior: draws_df &lt;- as_draws_df(samples$draws()) # Now let&#39;s plot the density for bias (prior and posterior) ggplot(draws_df) + geom_density(aes(bias), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(bias_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0, size = 2) + xlab(&quot;Bias&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_density(aes(beta), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(beta_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0.9, size = 2) + xlab(&quot;MemoryBeta&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_histogram(aes(`prior_preds5`), color = &quot;yellow&quot;, fill = &quot;lightyellow&quot;, alpha = 0.2) + geom_histogram(aes(`prior_preds7`), color = &quot;green&quot;, fill = &quot;lightgreen&quot;, alpha = 0.2) + geom_histogram(aes(`prior_preds9`), color = &quot;blue&quot;, fill = &quot;lightblue&quot;, alpha = 0.2) + xlab(&quot;Predicted heads out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_histogram(aes(`post_preds5`), color = &quot;yellow&quot;, fill = &quot;lightyellow&quot;, alpha = 0.3, bins = 90) + geom_histogram(aes(`post_preds7`), color = &quot;green&quot;, fill = &quot;lightgreen&quot;, alpha = 0.3, bins = 90) + geom_histogram(aes(`post_preds9`), color = &quot;blue&quot;, fill = &quot;lightblue&quot;, alpha = 0.3, bins = 90) + #geom_point(x = sum(data$h), y = 0, color = &quot;red&quot;, shape = 17, size = 5) + xlab(&quot;Predicted heads out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_histogram(aes(`prior_preds5`), color = &quot;lightblue&quot;, fill = &quot;blue&quot;, alpha = 0.3, bins = 90) + geom_histogram(aes(`post_preds5`), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3, bins = 90) + xlab(&quot;Predicted heads out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() 5.6 Prior sensitivity check for the memory model ## Now we adding different priors for theta prior_mean_bias &lt;- 0 prior_sd_bias &lt;- seq(0.1, 0.5, 0.1) prior_mean_beta &lt;- 0 prior_sd_beta &lt;- seq(0.1, 0.5, 0.1) priors &lt;- tibble(expand.grid(tibble(prior_mean_bias, prior_sd_bias, prior_mean_beta, prior_sd_beta))) stan_model &lt;- &quot; // The input (data) for the model data { int&lt;lower=1&gt; n; array[n] int h; array[n] int other; real prior_mean_bias; real&lt;lower=0&gt; prior_sd_bias; real prior_mean_beta; real&lt;lower=0&gt; prior_sd_beta; } // The parameters accepted by the model. parameters { real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)? real beta; // how strongly is previous rate impacting the decision? } transformed parameters{ vector[n] memory; for (trial in 1:n){ if (trial == 1) { memory[trial] = 0.5; } if (trial &lt; n){ memory[trial + 1] = memory[trial] + ((other[trial] - memory[trial]) / trial); if (memory[trial + 1] == 0){memory[trial + 1] = 0.01;} if (memory[trial + 1] == 1){memory[trial + 1] = 0.99;} } } } // The model to be estimated. model { // The priors target += normal_lpdf(bias | prior_mean_bias, prior_sd_bias); target += normal_lpdf(beta | prior_mean_beta, prior_sd_beta); // The model target += bernoulli_logit_lpmf(h | bias + beta * logit(memory)); } generated quantities{ real bias_prior; real beta_prior; int&lt;lower=0, upper=n&gt; prior_preds5; int&lt;lower=0, upper=n&gt; post_preds5; int&lt;lower=0, upper=n&gt; prior_preds7; int&lt;lower=0, upper=n&gt; post_preds7; int&lt;lower=0, upper=n&gt; prior_preds9; int&lt;lower=0, upper=n&gt; post_preds9; bias_prior = normal_rng(prior_mean_bias, prior_sd_bias); beta_prior = normal_rng(prior_mean_beta, prior_sd_beta); prior_preds5 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.5))); prior_preds7 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.7))); prior_preds9 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.9))); post_preds5 = binomial_rng(n, inv_logit(bias + beta * logit(0.5))); post_preds7 = binomial_rng(n, inv_logit(bias + beta * logit(0.7))); post_preds9 = binomial_rng(n, inv_logit(bias + beta * logit(0.9))); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W4_PriorMemory.stan&quot;) file &lt;- file.path(&quot;stan/W4_PriorMemory.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE)) dd &lt;- d %&gt;% subset(noise == 0.1 &amp; rate == 0.8) %&gt;% mutate(memory = lag(cumulativerate, 1)) dd$memory[1] &lt;- 0.5 pacman::p_load(future, purrr, furrr) plan(multisession, workers = 4) sim_d_and_fit &lt;- function(prior_mean_bias, prior_sd_bias, prior_mean_beta, prior_sd_beta) { data &lt;- list( n = nrow(dd), h = dd$choice, memory = dd$memory, prior_mean_bias = prior_mean_bias, prior_sd_bias = prior_sd_bias, prior_mean_beta = prior_mean_beta, prior_sd_beta = prior_sd_beta ) samples &lt;- mod$sample( data = data, seed = 1000, chains = 1, parallel_chains = 1, threads_per_chain = 1, iter_warmup = 1000, iter_sampling = 2000, refresh = 0, max_treedepth = 20, adapt_delta = 0.99, ) draws_df &lt;- as_draws_df(samples$draws()) temp &lt;- tibble(bias_prior = draws_df$bias_prior, beta_prior = draws_df$beta_prior, bias_posterior = draws_df$bias, beta_posterior = draws_df$beta, prior_preds5 = draws_df$prior_preds5, prior_preds7 = draws_df$prior_preds7, prior_preds9 = draws_df$prior_preds9, posterior_preds5 = draws_df$post_preds5, posterior_preds7 = draws_df$post_preds7, posterior_preds9 = draws_df$post_preds9, prior_mean_bias = prior_mean_bias, prior_sd_bias = prior_sd_bias, prior_mean_beta = prior_mean_beta, prior_sd_beta = prior_sd_beta) return(temp) } recovery_df &lt;- future_pmap_dfr(priors, sim_d_and_fit, .options = furrr_options(seed = TRUE)) write_csv(recovery_df, &quot;simdata/W4_MemoryPriorSensitivity.csv&quot;) recovery_df &lt;- read_csv(&quot;simdata/W4_MemoryPriorSensitivity.csv&quot;) ## Rows: 1250000 Columns: 14 ## ── Column specification ──────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## dbl (14): bias_prior, beta_prior, bias_posterior, beta_posterior, prior_preds5, prio... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ggplot(recovery_df, aes(prior_sd_beta, beta_posterior)) + geom_point(alpha = 0.1) + geom_hline(yintercept = 0.8, color = &quot;red&quot;) + geom_smooth(method = lm) + facet_wrap(.~prior_sd_bias) + theme_classic() ## `geom_smooth()` using formula = &#39;y ~ x&#39; "],["multilevel-modeling.html", "Chapter 6 Multilevel modeling 6.1 Intro to multilevel modeling 6.2 A multilevel version of the biased agent and of the simple memory agent 6.3 Generating the agents 6.4 Plotting the agents 6.5 Coding the multilevel agents 6.6 Multilevel full pooling", " Chapter 6 Multilevel modeling 6.1 Intro to multilevel modeling [Explanation on what multilevel modeling is - structure in the data, partial pooling, repeated measures] 6.2 A multilevel version of the biased agent and of the simple memory agent We are now conceptualizing our agents as being part of (sampled from) a more general population. This general population is characterized by a population level average parameter value (e.g. a general bias of 0.8 as we all like right hands more) and a certain variation in the population (e.g. a standard deviation of 0.1, as we are all a bit different from each other). Each biased agent’s rate is then sampled from that distribution. Same for the memory agents. [MISSING: DAG PLOTS OF THE TWO SCENARIOS] Again, it’s practical to work in log odds. Why? Well, it’s not unconceivable that an agent would be 3 sd from the mean. So a biased agent could have a rate of 0.8 + 3 * 0.1, which gives a rate of 1.1. It’s kinda impossible to choose 110% of the time the right hand. We want an easy way to avoid these situations without too carefully tweaking our parameters, or including exception statements (e.g. if rate &gt; 1, then rate = 1). Conversion to log odds is again a wonderful way to work in a boundless space, and in the last step shrinking everything back to 0-1 probability space. N.B. we model all agents with some added noise as we assume it cannot be eliminated from our studies. pacman::p_load(tidyverse, here, posterior, cmdstanr, brms, tidybayes) # Shared parameters agents &lt;- 100 trials &lt;- 120 noise &lt;- 0 # Biased agents parameters rateM &lt;- 1.386 # roughly 0.8 once inv_logit scaled rateSD &lt;- 0.65 # roughly giving a sd of 0.1 in prob scale # Memory agents parameters biasM &lt;- 0 biasSD &lt;- 0.1 betaM &lt;- 1.5 betaSD &lt;- 0.3 # Functions of the agents RandomAgentNoise_f &lt;- function(rate, noise) { choice &lt;- rbinom(1, 1, inv_logit_scaled(rate)) if (rbinom(1, 1, noise) == 1) { choice = rbinom(1, 1, 0.5) } return(choice) } MemoryAgentNoise_f &lt;- function(bias, beta, otherRate, noise) { rate &lt;- inv_logit_scaled(bias + beta * logit_scaled(otherRate)) choice &lt;- rbinom(1, 1, rate) if (rbinom(1, 1, noise) == 1) { choice = rbinom(1, 1, 0.5) } return(choice) } 6.3 Generating the agents [MISSING: PARALLELIZE] # Looping through all the agents to generate the data. d &lt;- NULL for (agent in 1:agents) { rate &lt;- rnorm(1, rateM, rateSD) bias &lt;- rnorm(1, biasM, biasSD) beta &lt;- rnorm(1, betaM, betaSD) randomChoice &lt;- rep(NA, trials) memoryChoice &lt;- rep(NA, trials) memoryRate &lt;- rep(NA, trials) for (trial in 1:trials) { randomChoice[trial] &lt;- RandomAgentNoise_f(rate, noise) if (trial == 1) { memoryChoice[trial] &lt;- rbinom(1,1,0.5) } else { memoryChoice[trial] &lt;- MemoryAgentNoise_f(bias, beta, mean(randomChoice[1:trial], na.rm = T), noise) } } temp &lt;- tibble(agent, trial = seq(trials), randomChoice, randomRate = rate, memoryChoice, memoryRate, noise, rateM, rateSD, bias, beta, biasM, biasSD, betaM, betaSD) if (agent &gt; 1) { d &lt;- rbind(d, temp) } else{ d &lt;- temp } } d &lt;- d %&gt;% group_by(agent) %&gt;% mutate( randomRate = cumsum(randomChoice) / seq_along(randomChoice), memoryRate = cumsum(memoryChoice) / seq_along(memoryChoice) ) 6.4 Plotting the agents # A plot of the proportion of right hand choices for the random agents p1 &lt;- ggplot(d, aes(trial, randomRate, group = agent, color = agent)) + geom_line(alpha = 0.5) + geom_hline(yintercept = 0.5, linetype = &quot;dashed&quot;) + ylim(0,1) + theme_classic() # A plot of the proportion of right hand choices for the memory agents p2 &lt;- ggplot(d, aes(trial, memoryRate, group = agent, color = agent)) + geom_line(alpha = 0.5) + geom_hline(yintercept = 0.5, linetype = &quot;dashed&quot;) + ylim(0,1) + theme_classic() p1 + p2 # A plot of whether memory and random agents are matched in proportion at different stages p3 &lt;- d %&gt;% subset(trial == 10) %&gt;% ggplot(aes(randomRate, memoryRate)) + geom_point() + geom_smooth(method = lm) + geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;) + xlim(0.25, 1) + ylim(0.25, 1) + xlab(&quot;correlation at 10 trials&quot;) + theme_bw() p4 &lt;- d %&gt;% subset(trial == 60) %&gt;% ggplot(aes(randomRate, memoryRate)) + geom_point() + geom_smooth(method = lm) + geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;) + xlim(0.25, 1) + ylim(0.25, 1) + xlab(&quot;correlation at 60 trials&quot;) + theme_bw() p5 &lt;- d %&gt;% subset(trial == 120) %&gt;% ggplot(aes(randomRate, memoryRate)) + geom_point() + geom_smooth(method = lm) + geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;) + xlim(0.25, 1) + ylim(0.25, 1) + xlab(&quot;correlation at 120 trials&quot;) + theme_bw() p3 + p4 + p5 ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## Warning: Removed 7 rows containing missing values (`geom_smooth()`). ## `geom_smooth()` using formula = &#39;y ~ x&#39; ## Warning: Removed 6 rows containing missing values (`geom_smooth()`). Note that as the n of trials increases, the memory model matches the random model better and better 6.5 Coding the multilevel agents 6.5.1 Multilevel random Remember that the simulated parameters are: * biasM &lt;- 0 * biasSD &lt;- 0.1 * betaM &lt;- 1.5 * betaSD &lt;- 0.3 Prep the data d1 &lt;- d %&gt;% subset(select = c(agent, randomChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = randomChoice) ## Create the data data &lt;- list( trials = trials, agents = agents, h = as.matrix(d1[,2:101]) ) stan_model &lt;- &quot; // // This STAN model infers a random bias from a sequences of 1s and 0s (right and left). Now multilevel // functions{ real normal_lb_rng(real mu, real sigma, real lb) { // normal distribution with a lower bound real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. n of trials and h of hands data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; } // The parameters accepted by the model. parameters { real thetaM; real&lt;lower = 0&gt; thetaSD; array[agents] real theta; } // The model to be estimated. model { target += normal_lpdf(thetaM | 0, 1); target += normal_lpdf(thetaSD | 0, .3) - normal_lccdf(0 | 0, .3); // The prior for theta is a uniform distribution between 0 and 1 target += normal_lpdf(theta | thetaM, thetaSD); for (i in 1:agents) target += bernoulli_logit_lpmf(h[,i] | theta[i]); } generated quantities{ real thetaM_prior; real&lt;lower=0&gt; thetaSD_prior; real&lt;lower=0, upper=1&gt; theta_prior; real&lt;lower=0, upper=1&gt; theta_posterior; int&lt;lower=0, upper = trials&gt; prior_preds; int&lt;lower=0, upper = trials&gt; posterior_preds; thetaM_prior = normal_rng(0,1); thetaSD_prior = normal_lb_rng(0,0.3,0); theta_prior = inv_logit(normal_rng(thetaM_prior, thetaSD_prior)); theta_posterior = inv_logit(normal_rng(thetaM, thetaSD)); prior_preds = binomial_rng(trials, inv_logit(thetaM_prior)); posterior_preds = binomial_rng(trials, inv_logit(thetaM)); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W5_MultilevelBias.stan&quot;) file &lt;- file.path(&quot;stan/W5_MultilevelBias.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99, ) samples$save_object(file = &quot;simmodels/W5_MultilevelBias.RDS&quot;) 6.5.2 Assessing multilevel random agents Besides the usual prior predictive checks, prior posterior update checks, posterior predictive checks, based on the population level estimates; we also want to plot at least a few of the single agents to assess how well the model is doing for them. [MISSING: PLOT MODEL ESTIMATES AGAINST N OF HEADS BY PARTICIPANT] samples &lt;- readRDS(&quot;simmodels/W5_MultilevelBias.RDS&quot;) samples$cmdstan_diagnose() ## File /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpTP5vj3/W5_MultilevelBias-202303101235-1-84831d.csv not found ## File /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpTP5vj3/W5_MultilevelBias-202303101235-2-84831d.csv not found ## No valid input files, exiting. samples$summary() ## # A tibble: 109 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -5780. -5780. 7.26 7.35 -5792. -5.77e+3 1.00 1370. 2125. ## 2 thetaM 1.49 1.49 0.0664 0.0678 1.38 1.60e+0 1.00 7644. 3557. ## 3 thetaSD 0.637 0.634 0.0523 0.0526 0.557 7.27e-1 1.00 5220. 3381. ## 4 theta[1] 0.663 0.661 0.184 0.188 0.366 9.68e-1 1.00 8209. 2723. ## 5 theta[2] 0.909 0.909 0.190 0.195 0.604 1.22e+0 1.00 10277. 2844. ## 6 theta[3] 1.28 1.27 0.216 0.213 0.932 1.64e+0 1.00 9117. 2544. ## 7 theta[4] 2.16 2.15 0.274 0.279 1.73 2.62e+0 1.00 8381. 2508. ## 8 theta[5] 1.51 1.50 0.217 0.214 1.16 1.86e+0 1.00 8492. 2303. ## 9 theta[6] 2.32 2.31 0.281 0.273 1.88 2.80e+0 1.00 9372. 2814. ## 10 theta[7] 2.10 2.09 0.275 0.267 1.66 2.57e+0 1.00 9292. 2740. ## # ℹ 99 more rows draws_df &lt;- as_draws_df(samples$draws()) ggplot(draws_df, aes(.iteration, thetaM, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws_df, aes(.iteration, thetaSD, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws_df) + geom_histogram(aes(prior_preds), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3) + xlab(&quot;Predicted right hands out of 120 trials&quot;) + ylab(&quot;Prior Density&quot;) + theme_classic() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(draws_df) + geom_density(aes(thetaM), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(thetaM_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 1.386) + xlab(&quot;Mean Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_density(aes(thetaSD), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(thetaSD_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0.65) + xlab(&quot;Variance of Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_density(aes(theta_posterior), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(theta_prior), fill = &quot;red&quot;, alpha = 0.3) + xlab(&quot;Overall Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_histogram(aes(prior_preds), color = &quot;darkblue&quot;, fill = &quot;lightblue&quot;, alpha = 0.3) + geom_histogram(aes(posterior_preds), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3) + xlab(&quot;Predicted right hands out of 120 trials&quot;) + ylab(&quot;Predictive Density&quot;) + theme_classic() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(draws_df) + geom_density(aes(inv_logit_scaled(`theta[1]`)), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`theta[15]`)), fill = &quot;green&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`theta[21]`)), fill = &quot;lightblue&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`theta[31]`)), fill = &quot;darkblue&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`theta[41]`)), fill = &quot;yellow&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`theta[51]`)), fill = &quot;darkgreen&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`theta[61]`)), fill = &quot;lightgreen&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(thetaM_prior)), fill = &quot;pink&quot;, alpha = 0.3) + geom_density(aes(theta_prior), fill = &quot;purple&quot;, alpha = 0.3) + xlab(&quot;Mean Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() draws_df &lt;- draws_df %&gt;% mutate( preds1 = rbinom(4000,120, inv_logit_scaled(`theta[1]`)), preds11 = rbinom(4000,120, inv_logit_scaled(`theta[11]`)), preds21 = rbinom(4000,120, inv_logit_scaled(`theta[21]`)), preds31 = rbinom(4000,120, inv_logit_scaled(`theta[31]`)), preds41 = rbinom(4000,120, inv_logit_scaled(`theta[41]`)), preds51 = rbinom(4000,120, inv_logit_scaled(`theta[51]`)), preds61 = rbinom(4000,120, inv_logit_scaled(`theta[61]`)), preds71 = rbinom(4000,120, inv_logit_scaled(`theta[71]`)), preds81 = rbinom(4000,120, inv_logit_scaled(`theta[81]`)), preds91 = rbinom(4000,120, inv_logit_scaled(`theta[91]`)), ) d2 &lt;- d %&gt;% group_by(agent) %&gt;% dplyr::summarise(right = sum(randomChoice)) ggplot(draws_df) + geom_density(aes(posterior_preds), color = &quot;skyblue1&quot;, alpha = 0.3) + geom_density(data = d2, aes(right), color = &quot;darkblue&quot;,alpha = 0.8) + xlab(&quot;Predicted right hands out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p1 &lt;- ggplot(draws_df) + geom_density(aes(preds1), color = &quot;skyblue1&quot;, alpha = 0.3) + geom_point(x = subset(d2, agent == 1)$right, y = 0, shape = 23, color = &quot;darkblue&quot;, fill = &quot;darkblue&quot;) + theme_classic() p2 &lt;- ggplot(draws_df) + geom_density(aes(preds11), color = &quot;skyblue1&quot;, alpha = 0.3) + geom_point(x = subset(d2, agent == 11)$right, y = 0, shape = 23, color = &quot;darkblue&quot;, fill = &quot;darkblue&quot;) + theme_classic() p3 &lt;- ggplot(draws_df) + geom_density(aes(preds21), color = &quot;skyblue1&quot;, alpha = 0.3) + geom_point(x = subset(d2, agent == 21)$right, y = 0, shape = 23, color = &quot;darkblue&quot;, fill = &quot;darkblue&quot;) + theme_classic() library(patchwork) p1 + p2 + p3 6.5.3 Multilevel memory [MISSING: DAGS] [MISSING: EXPLAIN NEW STAN CODE] [MISSING: POP VS IND LEVEL PREDICTIONS] Prep the data ## Create the data d1 &lt;- d %&gt;% subset(select = c(agent, memoryChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = memoryChoice) d2 &lt;- d %&gt;% subset(select = c(agent, randomChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = randomChoice) data &lt;- list( trials = trials, agents = agents, h = as.matrix(d1[1:120,2:101]), other = as.matrix(d2[1:120,2:101]) ) Code, compile and fit the model stan_model &lt;- &quot; // // functions{ real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; array[trials, agents] int other; } // The parameters accepted by the model. parameters { real biasM; real&lt;lower = 0&gt; biasSD; real betaM; real&lt;lower = 0&gt; betaSD; array[agents] real bias; array[agents] real beta; } transformed parameters { array[trials, agents] real memory; for (agent in 1:agents){ for (trial in 1:trials){ if (trial == 1) { memory[trial, agent] = 0.5; } if (trial &lt; trials){ memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;} if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;} } } } } // The model to be estimated. model { target += normal_lpdf(biasM | 0, 1); target += normal_lpdf(biasSD | 0, .3) - normal_lccdf(0 | 0, .3); target += normal_lpdf(betaM | 0, .3); target += normal_lpdf(betaSD | 0, .3) - normal_lccdf(0 | 0, .3); target += normal_lpdf(bias | biasM, biasSD); target += normal_lpdf(beta | betaM, betaSD); for (agent in 1:agents) for (trial in 1:trials){ target += bernoulli_logit_lpmf(h[trial,agent] | bias[agent] + logit(memory[trial, agent]) * (beta[agent])); } } generated quantities{ real biasM_prior; real&lt;lower=0&gt; biasSD_prior; real betaM_prior; real&lt;lower=0&gt; betaSD_prior; real bias_prior; real beta_prior; int&lt;lower=0, upper = trials&gt; prior_preds0; int&lt;lower=0, upper = trials&gt; prior_preds1; int&lt;lower=0, upper = trials&gt; prior_preds2; int&lt;lower=0, upper = trials&gt; posterior_preds0; int&lt;lower=0, upper = trials&gt; posterior_preds1; int&lt;lower=0, upper = trials&gt; posterior_preds2; array[agents] int&lt;lower=0, upper = trials&gt; posterior_predsID0; array[agents] int&lt;lower=0, upper = trials&gt; posterior_predsID1; array[agents] int&lt;lower=0, upper = trials&gt; posterior_predsID2; biasM_prior = normal_rng(0,1); biasSD_prior = normal_lb_rng(0,0.3,0); betaM_prior = normal_rng(0,1); betaSD_prior = normal_lb_rng(0,0.3,0); bias_prior = normal_rng(biasM_prior, biasSD_prior); beta_prior = normal_rng(betaM_prior, betaSD_prior); prior_preds0 = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior)); prior_preds1 = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior)); prior_preds2 = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior)); posterior_preds0 = binomial_rng(trials, inv_logit(biasM + 0 * betaM)); posterior_preds1 = binomial_rng(trials, inv_logit(biasM + 1 * betaM)); posterior_preds2 = binomial_rng(trials, inv_logit(biasM + 2 * betaM)); for (agent in 1:agents){ posterior_predsID0[agent] = binomial_rng(trials, inv_logit(bias[agent] + 0 * beta[agent])); posterior_predsID1[agent] = binomial_rng(trials, inv_logit(bias[agent] + 1 * beta[agent])); posterior_predsID2[agent] = binomial_rng(trials, inv_logit(bias[agent] + 2 * beta[agent])); } } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W5_MultilevelMemory.stan&quot;) file &lt;- file.path(&quot;stan/W5_MultilevelMemory.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99, ) samples$save_object(file = &quot;simmodels/W5_MultilevelMemory_centered.RDS&quot;) 6.5.4 Assessing multilevel memory samples &lt;- readRDS(&quot;simmodels/W5_MultilevelMemory_centered.RDS&quot;) samples$cmdstan_diagnose() ## File /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpTP5vj3/W5_MultilevelMemory-202303101235-1-8e8f81.csv not found ## File /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpTP5vj3/W5_MultilevelMemory-202303101235-2-8e8f81.csv not found ## No valid input files, exiting. samples$summary(c(&quot;biasM&quot;, &quot;betaM&quot;, &quot;biasSD&quot;, &quot;betaSD&quot;)) ## # A tibble: 4 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 biasM 0.539 0.537 0.0872 0.0859 0.400 0.686 1.00 324. 718. ## 2 betaM 1.02 1.02 0.0700 0.0694 0.906 1.14 1.00 460. 1066. ## 3 biasSD 0.283 0.282 0.0672 0.0689 0.176 0.394 1.01 269. 277. ## 4 betaSD 0.410 0.407 0.0493 0.0499 0.332 0.494 1.00 1438. 2248. draws_df &lt;- as_draws_df(samples$draws()) p1 &lt;- ggplot(draws_df, aes(.iteration, biasM, group = .chain, color = .chain)) + geom_line() + theme_classic() p2 &lt;- ggplot(draws_df, aes(.iteration, biasSD, group = .chain, color = .chain)) + geom_line() + theme_classic() p3 &lt;- ggplot(draws_df, aes(.iteration, betaM, group = .chain, color = .chain)) + geom_line() + theme_classic() p4 &lt;- ggplot(draws_df, aes(.iteration, betaSD, group = .chain, color = .chain)) + geom_line() + theme_classic() p1 + p2 + p3 + p4 6.5.4.1 Predictive prior checks ## ggplot(draws_df) + geom_histogram(aes(`prior_preds0`), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3) + geom_histogram(aes(`prior_preds1`), color = &quot;darkblue&quot;, fill = &quot;green&quot;, alpha = 0.3) + geom_histogram(aes(`prior_preds2`), color = &quot;darkblue&quot;, fill = &quot;red&quot;, alpha = 0.3) + xlab(&quot;Predicted right hands out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 6.5.4.2 Prior posterior update checks biasM &lt;- 0 biasSD &lt;- 0.1 betaM &lt;- 1.5 betaSD &lt;- 0.3 ## p1 &lt;- ggplot(draws_df) + geom_density(aes(biasM), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(biasM_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0) + xlab(&quot;Mean bias&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p2 &lt;- ggplot(draws_df) + geom_density(aes(biasSD), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(biasSD_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0.1) + xlab(&quot;Variance of bias&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p3 &lt;- ggplot(draws_df) + geom_density(aes(betaM), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(betaM_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 1.5) + xlab(&quot;Mean Beta&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p4 &lt;- ggplot(draws_df) + geom_density(aes(betaSD), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(betaSD_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0.3) + xlab(&quot;Variance of beta&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p1 + p2 + p3 + p4 6.5.4.3 Posterior predictive checks p1 &lt;- ggplot(draws_df) + geom_histogram(aes(`prior_preds0`), color = &quot;darkblue&quot;, fill = &quot;lightblue&quot;, alpha = 0.3) + geom_histogram(aes(`posterior_preds0`), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3) + xlab(&quot;Predicted right hands out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p2 &lt;- ggplot(draws_df) + geom_histogram(aes(`prior_preds1`), color = &quot;darkblue&quot;, fill = &quot;lightblue&quot;, alpha = 0.3) + geom_histogram(aes(`posterior_preds1`), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3) + xlab(&quot;Predicted right hands out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p3 &lt;- ggplot(draws_df) + geom_histogram(aes(`prior_preds2`), color = &quot;darkblue&quot;, fill = &quot;lightblue&quot;, alpha = 0.3) + geom_histogram(aes(`posterior_preds2`), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3) + xlab(&quot;Predicted right hands out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p1 + p2 + p3 ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. p1 &lt;- ggplot(draws_df, aes(biasM, biasSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p2 &lt;- ggplot(draws_df, aes(betaM, betaSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p3 &lt;- ggplot(draws_df, aes(biasM, betaM, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p4 &lt;- ggplot(draws_df, aes(biasSD, betaSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p1 + p2 + p3 + p4 6.5.5 Multilevel memory with non centered parameterization Prep the data ## Create the data d1 &lt;- d %&gt;% subset(select = c(agent, memoryChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = memoryChoice) d2 &lt;- d %&gt;% subset(select = c(agent, randomChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = randomChoice) data &lt;- list( trials = trials, agents = agents, h = as.matrix(d1[1:120,2:101]), other = as.matrix(d2[1:120,2:101]) ) Code, compile and and fit the model ## NON-CENTERED PARAMETRIZATION stan_model_nc &lt;- &quot; // // This STAN model is a multilevel memory agent // functions{ real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; array[trials, agents] int other; } // The parameters accepted by the model. parameters { real biasM; real&lt;lower = 0&gt; biasSD; real betaM; real&lt;lower = 0&gt; betaSD; vector[agents] biasID_z; vector[agents] betaID_z; } transformed parameters { array[trials, agents] real memory; vector[agents] biasID; vector[agents] betaID; for (agent in 1:agents){ for (trial in 1:trials){ if (trial == 1) { memory[trial, agent] = 0.5; } if (trial &lt; trials){ memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;} if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;} } } } biasID = biasID_z * biasSD; betaID = betaID_z * betaSD; } // The model to be estimated. model { target += normal_lpdf(biasM | 0, 1); target += normal_lpdf(biasSD | 0, .3) - normal_lccdf(0 | 0, .3); target += normal_lpdf(betaM | 0, .3); target += normal_lpdf(betaSD | 0, .3) - normal_lccdf(0 | 0, .3); target += std_normal_lpdf(to_vector(biasID_z)); // target += normal_lpdf(to_vector(biasID_z) | 0, 1); target += std_normal_lpdf(to_vector(betaID_z)); // target += normal_lpdf(to_vector(betaID_z) | 0, 1); for (agent in 1:agents){ for (trial in 1:trials){ target += bernoulli_logit_lpmf(h[trial,agent] | biasM + biasID[agent] + logit(memory[trial, agent]) * (betaM + betaID[agent])); } } } generated quantities{ real biasM_prior; real&lt;lower=0&gt; biasSD_prior; real betaM_prior; real&lt;lower=0&gt; betaSD_prior; real bias_prior; real beta_prior; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds2; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds2; biasM_prior = normal_rng(0,1); biasSD_prior = normal_lb_rng(0,0.3,0); betaM_prior = normal_rng(0,1); betaSD_prior = normal_lb_rng(0,0.3,0); bias_prior = normal_rng(biasM_prior, biasSD_prior); beta_prior = normal_rng(betaM_prior, betaSD_prior); for (agent in 1:agents){ prior_preds0[agent] = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior)); prior_preds1[agent] = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior)); prior_preds2[agent] = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior)); posterior_preds0[agent] = binomial_rng(trials, inv_logit(biasM + biasID[agent] + 0 * (betaM + betaID[agent]))); posterior_preds1[agent] = binomial_rng(trials, inv_logit(biasM + biasID[agent] + 1 * (betaM + betaID[agent]))); posterior_preds2[agent] = binomial_rng(trials, inv_logit(biasM + biasID[agent] + 2 * (betaM + betaID[agent]))); } } &quot; write_stan_file( stan_model_nc, dir = &quot;stan/&quot;, basename = &quot;W5_MultilevelMemory_nc.stan&quot;) file &lt;- file.path(&quot;stan/W5_MultilevelMemory_nc.stan&quot;) mod_nc &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod_nc$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99, ) samples$save_object(file = &quot;simmodels/W5_MultilevelMemory_noncentered.RDS&quot;) 6.5.6 Assessing multilevel memory samples &lt;- readRDS(&quot;simmodels/W5_MultilevelMemory_noncentered.RDS&quot;) samples$cmdstan_diagnose() ## File /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpTP5vj3/W5_MultilevelMemory_nc-202303101250-1-612dbb.csv not found ## File /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpTP5vj3/W5_MultilevelMemory_nc-202303101250-2-612dbb.csv not found ## No valid input files, exiting. samples$summary(c(&quot;biasM&quot;, &quot;betaM&quot;, &quot;biasSD&quot;, &quot;betaSD&quot;)) ## # A tibble: 4 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 biasM 0.538 0.537 0.0870 0.0875 0.397 0.683 1.00 1315. 2025. ## 2 betaM 1.02 1.02 0.0726 0.0732 0.901 1.14 1.00 1187. 2168. ## 3 biasSD 0.281 0.281 0.0702 0.0698 0.168 0.401 1.00 630. 956. ## 4 betaSD 0.411 0.409 0.0497 0.0493 0.333 0.499 1.00 1394. 2137. draws_df &lt;- as_draws_df(samples$draws()) p1 &lt;- ggplot(draws_df, aes(.iteration, biasM, group = .chain, color = .chain)) + geom_line() + theme_classic() p2 &lt;- ggplot(draws_df, aes(.iteration, biasSD, group = .chain, color = .chain)) + geom_line() + theme_classic() p3 &lt;- ggplot(draws_df, aes(.iteration, betaM, group = .chain, color = .chain)) + geom_line() + theme_classic() p4 &lt;- ggplot(draws_df, aes(.iteration, betaSD, group = .chain, color = .chain)) + geom_line() + theme_classic() p1 + p2 + p3 + p4 6.5.6.1 Predictive prior checks ## ggplot(draws_df) + geom_histogram(aes(`prior_preds0[1]`), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3) + geom_histogram(aes(`prior_preds1[1]`), color = &quot;darkblue&quot;, fill = &quot;green&quot;, alpha = 0.3) + geom_histogram(aes(`prior_preds2[1]`), color = &quot;darkblue&quot;, fill = &quot;red&quot;, alpha = 0.3) + xlab(&quot;Predicted right hands out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 6.5.6.2 Prior posterior update checks biasM &lt;- 0 biasSD &lt;- 0.1 betaM &lt;- 1.5 betaSD &lt;- 0.3 ## p1 &lt;- ggplot(draws_df) + geom_density(aes(logit_scaled(biasM)), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(biasM_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0) + xlab(&quot;Mean bias&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p2 &lt;- ggplot(draws_df) + geom_density(aes(biasSD), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(biasSD_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0.1) + xlab(&quot;Variance of bias&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p3 &lt;- ggplot(draws_df) + geom_density(aes(betaM), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(betaM_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 1.5) + xlab(&quot;Mean Beta&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p4 &lt;- ggplot(draws_df) + geom_density(aes(betaSD), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(betaSD_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = 0.3) + xlab(&quot;Variance of beta&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p1 + p2 + p3 + p4 6.5.6.3 Posterior predictive checks p1 &lt;- ggplot(draws_df) + geom_histogram(aes(`prior_preds0[1]`), color = &quot;darkblue&quot;, fill = &quot;lightblue&quot;, alpha = 0.3) + geom_histogram(aes(`posterior_preds0[1]`), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3) + xlab(&quot;Predicted right hands out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p2 &lt;- ggplot(draws_df) + geom_histogram(aes(`prior_preds1[1]`), color = &quot;darkblue&quot;, fill = &quot;lightblue&quot;, alpha = 0.3) + geom_histogram(aes(`posterior_preds1[1]`), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3) + xlab(&quot;Predicted right hands out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p3 &lt;- ggplot(draws_df) + geom_histogram(aes(`prior_preds2[1]`), color = &quot;darkblue&quot;, fill = &quot;lightblue&quot;, alpha = 0.3) + geom_histogram(aes(`posterior_preds2[1]`), color = &quot;darkblue&quot;, fill = &quot;blue&quot;, alpha = 0.3) + xlab(&quot;Predicted right hands out of 120 trials&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() p1 + p2 + p3 ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. p1 &lt;- ggplot(draws_df, aes(biasM, biasSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p2 &lt;- ggplot(draws_df, aes(betaM, betaSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p3 &lt;- ggplot(draws_df, aes(biasM, betaM, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p4 &lt;- ggplot(draws_df, aes(biasSD, betaSD, group = .chain, color = .chain)) + geom_point(alpha = 0.1) + theme_classic() p1 + p2 + p3 + p4 ggplot(draws_df) + geom_density(aes(inv_logit_scaled(`biasID[1]`)), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`biasID[15]`)), fill = &quot;green&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`biasID[21]`)), fill = &quot;lightblue&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`biasID[31]`)), fill = &quot;darkblue&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`biasID[41]`)), fill = &quot;yellow&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`biasID[51]`)), fill = &quot;darkgreen&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`biasID[61]`)), fill = &quot;lightgreen&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(biasM_prior)), fill = &quot;pink&quot;, alpha = 0.3) + geom_density(aes(bias_prior), fill = &quot;purple&quot;, alpha = 0.3) + xlab(&quot;Bias parameter&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_density(aes(inv_logit_scaled(`betaID[1]`)), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`betaID[15]`)), fill = &quot;green&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`betaID[21]`)), fill = &quot;lightblue&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`betaID[31]`)), fill = &quot;darkblue&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`betaID[41]`)), fill = &quot;yellow&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`betaID[51]`)), fill = &quot;darkgreen&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(`betaID[61]`)), fill = &quot;lightgreen&quot;, alpha = 0.3) + geom_density(aes(inv_logit_scaled(betaM_prior)), fill = &quot;pink&quot;, alpha = 0.3) + geom_density(aes(beta_prior), fill = &quot;purple&quot;, alpha = 0.3) + xlab(&quot;Beta parameter&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() 6.5.7 Multilevel memory with correlation between parameters stan_model_nc_cor &lt;- &quot; // // This STAN model infers a random bias from a sequences of 1s and 0s (heads and tails) // functions{ real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; array[trials, agents] int other; } // The parameters accepted by the model. parameters { real biasM; real betaM; vector&lt;lower = 0&gt;[2] tau; matrix[2, agents] z_IDs; cholesky_factor_corr[2] L_u; } transformed parameters { array[trials, agents] real memory; matrix[agents,2] IDs; IDs = (diag_pre_multiply(tau, L_u) * z_IDs)&#39;; for (agent in 1:agents){ for (trial in 1:trials){ if (trial == 1) { memory[trial, agent] = 0.5; } if (trial &lt; trials){ memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;} if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;} } } } } // The model to be estimated. model { target += normal_lpdf(biasM | 0, 1); target += normal_lpdf(tau[1] | 0, .3) - normal_lccdf(0 | 0, .3); target += normal_lpdf(betaM | 0, .3); target += normal_lpdf(tau[2] | 0, .3) - normal_lccdf(0 | 0, .3); target += lkj_corr_cholesky_lpdf(L_u | 2); target += std_normal_lpdf(to_vector(z_IDs)); for (agent in 1:agents){ for (trial in 1:trials){ target += bernoulli_logit_lpmf(h[trial, agent] | biasM + IDs[agent, 1] + memory[trial, agent] * (betaM + IDs[agent, 2])); } } } generated quantities{ real biasM_prior; real&lt;lower=0&gt; biasSD_prior; real betaM_prior; real&lt;lower=0&gt; betaSD_prior; real bias_prior; real beta_prior; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds2; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds2; biasM_prior = normal_rng(0,1); biasSD_prior = normal_lb_rng(0,0.3,0); betaM_prior = normal_rng(0,1); betaSD_prior = normal_lb_rng(0,0.3,0); bias_prior = normal_rng(biasM_prior, biasSD_prior); beta_prior = normal_rng(betaM_prior, betaSD_prior); for (i in 1:agents){ prior_preds0[i] = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior)); prior_preds1[i] = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior)); prior_preds2[i] = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior)); posterior_preds0[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 0 * (betaM + IDs[i,2]))); posterior_preds1[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 1 * (betaM + IDs[i,2]))); posterior_preds2[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 2 * (betaM + IDs[i,2]))); } } &quot; write_stan_file( stan_model_nc_cor, dir = &quot;stan/&quot;, basename = &quot;W5_MultilevelMemory_nc_cor.stan&quot;) file &lt;- file.path(&quot;stan/W5_MultilevelMemory_nc_cor.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99, ) samples$save_object(file = &quot;simmodels/Memory_noncentered_corr.RDS&quot;) 6.5.8 Assessing multilevel memory [MISSING LOTS OF EVALUATION] samples &lt;- readRDS(&quot;simmodels/W5_MultilevelMemory_noncentered_corr.RDS&quot;) samples$cmdstan_diagnose() ## File /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpTP5vj3/W5_MultilevelMemory_nc_cor-202303100657-1-969904.csv not found ## File /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpTP5vj3/W5_MultilevelMemory_nc_cor-202303100657-2-969904.csv not found ## No valid input files, exiting. 6.5.9 Multilevel memory no pooling [MISSING: EXPLANATION OF NO POOLING] stan_model &lt;- &quot; // The input (data) for the model. n of trials and h of heads data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; array[trials, agents] int other; } // The parameters accepted by the model. parameters { array[trials] real bias; array[trials] real beta; } transformed parameters { array[trials, agents] real memory; for (agent in 1:agents){ for (trial in 1:trials){ if (trial == 1) { memory[trial, agent] = 0.5; } if (trial &lt; trials){ memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;} if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;} } } } } // The model to be estimated. model { target += normal_lpdf(bias | 0, 1); target += normal_lpdf(beta | 0, 1); for (agent in 1:agents){ for (trial in 1:trials){ target += bernoulli_logit_lpmf(h[trial, agent] | bias[agent] + memory[trial, agent] * (beta[agent])); } } } generated quantities{ real bias_prior; real beta_prior; int&lt;lower=0, upper = trials&gt; prior_preds0; int&lt;lower=0, upper = trials&gt; prior_preds1; int&lt;lower=0, upper = trials&gt; prior_preds2; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds2; bias_prior = normal_rng(0,1); beta_prior = normal_rng(0,1); prior_preds0 = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior)); prior_preds1 = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior)); prior_preds2 = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior)); for (i in 1:agents){ posterior_preds0[i] = binomial_rng(trials, inv_logit(bias[i] + 0 * (beta[i]))); posterior_preds1[i] = binomial_rng(trials, inv_logit(bias[i] + 1 * (beta[i]))); posterior_preds2[i] = binomial_rng(trials, inv_logit(bias[i] + 2 * (beta[i]))); } } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W5_MultilevelMemory_nopooling.stan&quot;) file &lt;- file.path(&quot;stan/W5_MultilevelMemory_nopooling.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99, ) samples$save_object(file = &quot;simmodels/W5_MultilevelMemory_nopooling.RDS&quot;) [MISSING: Evaluation of NO POOLING] 6.6 Multilevel full pooling [MISSING: EXPLANATION OF FULL POOLING] stan_model &lt;- &quot; // The input (data) for the model. n of trials and h of heads data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; array[trials, agents] int other; } // The parameters accepted by the model. parameters { real bias; real beta; } transformed parameters { array[trials, agents] real memory; for (agent in 1:agents){ for (trial in 1:trials){ if (trial == 1) { memory[trial, agent] = 0.5; } if (trial &lt; trials){ memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;} if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;} } } } } // The model to be estimated. model { target += normal_lpdf(bias | 0, 1); target += normal_lpdf(beta | 0, 1); for (agent in 1:agents){ for (trial in 1:trials){ target += bernoulli_logit_lpmf(h[trial, agent] | bias + memory[trial, agent] * beta); } } } generated quantities{ real bias_prior; real beta_prior; int&lt;lower=0, upper = trials&gt; prior_preds0; int&lt;lower=0, upper = trials&gt; prior_preds1; int&lt;lower=0, upper = trials&gt; prior_preds2; int&lt;lower=0, upper = trials&gt; posterior_preds0; int&lt;lower=0, upper = trials&gt; posterior_preds1; int&lt;lower=0, upper = trials&gt; posterior_preds2; bias_prior = normal_rng(0,1); beta_prior = normal_rng(0,1); prior_preds0 = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior)); prior_preds1 = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior)); prior_preds2 = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior)); posterior_preds0 = binomial_rng(trials, inv_logit(bias + 0 * (beta))); posterior_preds1 = binomial_rng(trials, inv_logit(bias + 1 * (beta))); posterior_preds2 = binomial_rng(trials, inv_logit(bias + 2 * (beta))); } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W5_MultilevelMemory_fullpooling.stan&quot;) file &lt;- file.path(&quot;stan/W5_MultilevelMemory_fullpooling.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) # The following command calls Stan with specific options. samples &lt;- mod$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99, ) samples$save_object(file = &quot;simmodels/W5_MultilevelMemory_fullpooling.RDS&quot;) [MISSING: Evaluation of FULL POOLING] [MISSING: PARAMETER RECOVERY IN A MULTILEVEL FRAMEWORK (IND VS POP)] "],["model-comparison.html", "Chapter 7 Model comparison 7.1 Define parameters 7.2 Define biased and memory agents 7.3 Generating the agents 7.4 Prep the data 7.5 Log posterior likelihood 7.6 Create the models: multilevel biased agents 7.7 Multilevel memory model 7.8 Fitting the models to the data 7.9 Calculating the expected log predictive density of a model 7.10 Implementing Cross-Validation 7.11 Calculating elpd and comparing 7.12 Limitations of model comparison techniques 7.13 Mixture models 7.14 Stan model mixing biased and noise 7.15 Fitting and assessing the model 7.16 Basic evaluation 7.17 Multilevel mixture model", " Chapter 7 Model comparison [MISSING INTRO] Imagine having several models of what might be going on and want to know which is the best explanation of the data. E.g. Are people more likely to use a memory strategy, or a win stay lose shift strategy? Or are we justified in assuming that people react differently to losses than to wins (e.g. by being more likely to shift when losing, than to stay when winning)? Or would we be justified in assuming that capuchin monkeys and cognitive science students use the same model? Model comparison defines a broad range of practices aimed at identifying among a set of models the best model for a given data set. What “best” means is, however, a non-trivial question. Ideally, “best” would mean the model describing the mechanism that actually generated the data. However, as we will see that is a tricky proposition and we analysts tend to rely on proxies. There are many of such proxies in the literature. For instance, Nicenboim et al (2023) suggests employing either Bayes Factors or cross-validation (https://vasishth.github.io/bayescogsci/book/ch-comparison.html). In this course, we rely on cross-validation based predictive performance (this chapter) and mixture models (next chapter). In other words, this chapter will assess models in terms of their (estimated) ability to predict new (test) data. Remember that predictive performance is a very useful tool, but not a magical solution. It allows us to combat overfitting to the training sample (your model snuggling to your data so much that it fits both signal and noise), but it has key limitations, which we will discuss at the end of the chapter. To learn how to make model comparison, in this chapter, we rely on our usual simulation based approach to ensure that the method is doing what we want. We simulate the behavior of biased agents playing against the memory agents. This provides us with data generated according to two different mechanisms: biased agents and memory agents. We can fit both models separately on each of the two sets of agents, so we can compare the relative performance of the two models: can we identify the true model generating the data (in a setup where truth is known)? This is what is usually called “model recovery” and complements nicely “parameter recovery”. In model recovery we assess whether we can identify the correct model, in parameter recovery we assess whether - once we know the correct model - we can identify the correct parameter values. Let’s get going. 7.1 Define parameters pacman::p_load(tidyverse, here, posterior, cmdstanr, brms, tidybayes, loo, job) # Shared parameters agents &lt;- 100 trials &lt;- 120 noise &lt;- 0 # Biased agents parameters rateM &lt;- 1.386 # roughly 0.8 once inv_logit scaled rateSD &lt;- 0.65 # roughly giving a sd of 0.1 in prob scale # Memory agents parameters biasM &lt;- 0 biasSD &lt;- 0.1 betaM &lt;- 1.5 betaSD &lt;- 0.3 7.2 Define biased and memory agents # Functions of the agents RandomAgentNoise_f &lt;- function(rate, noise) { choice &lt;- rbinom(1, 1, inv_logit_scaled(rate)) if (rbinom(1, 1, noise) == 1) { choice = rbinom(1, 1, 0.5) } return(choice) } MemoryAgentNoise_f &lt;- function(bias, beta, otherRate, noise) { rate &lt;- inv_logit_scaled(bias + beta * logit_scaled(otherRate)) choice &lt;- rbinom(1, 1, rate) if (rbinom(1, 1, noise) == 1) { choice = rbinom(1, 1, 0.5) } return(choice) } 7.3 Generating the agents [MISSING: PARALLELIZE] # Looping through all the agents to generate the data. d &lt;- NULL for (agent in 1:agents) { rate &lt;- rnorm(1, rateM, rateSD) bias &lt;- rnorm(1, biasM, biasSD) beta &lt;- rnorm(1, betaM, betaSD) randomChoice &lt;- rep(NA, trials) memoryChoice &lt;- rep(NA, trials) memoryRate &lt;- rep(NA, trials) for (trial in 1:trials) { randomChoice[trial] &lt;- RandomAgentNoise_f(rate, noise) if (trial == 1) { memoryChoice[trial] &lt;- rbinom(1,1,0.5) } else { memoryChoice[trial] &lt;- MemoryAgentNoise_f(bias, beta, mean(randomChoice[1:trial], na.rm = T), noise) } } temp &lt;- tibble(agent, trial = seq(trials), randomChoice, randomRate = rate, memoryChoice, memoryRate, noise, rateM, rateSD, bias, beta, biasM, biasSD, betaM, betaSD) if (agent &gt; 1) { d &lt;- rbind(d, temp) } else{ d &lt;- temp } } d &lt;- d %&gt;% group_by(agent) %&gt;% mutate( randomRate = cumsum(randomChoice) / seq_along(randomChoice), memoryRate = cumsum(memoryChoice) / seq_along(memoryChoice) ) 7.4 Prep the data d1 &lt;- d %&gt;% subset(select = c(agent, randomChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = randomChoice) d2 &lt;- d %&gt;% subset(select = c(agent, memoryChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = memoryChoice) ## Create the data data_biased &lt;- list( trials = trials, agents = agents, h = as.matrix(d1[,2:101]), other = as.matrix(d2[,2:101]) ) data_memory &lt;- list( trials = trials, agents = agents, h = as.matrix(d2[,2:101]), other = as.matrix(d1[,2:101]) ) 7.5 Log posterior likelihood While the previous sections did not present any new materials (and therefore weren’t much commented), as we create our Stan models to fit to the data, we need to (re)introduce the notion of log-likelihood, or even better, log posterior likelihood. Given certain values for our parameters (let’s say a bias of 0 and beta for memory of 1) and for our variables (let’s say the vector of memory values estimated by the agent on a trial by trial basis), the model will predict a certain distribution of outcomes, that is, a certain distribution of choices (n times right, m times left hand). Comparing this to the actual data, we can identify how likely the model is to produce it. In other words, the probability that the model will actually generate the data we observed out of all its possible outcomes. Remember that we are doing Bayesian statistics, so this probability needs to be combined with the probability of the parameter values given the priors on those parameters. This would give us a posterior likelihood of the model’s parameter values given the data. The last step is that we need to work on a log scale. Working on a log scale is very useful because it avoids low probabilities (close to 0) being rounded down to exactly 0. [MISSING A LINK TO A LENGTHIER EXPLANATION]. By log-transforming the posterior likelihood, we now have the log-posterior likelihood. Now, remember that our agent’s memory varies on a trial by trial level. In other words, for each data point, for each agent we can calculate separate values of log-posterior likelihood for each of the possible values of the parameters. That is, we can have a distribution of log-posterior likelihood for each data point. Luckily for us telling Stan to calculate and such distributions is extremely easy: we just need to add to the generated quantities block the same log probability density/mass statement that we use in the model block, but here we specify it should be saved (replacing target += with an actual variable to be filled). N.B. Some of you might be wandering: if Stan is already using the log-posterior probability in the sampling process, why do we need to tell it to calculate and save it? Fair enough point. But Stan does not save by default (to avoid clogging your computer with endless data) and we need the log posterior likelihood saved as “log_lik” in order to be able to use more automated functions later on. 7.6 Create the models: multilevel biased agents Remember to add the log_lik part in the generated quantities block! stan_biased_model &lt;- &quot; functions{ real normal_lb_rng(real mu, real sigma, real lb) { // normal distribution with a lower bound real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. n of trials and h of hands data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; } // The parameters accepted by the model. parameters { real thetaM; real&lt;lower = 0&gt; thetaSD; array[agents] real theta; } // The model to be estimated. model { target += normal_lpdf(thetaM | 0, 1); target += normal_lpdf(thetaSD | 0, .3) - normal_lccdf(0 | 0, .3); // The prior for theta is a uniform distribution between 0 and 1 target += normal_lpdf(theta | thetaM, thetaSD); for (i in 1:agents) target += bernoulli_logit_lpmf(h[,i] | theta[i]); } generated quantities{ real thetaM_prior; real&lt;lower=0&gt; thetaSD_prior; real&lt;lower=0, upper=1&gt; theta_prior; real&lt;lower=0, upper=1&gt; theta_posterior; int&lt;lower=0, upper = trials&gt; prior_preds; int&lt;lower=0, upper = trials&gt; posterior_preds; array[trials, agents] real log_lik; thetaM_prior = normal_rng(0,1); thetaSD_prior = normal_lb_rng(0,0.3,0); theta_prior = inv_logit(normal_rng(thetaM_prior, thetaSD_prior)); theta_posterior = inv_logit(normal_rng(thetaM, thetaSD)); prior_preds = binomial_rng(trials, inv_logit(thetaM_prior)); posterior_preds = binomial_rng(trials, inv_logit(thetaM)); for (i in 1:agents){ for (t in 1:trials){ log_lik[t,i] = bernoulli_logit_lpmf(h[t,i] | theta[i]); } } } &quot; write_stan_file( stan_biased_model, dir = &quot;stan/&quot;, basename = &quot;W6_MultilevelBias.stan&quot;) file &lt;- file.path(&quot;stan/W6_MultilevelBias.stan&quot;) mod_biased &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) 7.7 Multilevel memory model stan_memory_model &lt;- &quot; functions{ real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; array[trials, agents] int other; } // The parameters accepted by the model. parameters { real biasM; real betaM; vector&lt;lower = 0&gt;[2] tau; matrix[2, agents] z_IDs; cholesky_factor_corr[2] L_u; } transformed parameters { array[trials, agents] real memory; matrix[agents,2] IDs; IDs = (diag_pre_multiply(tau, L_u) * z_IDs)&#39;; for (agent in 1:agents){ for (trial in 1:trials){ if (trial == 1) { memory[trial, agent] = 0.5; } if (trial &lt; trials){ memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;} if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;} } } } } // The model to be estimated. model { target += normal_lpdf(biasM | 0, 1); target += normal_lpdf(tau[1] | 0, .3) - normal_lccdf(0 | 0, .3); target += normal_lpdf(betaM | 0, .3); target += normal_lpdf(tau[2] | 0, .3) - normal_lccdf(0 | 0, .3); target += lkj_corr_cholesky_lpdf(L_u | 2); target += std_normal_lpdf(to_vector(z_IDs)); for (agent in 1:agents){ for (trial in 1:trials){ target += bernoulli_logit_lpmf(h[trial, agent] | biasM + IDs[agent, 1] + memory[trial, agent] * (betaM + IDs[agent, 2])); } } } generated quantities{ real biasM_prior; real&lt;lower=0&gt; biasSD_prior; real betaM_prior; real&lt;lower=0&gt; betaSD_prior; real bias_prior; real beta_prior; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds2; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds2; array[trials, agents] real log_lik; biasM_prior = normal_rng(0,1); biasSD_prior = normal_lb_rng(0,0.3,0); betaM_prior = normal_rng(0,1); betaSD_prior = normal_lb_rng(0,0.3,0); bias_prior = normal_rng(biasM_prior, biasSD_prior); beta_prior = normal_rng(betaM_prior, betaSD_prior); for (i in 1:agents){ prior_preds0[i] = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior)); prior_preds1[i] = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior)); prior_preds2[i] = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior)); posterior_preds0[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 0 * (betaM + IDs[i,2]))); posterior_preds1[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 1 * (betaM + IDs[i,2]))); posterior_preds2[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 2 * (betaM + IDs[i,2]))); for (t in 1:trials){ log_lik[t,i] = bernoulli_logit_lpmf(h[t, i] | biasM + IDs[i, 1] + memory[t, i] * (betaM + IDs[i, 2])); } } } &quot; write_stan_file( stan_memory_model, dir = &quot;stan/&quot;, basename = &quot;W6_MultilevelMemory.stan&quot;) file &lt;- file.path(&quot;stan/W6_MultilevelMemory.stan&quot;) mod_memory &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) 7.8 Fitting the models to the data # Fitting biased agent model to biased agent data fit_biased2biased &lt;- mod_biased$sample( data = data_biased, seed = 123, chains = 1, parallel_chains = 1, threads_per_chain = 4, iter_warmup = 2000, iter_sampling = 2000, refresh = 0, output_dir = &quot;simmodels&quot;, max_treedepth = 20, adapt_delta = 0.99 ) fit_biased2biased$save_object(file = &quot;simmodels/W6_fit_biased2biased.RDS&quot;) # Fitting biased agent model to memory agent data fit_biased2memory &lt;- mod_biased$sample( data = data_memory, seed = 123, chains = 1, parallel_chains = 1, threads_per_chain = 4, iter_warmup = 2000, iter_sampling = 2000, refresh = 0, output_dir = &quot;simmodels&quot;, max_treedepth = 20, adapt_delta = 0.99 ) fit_biased2memory$save_object(file = &quot;simmodels/W6_fit_biased2memory.RDS&quot;) fit_memory2biased &lt;- mod_memory$sample( data = data_biased, seed = 123, chains = 1, parallel_chains = 1, threads_per_chain = 4, iter_warmup = 2000, iter_sampling = 2000, refresh = 0, output_dir = &quot;simmodels&quot;, max_treedepth = 20, adapt_delta = 0.99 ) fit_memory2biased$save_object(file = &quot;simmodels/W6_fit_memory2biased.RDS&quot;) fit_memory2memory &lt;- mod_memory$sample( data = data_memory, seed = 123, chains = 1, parallel_chains = 1, threads_per_chain = 4, iter_warmup = 2000, iter_sampling = 2000, refresh = 0, output_dir = &quot;simmodels&quot;, max_treedepth = 20, adapt_delta = 0.99 ) fit_memory2memory$save_object(file = &quot;simmodels/W6_fit_memory2memory.RDS&quot;) 7.9 Calculating the expected log predictive density of a model In the previous section, we fitted each model (biased and memory) to each dataset (biased and memory), and calculated and saved the log-posterior likelihood distributions for each data point. However, as we know from previous courses, calculating the goodness of fit of a model on the actual data it has been trained/fitted on is a bad idea. Models - expecially complex models - tend to overfit to the data. The multilevel implementation we have used is a bit skeptical of the data (it pools information across agents and combines it with the data from any given agent, thus de facto regularizing the estimates). Still overfitting is a serious risk. Machine learning has made common practices of validation, that is, of keeping parts of the dataset out of the training/fitting process, in order to then see how well the trained model can predict those untouched data, and get an out of sample error. [RANT ON INTERNAL VS. EXTERNAL TEST SET: HOW WELL DOES IT GENERALIZE TO DIVERSE CONTEXTS?]. When the datasets are small, as it is often the case in cognitive science, keeping a substantial portion of the data out - substantial enough to be representative of a more general population - is problematic as it risks starving the model of data: there might not be enough data for reliable estimation of the parameter values. This is where the notion of cross-validation comes in: we can split the dataset in k folds, let’s say k = 10. Then each fold is in turn kept aside as validation set, the model is fitted on the other folds, and its predictive performance tested on the validation set. Repeat this operation of each of the folds. This operation ensures that all the data can be used for training as well as for validation, and is in its own terms quite genial. However, this does not mean it is free of shortcomings. First, small validation folds might not be representative of the diversity of true out-of-sample populations - and there is a tendency to set k equal to the number of datapoints (leave-one-out cross validation). Second, there are many ways in which information could leak or contaminate across folds if the pipeline is not very careful (e.g. via data preprocessing scaling the full dataset, or hyper-parameter estimation). Third, and crucial for our case here, cross validation implies refitting the model k times, which for Bayesian models might be very cumbersome (I once had a model that took 6 weeks to run). The elpd (expected log predictive density) is an attempt at estimating the out-of-sample error without actually re-running the model. To understand elpd we need to decompose it in several steps. Log pointwise predictive density (lppd) is the sum of the logarithm of the average log posterior likelihood of each observation ( Pr(yi) ) A penalty is given according to the sum of the variance in log posterior likelihood per each observation. The more unstable (varying) the higher the penalty. This is all still fully based on the training sample. Elpd moves it one step forward by weighting the lppd according to the frequency of the observation in the dataset excluding that observation. The more frequent, the more it matters. N.B. elpd only keeps one datapoint out, meaning that dependencies within larger clusters (e.g. repeated measures by participants) confound the measure. Let’s calculate this, and then we will implement a more properly cross-validated version. fit_biased2biased &lt;- readRDS(&quot;simmodels/W6_fit_memory2memory.RDS&quot;) Loo_biased2biased &lt;- fit_biased2biased$loo(save_psis = TRUE, cores = 4) p1 &lt;- plot(Loo_biased2biased) p1 &lt;- p1 + ylim(-0.4, 0.4) fit_biased2memory &lt;- readRDS(&quot;simmodels/W6_fit_biased2memory.RDS&quot;) Loo_biased2memory &lt;- fit_biased2memory$loo(save_psis = TRUE, cores = 4) plot(Loo_biased2memory) fit_memory2biased &lt;- readRDS(&quot;simmodels/W6_fit_memory2biased.RDS&quot;) Loo_memory2biased &lt;- fit_memory2biased$loo(save_psis = TRUE, cores = 4) plot(Loo_memory2biased) fit_memory2memory &lt;- readRDS(&quot;simmodels/W6_fit_memory2memory.RDS&quot;) Loo_memory2memory &lt;- fit_memory2memory$loo(save_psis = TRUE, cores = 4) plot(Loo_memory2memory) elpd &lt;- tibble( n = seq(12000), biased_diff_elpd = Loo_biased2biased$pointwise[, &quot;elpd_loo&quot;] - Loo_memory2biased$pointwise[, &quot;elpd_loo&quot;], memory_diff_elpd = Loo_memory2memory$pointwise[, &quot;elpd_loo&quot;] - Loo_biased2memory$pointwise[, &quot;elpd_loo&quot;]) p1 &lt;- ggplot(elpd, aes(x = n, y = biased_diff_elpd)) + geom_point(alpha = .1) + #xlim(.5,1.01) + #ylim(-1.5,1.5) + geom_hline(yintercept = 0, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + theme_bw() p2 &lt;- ggplot(elpd, aes(x = n, y = memory_diff_elpd)) + geom_point(alpha = .1) + #xlim(.5,1.01) + #ylim(-1.5,1.5) + geom_hline(yintercept = 0, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + theme_bw() library(patchwork) p1 + p2 loo_compare(Loo_biased2biased, Loo_memory2biased) ## elpd_diff se_diff ## model1 0.0 0.0 ## model2 -1414.1 83.1 loo_compare(Loo_biased2memory, Loo_memory2memory) ## elpd_diff se_diff ## model2 0.0 0.0 ## model1 -127.1 11.9 loo_model_weights(list(Loo_biased2biased, Loo_memory2biased)) ## Method: stacking ## ------ ## weight ## model1 0.768 ## model2 0.232 loo_model_weights(list(Loo_biased2memory, Loo_memory2memory)) ## Method: stacking ## ------ ## weight ## model1 0.000 ## model2 1.000 7.10 Implementing Cross-Validation As we mentioned, elpd per se is only an approximation of the cross-validated performance and it only leaves one datapoint out at a time. [MISSING: VERSION W TRANSFORMED DATA] 7.10.1 Create cross-validation ready stan model for biased agents N.B. compared to before we also need to include specifics for test data stan_biased_cv_model &lt;- &quot; // // This STAN model infers a random bias from a sequences of 1s and 0s (right and left). Now multilevel // functions{ real normal_lb_rng(real mu, real sigma, real lb) { // normal distribution with a lower bound real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. n of trials and h of hands data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; int&lt;lower = 1&gt; agents_test; array[trials, agents_test] int h_test; } // The parameters accepted by the model. parameters { real thetaM; real&lt;lower = 0&gt; thetaSD; array[agents] real theta; } // The model to be estimated. model { target += normal_lpdf(thetaM | 0, 1); target += normal_lpdf(thetaSD | 0, .3) - normal_lccdf(0 | 0, .3); // The prior for theta is a uniform distribution between 0 and 1 target += normal_lpdf(theta | thetaM, thetaSD); for (i in 1:agents) target += bernoulli_logit_lpmf(h[,i] | theta[i]); } generated quantities{ real thetaM_prior; real&lt;lower=0&gt; thetaSD_prior; real&lt;lower=0, upper=1&gt; theta_prior; real&lt;lower=0, upper=1&gt; theta_posterior; int&lt;lower=0, upper = trials&gt; prior_preds; int&lt;lower=0, upper = trials&gt; posterior_preds; array[trials, agents] real log_lik; array[trials, agents_test] real log_lik_test; thetaM_prior = normal_rng(0,1); thetaSD_prior = normal_lb_rng(0,0.3,0); theta_prior = inv_logit(normal_rng(thetaM_prior, thetaSD_prior)); theta_posterior = inv_logit(normal_rng(thetaM, thetaSD)); prior_preds = binomial_rng(trials, inv_logit(thetaM_prior)); posterior_preds = binomial_rng(trials, inv_logit(thetaM)); for (i in 1:agents){ for (t in 1:trials){ log_lik[t,i] = bernoulli_logit_lpmf(h[t,i] | theta[i]); } } for (i in 1:agents_test){ for (t in 1:trials){ log_lik_test[t,i] = bernoulli_lpmf(h_test[t,i] | theta_posterior); } } } &quot; write_stan_file( stan_biased_cv_model, dir = &quot;stan/&quot;, basename = &quot;W6_MultilevelBias_cv.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W6_MultilevelBias_cv.stan&quot; file &lt;- file.path(&quot;stan/W6_MultilevelBias_cv.stan&quot;) mod_biased_cv &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) 7.10.2 Create cross-validation ready stan model for memory agents stan_memory_cv_model &lt;- &quot; // // This STAN model infers a random bias from a sequences of 1s and 0s (heads and tails) // functions{ real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; array[trials, agents] int other; int&lt;lower = 1&gt; agents_test; array[trials, agents_test] int h_test; array[trials, agents_test] int other_test; } // The parameters accepted by the model. parameters { real biasM; real betaM; vector&lt;lower = 0&gt;[2] tau; matrix[2, agents] z_IDs; cholesky_factor_corr[2] L_u; } transformed parameters { array[trials, agents] real memory; array[trials, agents_test] real memory_test; matrix[agents,2] IDs; IDs = (diag_pre_multiply(tau, L_u) * z_IDs)&#39;; for (agent in 1:agents){ for (trial in 1:trials){ if (trial == 1) { memory[trial, agent] = 0.5; } if (trial &lt; trials){ memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;} if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;} } } } for (agent in 1:agents_test){ for (trial in 1:trials){ if (trial == 1) { memory_test[trial, agent] = 0.5; } if (trial &lt; trials){ memory_test[trial + 1, agent] = memory_test[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial); if (memory_test[trial + 1, agent] == 0){memory_test[trial + 1, agent] = 0.01;} if (memory_test[trial + 1, agent] == 1){memory_test[trial + 1, agent] = 0.99;} } } } } // The model to be estimated. model { target += normal_lpdf(biasM | 0, 1); target += normal_lpdf(tau[1] | 0, .3) - normal_lccdf(0 | 0, .3); target += normal_lpdf(betaM | 0, .3); target += normal_lpdf(tau[2] | 0, .3) - normal_lccdf(0 | 0, .3); target += lkj_corr_cholesky_lpdf(L_u | 2); target += std_normal_lpdf(to_vector(z_IDs)); for (agent in 1:agents){ for (trial in 1:trials){ target += bernoulli_logit_lpmf(h[trial, agent] | biasM + IDs[agent, 1] + memory[trial, agent] * (betaM + IDs[agent, 2])); } } } generated quantities{ real biasM_prior; real&lt;lower=0&gt; biasSD_prior; real betaM_prior; real&lt;lower=0&gt; betaSD_prior; real bias_prior; real beta_prior; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; prior_preds2; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds0; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds1; array[agents] int&lt;lower=0, upper = trials&gt; posterior_preds2; array[trials, agents] real log_lik; array[trials, agents_test] real log_lik_test; biasM_prior = normal_rng(0,1); biasSD_prior = normal_lb_rng(0,0.3,0); betaM_prior = normal_rng(0,1); betaSD_prior = normal_lb_rng(0,0.3,0); bias_prior = normal_rng(biasM_prior, biasSD_prior); beta_prior = normal_rng(betaM_prior, betaSD_prior); for (i in 1:agents){ prior_preds0[i] = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior)); prior_preds1[i] = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior)); prior_preds2[i] = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior)); posterior_preds0[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 0 * (betaM + IDs[i,2]))); posterior_preds1[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 1 * (betaM + IDs[i,2]))); posterior_preds2[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] + 2 * (betaM + IDs[i,2]))); for (t in 1:trials){ log_lik[t,i] = bernoulli_logit_lpmf(h[t, i] | biasM + IDs[i, 1] + memory[t, i] * (betaM + IDs[i, 2])); } } for (i in 1:agents_test){ for (t in 1:trials){ log_lik_test[t,i] = bernoulli_logit_lpmf(h_test[t,i] | biasM + memory_test[t, i] * betaM); } } } &quot; write_stan_file( stan_memory_cv_model, dir = &quot;stan/&quot;, basename = &quot;W6_MultilevelMemory_cv.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W6_MultilevelMemory_cv.stan&quot; file &lt;- file.path(&quot;stan/W6_MultilevelMemory_cv.stan&quot;) mod_memory_cv &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) [MISSING: PARALLELIZE] d$fold &lt;- kfold_split_grouped(K = 10, x = d$agent) log_pd_biased_kfold &lt;- matrix(nrow = 1000, ncol = 12000) log_pd_memory_kfold &lt;- matrix(nrow = 1000, ncol = 12000) for (k in unique(d$fold)) { # Training set for k d_train &lt;- d %&gt;% filter(fold != k) ## Create the data d_memory1_train &lt;- d_train %&gt;% subset(select = c(agent, memoryChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = memoryChoice) d_memory2_train &lt;- d_train %&gt;% subset(select = c(agent, randomChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = randomChoice) agents_n &lt;- length(unique(d_train$agent)) d_test &lt;- d %&gt;% filter(fold == k) d_memory1_test &lt;- d_test %&gt;% subset(select = c(agent, memoryChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = memoryChoice) d_memory2_test &lt;- d_test %&gt;% subset(select = c(agent, randomChoice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = randomChoice) agents_test_n &lt;- length(unique(d_test$agent)) data_memory &lt;- list( trials = trials, agents = agents_n, agents_test = agents_test_n, h = as.matrix(d_memory1_train[,2:(agents_n + 1)]), other = as.matrix(d_memory2_train[,2:(agents_n + 1)]), h_test = as.matrix(d_memory1_test[,2:(agents_test_n + 1)]), other_test = as.matrix(d_memory2_test[,2:(agents_test_n + 1)])) # Train the models fit_random &lt;- mod_biased_cv$sample( data = data_memory, seed = 123, chains = 1, threads_per_chain = 4, iter_warmup = 1000, iter_sampling = 1000, refresh = 1000, max_treedepth = 20, adapt_delta = 0.99 ) fit_memory &lt;- mod_memory_cv$sample( data = data_memory, seed = 123, chains = 1, threads_per_chain = 4, iter_warmup = 1000, iter_sampling = 1000, refresh = 1000, max_treedepth = 20, adapt_delta = 0.99 ) # Extract log likelihood which represents # the pointwise predictive density. # n.b. the matrix has 1000 row, and 12000 columns. # d$fold==k yields 12000 logical values, of which 1200 TRUEs, identifying 1200 columns ## the fit blabla yields 1000 obs (samples) and 1190 variables instead of 1200 log_pd_biased_kfold[, d$fold == k] &lt;- fit_random$draws(&quot;log_lik_test&quot;, format = &quot;matrix&quot;) log_pd_memory_kfold[, d$fold == k] &lt;- fit_memory$draws(&quot;log_lik_test&quot;, format = &quot;matrix&quot;) } save(log_pd_biased_kfold, log_pd_memory_kfold, file = &quot;simmodels/W6_CV_Biased&amp;Memory.RData&quot;) 7.11 Calculating elpd and comparing load(&quot;simmodels/W6_CV_Biased&amp;Memory.RData&quot;) elpd_biased_kfold &lt;- elpd(log_pd_biased_kfold) elpd_memory_kfold &lt;- elpd(log_pd_memory_kfold) loo_compare(elpd_biased_kfold, elpd_memory_kfold) ## elpd_diff se_diff ## model1 0.0 0.0 ## model2 -437.3 23.9 #loo_model_weights(elpd_biased_kfold, elpd_memory_kfold) 7.12 Limitations of model comparison techniques it might be overfitting to the training population, that is, to the 7.13 Mixture models 7.13.1 Load the dataset We load the data set from chapter NN, where we loop through possible rates and noise levels, and pick one agent to build up the model progressively. d &lt;- read_csv(&quot;simdata/W3_randomnoise.csv&quot;) ## Rows: 7920 Columns: 5 ## ── Column specification ──────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## dbl (5): trial, choice, rate, noise, cumulativerate ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. dd &lt;- d %&gt;% subset(rate == 0.8 &amp; noise == 0.1) data &lt;- list( n = 120, h = dd$choice ) 7.14 Stan model mixing biased and noise We then build a Stan model with the noise parameter stan_mixture_model &lt;- &quot; // This Stan model defines a mixture of bernoulli (random bias + noise) // // The input (data) for the model. n of trials and h of heads data { int&lt;lower=1&gt; n; array[n] int h; } // The parameters accepted by the model. parameters { real bias; real noise; } // The model to be estimated. model { // The prior for theta is a uniform distribution between 0 and 1 target += normal_lpdf(bias | 0, 1); target += normal_lpdf(noise | 0, 1); // The model consists of a binomial distributions with a rate theta target += log_sum_exp(log(inv_logit(noise)) + bernoulli_logit_lpmf(h | 0), log1m(inv_logit(noise)) + bernoulli_logit_lpmf(h | bias)); } generated quantities{ real&lt;lower=0, upper=1&gt; noise_p; real&lt;lower=0, upper=1&gt; bias_p; noise_p = inv_logit(noise); bias_p = inv_logit(bias); } &quot; write_stan_file( stan_mixture_model, dir = &quot;stan/&quot;, basename = &quot;W6_MixtureSingle.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W6_MixtureSingle.stan&quot; file &lt;- file.path(&quot;stan/W6_MixtureSingle.stan&quot;) mod_mixture &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) 7.15 Fitting and assessing the model samples &lt;- mod_mixture$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 1 Iteration: 500 / 4000 [ 12%] (Warmup) ## Chain 1 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 1 Iteration: 1500 / 4000 [ 37%] (Warmup) ## Chain 1 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 1 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 1 Iteration: 2500 / 4000 [ 62%] (Sampling) ## Chain 2 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 2 Iteration: 500 / 4000 [ 12%] (Warmup) ## Chain 2 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 2 Iteration: 1500 / 4000 [ 37%] (Warmup) ## Chain 2 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 2 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 2 Iteration: 2500 / 4000 [ 62%] (Sampling) ## Chain 1 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 1 Iteration: 3500 / 4000 [ 87%] (Sampling) ## Chain 1 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 2 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 2 Iteration: 3500 / 4000 [ 87%] (Sampling) ## Chain 2 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 1 finished in 0.2 seconds. ## Chain 2 finished in 0.2 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 0.2 seconds. ## Total execution time: 0.3 seconds. save(samples, data, file = &quot;simmodels/W7_singlemixture.RData&quot;) samples$save_object(file = &quot;simmodels/W7_singlemixture.RDS&quot;) samples$save_output_files(dir = &quot;simmodels&quot;, basename = &quot;W7_singlemixture&quot;) ## Moved 2 files and set internal paths to new locations: ## - /Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/simmodels/W7_singlemixture-202402142307-1-7cd9f8.csv ## - /Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/simmodels/W7_singlemixture-202402142307-2-7cd9f8.csv [MISSING: EVALUATION] 7.16 Basic evaluation samples$summary() ## # A tibble: 5 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -65.7 -65.4 1.03 0.713 -67.7 -64.7 1.00 1396. 1708. ## 2 bias 1.28 1.28 0.216 0.212 0.942 1.65 1.00 1990. 1860. ## 3 noise -0.400 -0.408 0.928 0.941 -1.92 1.11 1.00 2054. 2137. ## 4 noise_p 0.416 0.399 0.193 0.218 0.128 0.753 1.00 2054. 2137. ## 5 bias_p 0.781 0.782 0.0364 0.0361 0.719 0.839 1.00 1990. 1860. 7.17 Multilevel mixture model ### Multilevel mixture stan_multilevelMixture_model &lt;- &quot; // // This Stan model defines a mixture of bernoulli (random bias + noise) // functions{ real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. n of trials and h of heads data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; } // The parameters accepted by the model. parameters { real thetaM; real noiseM; // p of noise vector&lt;lower = 0&gt;[2] tau; matrix[2, agents] z_IDs; cholesky_factor_corr[2] L_u; } transformed parameters { matrix[agents,2] IDs; IDs = (diag_pre_multiply(tau, L_u) * z_IDs)&#39;; } // The model to be estimated. model { target += normal_lpdf(thetaM | 0, 1); target += normal_lpdf(tau[1] | 0, .3) - normal_lccdf(0 | 0, .3); target += normal_lpdf(noiseM | -1, .5); target += normal_lpdf(tau[2] | 0, .3) - normal_lccdf(0 | 0, .3); target += lkj_corr_cholesky_lpdf(L_u | 2); target += std_normal_lpdf(to_vector(z_IDs)); for (i in 1:agents) target += log_sum_exp( log(inv_logit(noiseM + IDs[i,2])) + // p of noise bernoulli_logit_lpmf(h[,i] | 0), // times post likelihood of the noise model log1m(inv_logit(noiseM + IDs[i,2])) + // 1 - p of noise bernoulli_logit_lpmf(h[,i] | thetaM + IDs[i,1])); // times post likelihood of the bias model } generated quantities{ real thetaM_prior; real&lt;lower=0&gt; thetaSD_prior; real noiseM_prior; real&lt;lower=0&gt; noiseSD_prior; real&lt;lower=0, upper=1&gt; theta_prior; real&lt;lower=0, upper=1&gt; noise_prior; real&lt;lower=0, upper=1&gt; theta_posterior; real&lt;lower=0, upper=1&gt; noise_posterior; array[trials,agents] int&lt;lower=0, upper = trials&gt; prior_noise; array[trials,agents] int&lt;lower=0, upper = trials&gt; posterior_noise; array[trials,agents] int&lt;lower=0, upper = trials&gt; prior_preds; array[trials,agents] int&lt;lower=0, upper = trials&gt; posterior_preds; array[trials, agents] real log_lik; thetaM_prior = normal_rng(0,1); thetaSD_prior = normal_lb_rng(0,0.3,0); theta_prior = inv_logit(normal_rng(thetaM_prior, thetaSD_prior)); noiseM_prior = normal_rng(-1,.5); noiseSD_prior = normal_lb_rng(0,0.3,0); noise_prior = inv_logit(normal_rng(noiseM_prior, noiseSD_prior)); theta_posterior = inv_logit(normal_rng(thetaM, tau[1])); noise_posterior = inv_logit(normal_rng(noiseM, tau[2])); for (i in 1:agents){ for (t in 1:trials){ prior_noise[t,i] = bernoulli_rng(noise_prior); posterior_noise[t,i] = bernoulli_rng(inv_logit(noiseM + IDs[i,2])); if(prior_noise[t,i]==1){ prior_preds[t,i] = bernoulli_rng(theta_prior); } else{ prior_preds[t,i] = bernoulli_rng(0.5); } if(posterior_noise[t,i]==1){ posterior_preds[t,i] = bernoulli_rng(inv_logit(thetaM + IDs[i,1])); } else{ posterior_preds[t,i] = bernoulli_rng(0.5); } log_lik[t,i] = log_sum_exp( log(inv_logit(noiseM + IDs[i,2])) + // p of noise bernoulli_logit_lpmf(h[t,i] | 0), // times post likelihood of the noise model log1m(inv_logit(noiseM + IDs[i,2])) + // 1 - p of noise bernoulli_logit_lpmf(h[t,i] | thetaM + IDs[i,1])); // times post likelihood of the bias model } } } &quot; write_stan_file( stan_multilevelMixture_model, dir = &quot;stan/&quot;, basename = &quot;W6_MixtureMultilevel.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W6_MixtureMultilevel.stan&quot; file &lt;- file.path(&quot;stan/W6_MixtureMultilevel.stan&quot;) mod_mixture &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) samples &lt;- mod_mixture$sample( data = data_biased, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 500, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 2 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 1 Iteration: 500 / 4000 [ 12%] (Warmup) ## Chain 2 Iteration: 500 / 4000 [ 12%] (Warmup) ## Chain 1 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 2 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 1 Iteration: 1500 / 4000 [ 37%] (Warmup) ## Chain 2 Iteration: 1500 / 4000 [ 37%] (Warmup) ## Chain 1 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 1 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 2 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 2 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 1 Iteration: 2500 / 4000 [ 62%] (Sampling) ## Chain 2 Iteration: 2500 / 4000 [ 62%] (Sampling) ## Chain 1 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 2 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 1 Iteration: 3500 / 4000 [ 87%] (Sampling) ## Chain 2 Iteration: 3500 / 4000 [ 87%] (Sampling) ## Chain 1 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 1 finished in 126.5 seconds. ## Chain 2 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 2 finished in 128.0 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 127.2 seconds. ## Total execution time: 128.2 seconds. save(samples, data, file = &quot;simmodels/W7_multimixture.RData&quot;) samples$save_object(file = &quot;simmodels/W7_multimixture.RDS&quot;) samples$save_output_files(dir = &quot;simmodels&quot;, basename = &quot;W7_multimixture&quot;) ## Moved 2 files and set internal paths to new locations: ## - /Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/simmodels/W7_multimixture-202402142310-1-34d434.csv ## - /Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/simmodels/W7_multimixture-202402142310-2-34d434.csv [MISSING: EVALUATION] samples$summary() ## # A tibble: 60,417 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -6.36e+3 -6.36e+3 12.4 12.3 -6.38e+3 -6.34e+3 1.00 1042. 1964. ## 2 thetaM 1.36e+0 1.36e+0 0.0681 0.0686 1.25e+0 1.48e+0 1.00 690. 1295. ## 3 noiseM -2.50e+0 -2.49e+0 0.316 0.315 -3.02e+0 -1.98e+0 1.00 4449. 2822. ## 4 tau[1] 6.13e-1 6.12e-1 0.0512 0.0501 5.32e-1 7.01e-1 1.00 1328. 2398. ## 5 tau[2] 2.04e-1 1.74e-1 0.154 0.150 1.65e-2 5.04e-1 1.00 3225. 2146. ## 6 z_IDs[1,… -9.89e-1 -9.90e-1 0.335 0.323 -1.54e+0 -4.32e-1 1.00 3404. 2731. ## 7 z_IDs[2,… -1.27e-2 -3.20e-2 0.999 0.970 -1.66e+0 1.65e+0 1.00 6980. 2385. ## 8 z_IDs[1,… 2.07e+0 2.05e+0 0.522 0.508 1.25e+0 2.97e+0 1.00 5776. 3029. ## 9 z_IDs[2,… -1.36e-2 -3.70e-3 1.00 0.980 -1.66e+0 1.64e+0 1.00 6082. 2961. ## 10 z_IDs[1,… -4.31e-1 -4.35e-1 0.356 0.362 -1.02e+0 1.60e-1 1.00 3908. 2225. ## # ℹ 60,407 more rows samples$loo() ## Warning: Some Pareto k diagnostic values are too high. See help(&#39;pareto-k-diagnostic&#39;) for details. ## ## Computed from 4000 by 12000 log-likelihood matrix ## ## Estimate SE ## elpd_loo -6171.3 52.2 ## p_loo 111.5 2.5 ## looic 12342.5 104.3 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 11732 97.8% 586 ## (0.5, 0.7] (ok) 174 1.5% 1624 ## (0.7, 1] (bad) 94 0.8% 718 ## (1, Inf) (very bad) 0 0.0% &lt;NA&gt; ## See help(&#39;pareto-k-diagnostic&#39;) for details. [MISSING: PARAMETER RECOVERY] [MISSING: BIASED VS. MEMORY?] "],["bonus-chapter-additional-models-developed-by-students.html", "Chapter 8 Bonus chapter: Additional models developed by students 8.1 Additional models 8.2 Implementing the WSLS model 8.3 Load packages 8.4 Generate data 8.5 Sanity check for the data 8.6 More sanity check 8.7 Create data for single agent model 8.8 Create the model 8.9 Basic assessment 8.10 Create multilevel data 8.11 Create the model 8.12 Quality checks", " Chapter 8 Bonus chapter: Additional models developed by students 8.1 Additional models Additional models that have been developed by previous students: 8.1.1 Probabilistic Win Stay Lose Shift 8.1.2 Probabilistic asymmetric Win Stay Lose Shift 8.1.3 Memory agent with exponential memory decay (rate) Memory = alpha * memory + (1 - alpha) * otherChoice 8.1.4 Memory agent with exponential memory decay (exponential) The agent uses a weighted memory store, where previous choices are weighted by a factor based on how far back in the past they were made, represented by power. The agent first creates a vector of weights for each of the previous choices based on their position in the memory store and the power value. This model implements exponential decay of memory, according to a power law. Specifically, the opposing agent’s choices up to the present trial are encoded as 1’s and -1’s. The choices are weighted, and then summed. So, on trial i, the memory of the previous trial j is given a weight corresponding to j^(-1). Higher values of j correspond to earlier trials, with j = 1 being the most recent. Then a choice is made based on this weight according to the following formula: Theta = inv_logit(alpha + beta * weightedMemory) [N.B. really poor parameter recovery] 8.1.5 Memory agent with exponential memory decay, but separate memory for wins and losses [N.B. really poor parameter recovery] 8.1.6 Memory agent with exponential memory decay, and with confidence Confidence is initialized at 0. There is a fixed confidence rate, which is added to confidence if the agent wins, subtracted if it loses. Confidence is then added to beta. 8.1.7 Reinforcement learning (Rescorla Wagner) 8.1.8 Hierarchical gaussian filter 8.2 Implementing the WSLS model [Motivating the choice to showcase the WSLS amongst all models] 8.3 Load packages pacman::p_load(tidyverse, here, posterior, cmdstanr, brms, tidybayes, loo) 8.4 Generate data [MISSING: EXPLAIN THE MODEL STEP BY STEP] [MISSING: PARALLELIZE AND MAKE IT MORE SIMILAR TO PREVIOUS DATASETS] 8.5 Sanity check for the data d &lt;- d %&gt;% group_by(agent, strategy) %&gt;% mutate( nextChoice = lead(choice), prevWin = lag(win), prevLose = lag(lose), cumulativerate = cumsum(choice) / seq_along(choice), performance = cumsum(feedback) / seq_along(feedback) ) %&gt;% subset(complete.cases(d)) %&gt;% subset(trial &gt; 1) p1 &lt;- ggplot(d, aes(trial, cumulativerate, group = agent, color = agent)) + geom_line() + geom_hline(yintercept = 0.5, linetype = &quot;dashed&quot;) + ylim(0,1) + theme_classic() + facet_wrap(.~strategy) p1 p2a &lt;- ggplot(subset(d, strategy == &quot;Random&quot;), aes(trial, 1 - performance, group = agent, color = agent)) + geom_line() + geom_hline(yintercept = 0.5, linetype = &quot;dashed&quot;) + ylim(0,1) + theme_classic() p2b &lt;- ggplot(subset(d, strategy == &quot;WSLS&quot;), aes(trial, performance, group = agent, color = agent)) + geom_line() + geom_hline(yintercept = 0.5, linetype = &quot;dashed&quot;) + ylim(0,1) + theme_classic() library(patchwork) p2a + p2b 8.6 More sanity check ## Checking lose/win are orthogonal ggplot(d, aes(win, lose)) + geom_point() + theme_bw() ## Checking lose/win do determine choice d %&gt;% subset(strategy == &quot;WSLS&quot;) %&gt;% mutate(nextChoice = lead(choice)) %&gt;% group_by(agent, win, lose) %&gt;% summarize(heads = mean(nextChoice)) %&gt;% ggplot(aes(win, heads)) + geom_point() + theme_bw() + facet_wrap(~lose) ## `summarise()` has grouped output by &#39;agent&#39;, &#39;win&#39;. You can override using the ## `.groups` argument. ## Warning: Removed 100 rows containing missing values (`geom_point()`). 8.7 Create data for single agent model d_a &lt;- d %&gt;% subset( strategy == &quot;WSLS&quot; &amp; agent == 2 ) data_wsls_simple &lt;- list( trials = trials - 1, h = d_a$choice, win = d_a$prevWin, lose = d_a$prevLose ) 8.8 Create the model [MISSING: MORE MEANINGFUL PREDICTIONS, BASED ON THE 4 SCENARIOS] stan_wsls_model &lt;- &quot; functions{ real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } data { int&lt;lower = 1&gt; trials; array[trials] int h; vector[trials] win; vector[trials] lose; } parameters { real alpha; real winB; real loseB; } model { target += normal_lpdf(alpha | 0, .3); target += normal_lpdf(winB | 1, 1); target += normal_lpdf(loseB | 1, 1); target += bernoulli_logit_lpmf(h | alpha + winB * win + loseB * lose); } generated quantities{ real alpha_prior; real winB_prior; real loseB_prior; array[trials] int prior_preds; array[trials] int posterior_preds; vector[trials] log_lik; alpha_prior = normal_rng(0, 1); winB_prior = normal_rng(0, 1); loseB_prior = normal_rng(0, 1); prior_preds = bernoulli_rng(inv_logit(winB_prior * win + loseB_prior * lose)); posterior_preds = bernoulli_rng(inv_logit(winB * win + loseB * lose)); for (t in 1:trials){ log_lik[t] = bernoulli_logit_lpmf(h[t] | winB * win + loseB * lose); } } &quot; write_stan_file( stan_wsls_model, dir = &quot;stan/&quot;, basename = &quot;W8_WSLS.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W8_WSLS.stan&quot; file &lt;- file.path(&quot;stan/W8_WSLS.stan&quot;) mod_wsls_simple &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;), pedantic = TRUE) samples_wsls_simple &lt;- mod_wsls_simple$sample( data = data_wsls_simple, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 1000, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 1 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 1 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 1 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 2 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 2 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 2 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 2 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 1 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 2 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 1 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 2 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 1 finished in 0.6 seconds. ## Chain 2 finished in 0.6 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 0.6 seconds. ## Total execution time: 0.8 seconds. 8.9 Basic assessment samples_wsls_simple$summary() ## # A tibble: 364 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -7.23e+1 -7.20e+1 1.26 1.04 -74.8 -71.0 1.00 1537. 2227. ## 2 alpha -5.53e-2 -5.34e-2 0.199 0.200 -0.389 0.265 1.00 2359. 2142. ## 3 winB 1.02e+0 1.01e+0 0.297 0.304 0.547 1.52 1.00 2311. 2347. ## 4 loseB 1.10e+0 1.09e+0 0.322 0.311 0.589 1.65 1.00 2208. 2225. ## 5 alpha_prior -1.14e-2 -5.82e-3 0.983 0.959 -1.66 1.57 1.00 4099. 4033. ## 6 winB_prior -1.96e-2 -2.65e-2 0.999 0.996 -1.63 1.67 1.00 4182. 3530. ## 7 loseB_prior 1.86e-4 -5.70e-3 1.01 1.02 -1.65 1.67 1.00 3953. 3659. ## 8 prior_preds[1] 5.05e-1 1 e+0 0.500 0 0 1 1.00 3797. NA ## 9 prior_preds[2] 5.06e-1 1 e+0 0.500 0 0 1 1.00 4120. NA ## 10 prior_preds[3] 5.08e-1 1 e+0 0.500 0 0 1 1.00 3941. NA ## # ℹ 354 more rows # Extract posterior samples and include sampling of the prior: draws_df &lt;- as_draws_df(samples_wsls_simple$draws()) # Now let&#39;s plot the density for theta (prior and posterior) ggplot(draws_df) + geom_density(aes(alpha), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(alpha_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = d_a$alpha[1]) + xlab(&quot;Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_density(aes(winB), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(winB_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = d_a$betaWin[1]) + xlab(&quot;Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_density(aes(loseB), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(loseB_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = d_a$betaLose[1]) + xlab(&quot;Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() [MISSING: FULL PARAMETER RECOVERY] 8.10 Create multilevel data ## Now multilevel model d_wsls1 &lt;- d %&gt;% subset(strategy == &quot;WSLS&quot;) %&gt;% subset(select = c(agent, choice)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = choice) d_wsls2 &lt;- d %&gt;% subset(strategy == &quot;WSLS&quot;) %&gt;% subset(select = c(agent, prevWin)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = prevWin) d_wsls3 &lt;- d %&gt;% subset(strategy == &quot;WSLS&quot;) %&gt;% subset(select = c(agent, prevLose)) %&gt;% mutate(row = row_number()) %&gt;% pivot_wider(names_from = agent, values_from = prevLose) ## Create the data data_wsls &lt;- list( trials = trials - 1, agents = agents, h = as.matrix(d_wsls1[,2:(agents + 1)]), win = as.matrix(d_wsls2[,2:(agents + 1)]), lose = as.matrix(d_wsls3[,2:(agents + 1)]) ) 8.11 Create the model [MISSING: ADD BIAS] [MISSING: BETTER PREDICTIONS BASED ON 4 SCENARIOS] stan_wsls_ml_model &lt;- &quot; functions{ real normal_lb_rng(real mu, real sigma, real lb) { real p = normal_cdf(lb | mu, sigma); // cdf for bounds real u = uniform_rng(p, 1); return (sigma * inv_Phi(u)) + mu; // inverse cdf for value } } // The input (data) for the model. data { int&lt;lower = 1&gt; trials; int&lt;lower = 1&gt; agents; array[trials, agents] int h; array[trials, agents] real win; array[trials, agents] real lose; } parameters { real winM; real loseM; vector&lt;lower = 0&gt;[2] tau; matrix[2, agents] z_IDs; cholesky_factor_corr[2] L_u; } transformed parameters { matrix[agents,2] IDs; IDs = (diag_pre_multiply(tau, L_u) * z_IDs)&#39;; } model { target += normal_lpdf(winM | 0, 1); target += normal_lpdf(tau[1] | 0, .3) - normal_lccdf(0 | 0, .3); target += normal_lpdf(loseM | 0, .3); target += normal_lpdf(tau[2] | 0, .3) - normal_lccdf(0 | 0, .3); target += lkj_corr_cholesky_lpdf(L_u | 2); target += std_normal_lpdf(to_vector(z_IDs)); for (i in 1:agents) target += bernoulli_logit_lpmf(h[,i] | to_vector(win[,i]) * (winM + IDs[i,1]) + to_vector(lose[,i]) * (loseM + IDs[i,2])); } generated quantities{ real winM_prior; real&lt;lower=0&gt; winSD_prior; real loseM_prior; real&lt;lower=0&gt; loseSD_prior; real win_prior; real lose_prior; array[trials,agents] int&lt;lower=0, upper = trials&gt; prior_preds; array[trials,agents] int&lt;lower=0, upper = trials&gt; posterior_preds; array[trials, agents] real log_lik; winM_prior = normal_rng(0,1); winSD_prior = normal_lb_rng(0,0.3,0); loseM_prior = normal_rng(0,1); loseSD_prior = normal_lb_rng(0,0.3,0); win_prior = normal_rng(winM_prior, winSD_prior); lose_prior = normal_rng(loseM_prior, loseSD_prior); for (i in 1:agents){ prior_preds[,i] = binomial_rng(trials, inv_logit(to_vector(win[,i]) * (win_prior) + to_vector(lose[,i]) * (lose_prior))); posterior_preds[,i] = binomial_rng(trials, inv_logit(to_vector(win[,i]) * (winM + IDs[i,1]) + to_vector(lose[,i]) * (loseM + IDs[i,2]))); for (t in 1:trials){ log_lik[t,i] = bernoulli_logit_lpmf(h[t,i] | to_vector(win[,i]) * (winM + IDs[i,1]) + to_vector(lose[,i]) * (loseM + IDs[i,2])); } } } &quot; write_stan_file( stan_wsls_ml_model, dir = &quot;stan/&quot;, basename = &quot;W8_wsls_ml.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W8_wsls_ml.stan&quot; file &lt;- file.path(&quot;stan/W8_wsls_ml.stan&quot;) mod_wsls &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;), pedantic = TRUE) samples_wsls_ml &lt;- mod_wsls$sample( data = data_wsls, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 1000, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 2 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 2 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 2 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 2 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 1 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 1 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 1 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 2 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 2 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 2 finished in 15767.0 seconds. ## Chain 1 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 1 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 1 finished in 24401.6 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 20084.3 seconds. ## Total execution time: 24401.7 seconds. 8.12 Quality checks samples_wsls_ml$summary() ## # A tibble: 36,115 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -5.94e+3 -5.94e+3 13.4 13.6 -5.97e+3 -5.92e+3 1.00 1010. 1927. ## 2 winM 1.55e+0 1.55e+0 0.0360 0.0352 1.49e+0 1.61e+0 1.00 3142. 2977. ## 3 loseM 1.40e+0 1.40e+0 0.0386 0.0384 1.34e+0 1.47e+0 1.00 4214. 2490. ## 4 tau[1] 2.02e-1 2.04e-1 0.0515 0.0494 1.14e-1 2.84e-1 1.00 1254. 1284. ## 5 tau[2] 1.03e-1 9.99e-2 0.0640 0.0750 9.46e-3 2.11e-1 1.00 830. 1457. ## 6 z_IDs[1,… 9.32e-1 9.29e-1 0.840 0.827 -4.35e-1 2.33e+0 1.00 3706. 2847. ## 7 z_IDs[2,… -2.27e-1 -2.29e-1 1.00 0.993 -1.88e+0 1.46e+0 1.00 4178. 2711. ## 8 z_IDs[1,… -8.61e-1 -8.67e-1 0.824 0.821 -2.22e+0 4.73e-1 1.00 4254. 2943. ## 9 z_IDs[2,… -2.54e-1 -2.54e-1 0.986 0.991 -1.86e+0 1.35e+0 1.00 4290. 2965. ## 10 z_IDs[1,… -9.20e-1 -9.42e-1 0.838 0.819 -2.28e+0 4.67e-1 1.00 4330. 3012. ## # ℹ 36,105 more rows # Extract posterior samples and include sampling of the prior: draws_df &lt;- as_draws_df(samples_wsls_ml$draws()) # Now let&#39;s plot the density for theta (prior and posterior) ggplot(draws_df) + geom_density(aes(winM), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(win_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = d$betaWinM[1]) + xlab(&quot;Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_density(aes(`tau[1]`), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(`winSD_prior`), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = d$betaWinSD[1]) + xlab(&quot;Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_density(aes(loseM), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(loseM_prior), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = d$betaLoseM[1]) + xlab(&quot;Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_density(aes(`tau[2]`), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(`loseSD_prior`), fill = &quot;red&quot;, alpha = 0.3) + geom_vline(xintercept = d$betaLoseSD[1]) + xlab(&quot;Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() [MISSING: Model comparison with biased] [MISSING: Mixture model with biased] "],["bayesian-models-of-cognition.html", "Chapter 9 Bayesian models of cognition 9.1 Load the packages 9.2 Design the model 9.3 Create the data 9.4 Visualize 9.5 Data for Stan 9.6 Create the Stan Model 9.7 Fitting the model 9.8 Basic evaluation 9.9 Weighted Bayes 9.10 Visualize 9.11 Build the Weighted Bayes Stan model (simple formula) 9.12 Model evaluation 9.13 Model recovery 9.14 Multilevel 9.15 Bonus: Build the Weighted Bayes Stan model (fancier formula) 9.16 Evaluation 9.17 Build a temporal Bayes (storing current belief as prior for next turn) 9.18 Evaluate 9.19 Multilevel version of the simple bayes model 9.20 Multilevel version of the weighted bayes model", " Chapter 9 Bayesian models of cognition 9.1 Load the packages pacman::p_load( tidyverse, brms, cmdstanr, patchwork ) 9.2 Design the model [MISSING: EXPLAIN THE MODEL] [MISSING: Explain the different outcomes, including examples of experiments] [MISSING: explain the difference between a simple Bayes with weights of 1 - accumulating evidence - and one with weights that sum up to 1 - integrating/averaging evidence] SimpleBayes_f &lt;- function(bias, Source1, Source2){ outcome &lt;- inv_logit_scaled(bias + logit_scaled(Source1) + logit_scaled(Source2)) return(outcome) } SimpleBayes_MultiSource_f &lt;- function(bias, sources) { outcome &lt;- inv_logit_scaled(bias + sum(logit_scaled(sources))) return(outcome) } 9.3 Create the data bias &lt;- 0 trials &lt;- seq(10) Source1 &lt;- seq(0.1,0.9, 0.1) Source2 &lt;- seq(0.1,0.9, 0.1) db &lt;- expand.grid(bias = bias, trials = trials, Source1 = Source1, Source2 = Source2) for (n in seq(nrow(db))) { db$belief[n] &lt;- SimpleBayes_f(db$bias[n], db$Source1[n], db$Source2[n]) db$choice[n] &lt;- rbinom(1,1, db$belief[n]) db$continuous[n] &lt;- db$belief[n]*9 db$discrete[n] &lt;- round(db$belief[n]*9,0) } 9.4 Visualize [MISSING: Explain] ggplot(db, aes(belief)) + geom_histogram(bins = 10, alpha = 0.3, color = &quot;black&quot;) + theme_bw() ggplot(db, aes(Source1, belief, color = Source2, group = Source2)) + geom_line() + theme_bw() ggplot(db, aes(choice)) + geom_histogram(bins = 10, alpha = 0.3, color = &quot;black&quot;) + theme_bw() ggplot(db, aes(Source1, choice, color = Source2, group = Source2)) + geom_smooth(se = F) + theme_bw() ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; ggplot(db, aes(continuous)) + geom_histogram(bins = 10, alpha = 0.3, color = &quot;black&quot;) + theme_bw() ggplot(db, aes(Source1, continuous, color = Source2, group = Source2)) + geom_smooth() + theme_bw() ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; ggplot(db, aes(discrete)) + geom_histogram(bins = 10, alpha = 0.3, color = &quot;black&quot;) + theme_bw() ggplot(db, aes(Source1, discrete, color = Source2, group = Source2)) + geom_smooth() + theme_bw() ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; 9.5 Data for Stan data_simpleBayes &lt;- list( N = nrow(db), y = db$choice, Source1 = db$Source1, Source2 = db$Source2 ) 9.6 Create the Stan Model stan_simpleBayes_model &lt;- &quot; data { int&lt;lower=0&gt; N; array[N] int y; array[N] real&lt;lower=0, upper = 1&gt; Source1; array[N] real&lt;lower=0, upper = 1&gt; Source2; } transformed data{ array[N] real l_Source1; array[N] real l_Source2; l_Source1 = logit(Source1); l_Source2 = logit(Source2); } parameters { real bias; } model { target += normal_lpdf(bias | 0, 1); target += bernoulli_logit_lpmf(y | bias + to_vector(l_Source1) + to_vector(l_Source2)); } generated quantities{ real bias_prior; array[N] real log_lik; bias_prior = normal_rng(0, 1); for (n in 1:N){ log_lik[n] = bernoulli_logit_lpmf(y[n] | bias + l_Source1[n] + l_Source2[n]); } } &quot; write_stan_file( stan_simpleBayes_model, dir = &quot;stan/&quot;, basename = &quot;W9_SimpleBayes.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W9_SimpleBayes.stan&quot; file &lt;- file.path(&quot;stan/W9_SimpleBayes.stan&quot;) mod_simpleBayes &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) 9.7 Fitting the model samples_simple &lt;- mod_simpleBayes$sample( data = data_simpleBayes, #fixed_param = TRUE, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1500, iter_sampling = 3000, refresh = 500 ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4500 [ 0%] (Warmup) ## Chain 1 Iteration: 500 / 4500 [ 11%] (Warmup) ## Chain 1 Iteration: 1000 / 4500 [ 22%] (Warmup) ## Chain 1 Iteration: 1500 / 4500 [ 33%] (Warmup) ## Chain 1 Iteration: 1501 / 4500 [ 33%] (Sampling) ## Chain 2 Iteration: 1 / 4500 [ 0%] (Warmup) ## Chain 2 Iteration: 500 / 4500 [ 11%] (Warmup) ## Chain 2 Iteration: 1000 / 4500 [ 22%] (Warmup) ## Chain 2 Iteration: 1500 / 4500 [ 33%] (Warmup) ## Chain 2 Iteration: 1501 / 4500 [ 33%] (Sampling) ## Chain 1 Iteration: 2000 / 4500 [ 44%] (Sampling) ## Chain 2 Iteration: 2000 / 4500 [ 44%] (Sampling) ## Chain 1 Iteration: 2500 / 4500 [ 55%] (Sampling) ## Chain 2 Iteration: 2500 / 4500 [ 55%] (Sampling) ## Chain 1 Iteration: 3000 / 4500 [ 66%] (Sampling) ## Chain 2 Iteration: 3000 / 4500 [ 66%] (Sampling) ## Chain 1 Iteration: 3500 / 4500 [ 77%] (Sampling) ## Chain 2 Iteration: 3500 / 4500 [ 77%] (Sampling) ## Chain 1 Iteration: 4000 / 4500 [ 88%] (Sampling) ## Chain 2 Iteration: 4000 / 4500 [ 88%] (Sampling) ## Chain 1 Iteration: 4500 / 4500 [100%] (Sampling) ## Chain 1 finished in 1.0 seconds. ## Chain 2 Iteration: 4500 / 4500 [100%] (Sampling) ## Chain 2 finished in 1.0 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 1.0 seconds. ## Total execution time: 1.3 seconds. 9.8 Basic evaluation samples_simple$cmdstan_diagnose() ## Processing csv files: /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/W9_SimpleBayes-202402150650-1-1b8ab4.csv, /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/W9_SimpleBayes-202402150650-2-1b8ab4.csv ## ## Checking sampler transitions treedepth. ## Treedepth satisfactory for all transitions. ## ## Checking sampler transitions for divergences. ## No divergent transitions found. ## ## Checking E-BFMI - sampler transitions HMC potential energy. ## E-BFMI satisfactory. ## ## Effective sample size satisfactory. ## ## Split R-hat values satisfactory all parameters. ## ## Processing complete, no problems detected. samples_simple$summary() ## # A tibble: 813 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -3.99e+2 -3.99e+2 6.97e-1 3.05e-1 -4.01e+2 -3.99e+2 1.00 3053. 3376. ## 2 bias -1.56e-1 -1.55e-1 8.87e-2 8.84e-2 -3.05e-1 -9.42e-3 1.00 2150. 3351. ## 3 bias_pri… -2.66e-2 -2.85e-2 1.01e+0 9.92e-1 -1.71e+0 1.65e+0 1.00 5342. 5967. ## 4 log_lik[… -1.05e-2 -1.05e-2 9.30e-4 9.27e-4 -1.22e-2 -9.06e-3 1.00 2150. 3351. ## 5 log_lik[… -1.05e-2 -1.05e-2 9.30e-4 9.27e-4 -1.22e-2 -9.06e-3 1.00 2150. 3351. ## 6 log_lik[… -1.05e-2 -1.05e-2 9.30e-4 9.27e-4 -1.22e-2 -9.06e-3 1.00 2150. 3351. ## 7 log_lik[… -1.05e-2 -1.05e-2 9.30e-4 9.27e-4 -1.22e-2 -9.06e-3 1.00 2150. 3351. ## 8 log_lik[… -1.05e-2 -1.05e-2 9.30e-4 9.27e-4 -1.22e-2 -9.06e-3 1.00 2150. 3351. ## 9 log_lik[… -1.05e-2 -1.05e-2 9.30e-4 9.27e-4 -1.22e-2 -9.06e-3 1.00 2150. 3351. ## 10 log_lik[… -1.05e-2 -1.05e-2 9.30e-4 9.27e-4 -1.22e-2 -9.06e-3 1.00 2150. 3351. ## # ℹ 803 more rows samples_simple$loo() ## ## Computed from 6000 by 810 log-likelihood matrix ## ## Estimate SE ## elpd_loo -398.8 15.8 ## p_loo 1.0 0.0 ## looic 797.7 31.7 ## ------ ## Monte Carlo SE of elpd_loo is 0.0. ## ## All Pareto k estimates are good (k &lt; 0.5). ## See help(&#39;pareto-k-diagnostic&#39;) for details. draws_df &lt;- as_draws_df(samples_simple$draws()) ggplot(draws_df, aes(.iteration, bias, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws_df) + geom_density(aes(bias), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_density(aes(bias_prior), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = db$bias[1]) + theme_bw() [MISSING PARAMETER RECOVERY] 9.9 Weighted Bayes [MISSING: EXPLANATION] [MISSING: FOCUS ON WEIGHTS AND THEIR SCALE: 0-1 on log-odds; 0.5-1 on probability] WeightedBayes_f &lt;- function(bias, Source1, Source2, w1, w2){ w1 &lt;- (w1 - 0.5)*2 w2 &lt;- (w2 - 0.5)*2 outcome &lt;- inv_logit_scaled(bias + w1 * logit_scaled(Source1) + w2 * logit_scaled(Source2)) return(outcome) } ## This version of the model is from Taking others into account (in the syllabus) ## It takes two sources of information and weights them, then adds a bias ## to generate a posterior on a 0-1 scale WeightedBayes_f1 &lt;- function(bias, Source1, Source2, w1, w2){ outcome &lt;- inv_logit_scaled(bias + weight_f(logit_scaled(Source1), w1) + weight_f(logit_scaled(Source2), w2)) return(outcome) } ## The weight_f formula comes from https://www.nature.com/articles/ncomms14218 ## and ensures that even if we work on a log-odds scale, we get the right weights ## It takes all values of L (- inf to +inf). Technically the only valid values for ## w are 0.5 (no consideration of the evidence) to 1 (taking the evidence at face value). ## In practice the function would also accept 0-0.5 (invert the evidence, at face value ## if 0, at decreased value as it grows towards 0.5), and slightly higher than 1 ## (overweighing the evidence, but it&#39;s very unstable and quickly gives NaN). weight_f &lt;- function(L, w){ return(log((w * exp(L) + 1 - w) / ((1 - w) * exp(L) + w))) } bias &lt;- 0 trials &lt;- seq(10) Source1 &lt;- seq(0.1,0.9, 0.1) Source2 &lt;- seq(0.1,0.9, 0.1) w1 &lt;- seq(0.5, 1, 0.1) w2 &lt;- seq(0.5, 1, 0.1) db &lt;- expand.grid(bias = bias, trials, Source1 = Source1, Source2 = Source2, w1 = w1, w2 = w2) for (n in seq(nrow(db))) { db$belief[n] &lt;- WeightedBayes_f(db$bias[n], db$Source1[n], db$Source2[n],db$w1[n], db$w2[n]) db$belief1[n] &lt;- WeightedBayes_f1(db$bias[n], db$Source1[n], db$Source2[n],db$w1[n], db$w2[n]) db$binary[n] &lt;- rbinom(1,1, db$belief[n]) db$binary1[n] &lt;- rbinom(1,1, db$belief1[n]) db$continuous[n] &lt;- db$belief[n] * 9 db$continuous1[n] &lt;- db$belief1[n] * 9 db$discrete[n] &lt;- round(db$belief[n] * 9,0) db$discrete1[n] &lt;- round(db$belief1[n] * 9,0) } 9.10 Visualize ggplot(db, aes(belief, belief1)) + geom_point() + theme_bw() ggplot(db) + geom_histogram(aes(belief), bins = 10, alpha = 0.3, color = &quot;black&quot;, fill = &quot;red&quot;) + geom_histogram(aes(belief1), bins = 10, alpha = 0.3, color = &quot;black&quot;, fill = &quot;blue&quot;) + theme_bw() p1 &lt;- ggplot(db, aes(Source1, belief, color = Source2, group = Source2)) + geom_line() + theme_bw() + facet_wrap(w1~w2) p2 &lt;- ggplot(db, aes(Source1, belief1, color = Source2, group = Source2)) + geom_line() + theme_bw() + facet_wrap(w1~w2) p1 + p2 9.11 Build the Weighted Bayes Stan model (simple formula) stan_WB_model &lt;- &quot; data { int&lt;lower=0&gt; N; array[N] int y; array[N] real &lt;lower = 0, upper = 1&gt; Source1; array[N] real &lt;lower = 0, upper = 1&gt; Source2; } transformed data { array[N] real l_Source1; array[N] real l_Source2; l_Source1 = logit(Source1); l_Source2 = logit(Source2); } parameters { real bias; // meaningful weights are btw 0.5 and 1 (theory reasons) real&lt;lower = 0.5, upper = 1&gt; w1; real&lt;lower = 0.5, upper = 1&gt; w2; } transformed parameters { real&lt;lower = 0, upper = 1&gt; weight1; real&lt;lower = 0, upper = 1&gt; weight2; // weight parameters are rescaled to be on a 0-1 scale (0 -&gt; no effects; 1 -&gt; face value) weight1 = (w1 - 0.5) * 2; weight2 = (w2 - 0.5) * 2; } model { target += normal_lpdf(bias | 0, 1); target += beta_lpdf(weight1 | 1, 1); target += beta_lpdf(weight2 | 1, 1); for (n in 1:N) target += bernoulli_logit_lpmf(y[n] | bias + weight1 *l_Source1[n] + weight2 * l_Source2[n]); } generated quantities{ array[N] real log_lik; real bias_prior; real w1_prior; real w2_prior; bias_prior = normal_rng(0, 1) ; w1_prior = 0.5 + inv_logit(normal_rng(0, 1))/2 ; w2_prior = 0.5 + inv_logit(normal_rng(0, 1))/2 ; for (n in 1:N) log_lik[n]= bernoulli_logit_lpmf(y[n] | bias + weight1 * l_Source1[n] + weight2 * l_Source2[n]); } &quot; write_stan_file( stan_WB_model, dir = &quot;stan/&quot;, basename = &quot;W9_WB.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W9_WB.stan&quot; file &lt;- file.path(&quot;stan/W9_WB.stan&quot;) mod_wb &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) db1 &lt;- db %&gt;% subset(w1 == 0.7 &amp; w2 == 0.9) p3 &lt;- ggplot(db1, aes(Source1, belief, color = Source2, group = Source2)) + geom_line() + theme_bw() p3 ggplot(db1, aes(Source1, binary)) + geom_smooth() + theme_bw() ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; data_weightedBayes &lt;- list( N = nrow(db1), y = db1$binary, Source1 = db1$Source1, Source2 = db1$Source2 ) samples_weighted &lt;- mod_wb$sample( data = data_weightedBayes, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1500, iter_sampling = 3000, refresh = 500 ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4500 [ 0%] (Warmup) ## Chain 2 Iteration: 1 / 4500 [ 0%] (Warmup) ## Chain 1 Iteration: 500 / 4500 [ 11%] (Warmup) ## Chain 2 Iteration: 500 / 4500 [ 11%] (Warmup) ## Chain 1 Iteration: 1000 / 4500 [ 22%] (Warmup) ## Chain 2 Iteration: 1000 / 4500 [ 22%] (Warmup) ## Chain 1 Iteration: 1500 / 4500 [ 33%] (Warmup) ## Chain 1 Iteration: 1501 / 4500 [ 33%] (Sampling) ## Chain 2 Iteration: 1500 / 4500 [ 33%] (Warmup) ## Chain 2 Iteration: 1501 / 4500 [ 33%] (Sampling) ## Chain 1 Iteration: 2000 / 4500 [ 44%] (Sampling) ## Chain 2 Iteration: 2000 / 4500 [ 44%] (Sampling) ## Chain 1 Iteration: 2500 / 4500 [ 55%] (Sampling) ## Chain 2 Iteration: 2500 / 4500 [ 55%] (Sampling) ## Chain 1 Iteration: 3000 / 4500 [ 66%] (Sampling) ## Chain 2 Iteration: 3000 / 4500 [ 66%] (Sampling) ## Chain 1 Iteration: 3500 / 4500 [ 77%] (Sampling) ## Chain 2 Iteration: 3500 / 4500 [ 77%] (Sampling) ## Chain 1 Iteration: 4000 / 4500 [ 88%] (Sampling) ## Chain 2 Iteration: 4000 / 4500 [ 88%] (Sampling) ## Chain 1 Iteration: 4500 / 4500 [100%] (Sampling) ## Chain 1 finished in 3.6 seconds. ## Chain 2 Iteration: 4500 / 4500 [100%] (Sampling) ## Chain 2 finished in 3.7 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 3.7 seconds. ## Total execution time: 4.1 seconds. 9.12 Model evaluation samples_weighted$cmdstan_diagnose() ## Processing csv files: /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/W9_WB-202402150650-1-470abd.csv, /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/W9_WB-202402150650-2-470abd.csv ## ## Checking sampler transitions treedepth. ## Treedepth satisfactory for all transitions. ## ## Checking sampler transitions for divergences. ## No divergent transitions found. ## ## Checking E-BFMI - sampler transitions HMC potential energy. ## E-BFMI satisfactory. ## ## Effective sample size satisfactory. ## ## Split R-hat values satisfactory all parameters. ## ## Processing complete, no problems detected. samples_weighted$summary() ## # A tibble: 819 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -4.71e+2 -4.71e+2 1.36 1.10 -474. -4.70e+2 1.00 2628. 3124. ## 2 bias -6.41e-3 -6.56e-3 0.0794 0.0785 -0.135 1.25e-1 1.00 5023. 3770. ## 3 w1 7.03e-1 7.03e-1 0.0331 0.0331 0.649 7.57e-1 1.00 4493. 3661. ## 4 w2 8.95e-1 8.94e-1 0.0353 0.0364 0.838 9.54e-1 1.00 4204. 2727. ## 5 weight1 4.06e-1 4.05e-1 0.0662 0.0662 0.298 5.14e-1 1.00 4493. 3661. ## 6 weight2 7.89e-1 7.87e-1 0.0705 0.0727 0.675 9.07e-1 1.00 4204. 2727. ## 7 log_lik[1] -7.14e-2 -6.99e-2 0.0169 0.0168 -0.101 -4.66e-2 1.00 3913. 3436. ## 8 log_lik[2] -7.14e-2 -6.99e-2 0.0169 0.0168 -0.101 -4.66e-2 1.00 3913. 3436. ## 9 log_lik[3] -7.14e-2 -6.99e-2 0.0169 0.0168 -0.101 -4.66e-2 1.00 3913. 3436. ## 10 log_lik[4] -2.70e+0 -2.70e+0 0.229 0.233 -3.09 -2.34e+0 1.00 3913. 3436. ## # ℹ 809 more rows samples_weighted$loo() ## ## Computed from 6000 by 810 log-likelihood matrix ## ## Estimate SE ## elpd_loo -467.0 12.8 ## p_loo 3.1 0.2 ## looic 933.9 25.5 ## ------ ## Monte Carlo SE of elpd_loo is 0.0. ## ## All Pareto k estimates are good (k &lt; 0.5). ## See help(&#39;pareto-k-diagnostic&#39;) for details. draws_df &lt;- as_draws_df(samples_weighted$draws()) ggplot(draws_df, aes(.iteration, bias, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws_df, aes(.iteration, w1, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws_df, aes(.iteration, w2, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() p1 &lt;- ggplot(draws_df) + geom_density(aes(bias), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_density(aes(bias_prior), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = db1$bias[1]) + theme_bw() p2 &lt;- ggplot(draws_df) + geom_density(aes(w1), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_density(aes(w1_prior), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = db1$w1[1]) + theme_bw() p3 &lt;- ggplot(draws_df) + geom_density(aes(w2), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_density(aes(w2_prior), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = db1$w2[1]) + theme_bw() p1 + p2 + p3 ggplot(draws_df) + geom_point(aes(w1, w2), alpha = 0.3) + theme_bw() ggplot(draws_df) + geom_point(aes(bias, w1), alpha = 0.3) + theme_bw() ggplot(draws_df) + geom_point(aes(bias, w2), alpha = 0.3) + theme_bw() 9.13 Model recovery bias &lt;- 0 trials &lt;- seq(10) Source1 &lt;- seq(0.1,0.9, 0.1) Source2 &lt;- seq(0.1,0.9, 0.1) w1 &lt;- 0.7 w2 &lt;- 0.9 db &lt;- expand.grid(bias = bias, trials, Source1 = Source1, Source2 = Source2, w1 = w1, w2 = w2) for (n in seq(nrow(db))) { db$simple_belief[n] &lt;- SimpleBayes_f(db$bias[n], db$Source1[n], db$Source2[n]) db$weighted_belief[n] &lt;- WeightedBayes_f(db$bias[n], db$Source1[n], db$Source2[n],db$w1[n], db$w2[n]) db$simple_binary[n] &lt;- rbinom(1,1, db$simple_belief[n]) db$weighted_binary[n] &lt;- rbinom(1,1, db$weighted_belief[n]) } data_SB &lt;- list( N = nrow(db), y = db$simple_binary, Source1 = db$Source1, Source2 = db$Source2 ) data_WB &lt;- list( N = nrow(db), y = db$weighted_binary, Source1 = db$Source1, Source2 = db$Source2 ) ## On the simple data simple2simple &lt;- mod_simpleBayes$sample( data = data_SB, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1500, iter_sampling = 3000, refresh = 500 ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4500 [ 0%] (Warmup) ## Chain 1 Iteration: 500 / 4500 [ 11%] (Warmup) ## Chain 1 Iteration: 1000 / 4500 [ 22%] (Warmup) ## Chain 1 Iteration: 1500 / 4500 [ 33%] (Warmup) ## Chain 1 Iteration: 1501 / 4500 [ 33%] (Sampling) ## Chain 1 Iteration: 2000 / 4500 [ 44%] (Sampling) ## Chain 2 Iteration: 1 / 4500 [ 0%] (Warmup) ## Chain 2 Iteration: 500 / 4500 [ 11%] (Warmup) ## Chain 2 Iteration: 1000 / 4500 [ 22%] (Warmup) ## Chain 2 Iteration: 1500 / 4500 [ 33%] (Warmup) ## Chain 2 Iteration: 1501 / 4500 [ 33%] (Sampling) ## Chain 2 Iteration: 2000 / 4500 [ 44%] (Sampling) ## Chain 1 Iteration: 2500 / 4500 [ 55%] (Sampling) ## Chain 1 Iteration: 3000 / 4500 [ 66%] (Sampling) ## Chain 2 Iteration: 2500 / 4500 [ 55%] (Sampling) ## Chain 2 Iteration: 3000 / 4500 [ 66%] (Sampling) ## Chain 1 Iteration: 3500 / 4500 [ 77%] (Sampling) ## Chain 1 Iteration: 4000 / 4500 [ 88%] (Sampling) ## Chain 2 Iteration: 3500 / 4500 [ 77%] (Sampling) ## Chain 1 Iteration: 4500 / 4500 [100%] (Sampling) ## Chain 2 Iteration: 4000 / 4500 [ 88%] (Sampling) ## Chain 1 finished in 1.0 seconds. ## Chain 2 Iteration: 4500 / 4500 [100%] (Sampling) ## Chain 2 finished in 1.1 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 1.1 seconds. ## Total execution time: 1.4 seconds. weighted2simple &lt;- mod_wb$sample( data = data_SB, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1500, iter_sampling = 3000, refresh = 500 ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4500 [ 0%] (Warmup) ## Chain 2 Iteration: 1 / 4500 [ 0%] (Warmup) ## Chain 1 Iteration: 500 / 4500 [ 11%] (Warmup) ## Chain 2 Iteration: 500 / 4500 [ 11%] (Warmup) ## Chain 1 Iteration: 1000 / 4500 [ 22%] (Warmup) ## Chain 2 Iteration: 1000 / 4500 [ 22%] (Warmup) ## Chain 1 Iteration: 1500 / 4500 [ 33%] (Warmup) ## Chain 1 Iteration: 1501 / 4500 [ 33%] (Sampling) ## Chain 2 Iteration: 1500 / 4500 [ 33%] (Warmup) ## Chain 2 Iteration: 1501 / 4500 [ 33%] (Sampling) ## Chain 1 Iteration: 2000 / 4500 [ 44%] (Sampling) ## Chain 2 Iteration: 2000 / 4500 [ 44%] (Sampling) ## Chain 1 Iteration: 2500 / 4500 [ 55%] (Sampling) ## Chain 2 Iteration: 2500 / 4500 [ 55%] (Sampling) ## Chain 2 Iteration: 3000 / 4500 [ 66%] (Sampling) ## Chain 1 Iteration: 3000 / 4500 [ 66%] (Sampling) ## Chain 2 Iteration: 3500 / 4500 [ 77%] (Sampling) ## Chain 1 Iteration: 3500 / 4500 [ 77%] (Sampling) ## Chain 2 Iteration: 4000 / 4500 [ 88%] (Sampling) ## Chain 1 Iteration: 4000 / 4500 [ 88%] (Sampling) ## Chain 2 Iteration: 4500 / 4500 [100%] (Sampling) ## Chain 2 finished in 4.5 seconds. ## Chain 1 Iteration: 4500 / 4500 [100%] (Sampling) ## Chain 1 finished in 4.8 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 4.7 seconds. ## Total execution time: 5.0 seconds. simple2weighted &lt;- mod_simpleBayes$sample( data = data_WB, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1500, iter_sampling = 3000, refresh = 500 ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4500 [ 0%] (Warmup) ## Chain 1 Iteration: 500 / 4500 [ 11%] (Warmup) ## Chain 1 Iteration: 1000 / 4500 [ 22%] (Warmup) ## Chain 1 Iteration: 1500 / 4500 [ 33%] (Warmup) ## Chain 1 Iteration: 1501 / 4500 [ 33%] (Sampling) ## Chain 2 Iteration: 1 / 4500 [ 0%] (Warmup) ## Chain 2 Iteration: 500 / 4500 [ 11%] (Warmup) ## Chain 2 Iteration: 1000 / 4500 [ 22%] (Warmup) ## Chain 2 Iteration: 1500 / 4500 [ 33%] (Warmup) ## Chain 2 Iteration: 1501 / 4500 [ 33%] (Sampling) ## Chain 1 Iteration: 2000 / 4500 [ 44%] (Sampling) ## Chain 1 Iteration: 2500 / 4500 [ 55%] (Sampling) ## Chain 2 Iteration: 2000 / 4500 [ 44%] (Sampling) ## Chain 2 Iteration: 2500 / 4500 [ 55%] (Sampling) ## Chain 1 Iteration: 3000 / 4500 [ 66%] (Sampling) ## Chain 1 Iteration: 3500 / 4500 [ 77%] (Sampling) ## Chain 2 Iteration: 3000 / 4500 [ 66%] (Sampling) ## Chain 2 Iteration: 3500 / 4500 [ 77%] (Sampling) ## Chain 1 Iteration: 4000 / 4500 [ 88%] (Sampling) ## Chain 1 Iteration: 4500 / 4500 [100%] (Sampling) ## Chain 2 Iteration: 4000 / 4500 [ 88%] (Sampling) ## Chain 1 finished in 1.0 seconds. ## Chain 2 Iteration: 4500 / 4500 [100%] (Sampling) ## Chain 2 finished in 1.0 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 1.0 seconds. ## Total execution time: 1.3 seconds. weighted2weighted &lt;- mod_wb$sample( data = data_WB, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1500, iter_sampling = 3000, refresh = 500 ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4500 [ 0%] (Warmup) ## Chain 2 Iteration: 1 / 4500 [ 0%] (Warmup) ## Chain 1 Iteration: 500 / 4500 [ 11%] (Warmup) ## Chain 2 Iteration: 500 / 4500 [ 11%] (Warmup) ## Chain 1 Iteration: 1000 / 4500 [ 22%] (Warmup) ## Chain 2 Iteration: 1000 / 4500 [ 22%] (Warmup) ## Chain 1 Iteration: 1500 / 4500 [ 33%] (Warmup) ## Chain 1 Iteration: 1501 / 4500 [ 33%] (Sampling) ## Chain 2 Iteration: 1500 / 4500 [ 33%] (Warmup) ## Chain 2 Iteration: 1501 / 4500 [ 33%] (Sampling) ## Chain 1 Iteration: 2000 / 4500 [ 44%] (Sampling) ## Chain 2 Iteration: 2000 / 4500 [ 44%] (Sampling) ## Chain 1 Iteration: 2500 / 4500 [ 55%] (Sampling) ## Chain 2 Iteration: 2500 / 4500 [ 55%] (Sampling) ## Chain 1 Iteration: 3000 / 4500 [ 66%] (Sampling) ## Chain 2 Iteration: 3000 / 4500 [ 66%] (Sampling) ## Chain 1 Iteration: 3500 / 4500 [ 77%] (Sampling) ## Chain 2 Iteration: 3500 / 4500 [ 77%] (Sampling) ## Chain 1 Iteration: 4000 / 4500 [ 88%] (Sampling) ## Chain 2 Iteration: 4000 / 4500 [ 88%] (Sampling) ## Chain 1 Iteration: 4500 / 4500 [100%] (Sampling) ## Chain 1 finished in 3.6 seconds. ## Chain 2 Iteration: 4500 / 4500 [100%] (Sampling) ## Chain 2 finished in 3.7 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 3.7 seconds. ## Total execution time: 4.0 seconds. Loo_simple2simple &lt;- simple2simple$loo(save_psis = TRUE, cores = 4) p1 &lt;- plot(Loo_simple2simple) Loo_weighted2simple &lt;- weighted2simple$loo(save_psis = TRUE, cores = 4) p2 &lt;- plot(Loo_weighted2simple) Loo_simple2weighted &lt;- simple2weighted$loo(save_psis = TRUE, cores = 4) p3 &lt;- plot(Loo_simple2weighted) Loo_weighted2weighted &lt;- weighted2weighted$loo(save_psis = TRUE, cores = 4) p4 &lt;- plot(Loo_weighted2weighted) elpd &lt;- tibble( n = seq(810), simple_diff_elpd = Loo_simple2simple$pointwise[, &quot;elpd_loo&quot;] - Loo_weighted2simple$pointwise[, &quot;elpd_loo&quot;], weighted_diff_elpd = Loo_weighted2weighted$pointwise[, &quot;elpd_loo&quot;] - Loo_simple2weighted$pointwise[, &quot;elpd_loo&quot;]) p1 &lt;- ggplot(elpd, aes(x = n, y = simple_diff_elpd)) + geom_point(alpha = .1) + #xlim(.5,1.01) + #ylim(-1.5,1.5) + geom_hline(yintercept = 0, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + theme_bw() p2 &lt;- ggplot(elpd, aes(x = n, y = weighted_diff_elpd)) + geom_point(alpha = .1) + #xlim(.5,1.01) + #ylim(-1.5,1.5) + geom_hline(yintercept = 0, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + theme_bw() library(patchwork) p1 + p2 loo_compare(Loo_simple2simple, Loo_weighted2simple) ## elpd_diff se_diff ## model1 0.0 0.0 ## model2 -1.3 1.0 loo_compare(Loo_weighted2weighted, Loo_simple2weighted) ## elpd_diff se_diff ## model1 0.0 0.0 ## model2 -36.9 9.4 loo_model_weights(list(Loo_simple2simple, Loo_weighted2simple)) ## Method: stacking ## ------ ## weight ## model1 1.000 ## model2 0.000 loo_model_weights(list(Loo_weighted2weighted, Loo_simple2weighted)) ## Method: stacking ## ------ ## weight ## model1 1.000 ## model2 0.000 9.14 Multilevel 9.15 Bonus: Build the Weighted Bayes Stan model (fancier formula) stan_WB1_model &lt;- &quot; functions{ real weight_f(real L_raw, real w_raw) { real L; real w; L = exp(L_raw); w = 0.5 + inv_logit(w_raw)/2; return log((w * L + 1 - w)./((1 - w) * L + w)); } } data { int&lt;lower=0&gt; N; array[N] int y; vector[N] Source1; vector[N] Source2; } parameters { real bias; real weight1; real weight2; } model { target += normal_lpdf(bias | 0, 1); target += normal_lpdf(weight1 | 0, 1.5); target += normal_lpdf(weight2 | 0, 1.5); for (n in 1:N){ target += bernoulli_logit_lpmf(y[n] | bias + weight_f(Source1[n], weight1) + weight_f(Source2[n], weight2)); } } generated quantities{ array[N] real log_lik; real bias_prior; real w1_prior; real w2_prior; real w1; real w2; bias_prior = normal_rng(0,1); w1_prior = normal_rng(0,1.5); w2_prior = normal_rng(0,1.5); w1_prior = 0.5 + inv_logit(normal_rng(0,1))/2; w2_prior = 0.5 + inv_logit(normal_rng(0,1))/2; w1 = 0.5 + inv_logit(weight1)/2; w2 = 0.5 + inv_logit(weight2)/2; for (n in 1:N){ log_lik[n] = bernoulli_logit_lpmf(y[n] | bias + weight_f(Source1[n], weight1) + weight_f(Source2[n], weight2)); } } &quot; write_stan_file( stan_WB1_model, dir = &quot;stan/&quot;, basename = &quot;W9_WB1.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W9_WB1.stan&quot; file &lt;- file.path(&quot;stan/W9_WB1.stan&quot;) mod_wb1 &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) db1 &lt;- db %&gt;% subset(w1 == 0.7 &amp; w2 == 1) %&gt;% mutate( l1 = logit_scaled(Source1), l2 = logit_scaled(Source2) ) data_weightedBayes1 &lt;- list( N = nrow(db1), y = db1$binary1, Source1 = logit_scaled(db1$Source1), Source2 = logit_scaled(db1$Source2) ) samples_weighted1 &lt;- mod_wb1$sample( data = data_weightedBayes1, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1500, iter_sampling = 3000, refresh = 500 ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4500 [ 0%] (Warmup) ## Chain 1 Iteration: 500 / 4500 [ 11%] (Warmup) ## Chain 1 Iteration: 1000 / 4500 [ 22%] (Warmup) ## Chain 1 Iteration: 1500 / 4500 [ 33%] (Warmup) ## Chain 1 Iteration: 1501 / 4500 [ 33%] (Sampling) ## Chain 1 Iteration: 2000 / 4500 [ 44%] (Sampling) ## Chain 1 Iteration: 2500 / 4500 [ 55%] (Sampling) ## Chain 1 Iteration: 3000 / 4500 [ 66%] (Sampling) ## Chain 1 Iteration: 3500 / 4500 [ 77%] (Sampling) ## Chain 1 Iteration: 4000 / 4500 [ 88%] (Sampling) ## Chain 1 Iteration: 4500 / 4500 [100%] (Sampling) ## Chain 2 Iteration: 1 / 4500 [ 0%] (Warmup) ## Chain 2 Iteration: 500 / 4500 [ 11%] (Warmup) ## Chain 2 Iteration: 1000 / 4500 [ 22%] (Warmup) ## Chain 2 Iteration: 1500 / 4500 [ 33%] (Warmup) ## Chain 2 Iteration: 1501 / 4500 [ 33%] (Sampling) ## Chain 2 Iteration: 2000 / 4500 [ 44%] (Sampling) ## Chain 2 Iteration: 2500 / 4500 [ 55%] (Sampling) ## Chain 2 Iteration: 3000 / 4500 [ 66%] (Sampling) ## Chain 2 Iteration: 3500 / 4500 [ 77%] (Sampling) ## Chain 2 Iteration: 4000 / 4500 [ 88%] (Sampling) ## Chain 2 Iteration: 4500 / 4500 [100%] (Sampling) ## Chain 1 finished in 0.0 seconds. ## Chain 2 finished in 0.0 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 0.0 seconds. ## Total execution time: 0.4 seconds. 9.16 Evaluation draws_df &lt;- as_draws_df(samples_weighted1$draws()) ggplot(draws_df, aes(.iteration, bias, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws_df, aes(.iteration, w1, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws_df, aes(.iteration, w2, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws_df) + geom_histogram(aes(bias), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_histogram(aes(bias_prior), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = db1$bias[1]) + theme_bw() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 1 rows containing missing values (`geom_vline()`). ggplot(draws_df) + geom_histogram(aes(w1), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_histogram(aes(w1_prior), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = db1$w1[1]) + theme_bw() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 1 rows containing missing values (`geom_vline()`). ggplot(draws_df) + geom_density(aes(w2), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_density(aes(w2_prior), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = db1$w2[1]) + theme_bw() ## Warning: Removed 1 rows containing missing values (`geom_vline()`). ggplot(draws_df) + geom_point(aes(w1, w2), alpha = 0.3) + theme_bw() ggplot(draws_df) + geom_point(aes(bias, w1), alpha = 0.3) + theme_bw() ggplot(draws_df) + geom_point(aes(bias, w2), alpha = 0.3) + theme_bw() 9.17 Build a temporal Bayes (storing current belief as prior for next turn) WeightedTimeBayes_f &lt;- function(bias, Source1, Source2, w1, w2){ w1 &lt;- (w1 - 0.5)*2 w2 &lt;- (w2 - 0.5)*2 outcome &lt;- inv_logit_scaled(bias + w1 * logit_scaled(Source1) + w2 * logit_scaled(Source2)) return(outcome) } bias &lt;- 0 trials &lt;- seq(10) Source1 &lt;- seq(0.1,0.9, 0.1) w1 &lt;- seq(0.5, 1, 0.1) w2 &lt;- seq(0.5, 1, 0.1) db &lt;- expand.grid(bias = bias, trials, Source1 = Source1, w1 = w1, w2 = w2) %&gt;% mutate(Source2 = NA, belief = NA, binary = NA) for (n in seq(nrow(db))) { if (n == 1) {db$Source2[1] = 0.5} db$belief[n] &lt;- WeightedTimeBayes_f(db$bias[n], db$Source1[n], db$Source2[n],db$w1[n], db$w2[n]) db$binary[n] &lt;- rbinom(1,1, db$belief[n]) if (n &lt; nrow(db)) {db$Source2[n + 1] &lt;- db$belief[n]} } stan_TB_model &lt;- &quot; data { int&lt;lower=0&gt; N; array[N] int y; array[N] real &lt;lower = 0, upper = 1&gt; Source1; } transformed data { array[N] real l_Source1; l_Source1 = logit(Source1); } parameters { real bias; // meaningful weights are btw 0.5 and 1 (theory reasons) real&lt;lower = 0.5, upper = 1&gt; w1; real&lt;lower = 0.5, upper = 1&gt; w2; } transformed parameters { real&lt;lower = 0, upper = 1&gt; weight1; real&lt;lower = 0, upper = 1&gt; weight2; array[N] real l_Source2; // weight parameters are rescaled to be on a 0-1 scale (0 -&gt; no effects; 1 -&gt; face value) weight1 = (w1 - 0.5) * 2; weight2 = (w2 - 0.5) * 2; l_Source2[1] = 0; for (n in 2:N){ l_Source2[n] = bias + weight1 * l_Source1[n] + weight2 * l_Source2[n-1]; } } model { target += normal_lpdf(bias | 0, 1); target += beta_lpdf(weight1 | 1, 1); target += beta_lpdf(weight2 | 1, 1); target += bernoulli_logit_lpmf(y[1] | bias + weight1 * l_Source1[1]); for (n in 2:N){ target += bernoulli_logit_lpmf(y[n] | l_Source2[n]); } } generated quantities{ array[N] real log_lik; real bias_prior; real w1_prior; real w2_prior; bias_prior = normal_rng(0, 1) ; w1_prior = 0.5 + inv_logit(normal_rng(0, 1))/2 ; w2_prior = 0.5 + inv_logit(normal_rng(0, 1))/2 ; for (n in 1:N) log_lik[n]= bernoulli_logit_lpmf(y[n] | l_Source2[n]); } &quot; write_stan_file( stan_TB_model, dir = &quot;stan/&quot;, basename = &quot;W9_TB.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W9_TB.stan&quot; file &lt;- file.path(&quot;stan/W9_TB.stan&quot;) mod_tb &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) db1 &lt;- db %&gt;% subset(w1 == 0.7 &amp; w2 == 0.9) data_TB &lt;- list( N = nrow(db1), y = db1$binary, Source1 = db1$Source1 ) samples_TB &lt;- mod_tb$sample( data = data_TB, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 3000, refresh = 500, adapt_delta = 0.99, max_treedepth = 20 ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 5000 [ 0%] (Warmup) ## Chain 1 Iteration: 500 / 5000 [ 10%] (Warmup) ## Chain 2 Iteration: 1 / 5000 [ 0%] (Warmup) ## Chain 2 Iteration: 500 / 5000 [ 10%] (Warmup) ## Chain 1 Iteration: 1000 / 5000 [ 20%] (Warmup) ## Chain 1 Iteration: 1500 / 5000 [ 30%] (Warmup) ## Chain 2 Iteration: 1000 / 5000 [ 20%] (Warmup) ## Chain 2 Iteration: 1500 / 5000 [ 30%] (Warmup) ## Chain 1 Iteration: 2000 / 5000 [ 40%] (Warmup) ## Chain 1 Iteration: 2001 / 5000 [ 40%] (Sampling) ## Chain 2 Iteration: 2000 / 5000 [ 40%] (Warmup) ## Chain 2 Iteration: 2001 / 5000 [ 40%] (Sampling) ## Chain 1 Iteration: 2500 / 5000 [ 50%] (Sampling) ## Chain 1 Iteration: 3000 / 5000 [ 60%] (Sampling) ## Chain 1 Iteration: 3500 / 5000 [ 70%] (Sampling) ## Chain 2 Iteration: 2500 / 5000 [ 50%] (Sampling) ## Chain 1 Iteration: 4000 / 5000 [ 80%] (Sampling) ## Chain 1 Iteration: 4500 / 5000 [ 90%] (Sampling) ## Chain 2 Iteration: 3000 / 5000 [ 60%] (Sampling) ## Chain 1 Iteration: 5000 / 5000 [100%] (Sampling) ## Chain 1 finished in 1.9 seconds. ## Chain 2 Iteration: 3500 / 5000 [ 70%] (Sampling) ## Chain 2 Iteration: 4000 / 5000 [ 80%] (Sampling) ## Chain 2 Iteration: 4500 / 5000 [ 90%] (Sampling) ## Chain 2 Iteration: 5000 / 5000 [100%] (Sampling) ## Chain 2 finished in 2.9 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 2.4 seconds. ## Total execution time: 3.2 seconds. 9.18 Evaluate samples_TB$cmdstan_diagnose() ## Processing csv files: /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/W9_TB-202402150651-1-26c994.csv, /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/W9_TB-202402150651-2-26c994.csv ## ## Checking sampler transitions treedepth. ## Treedepth satisfactory for all transitions. ## ## Checking sampler transitions for divergences. ## No divergent transitions found. ## ## Checking E-BFMI - sampler transitions HMC potential energy. ## E-BFMI satisfactory. ## ## Effective sample size satisfactory. ## ## Split R-hat values satisfactory all parameters. ## ## Processing complete, no problems detected. #samples_TB$loo() samples_TB$summary() ## # A tibble: 189 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -50.5 -50.0 1.77 1.53 -54.0 -48.5 1.00 976. 1188. ## 2 bias -0.0234 -0.00914 0.117 0.0931 -0.234 0.141 1.00 1880. 1819. ## 3 w1 0.756 0.744 0.111 0.128 0.595 0.956 1.00 754. 1188. ## 4 w2 0.809 0.825 0.101 0.108 0.620 0.944 1.00 792. 1150. ## 5 weight1 0.511 0.488 0.222 0.256 0.189 0.912 1.00 754. 1188. ## 6 weight2 0.617 0.649 0.202 0.215 0.240 0.888 1.00 792. 1150. ## 7 l_Source2[1] 0 0 0 0 0 0 NA NA NA ## 8 l_Source2[2] -1.15 -1.09 0.527 0.596 -2.09 -0.387 1.00 855. 1362. ## 9 l_Source2[3] -1.76 -1.76 0.654 0.722 -2.86 -0.726 1.00 956. 1412. ## 10 l_Source2[4] -2.14 -2.15 0.685 0.721 -3.29 -1.02 1.00 1083. 1496. ## # ℹ 179 more rows draws_df &lt;- as_draws_df(samples_TB$draws()) p1 &lt;- ggplot(draws_df, aes(.iteration, bias, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() p2 &lt;- ggplot(draws_df, aes(.iteration, w1, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() p3 &lt;- ggplot(draws_df, aes(.iteration, w2, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() p1 + p2 + p3 p1 &lt;- ggplot(draws_df) + geom_density(aes(bias), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_density(aes(bias_prior), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = db1$bias[1]) + theme_bw() p2 &lt;- ggplot(draws_df) + geom_density(aes(w1), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_density(aes(w1_prior), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = db1$w1[1]) + theme_bw() p3 &lt;- ggplot(draws_df) + geom_density(aes(w2), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_density(aes(w2_prior), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = db1$w2[1]) + theme_bw() p1 + p2 + p3 p1 &lt;- ggplot(draws_df) + geom_point(aes(w1, w2), alpha = 0.3) + theme_bw() p2 &lt;- ggplot(draws_df) + geom_point(aes(bias, w1), alpha = 0.3) + theme_bw() p3 &lt;- ggplot(draws_df) + geom_point(aes(bias, w2), alpha = 0.3) + theme_bw() p1 + p2 + p3 [MISSING: model seems good at recovering. BUT HIGH correlations between weights and funnels, so we would probably be safer reparameterizing] 9.19 Multilevel version of the simple bayes model stan_simpleBayes_ml_model &lt;- &quot; data { int&lt;lower=0&gt; N; // n of trials int&lt;lower=0&gt; S; // n of participants array[N, S] int y; array[N, S] real&lt;lower=0, upper = 1&gt; Source1; array[N, S] real&lt;lower=0, upper = 1&gt; Source2; } transformed data{ array[N, S] real l_Source1; array[N, S] real l_Source2; l_Source1 = logit(Source1); l_Source2 = logit(Source2); } parameters { real biasM; real biasSD; array[S] real z_bias; } transformed parameters { vector[S] biasC; vector[S] bias; biasC = biasSD * to_vector(z_bias); bias = biasM + biasC; } model { target += normal_lpdf(biasM | 0, 1); target += normal_lpdf(biasSD | 0, 1) - normal_lccdf(0 | 0, 1); target += std_normal_lpdf(to_vector(z_bias)); for (s in 1:S){ target += bernoulli_logit_lpmf(y[,s] | bias[s] + to_vector(l_Source1[,s]) + to_vector(l_Source2[,s])); } } &quot; write_stan_file( stan_simpleBayes_ml_model, dir = &quot;stan/&quot;, basename = &quot;W9_SimpleBayes_ml.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W9_SimpleBayes_ml.stan&quot; file &lt;- file.path(&quot;stan/W9_SimpleBayes_ml.stan&quot;) mod_simpleBayes &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) 9.20 Multilevel version of the weighted bayes model stan_WB_ml_model &lt;- &quot; data { int&lt;lower=0&gt; N; // n of trials int&lt;lower=0&gt; S; // n of participants array[N, S] int y; array[N, S] real&lt;lower=0, upper = 1&gt; Source1; array[N, S] real&lt;lower=0, upper = 1&gt; Source2; } transformed data { array[N,S] real l_Source1; array[N,S] real l_Source2; l_Source1 = logit(Source1); l_Source2 = logit(Source2); } parameters { real biasM; real w1_M; real w2_M; vector&lt;lower = 0&gt;[3] tau; matrix[3, S] z_IDs; cholesky_factor_corr[3] L_u; } transformed parameters{ matrix[S,3] IDs; IDs = (diag_pre_multiply(tau, L_u) * z_IDs)&#39;; } model { target += normal_lpdf(biasM | 0, 1); target += normal_lpdf(tau[1] | 0, 1) - normal_lccdf(0 | 0, 1); target += normal_lpdf(w1_M | 0, 1); target += normal_lpdf(tau[2] | 0, 1) - normal_lccdf(0 | 0, 1); target += normal_lpdf(w2_M | 0, 1); target += normal_lpdf(tau[3] | 0, 1) - normal_lccdf(0 | 0, 1); target += lkj_corr_cholesky_lpdf(L_u | 3); target += std_normal_lpdf(to_vector(z_IDs)); for (s in 1:S){ for (n in 1:N){ target += bernoulli_logit_lpmf(y[n,s] | biasM + IDs[s, 1] + (w1_M + IDs[s, 2]) * l_Source1[n,s] + (w2_M + IDs[s, 3]) * l_Source2[n,s]); }} } &quot; write_stan_file( stan_WB_ml_model, dir = &quot;stan/&quot;, basename = &quot;W9_WB_ml.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W9_WB_ml.stan&quot; file &lt;- file.path(&quot;stan/W9_WB_ml.stan&quot;) mod_wb &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) [MISSING: Fitting on real data and model comparison] pacman::p_load( tidyverse, future, purrr, furrr, patchwork, brms, cmdstanr ) "],["categorization-models.html", "Chapter 10 Categorization models 10.1 Multilevel GCM 10.2 Now we parallelize [N.B. NOT FINISHED]", " Chapter 10 Categorization models In this module the course covers formal models of categorization. In particular, here we implement a version of the Generalized Context Model (from now on GCM). [MISSING: INTRODUCTION TO THE GCM] In order to understand the GCM, we will rely on a setup from Kruschke 1993. Participants go through 8 blocks of trials. Within each block, participants see 8 stimuli, the same across every block. Each stimulus has to be categorised (classified) as belonging to either category A or category B. After categorizing a stimulus, feedback is given, so that the participant knows which category the stimulus truly belongs to. The stimuli differ along two continuous dimensions (more specifically the height of a square and the position of a line with it). Following on the structure in Kruschke 1993, we need to start simulating data. Let’s start with the stimuli. # Defining the stimuli, their height and position features, and their category stimulus &lt;- c(5,3,7,1,8,2,6,4) height &lt;- c(1,1, 2,2, 3,3, 4,4) position &lt;- c(2,3, 1,4, 1,4, 2,3) category &lt;- as.factor(c(0,0, 1,0, 1,0, 1,1)) # Making this into a tibble stimuli &lt;- tibble(stimulus, height, position, category) # Plotting to make sure all looks right ggplot(stimuli, aes(position, height, color = category, label = stimulus)) + geom_point(shape = 16, size = 3) + geom_label() + geom_abline(intercept = 0, slope = 1, linetype = &quot;dashed&quot;) + theme_bw() # Generating the sequence of stimuli in the full experiment sequence &lt;- c() for (i in 1:8) { temp &lt;- sample(seq(8), 8, replace = F) sequence &lt;- append(sequence, temp) } experiment &lt;- tibble(stimulus = sequence, height = NA, position = NA, category = NA) for (i in seq(nrow(experiment))) { experiment$height[i] &lt;- stimuli$height[stimuli$stimulus == experiment$stimulus[i]] experiment$position[i] &lt;- stimuli$position[stimuli$stimulus == experiment$stimulus[i]] experiment$category[i] &lt;- as.numeric(as.character(stimuli$category[stimuli$stimulus == experiment$stimulus[i]])) } We then have to simulate an agent using the GCM to assess the stimuli. N.B. code based on work by Sara Østergaard First we define functions for distance and similarity and assess them. Distance takes feature values along n dimensions and calculate their euclidean distance, weighing dimensions according to pregiven weights (w). Similarity decays exponentially with distance, with a pre-given exponent (c). See plot. # Distance distance &lt;- function(vect1, vect2, w) { return(sum(w * abs(vect1 - vect2))) } # Similarity similarity &lt;- function(distance, c) { return(exp(-c * distance)) } # Let&#39;s assess similarity dd &lt;- tibble( expand_grid( distance = c(0,.1,.2, .3,.4,.5,1,1.5,2,3,4,5,6), c = c(0.1, 0.2, 0.5, 0.7, 1, 1.5, 2, 3, 4, 5, 6))) %&gt;% mutate( similarity = similarity(distance, c) ) dd %&gt;% mutate(c = factor(c)) %&gt;% ggplot() + geom_line(aes(distance, similarity, group = c, color = c)) + theme_bw() # With distance and similarity in place, we now need to implement an agent that can observe stimuli, put them into categories according to feedback and - once enough stimuli are collected to have at least one exemplar in each category - compare stimuli to exemplars in each category and assess which category is more likely. In other words: 1) if not enough stimuli have already been observed, the agent picks a category at random, receives feedback and adjusts accordingly the category; otherwise, 2) it assesses average distance (according to weights) from observed exemplars by category; calculates similarity (according to c); and uses the relative similarity to the two categories to produce a probability of choosing category one. then it receives feedback and adjusts category accordingly. As usual we make the agent a function, so that we can more easily deploy it. ### generative model ### gcm &lt;- function(w, c, obs, cat_one, quiet = TRUE) { # create an empty list to save probability of saying &quot;1&quot; for each trial r &lt;- c() ntrials &lt;- nrow(obs) for (i in 1:ntrials) { # If quiet is FALSE, print every ten trials if (!quiet &amp;&amp; i %% 10 == 0) { print(paste(&quot;i =&quot;, i)) } # if this is the first trial, or there any category with no exemplars seen yet, set the choice to random if (i == 1 || sum(cat_one[1:(i - 1)]) == 0 || sum(cat_one[1:(i - 1)]) == (i - 1)) { r &lt;- c(r, .5) } else { similarities &lt;- c() # for each previously seen stimulus assess distance and similarity for (e in 1:(i - 1)) { sim &lt;- similarity(distance(obs[i, ], obs[e, ], w), c) similarities &lt;- c(similarities, sim) } # Calculate prob of saying &quot;1&quot; by dividing similarity to 1 by the sum of similarity to 1 and to 2 numerator &lt;- 0.5 * sum(similarities[cat_one[1:(i - 1)] == 1]) denominator &lt;- 0.5 * sum(similarities[cat_one[1:(i - 1)] == 1]) + 0.5 * sum(similarities[cat_one[1:(i - 1)] == 0]) r &lt;- c(r, numerator / denominator) } } return(rbinom(ntrials, 1, r)) } With the agent in place, we can now simulate behavior on our simulated stimuli and observe the impact of different weights and scaling parameters c. # function for simulation responses simulate_responses &lt;- function(agent, w, c) { observations &lt;- experiment %&gt;% select(c(&quot;height&quot;, &quot;position&quot;)) category &lt;- experiment$category if (w == &quot;equal&quot;) { weight &lt;- rep(1 / 2, 2) } else if (w == &quot;skewed1&quot;) { weight &lt;- c(0, 1) } else if (w == &quot;skewed2&quot;) { weight &lt;- c(0.1, 0.9) } # simulate responses responses &lt;- gcm( weight, c, observations, category ) tmp_simulated_responses &lt;- experiment %&gt;% mutate( trial = seq(nrow(experiment)), sim_response = responses, correct = ifelse(category == sim_response, 1, 0), performance = cumsum(correct) / seq_along(correct), c = c, w = w, agent = agent ) return(tmp_simulated_responses) } # simulate responses plan(multisession, workers = availableCores()) param_df &lt;- dplyr::tibble( expand_grid( agent = 1:10, c = seq(.1, 2, 0.2), w = c(&quot;equal&quot;, &quot;skewed1&quot;, &quot;skewed2&quot;) ) ) simulated_responses &lt;- future_pmap_dfr(param_df, simulate_responses, .options = furrr_options(seed = TRUE) ) And now we can try a few plots to better understand how the model fares and the difference made by weights and scaling factors. p3 &lt;- simulated_responses %&gt;% mutate(w = as.factor(w)) %&gt;% ggplot(aes(trial, performance, group = w, color = w)) + geom_smooth() + theme_bw() + facet_wrap(c ~ .) p4 &lt;- simulated_responses %&gt;% mutate(c = as.factor(c)) %&gt;% ggplot(aes(trial, performance, group = c, color = c)) + geom_smooth() + theme_bw() + facet_wrap(w ~ .) p3 + p4 ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; p5 &lt;- simulated_responses %&gt;% mutate(c = as.factor(c)) %&gt;% ggplot(aes(st, performance, group = c, color = c)) + geom_smooth() + theme_bw() + facet_wrap(w ~ .) [MISSING: Discussion of how to make sense of the plots: Equal Weights (matching the actual rule) generating better decisions as long as c is above 1] While we could try different scenarios, let us now move on to inference. We need to build the same GCM model in Stan. [MISSING: MORE DETAILED EXPLANATION] gcm_model &lt;- &quot; // Generalized Context Model (GCM) data { int&lt;lower=1&gt; ntrials; // number of trials int&lt;lower=1&gt; nfeatures; // number of predefined relevant features array[ntrials] int&lt;lower=0, upper=1&gt; cat_one; // true responses on a trial by trial basis array[ntrials] int&lt;lower=0, upper=1&gt; y; // decisions on a trial by trial basis array[ntrials, nfeatures] real obs; // stimuli as vectors of features real&lt;lower=0, upper=1&gt; b; // initial bias for category one over two // priors vector[nfeatures] w_prior_values; // concentration parameters for dirichlet distribution &lt;lower=1&gt; array[2] real c_prior_values; // mean and variance for logit-normal distribution } transformed data { array[ntrials] int&lt;lower=0, upper=1&gt; cat_two; // dummy variable for category two over cat 1 array[sum(cat_one)] int&lt;lower=1, upper=ntrials&gt; cat_one_idx; // array of which stimuli are cat 1 array[ntrials-sum(cat_one)] int&lt;lower=1, upper=ntrials&gt; cat_two_idx; // array of which stimuli are cat 2 int idx_one = 1; // Initializing int idx_two = 1; for (i in 1:ntrials){ cat_two[i] = abs(cat_one[i]-1); if (cat_one[i]==1){ cat_one_idx[idx_one] = i; idx_one +=1; } else { cat_two_idx[idx_two] = i; idx_two += 1; } } } parameters { simplex[nfeatures] w; // simplex means sum(w)=1 real logit_c; } transformed parameters { // parameter c real&lt;lower=0, upper=2&gt; c = inv_logit(logit_c)*2; // times 2 as c is bounded between 0 and 2 // parameter r (probability of response = category 1) array[ntrials] real&lt;lower=0.0001, upper=0.9999&gt; r; array[ntrials] real rr; for (i in 1:ntrials) { // calculate distance from obs to all exemplars array[(i-1)] real exemplar_sim; for (e in 1:(i-1)){ array[nfeatures] real tmp_dist; for (j in 1:nfeatures) { tmp_dist[j] = w[j]*abs(obs[e,j] - obs[i,j]); } exemplar_sim[e] = exp(-c * sum(tmp_dist)); } if (sum(cat_one[:(i-1)])==0 || sum(cat_two[:(i-1)])==0){ // if there are no examplars in one of the categories r[i] = 0.5; } else { // calculate similarity array[2] real similarities; array[sum(cat_one[:(i-1)])] int tmp_idx_one = cat_one_idx[:sum(cat_one[:(i-1)])]; array[sum(cat_two[:(i-1)])] int tmp_idx_two = cat_two_idx[:sum(cat_two[:(i-1)])]; similarities[1] = sum(exemplar_sim[tmp_idx_one]); similarities[2] = sum(exemplar_sim[tmp_idx_two]); // calculate r[i] rr[i] = (b*similarities[1]) / (b*similarities[1] + (1-b)*similarities[2]); // to make the sampling work if (rr[i] &gt; 0.9999){ r[i] = 0.9999; } else if (rr[i] &lt; 0.0001) { r[i] = 0.0001; } else if (rr[i] &gt; 0.0001 &amp;&amp; rr[i] &lt; 0.9999) { r[i] = rr[i]; } else { r[i] = 0.5; } } } } model { // Priors target += dirichlet_lpdf(w | w_prior_values); target += normal_lpdf(logit_c | c_prior_values[1], c_prior_values[2]); // Decision Data target += bernoulli_lpmf(y | r); } generated quantities { // priors simplex[nfeatures] w_prior = dirichlet_rng(w_prior_values); real logit_c_prior = normal_rng(c_prior_values[1], c_prior_values[2]); real&lt;lower=0, upper=2&gt; c_prior = inv_logit(logit_c_prior)*2; // prior pred array[ntrials] real&lt;lower=0, upper=1&gt; r_prior; array[ntrials] real rr_prior; for (i in 1:ntrials) { // calculate distance from obs to all exemplars array[(i-1)] real exemplar_dist; for (e in 1:(i-1)){ array[nfeatures] real tmp_dist; for (j in 1:nfeatures) { tmp_dist[j] = w_prior[j]*abs(obs[e,j] - obs[i,j]); } exemplar_dist[e] = sum(tmp_dist); } if (sum(cat_one[:(i-1)])==0 || sum(cat_two[:(i-1)])==0){ // if there are no examplars in one of the categories r_prior[i] = 0.5; } else { // calculate similarity array[2] real similarities; array[sum(cat_one[:(i-1)])] int tmp_idx_one = cat_one_idx[:sum(cat_one[:(i-1)])]; array[sum(cat_two[:(i-1)])] int tmp_idx_two = cat_two_idx[:sum(cat_two[:(i-1)])]; similarities[1] = exp(-c_prior * sum(exemplar_dist[tmp_idx_one])); similarities[2] = exp(-c_prior * sum(exemplar_dist[tmp_idx_two])); // calculate r[i] rr_prior[i] = (b*similarities[1]) / (b*similarities[1] + (1-b)*similarities[2]); // to make the sampling work if (rr_prior[i] == 1){ r_prior[i] = 0.9999; } else if (rr_prior[i] == 0) { r_prior[i] = 0.0001; } else if (rr_prior[i] &gt; 0 &amp;&amp; rr_prior[i] &lt; 1) { r_prior[i] = rr_prior[i]; } else { r_prior[i] = 0.5; } } } array[ntrials] int&lt;lower=0, upper=1&gt; priorpred = bernoulli_rng(r_prior); // posterior pred array[ntrials] int&lt;lower=0, upper=1&gt; posteriorpred = bernoulli_rng(r); array[ntrials] int&lt;lower=0, upper=1&gt; posteriorcorrect; for (i in 1:ntrials) { if (posteriorpred[i] == cat_one[i]) { posteriorcorrect[i] = 1; } else { posteriorcorrect[i] = 0; } } // log likelihood array[ntrials] real log_lik; for (i in 1:ntrials) { log_lik[i] = bernoulli_lpmf(y[i] | r[i]); } }&quot; write_stan_file( gcm_model, dir = &quot;stan/&quot;, basename = &quot;W10_GCM.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W10_GCM.stan&quot; file &lt;- file.path(&quot;stan/W10_GCM.stan&quot;) mod_GCM &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) Now it’s time to fit the data d &lt;- simulated_responses %&gt;% subset( c == &quot;1.1&quot; &amp; w == &quot;equal&quot; ) gcm_data &lt;- list( ntrials = nrow(d), nfeatures = 2, cat_one = d$category, y = d$sim_response, obs = as.matrix(d[, c(&quot;height&quot;, &quot;position&quot;)]), b = 0.5, w_prior_values = c(1, 1), c_prior_values = c(0, 1) ) samples_gcm &lt;- mod_GCM$sample( data = gcm_data, seed = 123, chains = 1, parallel_chains = 1, threads_per_chain = 4, iter_warmup = 1000, iter_sampling = 1000, refresh = 500 ) ## Running MCMC with 1 chain, with 4 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 2182.1 seconds. Now we need to check the model samples_gcm$cmdstan_diagnose() ## Processing csv files: /var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/W10_GCM-202402150652-1-85a406.csv ## ## Checking sampler transitions treedepth. ## Treedepth satisfactory for all transitions. ## ## Checking sampler transitions for divergences. ## No divergent transitions found. ## ## Checking E-BFMI - sampler transitions HMC potential energy. ## E-BFMI satisfactory. ## ## Effective sample size satisfactory. ## ## Split R-hat values satisfactory all parameters. ## ## Processing complete, no problems detected. samples_gcm$summary() ## # A tibble: 5,129 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -392. -392. 0.976 0.695 -394. -391. 1.00 503. 754. ## 2 w[1] 0.485 0.483 0.0590 0.0591 0.389 0.581 1.00 583. 624. ## 3 w[2] 0.515 0.517 0.0590 0.0591 0.419 0.611 1.00 583. 624. ## 4 logit_c -0.0957 -0.0940 0.166 0.166 -0.371 0.186 1.00 838. 716. ## 5 c 0.953 0.953 0.0823 0.0827 0.817 1.09 1.00 838. 716. ## 6 r[1] 0.5 0.5 0 0 0.5 0.5 NA NA NA ## 7 r[2] 0.5 0.5 0 0 0.5 0.5 NA NA NA ## 8 r[3] 0.5 0.5 0 0 0.5 0.5 NA NA NA ## 9 r[4] 0.394 0.394 0.0382 0.0372 0.331 0.456 1.00 598. 494. ## 10 r[5] 0.385 0.385 0.0101 0.00964 0.367 0.401 1.00 760. 544. ## # ℹ 5,119 more rows draws_df &lt;- as_draws_df(samples_gcm$draws()) ggplot(draws_df, aes(.iteration, c, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws_df, aes(.iteration, logit_c, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws_df, aes(.iteration, `w[1]`, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws_df, aes(.iteration, `w[2]`, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws_df) + geom_histogram(aes(c), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_histogram(aes(c_prior), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = d$c[1]) + theme_bw() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(draws_df) + geom_histogram(aes(`w[1]`), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_histogram(aes(`w_prior[1]`), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = 0.5) + theme_bw() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(draws_df) + geom_histogram(aes(`w[2]`), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_histogram(aes(`w_prior[2]`), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = 0.5) + theme_bw() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(draws_df) + geom_point(aes(c, `w[2]`), alpha = 0.6, color = &quot;lightblue&quot;) + theme_bw() ggplot(draws_df) + geom_point(aes(c, `w[1]`), alpha = 0.6, color = &quot;lightblue&quot;) + theme_bw() ggplot(draws_df) + geom_point(aes(`w[1]`, `w[2]`), alpha = 0.6, color = &quot;lightblue&quot;) + theme_bw() C looks like crap, while weights seem decently recovered. Let’s look at the larger picture, but looping through the different combinations of parameter values. pacman::p_load(future, purrr, furrr) plan(multisession, workers = availableCores()) sim_d_and_fit &lt;- function(agent, scaling, weights) { temp &lt;- simulated_responses %&gt;% subset( c == scaling &amp; w == weights &amp; agent == agent ) data &lt;- list( ntrials = nrow(temp), nfeatures = 2, cat_one = temp$category, y = temp$sim_response, obs = as.matrix(temp[, c(&quot;height&quot;, &quot;position&quot;)]), b = 0.5, w_prior_values = c(1, 1), c_prior_values = c(0, 1) ) samples_gcm &lt;- mod_GCM$sample( data = data, seed = 123, chains = 1, parallel_chains = 1, threads_per_chain = 4, iter_warmup = 1000, iter_sampling = 1000, refresh = 500 ) draws_df &lt;- as_draws_df(samples_gcm$draws()) temp &lt;- tibble(trueC = scaling, trueW = weights, agent = agent, estC = draws_df$c, estW1 = draws_df$`w[1]`, estW2 = draws_df$`w[2]` ) return(temp) } temp &lt;- tibble(unique(simulated_responses[,c(&quot;agent&quot;, &quot;c&quot;, &quot;w&quot;)])) %&gt;% rename( scaling = c, weights = w ) recovery_df &lt;- future_pmap_dfr(temp, sim_d_and_fit, .options = furrr_options(seed = TRUE)) write_csv(recovery_df, &quot;simdata/W10_GCM_recoverydf.csv&quot;) Time to visualize recovery_df &lt;- read_csv(&quot;simdata/W10_GCM_recoverydf.csv&quot;) ## Rows: 300000 Columns: 6 ## ── Column specification ──────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): trueW ## dbl (5): trueC, agent, estC, estW1, estW2 ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. p1 &lt;- ggplot(recovery_df) + geom_density(aes(estC, group = trueW, fill = trueW), alpha = 0.3) + #geom_vline(xintercept = trueC) + facet_wrap(. ~ trueC) + theme_bw() p2 &lt;- ggplot(recovery_df) + geom_density(aes(estW1, group = trueW, fill = trueW), alpha = 0.3) + #geom_vline(xintercept = trueC) + facet_wrap(trueC ~ .) + theme_bw() p1 / p2 10.1 Multilevel GCM [MISSING: quick reminder of what it means to make GCM multilevel: weights and can vary by participants, but they do not do so in correlated ways] 10.1.1 Simulate hierarchical simplices We need weights that sum up to 1 at the population level and at the individual level. Let’s simulate the dirichlet distribution to see how it does it. simulate_dirichlet &lt;- function(weights, kappa, agents){ w_n &lt;- length(weights) w_ind &lt;- rdirichlet(agents, weights * kappa) w_ind_df &lt;- tibble( agent = as.factor(rep(seq(agents), each = w_n)), value = c(w_ind), weight = rep(seq(w_n), agents) ) return(w_ind_df) } d &lt;- simulate_dirichlet(weights = c(0.5, 0.5), kappa = 100, agents = 10) p1 &lt;- ggplot(d, aes(weight, value, group = agent, color = agent)) + geom_point() + geom_line(linetype = &quot;dashed&quot;, alpha = 0.5) + ylim(0,1) + theme_bw() d &lt;- simulate_dirichlet(weights = c(0.5, 0.5), kappa = 1, agents = 10) p2 &lt;- ggplot(d, aes(weight, value, group = agent, color = agent)) + geom_point() + geom_line(linetype = &quot;dashed&quot;, alpha = 0.5) + ylim(0,1) + theme_bw() p1 + p2 10.1.2 Set up the data simulation We need to feed: - agents - scaling (M and SD) - weights (weights and concentration) agents &lt;- 10 scalingM &lt;- 1 scalingSD &lt;- 0.1 weights &lt;- c(0.5,0.5) kappa &lt;- 1 # First one agent, just to make sure it works simulate_responses &lt;- function(agent, weights, c) { observations &lt;- experiment %&gt;% select(c(&quot;height&quot;, &quot;position&quot;)) category &lt;- experiment$category # simulate responses responses &lt;- gcm( weights, c, observations, category ) tmp_simulated_responses &lt;- experiment %&gt;% mutate( trial = seq(nrow(experiment)), sim_response = responses, correct = ifelse(category == sim_response, 1, 0), performance = cumsum(correct) / seq_along(correct), c = c, w1 = weights[1], w2 = weights[2], agent = agent ) return(tmp_simulated_responses) } d &lt;- simulate_responses(agents, weights, scalingM) ## Then we make sure to simulate n agents simulate_ml_responses &lt;- function(agents, scalingM, scalingSD, weights, kappa) { w_ind &lt;- rdirichlet(agents, weights * kappa) c_ind &lt;- rnorm(agents, scalingM, scalingSD) for (i in 1:agents) { tmp &lt;- simulate_responses(i, weights = c(w_ind[i,1:2]), c = c_ind[i]) if (i == 1) { simulated_responses &lt;- tmp } else { simulated_responses &lt;- rbind(simulated_responses, tmp) } } return(simulated_responses) } # Simulate and visualize d &lt;- simulate_ml_responses(agents, scalingM, scalingSD, weights, kappa) ggplot(d, aes(trial, performance)) + geom_smooth() + geom_line(aes(group = agent, color = agent)) + theme_bw() ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; 10.1.3 Set up the Stan model gcm_ml_model &lt;- &quot; // Generalized Context Model (GCM) - multilevel version data { int&lt;lower=1&gt; nsubjects; // number of subjects int&lt;lower=1&gt; ntrials; // number of trials int&lt;lower=1&gt; nfeatures; // number of predefined relevant features array[ntrials] int&lt;lower=0, upper=1&gt; cat_one; // true responses on a trial by trial basis array[ntrials, nsubjects] int&lt;lower=0, upper=1&gt; y; // decisions on a trial by trial basis array[ntrials, nfeatures] real obs; // stimuli as vectors of features assuming all participants get the same sequence real&lt;lower=0, upper=1&gt; b; // initial bias for category one over two // priors vector[nfeatures] w_prior_values; // concentration parameters for dirichlet distribution &lt;lower=1&gt; array[2] real c_prior_values; // mean and variance for logit-normal distribution } transformed data { // assuming all participants get the same sequence array[ntrials] int&lt;lower=0, upper=1&gt; cat_two; // dummy variable for category two over cat 1 array[sum(cat_one)] int&lt;lower=1, upper = ntrials&gt; cat_one_idx; // array of which stimuli are cat 1 array[ntrials - sum(cat_one)] int&lt;lower = 1, upper = ntrials&gt; cat_two_idx; // array of which stimuli are cat 2 int idx_one = 1; // Initializing int idx_two = 1; for (i in 1:ntrials){ cat_two[i] = abs(cat_one[i]-1); if (cat_one[i]==1){ cat_one_idx[idx_one] = i; idx_one +=1; } else { cat_two_idx[idx_two] = i; idx_two += 1; } } } parameters { real logit_c_M; // Pop Mean of the scaling parameter (how fast similarity decrease with distance). real&lt;lower = 0&gt; logit_c_SD; // Pop SD of the scaling parameter (how fast similarity decrease with distance). vector[nsubjects] logit_c; // scaling parameter (how fast similarity decrease with distance). simplex[nfeatures] weight; // simplex means sum(w)=1 real&lt;lower=0&gt; kappa; array[nsubjects] simplex[nfeatures] w_ind; // weight parameter (how much attention should be paid to feature 1 related to feature 2 - summing up to 1) } transformed parameters { // parameter w vector[nfeatures] alpha = kappa * weight; // parameter c vector&lt;lower=0,upper=2&gt;[nsubjects] c = inv_logit(logit_c)*2; // times 2 as c is bounded between 0 and 2 // parameter r (probability of response = category 1) array[ntrials, nsubjects] real&lt;lower=0.0001, upper=0.9999&gt; r; array[ntrials, nsubjects] real rr; for (sub in 1:nsubjects) { for (trial in 1:ntrials) { // calculate distance from obs to all exemplars array[(trial-1)] real exemplar_sim; for (e in 1:(trial-1)){ array[nfeatures] real tmp_dist; for (feature in 1:nfeatures) { tmp_dist[feature] = w_ind[sub,feature]*abs(obs[e,feature] - obs[trial,feature]); } exemplar_sim[e] = exp(-c[sub] * sum(tmp_dist)); } if (sum(cat_one[:(trial-1)])==0 || sum(cat_two[:(trial-1)])==0){ // if there are no examplars in one of the categories r[trial,sub] = 0.5; } else { // calculate similarity array[2] real similarities; array[sum(cat_one[:(trial-1)])] int tmp_idx_one = cat_one_idx[:sum(cat_one[:(trial-1)])]; array[sum(cat_two[:(trial-1)])] int tmp_idx_two = cat_two_idx[:sum(cat_two[:(trial-1)])]; similarities[1] = sum(exemplar_sim[tmp_idx_one]); similarities[2] = sum(exemplar_sim[tmp_idx_two]); // calculate r rr[trial,sub] = (b*similarities[1]) / (b*similarities[1] + (1-b)*similarities[2]); // to make the sampling work if (rr[trial,sub] &gt; 0.9999){ r[trial,sub] = 0.9999; } else if (rr[trial,sub] &lt; 0.0001) { r[trial,sub] = 0.0001; } else if (rr[trial,sub] &gt; 0.0001 &amp;&amp; rr[trial,sub] &lt; 0.9999) { r[trial,sub] = rr[trial,sub]; } else { r[trial,sub] = 0.5; }}}}} model { // Priors target += exponential_lpdf(kappa | 0.1); target += dirichlet_lpdf(weight | w_prior_values); target += normal_lpdf(logit_c_M | c_prior_values[1], c_prior_values[2]); target += normal_lpdf(logit_c_SD | 0, 1) - normal_lccdf(0 | 0, 1); target += normal_lpdf(logit_c | logit_c_M, logit_c_SD); // Decision Data for (sub in 1:nsubjects){ target += dirichlet_lpdf(w_ind[sub] | alpha); for (trial in 1:ntrials){ target += bernoulli_lpmf(y[trial,sub] | r[trial,sub]); } } } // generated quantities { // // priors // simplex[nfeatures] w_prior = dirichlet_rng(w_prior_values); // real logit_c_prior = normal_rng(c_prior_values[1], c_prior_values[2]); // real&lt;lower=0, upper=2&gt; c_prior = inv_logit(logit_c_prior)*2; // // // prior pred // array[ntrials] real&lt;lower=0, upper=1&gt; r_prior; // array[ntrials] real rr_prior; // for (i in 1:ntrials) { // // // calculate distance from obs to all exemplars // array[(i-1)] real exemplar_dist; // for (e in 1:(i-1)){ // array[nfeatures] real tmp_dist; // for (j in 1:nfeatures) { // tmp_dist[j] = w_prior[j]*abs(obs[e,j] - obs[i,j]); // } // exemplar_dist[e] = sum(tmp_dist); // } // // if (sum(cat_one[:(i-1)])==0 || sum(cat_two[:(i-1)])==0){ // if there are no examplars in one of the categories // r_prior[i] = 0.5; // // } else { // // calculate similarity // array[2] real similarities; // // array[sum(cat_one[:(i-1)])] int tmp_idx_one = cat_one_idx[:sum(cat_one[:(i-1)])]; // array[sum(cat_two[:(i-1)])] int tmp_idx_two = cat_two_idx[:sum(cat_two[:(i-1)])]; // similarities[1] = exp(-c_prior * sum(exemplar_dist[tmp_idx_one])); // similarities[2] = exp(-c_prior * sum(exemplar_dist[tmp_idx_two])); // // // calculate r[i] // rr_prior[i] = (b*similarities[1]) / (b*similarities[1] + (1-b)*similarities[2]); // // // to make the sampling work // if (rr_prior[i] == 1){ // r_prior[i] = 0.9999; // } else if (rr_prior[i] == 0) { // r_prior[i] = 0.0001; // } else if (rr_prior[i] &gt; 0 &amp;&amp; rr_prior[i] &lt; 1) { // r_prior[i] = rr_prior[i]; // } else { // r_prior[i] = 0.5; // } // } // } // // array[ntrials] int&lt;lower=0, upper=1&gt; priorpred = bernoulli_rng(r_prior); // // // // posterior pred // array[ntrials] int&lt;lower=0, upper=1&gt; posteriorpred = bernoulli_rng(r); // array[ntrials] int&lt;lower=0, upper=1&gt; posteriorcorrect; // for (i in 1:ntrials) { // if (posteriorpred[i] == cat_one[i]) { // posteriorcorrect[i] = 1; // } else { // posteriorcorrect[i] = 0; // } // } // // // // log likelihood // array[ntrials] real log_lik; // // for (i in 1:ntrials) { // log_lik[i] = bernoulli_lpmf(y[i] | r[i]); // } // // } &quot; write_stan_file( gcm_ml_model, dir = &quot;stan/&quot;, basename = &quot;W10_GCM_ml.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W10_GCM_ml.stan&quot; file &lt;- file.path(&quot;stan/W10_GCM_ml.stan&quot;) mod_GCM_ml &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;)) ## Fit the simulated data d1 &lt;- d[,c(&quot;agent&quot;,&quot;trial&quot;,&quot;sim_response&quot;)] %&gt;% pivot_wider( names_from = agent, values_from = c(sim_response)) gcm_ml_data &lt;- list( nsubjects = agents, ntrials = nrow(experiment), nfeatures = 2, cat_one = experiment$category, y = as.matrix(d1[, 2:(agents + 1)]), obs = as.matrix(experiment[, c(&quot;height&quot;, &quot;position&quot;)]), b = 0.5, w_prior_values = c(1, 1), c_prior_values = c(0, 1) ) samples_gcm_ml &lt;- mod_GCM_ml$sample( data = gcm_ml_data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 1000, iter_sampling = 1000, refresh = 1000 ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 finished in 174.9 seconds. ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 208.2 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 191.5 seconds. ## Total execution time: 208.4 seconds. ## Warning: 125 of 2000 (6.0%) transitions ended with a divergence. ## See https://mc-stan.org/misc/warnings for details. ## Warning: 1 of 2 chains had an E-BFMI less than 0.3. ## See https://mc-stan.org/misc/warnings for details. draws &lt;- as_draws_df(samples_gcm_ml) ggplot(draws, aes(.iteration, logit_c_M, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws, aes(.iteration, logit_c_SD, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws, aes(.iteration, `weight[1]`, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws, aes(.iteration, `weight[2]`, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() ggplot(draws, aes(.iteration, `kappa`, group = .chain, color = .chain)) + geom_line(alpha = 0.5) + theme_classic() draws %&gt;% mutate(c_prior = rnorm(nrow(draws), 1,1)) %&gt;% ggplot() + geom_histogram(aes(logit_c_M), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_histogram(aes(c_prior), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = logit_scaled(scalingM,0, 2)) + theme_bw() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. library(msm) draws %&gt;% mutate(c_prior = rtnorm(nrow(draws), 0, 1, lower = 0)) %&gt;% ggplot() + geom_histogram(aes(logit_c_SD), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_histogram(aes(c_prior), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = 0.5) + theme_bw() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. draws %&gt;% mutate(`w_prior[1]` = rdirichlet(nrow(draws), c(1, 1))[,1]) %&gt;% ggplot() + geom_histogram(aes(`weight[1]`), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_histogram(aes(`w_prior[1]`), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = 0.5) + theme_bw() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. draws %&gt;% mutate(`w_prior[2]` = rdirichlet(nrow(draws), c(1, 1))[,1]) %&gt;% ggplot() + geom_histogram(aes(`weight[2]`), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_histogram(aes(`w_prior[2]`), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = 0.5) + theme_bw() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. draws %&gt;% mutate(`kappa_prior` = rexp(nrow(draws), 0.1)) %&gt;% ggplot() + geom_histogram(aes(`kappa`), alpha = 0.6, fill = &quot;lightblue&quot;) + geom_histogram(aes(`kappa_prior`), alpha = 0.6, fill = &quot;pink&quot;) + geom_vline(xintercept = 1) + theme_bw() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(draws) + geom_point(aes(`weight[1]`, `weight[2]`), alpha = 0.6, color = &quot;lightblue&quot;) + theme_bw() ggplot(draws) + geom_point(aes(logit_c_M, logit_c_SD), alpha = 0.6, color = &quot;lightblue&quot;) + theme_bw() ggplot(draws) + geom_point(aes(kappa, `weight[1]`), alpha = 0.6, color = &quot;lightblue&quot;) + theme_bw() ggplot(draws) + geom_point(aes(kappa, `weight[2]`), alpha = 0.6, color = &quot;lightblue&quot;) + theme_bw() ggplot(draws) + geom_point(aes(kappa, `logit_c_M`), alpha = 0.6, color = &quot;lightblue&quot;) + theme_bw() 10.2 Now we parallelize [N.B. NOT FINISHED] # ## Then we create the function that simulates data and fits the model, so we can quickly go through multiple parameter values in the simulation # # sim_ml_and_fit &lt;- function(agents, scalingM, scalingSD, weights, kappa) { # # d &lt;- simulate_ml_responses(agents, scalingM, scalingSD, weights, kappa) # # d1 &lt;- d[,c(&quot;agent&quot;,&quot;trial&quot;,&quot;sim_response&quot;)] %&gt;% pivot_wider( # names_from = agent, # values_from = c(sim_response)) # # gcm_ml_data &lt;- list( # nsubjects = agents, # ntrials = nrow(experiment), # nfeatures = 2, # cat_one = experiment$category, # y = as.matrix(d1[, 2:(agents + 1)]), # obs = as.matrix(experiment[, c(&quot;height&quot;, &quot;position&quot;)]), # b = 0.5, # w_prior_values = c(1, 1), # c_prior_values = c(0, 1) # ) # # samples_gcm_ml &lt;- mod_GCM_ml$sample( # data = gcm_ml_data, # seed = 123, # chains = 2, # parallel_chains = 2, # threads_per_chain = 2, # iter_warmup = 1000, # iter_sampling = 1000, # refresh = 1000 # ) # # # draws_df &lt;- as_draws_df(samples_gcm$draws()) # temp &lt;- tibble(trueC_M = scalingM, # trueC_SD = scalingSD, # trueW1 = weights[1], # trueW2 = weights[2], # trueKappa = kappa, # agents = agents, # # FROM HERE # estC = draws_df$c, # estW1 = draws_df$`w[1]`, # estW2 = draws_df$`w[2]` # ) # # return(temp) # # } # # ## Now I need to make a list of lists # # # temp &lt;- tibble(unique(simulated_responses[,c(&quot;agent&quot;, &quot;c&quot;, &quot;w&quot;)])) %&gt;% # rename( # scaling = c, # weights = w # ) # # recovery_df &lt;- future_pmap_dfr(temp, sim_d_and_fit, .options = furrr_options(seed = TRUE)) # # write_csv(recovery_df, &quot;simdata/W10_GCM_recoverydf.csv&quot;) 10.2.1 Student-produced models of categorization Attempting to identify features Attempting to associate 1 of the features to one of the outcome dimensions (e.g. green as danger), test hypothesis, stay if positive, try different trait if negative. [missing details on how to define the hypothesized association, and how much evidence needed to shift] Remembering the rule and/or remembering the single exemplars Focusing on 1 feature 1 outcome vs trying to incorporate additional features Using arbitrary associations btw features and outcomes vs. relying on intuition (raised arms are dangerous) "],["categorization-models-1.html", "Chapter 11 Categorization models 11.1 Defining parameters 11.2 Simulating with alpha 0.9 and p 0.9 11.3 Simulating with p = 0.75 11.4 What about asymmetric learning? 11.5 Model fitting: symmetric RL 11.6 Model fitting: asymmetric RL 11.7 Model fitting: multilevel", " Chapter 11 Categorization models In this module the course covers reinforcement learning. In particular, here we implement a version of the Rescorla-Wagner model. [Missing additional RL models] softmax &lt;- function(x, tau) { outcome = 1 / (1 + exp(-tau * x)) return(outcome) } ValueUpdate = function(value, alpha, choice, feedback) { PE &lt;- feedback - value v1 &lt;- value[1] + alpha * (1 - choice) * (feedback - value[1]) v2 &lt;- value[2] + alpha * (choice) * (feedback - value[2]) updatedValue &lt;- c(v1, v2) return(updatedValue) } 11.1 Defining parameters agents &lt;- 100 trials &lt;- 120 11.2 Simulating with alpha 0.9 and p 0.9 value &lt;- c(0,0) alpha &lt;- 0.9 temperature &lt;- 1 choice &lt;- 0 feedback &lt;- -1 p &lt;- 0.9 # probability that choice 0 gives a prize (1-p is probability that choice 1 gives a prize) ValueUpdate(value, alpha, choice, feedback) ## [1] -0.9 0.0 d &lt;- tibble(trial = rep(NA, trials), choice = rep(NA, trials), value1 = rep(NA, trials), value2 = rep(NA, trials), feedback = rep(NA, trials)) Bot &lt;- rbinom(trials, 1, p) for (i in 1:trials) { choice &lt;- 1 #rbinom(1, 1, softmax(value[2] - value[1], temperature)) feedback &lt;- ifelse(Bot[i] == choice, 1, -1) value &lt;- ValueUpdate(value, alpha, choice, feedback) d$choice[i] &lt;- choice d$value1[i] &lt;- value[1] d$value2[i] &lt;- value[2] d$feedback[i] &lt;- feedback } d &lt;- d %&gt;% mutate( trial = seq(trials), prevFeedback = lead(feedback)) ggplot(subset(d, trial &lt; 21)) + geom_line(aes(trial, value1), color = &quot;green&quot;) + geom_line(aes(trial, value2), color = &quot;blue&quot;) + geom_line(aes(trial, prevFeedback), color = &quot;red&quot;) + theme_bw() 11.3 Simulating with p = 0.75 # Let&#39;s imagine a situation where the underlying rate is 0.75 alpha &lt;- 0.9 temperature &lt;- 5 choice &lt;- 0 feedback &lt;- -1 p &lt;- 0.75 # probability that choice 0 gives a prize (1-p is probability that choice 1 gives a prize) df &lt;- NULL n &lt;- 1 for (temperature in c(0.01, 0.5, 1, 5, 10, 15)) { for (alpha in seq(0.1, 1, 0.1)) { value &lt;- c(0,0) d &lt;- tibble(trial = rep(NA, trials), choice = rep(NA, trials), value1 = rep(NA, trials), value2 = rep(NA, trials), feedback = rep(NA, trials), alpha = rep(NA, trials), temperature = rep(NA, trials), agent = n) for (i in 1:trials) { choice &lt;- rbinom(1, 1, softmax(value[2] - value[1], temperature)) feedback &lt;- ifelse(Bot[i] == choice, 1, -1) value &lt;- ValueUpdate(value, alpha, choice, feedback) d$trial[i] &lt;- i d$choice[i] &lt;- choice d$value1[i] &lt;- value[1] d$value2[i] &lt;- value[2] d$feedback[i] &lt;- feedback d$alpha[i] &lt;- alpha d$temperature[i] &lt;- temperature } if (exists(&quot;df&quot;)) {df &lt;- rbind(df, d)} else {df &lt;- d} n &lt;- n + 1 } } df &lt;- df %&gt;% group_by(alpha, temperature) %&gt;% mutate( prevFeedback = lead(feedback)) d1 &lt;- df %&gt;% subset(trial &lt; 21 &amp; temperature == 0.01) ggplot() + geom_line(data = subset(d1, alpha == 1), aes(trial, prevFeedback), color = &quot;red&quot;) + geom_line(data = subset(d1, alpha == 0.9), aes(trial, value2), color = &quot;purple&quot;) + geom_line(data = subset(d1, alpha == 0.5), aes(trial, value2), color = &quot;blue&quot;) + geom_line(data = subset(d1, alpha == 0.2), aes(trial, value2), color = &quot;green&quot;) + theme_bw() df &lt;- df %&gt;% group_by(alpha, temperature) %&gt;% mutate( rate = cumsum(choice) / seq_along(choice), performance = cumsum(feedback) / seq_along(feedback) ) ggplot(subset(df, trial &lt; 41), aes(trial, performance, group = alpha, color = alpha)) + geom_line(alpha = 0.5) + facet_wrap(.~temperature) + theme_bw() ggplot(subset(df, trial &lt; 41), aes(trial, performance, group = temperature, color = temperature)) + geom_line(alpha = 0.5) + facet_wrap(.~alpha) + theme_bw() 11.4 What about asymmetric learning? [Missing: simulations of RL with different alphas for positive and negative feedback] 11.5 Model fitting: symmetric RL d &lt;- df %&gt;% subset(alpha == 0.6 &amp; temperature == 5) data &lt;- list( trials = trials, choice = d$choice + 1, feedback = d$feedback ) stan_model &lt;- &quot; data { int&lt;lower=1&gt; trials; array[trials] int&lt;lower=1,upper=2&gt; choice; array[trials] int&lt;lower=-1,upper=1&gt; feedback; } transformed data { vector[2] initValue; // initial values for V initValue = rep_vector(0.0, 2); } parameters { real&lt;lower=0, upper=1&gt; alpha; // learning rate real&lt;lower=0, upper=20&gt; temperature; // softmax inv.temp. } model { real pe; vector[2] value; vector[2] theta; target += uniform_lpdf(alpha | 0, 1); target += uniform_lpdf(temperature | 0, 20); value = initValue; for (t in 1:trials) { theta = softmax( temperature * value); // action prob. computed via softmax target += categorical_lpmf(choice[t] | theta); pe = feedback[t] - value[choice[t]]; // compute pe for chosen value only value[choice[t]] = value[choice[t]] + alpha * pe; // update chosen V } } generated quantities{ real&lt;lower=0, upper=1&gt; alpha_prior; real&lt;lower=0, upper=20&gt; temperature_prior; real pe; vector[2] value; vector[2] theta; real log_lik; alpha_prior = uniform_rng(0,1); temperature_prior = uniform_rng(0,20); value = initValue; log_lik = 0; for (t in 1:trials) { theta = softmax( temperature * value); // action prob. computed via softmax log_lik = log_lik + categorical_lpmf(choice[t] | theta); pe = feedback[t] - value[choice[t]]; // compute pe for chosen value only value[choice[t]] = value[choice[t]] + alpha * pe; // update chosen V } } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W11_RL_symmetric.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W11_RL_symmetric.stan&quot; file &lt;- file.path(&quot;stan/W11_RL_symmetric.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;), pedantic = TRUE) samples &lt;- mod$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 1000, output_dir = &quot;simmodels&quot;, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 2 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 1 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 2 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 1 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 1 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 2 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 2 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 1 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 2 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 1 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 1 finished in 1.9 seconds. ## Chain 2 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 2 finished in 1.9 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 1.9 seconds. ## Total execution time: 2.2 seconds. # Same the fitted model samples$save_object(&quot;simmodels/W11_RL_symmetric.rds&quot;) samples$cmdstan_diagnose() ## Processing csv files: /Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/simmodels/W11_RL_symmetric-202402150732-1-8fd82a.csv, /Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/simmodels/W11_RL_symmetric-202402150732-2-8fd82a.csv ## ## Checking sampler transitions treedepth. ## Treedepth satisfactory for all transitions. ## ## Checking sampler transitions for divergences. ## No divergent transitions found. ## ## Checking E-BFMI - sampler transitions HMC potential energy. ## E-BFMI satisfactory. ## ## Effective sample size satisfactory. ## ## Split R-hat values satisfactory all parameters. ## ## Processing complete, no problems detected. samples$summary() ## # A tibble: 11 × 10 ## variable mean median sd mad q5 q95 rhat ess_bulk ess_tail ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lp__ -1.37e+1 -1.33e+1 1.15 0.749 -1.60e+1 -12.6 1.00 1409. 1628. ## 2 alpha 6.07e-1 6.13e-1 0.146 0.149 3.57e-1 0.840 1.00 2087. 1606. ## 3 temperat… 4.61e+0 4.40e+0 1.30 1.13 2.94e+0 7.03 1.00 1942. 1747. ## 4 alpha_pr… 4.99e-1 4.96e-1 0.286 0.364 5.24e-2 0.947 1.00 4069. 3923. ## 5 temperat… 9.86e+0 9.81e+0 5.73 7.34 1.07e+0 18.9 1.00 3739. 3853. ## 6 pe 4.68e-1 4.89e-1 0.0998 0.0910 2.69e-1 0.593 1.00 2088. 1606. ## 7 value[1] -9.13e-1 -9.42e-1 0.0901 0.0607 -9.96e-1 -0.734 1.00 2086. 1606. ## 8 value[2] 8.02e-1 8.11e-1 0.103 0.108 6.18e-1 0.957 1.00 2099. 1606. ## 9 theta[1] 4.69e-3 1.84e-3 0.00757 0.00251 2.38e-5 0.0193 1.00 1929. 1534. ## 10 theta[2] 9.95e-1 9.98e-1 0.00757 0.00251 9.81e-1 1.00 1.00 1937. 1555. ## 11 log_lik -1.03e+1 -1.00e+1 1.04 0.709 -1.25e+1 -9.38 1.00 1503. 1788. draws_df &lt;- as_draws_df(samples$draws()) ggplot(draws_df, aes(.iteration, alpha, group = .chain, color = .chain)) + geom_line() + theme_classic() ggplot(draws_df, aes(.iteration, temperature, group = .chain, color = .chain)) + geom_line() + theme_classic() ggplot(draws_df) + geom_density(aes(alpha), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(alpha_prior), fill = &quot;red&quot;, alpha = 0.3) + xlab(&quot;Learning Rate&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() ggplot(draws_df) + geom_density(aes(temperature), fill = &quot;blue&quot;, alpha = 0.3) + geom_density(aes(temperature_prior), fill = &quot;red&quot;, alpha = 0.3) + xlab(&quot;(inverse) temperature&quot;) + ylab(&quot;Posterior Density&quot;) + theme_classic() 11.6 Model fitting: asymmetric RL stan_model &lt;- &quot; data { int&lt;lower=1&gt; trials; array[trials] int&lt;lower=1,upper=2&gt; choice; array[trials] int&lt;lower=-1,upper=1&gt; feedback; } transformed data { vector[2] initValue; // initial values for V initValue = rep_vector(0.0, 2); } parameters { real&lt;lower=0, upper=1&gt; alpha_pos; // learning rate real&lt;lower=0, upper=1&gt; alpha_neg; // learning rate real&lt;lower=0, upper=20&gt; temperature; // softmax inv.temp. } model { real pe; vector[2] value; vector[2] theta; target += uniform_lpdf(alpha_pos | 0, 1); target += uniform_lpdf(alpha_neg | 0, 1); target += uniform_lpdf(temperature | 0, 20); value = initValue; for (t in 1:trials) { theta = softmax( temperature * value); // action prob. computed via softmax target += categorical_lpmf(choice[t] | theta); pe = feedback[t] - value[choice[t]]; // compute pe for chosen value only if (pe &lt; 0) value[choice[t]] = value[choice[t]] + alpha_neg * pe; // update chosen V if (pe &gt; 0) value[choice[t]] = value[choice[t]] + alpha_pos * pe; // update chosen V } } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W11_RL_asymmetric.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W11_RL_asymmetric.stan&quot; file &lt;- file.path(&quot;stan/W11_RL_asymmetric.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;), pedantic = TRUE) samples &lt;- mod$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 1000, output_dir = &quot;simmodels&quot;, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 2 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 1 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 2 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 1 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 1 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 2 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 2 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 2 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 1 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 2 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 2 finished in 2.5 seconds. ## Chain 1 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 1 finished in 2.8 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 2.7 seconds. ## Total execution time: 2.9 seconds. # Same the fitted model samples$save_object(&quot;simmodels/W11_RL_asymmetric.rds&quot;) 11.7 Model fitting: multilevel ## Multilevel agents &lt;- 100 trials &lt;- 120 df &lt;- NULL for (agent in 1:agents) { temperature &lt;- boot::inv.logit(rnorm(1, -2, 0.3))*20 alpha &lt;- boot::inv.logit(rnorm(1, 1.1, 0.3)) value &lt;- c(0,0) d &lt;- tibble(trial = rep(NA, trials), choice = rep(NA, trials), value1 = rep(NA, trials), value2 = rep(NA, trials), feedback = rep(NA, trials), alpha = alpha, temperature = temperature, agent = agent) for (i in 1:trials) { choice &lt;- rbinom(1, 1, softmax(value[2] - value[1], temperature)) feedback &lt;- ifelse(Bot[i] == choice, 1, -1) value &lt;- ValueUpdate(value, alpha, choice, feedback) d$trial[i] &lt;- i d$choice[i] &lt;- choice d$value1[i] &lt;- value[1] d$value2[i] &lt;- value[2] d$feedback[i] &lt;- feedback d$alpha[i] &lt;- alpha d$temperature[i] &lt;- temperature } if (exists(&quot;df&quot;)) {df &lt;- rbind(df, d)} else {df &lt;- d} } df &lt;- df %&gt;% group_by(alpha, temperature) %&gt;% mutate( prevFeedback = lead(feedback)) ## Create the data trials &lt;- trials agents &lt;- agents d_choice &lt;- df %&gt;% subset(select = c(agent, choice)) %&gt;% mutate(row = rep(seq(trials),agents)) %&gt;% pivot_wider(names_from = agent, values_from = choice) d_feedback &lt;- df %&gt;% subset(select = c(agent, feedback)) %&gt;% mutate(row = rep(seq(trials),agents)) %&gt;% pivot_wider(names_from = agent, values_from = feedback) data &lt;- list( trials = trials, agents = agents, choice = as.matrix(d_choice[,2:(agents + 1)]), feedback = as.matrix(d_feedback[,2:(agents + 1)]) ) data$choice &lt;- data$choice + 1 stan_model &lt;- &quot; data { int&lt;lower=1&gt; trials; int&lt;lower=1&gt; agents; array[trials, agents] int&lt;lower=1,upper=2&gt; choice; array[trials, agents] int&lt;lower=-1,upper=1&gt; feedback; } transformed data { vector[2] initValue; // initial values for V initValue = rep_vector(0.0, 2); } parameters { real alphaM; // learning rate real temperatureM; // softmax inv.temp. vector&lt;lower = 0&gt;[2] tau; matrix[2, agents] z_IDs; cholesky_factor_corr[2] L_u; } transformed parameters { matrix[agents,2] IDs; IDs = (diag_pre_multiply(tau, L_u) * z_IDs)&#39;; } model { real pe; vector[2] value; vector[2] theta; target += normal_lpdf(alphaM | 0, 1); target += normal_lpdf(temperatureM | 0, 1); target += normal_lpdf(tau[1] | 0, .3) - normal_lccdf(0 | 0, .3); target += normal_lpdf(tau[2] | 0, .3) - normal_lccdf(0 | 0, .3); target += lkj_corr_cholesky_lpdf(L_u | 2); target += std_normal_lpdf(to_vector(z_IDs)); for (agent in 1:agents){ value = initValue; for (t in 1:trials) { theta = softmax( inv_logit(temperatureM + IDs[agent,2]) * 20 * value); // action prob. computed via softmax target += categorical_lpmf(choice[t, agent] | theta); pe = feedback[t, agent] - value[choice[t, agent]]; // compute pe for chosen value only value[choice[t, agent]] = value[choice[t, agent]] + inv_logit(alphaM + IDs[agent,1]) * pe; // update chosen V } } } &quot; write_stan_file( stan_model, dir = &quot;stan/&quot;, basename = &quot;W11_RL_multilevel.stan&quot;) ## [1] &quot;/Users/au209589/Dropbox/Teaching/AdvancedCognitiveModeling23_book/stan/W11_RL_multilevel.stan&quot; file &lt;- file.path(&quot;stan/W11_RL_multilevel.stan&quot;) mod &lt;- cmdstan_model(file, cpp_options = list(stan_threads = TRUE), stanc_options = list(&quot;O1&quot;), pedantic = TRUE) samples &lt;- mod$sample( data = data, seed = 123, chains = 2, parallel_chains = 2, threads_per_chain = 2, iter_warmup = 2000, iter_sampling = 2000, refresh = 1000, output_dir = &quot;simmodels&quot;, max_treedepth = 20, adapt_delta = 0.99, ) ## Running MCMC with 2 parallel chains, with 2 thread(s) per chain... ## ## Chain 1 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in &#39;/var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/model-47d0691c5d7c.stan&#39;, line 40, column 2 to column 44) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in &#39;/var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/model-47d0691c5d7c.stan&#39;, line 40, column 2 to column 44) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in &#39;/var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/model-47d0691c5d7c.stan&#39;, line 40, column 2 to column 44) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 2 Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in &#39;/var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/model-47d0691c5d7c.stan&#39;, line 40, column 2 to column 44) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in &#39;/var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/model-47d0691c5d7c.stan&#39;, line 40, column 2 to column 44) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in &#39;/var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/model-47d0691c5d7c.stan&#39;, line 40, column 2 to column 44) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 2 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in &#39;/var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/model-47d0691c5d7c.stan&#39;, line 40, column 2 to column 44) ## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 2 ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in &#39;/var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/model-47d0691c5d7c.stan&#39;, line 40, column 2 to column 44) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 2 Iteration: 1000 / 4000 [ 25%] (Warmup) ## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue: ## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in &#39;/var/folders/lt/zspkqnxd5yg92kybm5f433_cfjr0d6/T/RtmpP3dlfk/model-47d0691c5d7c.stan&#39;, line 40, column 2 to column 44) ## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine, ## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified. ## Chain 1 ## Chain 1 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 1 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 2 Iteration: 2000 / 4000 [ 50%] (Warmup) ## Chain 2 Iteration: 2001 / 4000 [ 50%] (Sampling) ## Chain 1 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 2 Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 1 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 1 finished in 1616.0 seconds. ## Chain 2 Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 2 finished in 9821.7 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 5718.9 seconds. ## Total execution time: 9821.6 seconds. # Same the fitted model samples$save_object(&quot;simmodels/W11_RL_multilevel.rds&quot;) [Missing discussion of alternative models of RL: counterfactual learning, sequential learning, etc.] "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
