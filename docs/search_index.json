[["index.html", "01 - The Pizza Experiment Chapter 1 Advanced Cognitive Modeling 1.1 The goal of the course 1.2 List of lectures and practical exercises 1.3 Preparation before the course", " 01 - The Pizza Experiment Riccardo Fusaroli 2025-01-31 Chapter 1 Advanced Cognitive Modeling These are the teaching notes for Advanced Cognitive Modeling - taught in 2025 at the M.Sc. in Cognitive Science at Aarhus University (and building on previous years). The syllabus is available at TBA The videos are available at TBA 1.1 The goal of the course Advanced cognitive modeling is a course on how to think through, formalize and validate models of cognitive processes. In other words, we will be thinking about how people learn, and make decisions both in the lab and in the real world, and to robustly assess our hypothesized mechanisms. The course has 3 interrelated aims: to guide you through how models of cognitive processes are thought through and built (more than a toolbox of existing scripts); to provide (or reinforce) a good Bayesian workflow (simulation, prior assessment, parameter/model recovery, model fit assessment) to build robust and reliable models; to develop your probabilistic modeling skills (we will be dealing with brms, and also directly with stan). At the end of the course, you should be able to start thinking about how to use your own theoretical knowledge in cognitive science to build your own models, as well as to robustly evaluate existing models and their applicability. The course will be very hands-on. The main goal of the course is not just for you to understand how cognitive modeling works, but to build and use your own models. The lectures will include conceptual discussions of cognitive modeling and the specific models we will be dealing with, but also introduction to the coding exercises in the practical exercises (e.g. how to code in Stan). During the practical exercises, we will collect some data or explore existing datasets, design models together, and code them up: simulating how a person using those processes would perform, inferring parameters from simulated and real data, assessing model quality. We will take the time to do this together, and there will be time for lots of questions. The schedule for the course will therefore be somewhat flexible, and adaptive to your collective learning speed. 1.2 List of lectures and practical exercises 1.3 Preparation before the course Before starting the course, you need to get your computers and brains in ship-shape so we can focus on modeling! In terms of computers, you need to make sure you have the following software installed and working: up-to-date R (version 4.4 or above) and Rstudio (version 2024.12.0 or above) installed and working. See here for a more detailed instruction on how to install R and Rstudio: https://happygitwithr.com/install-r-rstudio.html the “brms” package installed: https://github.com/paul-buerkner/brms N.B. it’s not always as simple as doing an install.packages(“brms”), so do follow the linked guide! the “cmdstanr” package: https://mc-stan.org/cmdstanr/articles/cmdstanr.html N.B. it’s not always as simple as doing an install.packages(“cmdstanr”), so do follow the linked guide! N.B. technically you can run all our exercises without cmdstanr if it turns to be too demanding, but your computer will be much slower. Without these packages working, you will not be able to tackle the practical exercises, so install them before you move to the next section and make sure there are no errors or worrying warnings. Once your computer is ready, you should also get your brain ready. This workshop focuses on how to do Bayesian data analysis and does not go into the details of Bayes’ theorem. If you are not familiar with the theorem or need a quick refresh, we strongly recommend you give this 15 min video a watch before the workshop. This should make talk of priors and posteriors much easier to parse. https://www.youtube.com/watch?v=HZGCoVF3YvM This workshop does not cover basic R coding and basic statistical modeling, they are taken for granted. I know not everybody comes from the Bsc in Cognitive Science, so if you feel you need some practice: An amazing intro to R and the tidyverse (free online): https://r4ds.had.co.nz/ (I know some of you have also been referred to swirl and datacamp, I don’t know those resources, so have a look at the one above to check you know enough) A intro to Bayesian statistics in brms (summarizing key points from methods 4 in the bachelor): https://4ccoxau.github.io/PriorsWorkshop/ videos + exercises. "],["pizza-stone-temperature-analysis-a-bayesian-modeling-approach.html", "Chapter 2 Pizza Stone Temperature Analysis: A Bayesian Modeling Approach 2.1 Learning Objectives 2.2 Prerequisites 2.3 Part 1: Exploring the Pizza Stone Temperature Data 2.4 Part 2: Initial Statistical Modeling 2.5 Part 3: Understanding the Physics Model 2.6 Part 4: Implementing the Physics-Based Model 2.7 Part 5: Model Analysis and Practical Applications 2.8 Conclusions", " Chapter 2 Pizza Stone Temperature Analysis: A Bayesian Modeling Approach 2.1 Learning Objectives This first module is a bit odd, in that it pushes you straight into the deep waters of a complex example. I don’t expect you to understand all the technicalities. But, by completing this tutorial, you will be able to better grasp the importance of generative modeling, that is, of modeling that is focused on the underlying mechanisms producing the data. On the side you might learn something about how to * Implement physics-based thermal modeling using R and Stan * Apply Bayesian inference to real-world temperature data * Compare different statistical models using posterior predictions * Create professional visualizations of temperature evolution * Make practical predictions about heating times under various conditions Oh, and you’ll probably get hungry as well! 2.2 Prerequisites Intermediate R programming knowledge Basic understanding of Bayesian statistics Required Packages required_packages &lt;- c( &quot;tidyverse&quot;, # For data manipulation and visualization &quot;brms&quot;, # For Bayesian regression modeling &quot;bayesplot&quot;, # For visualization of Bayesian models &quot;tidybayes&quot;, # For working with Bayesian samples &quot;cmdstanr&quot; # For Stan implementation ) # Install and load packages for (pkg in required_packages) { if (!require(pkg, character.only = TRUE)) { install.packages(pkg) library(pkg, character.only = TRUE) } } 2.3 Part 1: Exploring the Pizza Stone Temperature Data In this study, we collected temperature measurements from a pizza stone in a gas-fired oven using an infrared temperature gun. Three different raters (N, TR, and R) took measurements over time to track how the stone heated up. Understanding how pizza stones heat up is crucial for achieving the perfect pizza crust, as consistent and sufficient stone temperature is essential for proper baking. The measurements were taken as follows: # Load and examine the data data &lt;- tibble( Order = rep(0:18, 3), Seconds = rep(c(0, 175, 278, 333, 443, 568, 731, 773, 851, 912, 980, 1040, 1074, 1124, 1175, 1237, 1298, 1359, 1394), 3), Temperature = c(15.1, 233, 244, 280, 289, 304, 343, NA, 333, 341, 320, 370, 325, 362, 363, 357, 380, 376, 380, 14.5, 139.9, 153, 36.1, 254, 459, 263, 369, rep(NA, 11), 12.9, 149.5, 159, 179.4, 191.7, 201, 210, NA, 256, 257, 281, 293, 297, 309, 318, 321, rep(NA, 3)), Rater = rep(c(&quot;N&quot;, &quot;TR&quot;, &quot;R&quot;), each = 19) ) # Create summary statistics summary_stats &lt;- data %&gt;% group_by(Rater) %&gt;% summarize( n_measurements = sum(!is.na(Temperature)), mean_temp = mean(Temperature, na.rm = TRUE), sd_temp = sd(Temperature, na.rm = TRUE), min_temp = min(Temperature, na.rm = TRUE), max_temp = max(Temperature, na.rm = TRUE) ) # Display summary statistics knitr::kable(summary_stats, digits = 1) Rater n_measurements mean_temp sd_temp min_temp max_temp N 18 312.0 86.4 15.1 380 R 15 229.0 83.9 12.9 321 TR 8 211.1 155.2 14.5 459 2.3.1 Initial Data Visualization Let’s visualize how the temperature evolves over time for each rater: ggplot(data, aes(x = Seconds/60, y = Temperature, color = Rater)) + geom_point(size = 3, alpha = 0.7) + geom_line(alpha = 0.5) + labs( title = &quot;Pizza Stone Temperature Evolution&quot;, subtitle = &quot;Measurements by three different raters&quot;, x = &quot;Time (minutes)&quot;, y = &quot;Temperature (°C)&quot;, color = &quot;Rater&quot; ) + theme_bw() + scale_color_brewer(palette = &quot;Set1&quot;) ## Warning: Removed 16 rows containing missing values or values outside the scale range ## (`geom_point()`). ## Warning: Removed 14 rows containing missing values or values outside the scale range ## (`geom_line()`). 2.3.2 Key Observations Several interesting patterns emerge from our data: Heating Patterns: The temperature generally increases over time, but not uniformly. We observe some fluctuations that might be due to: Variation in gas flame intensity Different measurement locations on the stone Measurement technique differences between raters Measurement Patterns by Rater Rater N maintained consistent measurements throughout the experiment Rater TR shows more variability and fewer total measurements Rater R shows a more gradual temperature increase pattern Missing Data: Some measurements are missing (NA values), particularly in the later time points for Rater TR. This is common in real-world data collection and needs to be considered in our analysis. Let’s examine the rate of temperature change: # Calculate temperature change rate data_with_rate &lt;- data %&gt;% group_by(Rater) %&gt;% arrange(Seconds) %&gt;% mutate( temp_change = (Temperature - lag(Temperature)) / (Seconds - lag(Seconds)) * 60, minutes = Seconds/60 ) %&gt;% filter(!is.na(temp_change)) # Visualize temperature change rate ggplot(data_with_rate, aes(x = minutes, y = temp_change, color = Rater)) + geom_point() + geom_smooth(se = FALSE, span = 0.75) + labs( title = &quot;Rate of Temperature Change Over Time&quot;, subtitle = &quot;Degrees Celsius per minute&quot;, x = &quot;Time (minutes)&quot;, y = &quot;Temperature Change Rate (°C/min)&quot;, color = &quot;Rater&quot; ) + theme_bw() + scale_color_brewer(palette = &quot;Set1&quot;) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; This visualization reveals that the heating rate is highest in the first few minutes and gradually decreases as the stone temperature approaches the oven temperature. This aligns with Newton’s Law of Cooling/Heating, which we will explore in the next section. 2.4 Part 2: Initial Statistical Modeling Before developing our physics-based model, let’s explore how standard statistical approaches perform in modeling our temperature data. We’ll implement two types of models using the brms package: a linear mixed-effects model and a lognormal mixed-effects model. Both models will account for variations between raters. 2.4.1 Model Setup and Priors First, let’s ensure we have a directory for our models and set up our computational parameters: # Create models directory if it doesn&#39;t exist dir.create(&quot;models&quot;, showWarnings = FALSE) # Define computational parameters mc_settings &lt;- list( chains = 2, iter = 6000, seed = 123, backend = &quot;cmdstanr&quot; ) 2.4.2 Linear Mixed-Effects Model We begin with a linear mixed-effects model, which assumes that temperature increases linearly with time but allows for different patterns across raters. This model includes both fixed effects (overall time trend) and random effects (rater-specific variations). # Define priors for linear model linear_priors &lt;- c( prior(normal(15, 20), class = &quot;Intercept&quot;), # Centered around room temperature prior(normal(0, 1), class = &quot;b&quot;), # Expected temperature change per second prior(normal(0, 100), class = &quot;sigma&quot;), # Residual variation prior(normal(0, 100), class = &quot;sd&quot;), # Random effects variation prior(lkj(3), class = &quot;cor&quot;) # Random effects correlation ) # Fit linear mixed-effects model linear_model &lt;- brm( Temperature ~ Seconds + (1 + Seconds | Rater), data = data, family = gaussian, prior = linear_priors, chains = mc_settings$chains, iter = mc_settings$iter, seed = mc_settings$seed, backend = mc_settings$backend, file = &quot;models/01_pizza_linear_model&quot;, cores = 2, adapt_delta = 0.99, max_treedepth = 20 ) # Display model summary summary(linear_model) ## Warning: There were 29 divergent transitions after warmup. Increasing ## adapt_delta above 0.99 may help. See ## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: Temperature ~ Seconds + (1 + Seconds | Rater) ## Data: data (Number of observations: 41) ## Draws: 2 chains, each with iter = 6000; warmup = 3000; thin = 1; ## total post-warmup draws = 6000 ## ## Multilevel Hyperparameters: ## ~Rater (Number of levels: 3) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS ## sd(Intercept) 88.18 49.29 14.36 210.34 1.00 1804 ## sd(Seconds) 0.70 0.57 0.15 2.34 1.00 1226 ## cor(Intercept,Seconds) -0.03 0.38 -0.71 0.67 1.00 2106 ## Tail_ESS ## sd(Intercept) 1750 ## sd(Seconds) 1398 ## cor(Intercept,Seconds) 3251 ## ## Regression Coefficients: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 75.42 71.38 -110.73 194.77 1.00 1461 1136 ## Seconds -0.08 0.11 -0.25 0.19 1.00 1406 1133 ## ## Further Distributional Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 58.36 7.51 46.01 75.32 1.00 3735 3662 ## ## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). # Generate predictions linear_preds &lt;- fitted( linear_model, newdata = data, probs = c(0.025, 0.975) ) %&gt;% as_tibble() %&gt;% bind_cols(data) 2.4.3 Lognormal Mixed-Effects Model The lognormal model accounts for the fact that temperature changes might be proportional rather than additive, and ensures predictions cannot go below zero (I don’t bring my oven out in the freezing cold!). # Define priors for lognormal model lognormal_priors &lt;- c( prior(normal(2.7, 1), class = &quot;Intercept&quot;), # Log scale for room temperature prior(normal(0, 0.01), class = &quot;b&quot;), # Expected log-scale change per second prior(normal(0, 1), class = &quot;sigma&quot;), # Log-scale residual variation prior(normal(0, 1), class = &quot;sd&quot;), # Random effects variation prior(lkj(3), class = &quot;cor&quot;) # Random effects correlation ) # Fit lognormal mixed-effects model lognormal_model &lt;- brm( Temperature ~ Seconds + (1 + Seconds | Rater), data = data, family = lognormal, prior = lognormal_priors, chains = mc_settings$chains, cores = 2, adapt_delta = 0.99, max_treedepth = 20, iter = mc_settings$iter, seed = mc_settings$seed, backend = mc_settings$backend, file = &quot;models/01_pizza_lognormal_model&quot; ) # Generate predictions lognormal_preds &lt;- fitted( lognormal_model, newdata = data, probs = c(0.025, 0.975) ) %&gt;% as_tibble() %&gt;% bind_cols(data) 2.4.4 Model Comparison and Visualization Let’s compare how these models fit our data: # Compare models using LOO model_comparison &lt;- loo_compare( loo(linear_model), loo(lognormal_model) ) ## Warning: Found 3 observations with a pareto_k &gt; 0.7 in model &#39;linear_model&#39;. ## We recommend to set &#39;moment_match = TRUE&#39; in order to perform moment matching ## for problematic observations. ## Warning: Found 2 observations with a pareto_k &gt; 0.7 in model ## &#39;lognormal_model&#39;. We recommend to set &#39;moment_match = TRUE&#39; in order to ## perform moment matching for problematic observations. # Create comparison plot ggplot() + # Raw data points geom_point(data = data, aes(x = Seconds/60, y = Temperature, color = Rater), alpha = 0.5) + # Linear model predictions geom_line(data = linear_preds, aes(x = Seconds/60, y = Estimate, linetype = &quot;Linear&quot;), color = &quot;blue&quot;) + geom_ribbon(data = linear_preds, aes(x = Seconds/60, ymin = Q2.5, ymax = Q97.5), fill = &quot;blue&quot;, alpha = 0.1) + # Lognormal model predictions geom_line(data = lognormal_preds, aes(x = Seconds/60, y = Estimate, linetype = &quot;Lognormal&quot;), color = &quot;red&quot;) + geom_ribbon(data = lognormal_preds, aes(x = Seconds/60, ymin = Q2.5, ymax = Q97.5), fill = &quot;red&quot;, alpha = 0.1) + # Formatting facet_wrap(~Rater) + labs( title = &quot;Comparison of Statistical Models&quot;, subtitle = &quot;Linear vs Lognormal Mixed-Effects Models&quot;, x = &quot;Time (minutes)&quot;, y = &quot;Temperature (°C)&quot;, linetype = &quot;Model Type&quot; ) + theme_bw() ## Warning: Removed 16 rows containing missing values or values outside the scale range ## (`geom_point()`). # Create comparison plot but capping the y axis ggplot() + # Raw data points geom_point(data = data, aes(x = Seconds/60, y = Temperature, color = Rater), alpha = 0.5) + # Linear model predictions geom_line(data = linear_preds, aes(x = Seconds/60, y = Estimate, linetype = &quot;Linear&quot;), color = &quot;blue&quot;) + geom_ribbon(data = linear_preds, aes(x = Seconds/60, ymin = Q2.5, ymax = Q97.5), fill = &quot;blue&quot;, alpha = 0.1) + # Lognormal model predictions geom_line(data = lognormal_preds, aes(x = Seconds/60, y = Estimate, linetype = &quot;Lognormal&quot;), color = &quot;red&quot;) + geom_ribbon(data = lognormal_preds, aes(x = Seconds/60, ymin = Q2.5, ymax = Q97.5), fill = &quot;red&quot;, alpha = 0.1) + ylim(0, 1000) + # Formatting facet_wrap(~Rater) + labs( title = &quot;Comparison of Statistical Models&quot;, subtitle = &quot;Linear vs Lognormal Mixed-Effects Models&quot;, x = &quot;Time (minutes)&quot;, y = &quot;Temperature (°C)&quot;, linetype = &quot;Model Type&quot; ) + theme_bw() ## Warning: Removed 16 rows containing missing values or values outside the scale range ## (`geom_point()`). ## Warning: Removed 8 rows containing missing values or values outside the scale range ## (`geom_line()`). 2.4.5 Model Assessment I have seen worse models in my time, but they do seem to have important issues: The linear mixed-effects model assumes a constant rate of temperature change, which we can see is not at all accurate. The actual temperature increase is fast at the beginning and appears to slow down over time, particularly at higher temperatures. While this model has the advantage of simplicity, it is not likely to produce accurate predictions as it seem to fail to capture the underlying physics of heat transfer. The lognormal mixed-effects model is completely off. Further, the models produce some divergences, which is often a sign that they are not well suited to the data. I suggest that the issue is that neither model incorporates our knowledge of heat transfer physics, which suggests an exponential approach to equilibrium temperature. This limitation motivates our next section, where we’ll develop a physics-based model. 2.5 Part 3: Understanding the Physics Model Temperature evolution in a pizza stone follows Newton’s Law of Cooling/Heating. We’ll start by exploring this physical model before applying it to real data. 2.5.1 The Basic Temperature Evolution Equation The temperature evolution of a pizza stone in a gas-fired oven is governed by the heat diffusion equation, which describes how heat flows through solid materials. This comprehensive equation accounts for all aspects of heat transfer: ρcp ∂T/∂t = k∇²T + Q In this equation, ρ represents the density of the pizza stone, while cp denotes its specific heat capacity - the amount of energy needed to raise its temperature by one degree. The temperature T varies with time t, and k represents the stone’s thermal conductivity. The Laplacian operator ∇² captures how temperature varies across different points in the stone, while Q represents the heat input from the oven’s flames. While this equation provides a complete description of heat flow, we can significantly simplify our analysis by applying the lumped capacitance model. This simplification assumes that the temperature throughout the pizza stone remains uniform at any given time - a reasonable assumption given the stone’s relatively thin profile and good thermal conductivity. This approach reduces our model to: dT/dt = h * A/(m * cp) * (T∞ - T) This simplified equation relates the rate of temperature change to the difference between the current stone temperature T and the flame temperature T∞. The coefficient h represents the heat transfer coefficient between the flame and stone, A is the stone’s surface area exposed to heat, m is its mass, and cp remains the specific heat capacity. To solve this differential equation, we begin by separating variables: dT/(T∞ - T) = (hA/(mcp)) * dt Integration of both sides yields: -ln|T∞ - T| = (hA/(mcp)) * t + C Using the initial condition that the temperature equals Ti when time equals zero, we can determine the integration constant C = -ln|T∞ - Ti|. Substituting this back and solving for temperature gives us: T = T∞ + (Ti - T∞) * exp(-hAt/(m*cp)) For practical analysis, we can combine all the physical parameters that determine heating rate into a single coefficient, which we’ll call HOT: HOT = hA/(mcp) This gives us our final working equation: T = T∞ + (Ti - T∞) * exp(-HOT * t) This equation retains the essential physics while providing a practical model for analyzing our experimental data. The HOT coefficient encapsulates the combined effects of heat transfer efficiency, stone geometry, and material properties into a single parameter that determines how quickly the stone approaches the flame temperature. 2.6 Part 4: Implementing the Physics-Based Model Having established the theoretical foundation for our heat transfer model, we now move to its practical implementation. We will use Stan to create a Bayesian implementation of our physics-based model, allowing us to account for measurement uncertainty and variation between raters. First, we prepare our data for the Stan model. Our model requires initial temperatures, time measurements, and observed temperatures from each rater: # Create data structure for Stan stan_data &lt;- list( N = nrow(data %&gt;% filter(!is.na(Temperature))), time = data %&gt;% filter(!is.na(Temperature)) %&gt;% pull(Seconds), temp = data %&gt;% filter(!is.na(Temperature)) %&gt;% pull(Temperature), n_raters = 3, rater = as.numeric(factor(data %&gt;% filter(!is.na(Temperature)) %&gt;% pull(Rater))), Ti = c(100, 100, 100), # Initial temperature estimates Tinf = 450 # Flame temperature estimate ) Next, we implement our physics-based model in Stan. The model incorporates our derived equation while allowing for rater-specific heating coefficients: stan_code &lt;- &quot; data { int&lt;lower=0&gt; N; // Number of observations vector[N] time; // Time points vector[N] temp; // Observed temperatures int&lt;lower=0&gt; n_raters; // Number of raters array[N] int&lt;lower=1,upper=n_raters&gt; rater; // Rater indices vector[n_raters] Ti; // Initial temperatures real Tinf; // Flame temperature } parameters { vector&lt;lower=0&gt;[n_raters] HOT; // Heating coefficients vector&lt;lower=0&gt;[n_raters] sigma; // Measurement error } model { vector[N] mu; // Physics-based temperature prediction for (i in 1:N) { mu[i] = Tinf + (Ti[rater[i]] - Tinf) * exp(-HOT[rater[i]] * time[i]); } // Prior distributions target += normal_lpdf(HOT | 0.005, 0.005); // Prior for heating rate target += exponential_lpdf(sigma | 1); // Prior for measurement error // Likelihood target += normal_lpdf(temp | mu, sigma[rater]); } &quot; # Save the model writeLines(stan_code, &quot;models/pizza_physics_model.stan&quot;) # Compile and fit the model mod &lt;- cmdstan_model(&quot;models/pizza_physics_model.stan&quot;) fit &lt;- mod$sample( data = stan_data, seed = 123, chains = 2, parallel_chains = 2 ) ## Running MCMC with 2 parallel chains... ## ## Chain 1 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 1 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 1 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 1 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 1 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 1 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 1 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 1 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 1 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 1 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 1 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 1 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 1 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 1 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 1 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 1 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 1 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 1 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 1 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 1 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 1 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 1 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 2 Iteration: 1 / 2000 [ 0%] (Warmup) ## Chain 2 Iteration: 100 / 2000 [ 5%] (Warmup) ## Chain 2 Iteration: 200 / 2000 [ 10%] (Warmup) ## Chain 2 Iteration: 300 / 2000 [ 15%] (Warmup) ## Chain 2 Iteration: 400 / 2000 [ 20%] (Warmup) ## Chain 2 Iteration: 500 / 2000 [ 25%] (Warmup) ## Chain 2 Iteration: 600 / 2000 [ 30%] (Warmup) ## Chain 2 Iteration: 700 / 2000 [ 35%] (Warmup) ## Chain 2 Iteration: 800 / 2000 [ 40%] (Warmup) ## Chain 2 Iteration: 900 / 2000 [ 45%] (Warmup) ## Chain 2 Iteration: 1000 / 2000 [ 50%] (Warmup) ## Chain 2 Iteration: 1001 / 2000 [ 50%] (Sampling) ## Chain 2 Iteration: 1100 / 2000 [ 55%] (Sampling) ## Chain 2 Iteration: 1200 / 2000 [ 60%] (Sampling) ## Chain 2 Iteration: 1300 / 2000 [ 65%] (Sampling) ## Chain 2 Iteration: 1400 / 2000 [ 70%] (Sampling) ## Chain 2 Iteration: 1500 / 2000 [ 75%] (Sampling) ## Chain 2 Iteration: 1600 / 2000 [ 80%] (Sampling) ## Chain 2 Iteration: 1700 / 2000 [ 85%] (Sampling) ## Chain 2 Iteration: 1800 / 2000 [ 90%] (Sampling) ## Chain 2 Iteration: 1900 / 2000 [ 95%] (Sampling) ## Chain 2 Iteration: 2000 / 2000 [100%] (Sampling) ## Chain 1 finished in 0.1 seconds. ## Chain 2 finished in 0.1 seconds. ## ## Both chains finished successfully. ## Mean chain execution time: 0.1 seconds. ## Total execution time: 0.3 seconds. The Stan implementation translates our mathematical model into a computational framework. We assign informative priors to our parameters based on physical understanding: the heating coefficient (HOT) is expected to be small but positive, while measurement error (sigma) follows an exponential distribution to ensure positivity while allowing for varying levels of uncertainty between raters. To visualize our model’s predictions and assess its performance, we extract posterior samples and generate predictions across our time range: # Extract draws post &lt;- as_draws_df(fit$draws()) %&gt;% select(starts_with(&quot;HOT&quot;), starts_with(&quot;sigma&quot;)) %&gt;% slice_sample(n = 100) ## Warning: Dropping &#39;draws_df&#39; class as required metadata was removed. # Create prediction grid pred_data &lt;- crossing( time = seq(0, max(stan_data$time), length.out = 100), rater = 1:stan_data$n_raters ) %&gt;% mutate( Ti = stan_data$Ti[rater], Tinf = stan_data$Tinf ) # Generate predictions pred_matrix &lt;- matrix(NA, nrow = nrow(pred_data), ncol = 100) for (i in 1:nrow(pred_data)) { pred_matrix[i,] &lt;- with(pred_data[i,], Tinf + (Ti - Tinf) * exp(-as.matrix(post)[,rater] * time)) } # Summarize predictions predictions &lt;- pred_data %&gt;% mutate( mean = rowMeans(pred_matrix), lower = apply(pred_matrix, 1, quantile, 0.025), upper = apply(pred_matrix, 1, quantile, 0.975) ) # Create visualization ggplot(predictions, aes(x = time/60)) + geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) + geom_line(aes(y = mean)) + geom_point( data = data %&gt;% filter(!is.na(Temperature)) %&gt;% mutate(rater = case_when( Rater == &quot;N&quot; ~ 1, Rater == &quot;TR&quot; ~ 2, Rater == &quot;R&quot; ~ 3 )), aes(x = Seconds/60, y = Temperature) ) + facet_wrap(~rater, labeller = labeller(rater = c( &quot;1&quot; = &quot;Rater N&quot;, &quot;2&quot; = &quot;Rater TR&quot;, &quot;3&quot; = &quot;Rater R&quot; ))) + labs( title = &quot;Physics-Based Model Predictions&quot;, x = &quot;Time (minutes)&quot;, y = &quot;Temperature (°C)&quot; ) + theme_bw() Our implementation combines the theoretical understanding developed in Part 3 with practical considerations for real-world data analysis. The model accounts for measurement uncertainty while maintaining the fundamental physics of heat transfer, providing a robust framework for understanding pizza stone temperature evolution. 2.7 Part 5: Model Analysis and Practical Applications Having implemented our physics-based model, we can now analyze its predictions and develop practical insights for pizza stone temperature management. A key question for pizza making is how long it takes to reach optimal cooking temperatures under different conditions. We begin by creating a function that calculates the time needed to reach a target temperature: time_to_temp &lt;- function(target_temp, HOT, Ti, Tinf) { # Solve: target = Tinf + (Ti - Tinf) * exp(-HOT * t) # for t t = -1/HOT * log((target_temp - Tinf)/(Ti - Tinf)) return(t/60) # Convert seconds to minutes } To understand heating times across different oven conditions, we examine how varying flame temperatures affect the time needed to reach pizza-making temperatures. We extract the heating coefficients from our fitted model and analyze temperature scenarios: # Extract HOT samples from our posterior hot_samples &lt;- as_draws_df(fit$draws()) %&gt;% select(starts_with(&quot;HOT&quot;)) ## Warning: Dropping &#39;draws_df&#39; class as required metadata was removed. # Create prediction grid for different flame temperatures pred_data &lt;- crossing( Tinf = seq(450, 1200, by = 50), # Range of flame temperatures rater = 1:3 ) %&gt;% mutate( Ti = stan_data$Ti[rater], target_temp = 400 # Target temperature for pizza cooking ) # Calculate heating times across conditions n_samples &lt;- 100 time_preds &lt;- map_dfr(1:nrow(pred_data), function(i) { times &lt;- sapply(1:n_samples, function(j) { hot &lt;- hot_samples[j, paste0(&quot;HOT[&quot;, pred_data$rater[i], &quot;]&quot;)][[1]] time_to_temp( pred_data$target_temp[i], hot, pred_data$Ti[i], pred_data$Tinf[i] ) }) data.frame( rater = pred_data$rater[i], Tinf = pred_data$Tinf[i], mean_time = mean(times), lower = quantile(times, 0.025), upper = quantile(times, 0.975) ) }) # Visualize heating time predictions ggplot(time_preds, aes(x = Tinf)) + geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) + geom_line(aes(y = mean_time)) + facet_wrap(~rater, labeller = labeller(rater = c( &quot;1&quot; = &quot;Rater N&quot;, &quot;2&quot; = &quot;Rater TR&quot;, &quot;3&quot; = &quot;Rater R&quot; ))) + labs( title = &quot;Time Required to Reach Pizza-Making Temperature&quot;, subtitle = &quot;Target temperature: 400°C&quot;, x = &quot;Flame Temperature (°C)&quot;, y = &quot;Minutes to reach target&quot; ) + theme_bw() Our analysis reveals several important insights for practical pizza making. First, the heating time decreases nonlinearly with flame temperature, showing diminishing returns at very high temperatures. We can also observe differences between raters in their measured heating times. These variations likely stem from differences in measurement technique and location on the stone, highlighting the importance of consistent temperature monitoring practices. For practical application, we can provide specific heating guidelines based on our model. At a typical flame temperature of 800°C, the model predicts it will take approximately 20-30 minutes to reach optimal pizza-making temperature, assuming room temperature start. However, this time can vary significantly based on: Initial stone temperature Flame temperature and consistency Environmental conditions 2.8 Conclusions All of this to work with heat, which is a well understood and supposedly simple physical phenomenon. Yet we need complex models to better understand this (and what I sketched here could be vastly improved still). I want you to keep this in mind when we then go and talk about cognitive phenomena, like decision-making or memory. Can we really just run regressions? A second important lesson is that we need to pick the level of analysis. Here we work on heat, but we completely ignored e.g. particle level details. They would actually impede what we want to do. It’s the same for cognitive processes. We don’t (always) need to invoke the brain to model generative processes. Sometimes it helps, sometimes it doesn’t at the stage of research in which we are. The course will try to develop solid foundations for modeling at this “cognitive” level of analysis. You’ll be ready to tackle neurocognitive aspects at the end of the course. Finally, I hope you are hungry now. I know I am. Let’s go and make some pizza! "],["building-verbal-models-of-the-matching-pennies-game.html", "Chapter 3 Building verbal models of the matching pennies game 3.1 Trying out the game and collecting your own data 3.2 Start Theorizing 3.3 The distinction between participant and researcher perspectives 3.4 Strategies 3.5 Cognitive constraints 3.6 Continuity between models 3.7 Mixture of strategies 3.8 Differences from more traditional (general linear model-based) approaches", " Chapter 3 Building verbal models of the matching pennies game 3.1 Trying out the game and collecting your own data Today’s practical exercise is structured as follows: In order to do computational models we need a phenomenon to study (and ideally some data), you will therefore undergo an experiment, which will provide you with two specific cognitive domains to describe (one for now, one for later), and data from yourselves. You will now have to play the Matching Pennies Game against each other. In the Matching Pennies Game you and your opponent have to choose either “left” or “right” to indicate the hand in which the penny is hidden. If you are the matcher, you win by choosing the same as your opponent. If you are the hider with the penny, you win by choosing the opposite as your opponent. You should run 30 rounds with one of you being the hider and the other the matcher and then exchange roles for 30 more rounds. When you are the matcher, keep track of your score: every time you guess right you get +1, every time you don’t you get -1. The hider gets exactly the opposite, so if the matcher ends with a negative score, the hider has won and vice versa. Given you play many trials the game can take a while. If you want to take a break or do it in two sessions, feel free! Try to pay attention and aim at winning. As you play also try to figure out what kind of strategies might be at play for you and for the opponents. How are you deciding whether to choose left or right? Feel free to take notes. 3.2 Start Theorizing The goal of today’s assignment is to build models of the strategies and cognitive processes underlying behavior in the matching pennies game. In other words, to build hypotheses as to how the data is generated. The goal is to: 1) get you more aware of the issue of theory building (and assessment); 2) identify a small set of verbal models that we can then formalize in mathematical cognitive models and algorithms for simulations and model fitting. First, let’s take a little free discussion: Did you enjoy the game? What was the game about? What do you think your opponent was doing? Below you can observe how a previous year of CogSci did against bots (computational agents) playing according to different strategies. Look at the plots below, where the x axes indicate trial, the y axes how many points the CogSci’ers scored (0 being chance, negative means being completely owned by the bots, positive owning the bot) and the different colors indicate different strategies employed by the bots. Strategy “-2” was a Win-Stay-Lose-Shift bot: when it got a +1, it repeated its previous move (e.g. right if it had just played right), otherwise it would perform the opposite move (e.g. left if it had just played right). Strategy “-1” was a biased Nash both, playing “right” 80% of the time. Strategy “0” indicates a reinforcement learning bot; “1” a bot assuming you were playing according to a reinforcement learning strategy and trying to infer your learning and temperature parameters; “2” a bot assuming you were following strategy “1” and trying to accordingly infer your parameters. library(tidyverse) d &lt;- read_csv(&quot;data/MP_MSc_CogSci22.csv&quot;) %&gt;% mutate(BotStrategy = as.factor(BotStrategy)) ## Rows: 4400 Columns: 11 ## ── Column specification ────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): ID, BotParameters ## dbl (9): BotStrategyN, Role, player.tom_role, Choice, BotChoice, Payoff, B... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. d$Role &lt;- ifelse(d$Role == 0, &quot;Matcher&quot;, &quot;Hider&quot;) ggplot(d, aes(Trial, Payoff, group = BotStrategy, color = BotStrategy)) + geom_smooth(se = F) + theme_classic() + facet_wrap(.~Role) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; That doesn’t look too good, ah? What about individual variability? In the plot below we indicate the score of each of the former students, against the different bots. d1 &lt;- d %&gt;% group_by(ID, BotStrategy) %&gt;% dplyr::summarize(Score = sum(Payoff)) ## `summarise()` has grouped output by &#39;ID&#39;. You can override using the ## `.groups` argument. ggplot(d1, aes(BotStrategy, Score, label = ID)) + geom_point(aes(color = ID)) + geom_boxplot(alpha = 0.3) + theme_classic() ## Warning: The following aesthetics were dropped during statistical transformation: ## label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure ## in the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Now, let’s take a bit of group discussion. Get together in groups, and discuss which strategies and cognitive processes might underlie your and the agents’ behaviors in the game. One thing to keep in mind is what a model is: a simplification that can help us make sense of the world. In other words, any behavior is incredibly complex and involves many complex cognitive mechanisms. So start simple, and if you think it’s too simple, progressively add simple components. Once your study group has discussed a few (during the PE), let’s discuss them. Here are the key points from the previous runs of the activity. 3.3 The distinction between participant and researcher perspectives As participants we might not be aware of the strategy we use, or we might believe something erroneous. The exercise here is to act as researchers: what are the principles underlying the participants’ behaviors, no matter what the participants know or believe? Note that talking to participants and being participants helps developing ideas, but it’s not the end point of the process. Also note that as cognitive scientists we can rely on what we have learned about cognitive processes (e.g. memory). Another important component of the distinction is that participants leave in a rich world: they rely on facial expressions and bodily posture, the switch strategies, etc. On the other hand, the researcher is trying to identify one or few at most “simple” strategies. Rich bodily interactions and mixtures or sequences of multiple strategies are not a good place to start modeling. These aspects are a poor starting point for building your first model, and are often pretty difficult to fit to empirical data. Nevertheless, they are important intuitions that the researcher should (eventually?) accommodate. 3.4 Strategies 3.4.1 Random strategies Players might simply be randomly choosing “head” or “tail” independently on the opponent’s choices and of how well they are doing. Choices could be fully at random (50% “head”, 50% “tail”) or biased (e.g. 60% “head”, 40% tail). 3.4.2 Immediate reaction Another simple strategy is simply to follow the previous choice: if it was successful keep it, if not change it. This strategy is also called Win-Stay-Lose-Shift (WSLS). Alternatively, one could do the opposite: Win-Shift-Lose-Stay. 3.4.3 Keep track of the bias (perfect memory) A player could keep track of biases in the opponent: count the proportion of “head” on the total trials so far and choose whichever choice has been made most often by the opponent. 3.4.4 Keep track of the bias (imperfect memory) A player could not be able to keep in mind all previous trials, or decide to forget old trials, in case the biase shifts over time. So we could use only the last n trials, or do a weighted mean with weigths proportional to temporal closeness (the more recent, the higher the weight). 3.4.5 Reinforcement learning Since there is a lot of leeway in how much memory we should keep of previous trials, we could also use a model that explicitly estimates how much players are learning on a trial by trial basis (high learning, low memory; low learning, high memory). This is the model of reinforcement learning, which we will deal with in future chapters. Shortly described, reinforcement learning assumes that each choice has a possible reward (probability of winning) and at every trial given the feedback received updates the expected value of the choice taken. The update depends on the prediction error (difference between expected and actual reward) and the learning rate. 3.4.6 k-ToM Reinforcement learning is a neat model, but can be problematic when playing against other agents: what the game is really about is not assessing the probability of the opponent choosing “head” generalizing from their past choices, but predicting what they will do. This requires making an explicit model of how the opponent chooses. k-ToM models will be dealt with in future chapters, but can be here anticipated as models assuming that the opponent follows a random bias (0-ToM), or models us as following a random bias (1-ToM), or models us modeling them as following a random bias (2-ToM), etc. 3.4.7 Other possible strategies Many additional strategies can be generated by combining former strategies. Generating random output is hard, so if we want to confuse the opponent, we could act first choosing tail 8 times, and then switching to a WSLS strategy for 4 trials, and then choosing head 4 times. Or implementing any of the previous strategies and doing the opposite “to mess with the opponent”. 3.5 Cognitive constraints As we discuss strategies, we can also identify several cognitive constraints that we know from former studies: in particular, memory, perseveration, and errors. 3.5.1 Memory Humans have limited memory and a tendency to forget that is roughly exponential. Models assuming perfect memory for longer stretches of trials are unrealistic. We could for instance use the exponential decay of memory to create weights following the same curve in the “keeping track of bias” models. Roughly, this is what reinforcement learning is doing via the learning rate parameter. 3.5.2 Perseveration Winning choice is not changed. People tend to have a tendency to perseverate with “good” choices independently of which other strategy they might be using. 3.5.3 Errors Humans make mistakes, get distracted, push the wrong button, forget to check whether they won or lost before. So a realistic model of what happens in these games should contain a certain chance of making a mistake. E.g. a 10% chance that any choice will be perfectly random instead of following the strategy. Such random deviations from the strategy might also be conceptualized as explorations: keeping the door open to the strategy not being optimal and therefore testing other choices. For instance, one could have an imperfect WSLS where the probability of staying if winning (or shifting if losing) is only 80% and not 100%. Further, these deviations could be asymmetric, with the probability of staying if winning is 80% and of shifting if losing is 100%; for instance if negative and positive feedback are perceived asymmetrically. 3.6 Continuity between models Many of these models are simply extreme cases of others. For instance, WSLS is a reinforcement learning model with an extreme learning rate (reward replaces the formerly expected value without any moderation), which is also a memory model with a memory of 1 previous trial. k-ToM builds on reinforcement learning: at level 1 assumes the other is a RL agent. 3.7 Mixture of strategies We discussed that there are techniques to consider the data generated by a mixture of models: estimating the probability that they are generated by model 1 or 2 or n. This probability can then be conditioned, according to our research question, to group (are people w schizophrenia more likely to employ model 1) or ID (are different participants using different models), or condition, or… We discussed that we often need lots of data to disambiguate between models, so conditioning e.g. on trial would in practice almost (?) never work. 3.8 Differences from more traditional (general linear model-based) approaches In a more traditional approach we would carefully set up the experiment to discriminate between hypotheses. For instance, if the hypothesis is that humans deploy ToM only when playing against intentional agents, we can set agents with increasing levels of k-ToM against humans, set up two framings (this is a human playing hide and seek, this is a slot machine), and assess whether humans perform differently. E.g. whether they perform better when thinking it’s a human. We analyze performance e.g. as binary outcome on a trial by trial base and condition its rate on framing and complexity. If framing makes a difference in the expected direction, we are good. If we do this properly, thanks to the clever experimental designs we set up, we can discriminate between hypotheses. And that is good. However, cognitive modeling opens additional opportunities. For instance, we can actually reconstruct which level of recursion the participants are enacting and if it changes over time. This might be very useful in the experimental setup, and crucial in more observational setups. Cognitive modeling also allows us to discriminate between different cognitive components more difficult to assess by looking at performance only. For instance, why are participants performing less optimally when facing a supposedly non-intentional agent? Is their learning rate different? Is their estimate of volatility different? In other setups, e.g. a gambling context, we might observe that some participants (e.g. parkinson’s patients) are gambling away much. Is this due to changes in their risk-seeking propensities, loss aversion, or changes in the ability to actually learn the reward structure? Experimental setups help, but cognitive modeling can provide more nuanced and direct evidence. "],["from-verbal-to-formal-models.html", "Chapter 4 From verbal to formal models 4.1 Learning Objectives 4.2 Defining general conditions 4.3 Implementing a random agent 4.4 Implementing a Win-Stay-Lose-Shift agent 4.5 Now we scale it up", " Chapter 4 From verbal to formal models 4.1 Learning Objectives By the end of this exercise, you will be able to: Transform verbal descriptions of decision-making strategies into formal computational models Implement and test different agent-based models in R Compare and evaluate the performance of different strategic agents Visualize and interpret simulation results at scale By computationally implementing the our models, we are forced to make them very explicit in their assumptions; we become able to simulate the models in a variety of different situations and therefore better understand their implications So, the steps for today’s exercise are: choose two of the models and formalize them, that is, produce an algorithm that enacts the strategy, so we can simulate them. implement the algorithms as functions: getting an input and producing an output, so we can more easily implement them across various contexts (e.g. varying amount of trials, input, etc). See R4DataScience, if you need a refresher: https://r4ds.had.co.nz/functions.html implement a Random Bias agent (choosing “head” 70% of the times) and get your agents to play against it for 120 trials (and save the data) implement a Win-Stay-Lose-Shift agent (keeping the same choice if it won, changing it if it lost) and do the same. Now scale up the simulation: have 100 agents for each of your strategy playing against both Random Bias and Win-Stay-Lose-Shift and save their data. Figure out a good way to visualize the data to assess which strategy performs better, whether that changes over time and generally explore what the agents are doing. 4.2 Defining general conditions pacman::p_load(tidyverse, patchwork) # Number of trials per simulation trials &lt;- 120 # Number of agents to simulate agents &lt;- 100 # Optional: Set random seed for reproducibility # set.seed(123) 4.3 Implementing a random agent Remember a random agent is an agent that picks at random between “right” and “left” independently on what the opponent is doing. A random agent might be perfectly random (50% chance of choosing “right”, same for “left”) or biased. The variable “rate” determines the rate of choosing “right”. rate &lt;- 0.5 RandomAgent &lt;- rbinom(trials, 1, rate) # we simply sample randomly from a binomial # Now let&#39;s plot how it&#39;s choosing d1 &lt;- tibble(trial = seq(trials), choice = RandomAgent) p1 &lt;- ggplot(d1, aes(trial, choice)) + geom_line() + labs( title = &quot;Random Agent Behavior (rate 0.5)&quot;, x = &quot;Trial Number&quot;, y = &quot;Choice (0/1)&quot; ) + theme_classic() p1 # What if we were to compare it to an agent being biased? rate &lt;- 0.8 RandomAgent &lt;- rbinom(trials, 1, rate) # we simply sample randomly from a binomial # Now let&#39;s plot how it&#39;s choosing d2 &lt;- tibble(trial = seq(trials), choice = RandomAgent) p2 &lt;- ggplot(d2, aes(trial, choice)) + geom_line() + labs( title = &quot;Biased Random Agent Behavior&quot;, x = &quot;Trial Number&quot;, y = &quot;Choice (0/1)&quot; ) + theme_classic() p1 + p2 # Tricky to see, let&#39;s try writing the cumulative rate: d1$cumulativerate &lt;- cumsum(d1$choice) / seq_along(d1$choice) d2$cumulativerate &lt;- cumsum(d2$choice) / seq_along(d2$choice) p3 &lt;- ggplot(d1, aes(trial, cumulativerate)) + geom_line() + ylim(0,1) + labs( title = &quot;Random Agent Behavior&quot;, x = &quot;Trial Number&quot;, y = &quot;Cumulative probability of choosing 1 (0-1)&quot; ) + theme_classic() p4 &lt;- ggplot(d2, aes(trial, cumulativerate)) + geom_line() + labs( title = &quot;Random Agent Behavior&quot;, x = &quot;Trial Number&quot;, y = &quot;Cumulative probability of choosing 1 (0-1)&quot; ) + ylim(0,1) + theme_classic() p3 + p4 ## Now in the same plot d1$rate &lt;- 0.5 d2$rate &lt;- 0.8 d &lt;- rbind(d1,d2) %&gt;% mutate(rate = as.factor(rate)) p5 &lt;- ggplot(d, aes(trial, cumulativerate, color = rate, group = rate)) + geom_line() + labs( title = &quot;Random Agents Behavior&quot;, x = &quot;Trial Number&quot;, y = &quot;Cumulative probability of choosing 1 (0-1)&quot; ) + ylim(0,1) + theme_classic() p5 # Now as a function #&#39; Create a random decision-making agent #&#39; @param input Vector of previous choices (not used but included for API consistency) #&#39; @param rate Probability of choosing option 1 (default: 0.5 for unbiased) #&#39; @return Vector of binary choices #&#39; @examples #&#39; # Create unbiased random agent for 10 trials #&#39; choices &lt;- RandomAgent_f(rep(1,10), 0.5) RandomAgent_f &lt;- function(input, rate = 0.5) { # Input validation if (!is.numeric(rate) || rate &lt; 0 || rate &gt; 1) { stop(&quot;Rate must be a probability between 0 and 1&quot;) } n &lt;- length(input) choice &lt;- rbinom(n, 1, rate) return(choice) } input &lt;- rep(1,trials) # it doesn&#39;t matter, it&#39;s not taken into account choice &lt;- RandomAgent_f(input, rate) d3 &lt;- tibble(trial = seq(trials), choice) ggplot(d3, aes(trial, choice)) + geom_line() + labs( title = &quot;Random Agent Behavior&quot;, x = &quot;Trial Number&quot;, y = &quot;Cumulative probability of choosing 1 (0-1)&quot; ) + theme_classic() ## What if there&#39;s noise? RandomAgentNoise_f &lt;- function(input, rate, noise){ n &lt;- length(input) choice &lt;- rbinom(n, 1, rate) if (rbinom(1, 1, noise) == 1) {choice = rbinom(1,1,0.5)} return(choice) } 4.4 Implementing a Win-Stay-Lose-Shift agent #&#39; Create a Win-Stay-Lose-Shift decision-making agent #&#39; @param prevChoice Previous choice made by the agent (0 or 1) #&#39; @param feedback Success of previous choice (1 for win, 0 for loss) #&#39; @param noise Optional probability of random choice (default: 0) #&#39; @return Next choice (0 or 1) #&#39; @examples #&#39; # Basic WSLS decision after a win #&#39; next_choice &lt;- WSLSAgent_f(prevChoice = 1, feedback = 1) WSLSAgent_f &lt;- function(prevChoice, feedback, noise = 0) { # Input validation if (!is.numeric(prevChoice) || !prevChoice %in% c(0,1)) { stop(&quot;Previous choice must be 0 or 1&quot;) } if (!is.numeric(feedback) || !feedback %in% c(0,1)) { stop(&quot;Feedback must be 0 or 1&quot;) } if (!is.numeric(noise) || noise &lt; 0 || noise &gt; 1) { stop(&quot;Noise must be a probability between 0 and 1&quot;) } # Core WSLS logic choice &lt;- if (feedback == 1) { prevChoice # Stay with previous choice if won } else { 1 - prevChoice # Switch to opposite choice if lost } # Apply noise if specified if (noise &gt; 0 &amp;&amp; runif(1) &lt; noise) { choice &lt;- sample(c(0,1), 1) } return(choice) } WSLSAgentNoise_f &lt;- function(prevChoice, Feedback, noise){ if (Feedback == 1) { choice = prevChoice } else if (Feedback == 0) { choice = 1 - prevChoice } if (rbinom(1, 1, noise) == 1) {choice &lt;- rbinom(1, 1, .5)} return(choice) } WSLSAgent &lt;- WSLSAgent_f(1, 0) # Against a random agent Self &lt;- rep(NA, trials) Other &lt;- rep(NA, trials) Self[1] &lt;- RandomAgent_f(1, 0.5) Other &lt;- RandomAgent_f(seq(trials), rate) for (i in 2:trials) { if (Self[i - 1] == Other[i - 1]) { Feedback = 1 } else {Feedback = 0} Self[i] &lt;- WSLSAgent_f(Self[i - 1], Feedback) } sum(Self == Other) ## [1] 73 df &lt;- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other)) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, Self)) + geom_line(color = &quot;blue&quot;, aes(trial, Other)) + labs( title = &quot;WSLS Agent (red) vs Biased Random Opponent (blue)&quot;, x = &quot;Trial Number&quot;, y = &quot;Choice (0/1)&quot;, color = &quot;Agent Type&quot; ) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, Feedback)) + geom_line(color = &quot;blue&quot;, aes(trial, 1 - Feedback)) + labs( title = &quot;WSLS Agent (red) vs Biased Random Opponent (blue)&quot;, x = &quot;Trial Number&quot;, y = &quot;Feedback received (0/1)&quot;, color = &quot;Agent Type&quot; ) df$cumulativerateSelf &lt;- cumsum(df$Feedback) / seq_along(df$Feedback) df$cumulativerateOther &lt;- cumsum(1 - df$Feedback) / seq_along(df$Feedback) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, cumulativerateSelf)) + geom_line(color = &quot;blue&quot;, aes(trial, cumulativerateOther)) + labs( title = &quot;WSLS Agent (red) vs Biased Random Opponent (blue)&quot;, x = &quot;Trial Number&quot;, y = &quot;Cumulative probability of choosing 1 (0-1)&quot;, color = &quot;Agent Type&quot; ) # Against a Win-Stay-Lose Shift Self &lt;- rep(NA, trials) Other &lt;- rep(NA, trials) Self[1] &lt;- RandomAgent_f(1, 0.5) Other[1] &lt;- RandomAgent_f(1, 0.5) for (i in 2:trials) { if (Self[i - 1] == Other[i - 1]) { Feedback = 1 } else {Feedback = 0} Self[i] &lt;- WSLSAgent_f(Self[i - 1], Feedback) Other[i] &lt;- WSLSAgent_f(Other[i - 1], 1 - Feedback) } sum(Self == Other) ## [1] 60 df &lt;- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other)) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, Self)) + geom_line(color = &quot;blue&quot;, aes(trial, Other)) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, Feedback)) + geom_line(color = &quot;blue&quot;, aes(trial, 1 - Feedback)) df$cumulativerateSelf &lt;- cumsum(df$Feedback) / seq_along(df$Feedback) df$cumulativerateOther &lt;- cumsum(1 - df$Feedback) / seq_along(df$Feedback) ggplot(df) + theme_classic() + geom_line(color = &quot;red&quot;, aes(trial, cumulativerateSelf)) + geom_line(color = &quot;blue&quot;, aes(trial, cumulativerateOther)) 4.5 Now we scale it up trials = 120 agents = 100 # WSLS vs agents with varying rates for (rate in seq(from = 0.5, to = 1, by = 0.05)) { for (agent in seq(agents)) { Self &lt;- rep(NA, trials) Other &lt;- rep(NA, trials) Self[1] &lt;- RandomAgent_f(1, 0.5) Other &lt;- RandomAgent_f(seq(trials), rate) for (i in 2:trials) { if (Self[i - 1] == Other[i - 1]) { Feedback = 1 } else {Feedback = 0} Self[i] &lt;- WSLSAgent_f(Self[i - 1], Feedback) } temp &lt;- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other), agent, rate) if (agent == 1 &amp; rate == 0.5) {df &lt;- temp} else {df &lt;- bind_rows(df, temp)} } } ## WSLS with another WSLS for (agent in seq(agents)) { Self &lt;- rep(NA, trials) Other &lt;- rep(NA, trials) Self[1] &lt;- RandomAgent_f(1, 0.5) Other[1] &lt;- RandomAgent_f(1, 0.5) for (i in 2:trials) { if (Self[i - 1] == Other[i - 1]) { Feedback = 1 } else {Feedback = 0} Self[i] &lt;- WSLSAgent_f(Self[i - 1], Feedback) Other[i] &lt;- WSLSAgent_f(Other[i - 1], 1 - Feedback) } temp &lt;- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other), agent, rate) if (agent == 1 ) {df1 &lt;- temp} else {df1 &lt;- bind_rows(df1, temp)} } 4.5.1 And we visualize it ggplot(df, aes(trial, Feedback, group = rate, color = rate)) + geom_smooth(se = F) + theme_classic() ## `geom_smooth()` using method = &#39;gam&#39; and formula = &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; We can see that the bigger the bias in the random agent, the bigger the performance in the WSLS (the higher the chances the random agent picks the same hand more than once in a row). Now it’s your turn to follow a similar process for your 2 chosen strategies. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
