--- 
title: "Advanced Cognitive Modeling Notes"
author: "Riccardo Fusaroli"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
# output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: openscapes/series
description: "My notes for the advanced cognitive modeling course - 2025"
---

# Advanced Cognitive Modeling 

These course notes support the Advanced Cognitive Modeling course taught in the Master's program in Cognitive Science at Aarhus University. The course represents a journey into how we can understand cognitive processes through the formalization and implementation of hypothesized mechanisms, their testing and validation.

## Course Philosophy and Approach

Advanced cognitive modeling focuses on three interrelated objectives that shape how we approach the modeling of cognitive processes:

The first objective centers on understanding the thought process behind model development. Rather than simply providing a toolbox of existing scripts, we explore how cognitive models are conceptualized and constructed from the ground up. This approach ensures you develop the skills to create novel models for unique research questions.

The second objective emphasizes mastering the Bayesian workflow essential for robust model development. This workflow encompasses simulation design, prior assessment, parameter recovery testing, and thorough model fit evaluation. These skills ensure your models are not just theoretically sound but also practically reliable and generalize way beyond cognitive modeling.

The third objective focuses on developing advanced probabilistic modeling capabilities. Through hands-on experience with Stan, you will learn to implement increasingly sophisticated models while maintaining scientific rigor.

## Course Structure and Learning Path

The course follows a carefully structured progression that builds your modeling capabilities step by step:

After a deepdive into the physics of pizza ovens, we begin with simple scenarios that introduce fundamental modeling concepts. Each subsequent chapter introduces new modeling techniques while building upon previous knowledge. This cumulative approach ensures you develop a deep understanding of both basic principles and advanced applications.

The chapters include theoretical discussions paired with practical coding exercises. During practical sessions, we work with real datasets, design models collaboratively, and implement them using modern statistical tools. This hands-on approach provides ample opportunity for questions and exploration.

The course schedule maintains flexibility to adapt to the collective learning pace of each cohort. While we have clear learning objectives, we ensure everyone develops a solid foundation before moving to more advanced topics.

## Prerequisites and Preparation

To make the most of this course, students should prepare their technical environment and review fundamental concepts:

Software Requirements:
- R (version 4.4 or above)
- RStudio (version 2024.12.0 or above)
- brms package with proper configuration
- cmdstanr package with complete installation

Technical Prerequisites:
- Working knowledge of R programming
- Basic understanding of Bayesian statistics
- Familiarity with cognitive science fundamentals

Additional Resources:
- Introduction to R and tidyverse: https://r4ds.had.co.nz/
- A condensed Bayesian statistics primer (by Chris Cox and me): https://4ccoxau.github.io/PriorsWorkshop/

## Course Resources

The course materials include:
- Lecture notes and presentations
- Practical exercise guides
- Example code and solutions
- Additional readings and references

For comprehensive information:
- Course syllabus: [TBA]
- Lecture videos: [TBA]

## About These Notes

These notes represent an evolving resource that builds upon previous iterations of the course while incorporating new developments in the field. They are designed to serve both as a learning guide during the course and as a reference for your future research endeavors.

<!--chapter:end:index.Rmd-->

---
title: "01 - The Pizza Experiment"
output: html_document
date: "2025-01-31"
---

```{r}
knitr::opts_chunk$set(
  warning = FALSE,        # Suppress warnings
  message = FALSE,        # Suppress package loading messages
  echo = TRUE,           # Show R code
  fig.width = 8,         # Set default figure width
  fig.height = 5,        # Set default figure height
  fig.align = 'center',  # Center figures
  out.width = "80%",     # Make figures 80% of text width
  dpi = 300             # Set high resolution for figures
)
```


# Foundations

## From Pizza to Cognitive Models: An Introduction

This chapter introduces core modeling concepts through an unexpected lens: the physics of pizza stone heating. While this might seem far removed from cognitive science, it provides an insightful introduction to the challenges and methodologies of modeling complex phenomena.

## Why Start with Pizza?

Do I even need to answer that question? Because pizza, obviously.

In any case, understanding how humans think and make decisions is arguably one of the most complex challenges in science. Rather than diving directly into this complexity, we begin with a more tractable problem: modeling how a pizza stone heats up in an oven. This seemingly simple process introduces us to key modeling concepts:

- The importance of selecting appropriate levels of analysis
- The role of prior knowledge in model development
- The challenge of balancing model complexity with practical utility
- The necessity of rigorous validation approaches

Through this concrete example, we can focus on understanding modeling principles without the added complexity of cognitive theory.


## Learning Objectives

This first chpater is a bit odd, in that it pushes you straight into the deep waters of a complex example. I don't expect you to understand all the technicalities. But, by completing this tutorial, you will be able to better grasp the importance of generative modeling, that is, of modeling that is focused on the underlying mechanisms producing the data.

On the side you might learn something about how to
* Implement physics-based thermal modeling using R and Stan
* Apply Bayesian inference to real-world temperature data
* Compare different statistical models using posterior predictions
* Create professional visualizations of temperature evolution
* Make practical predictions about heating times under various conditions

Oh, and you'll probably get hungry as well!


Required Packages

```{r, required packages}

required_packages <- c(
  "tidyverse",  # For data manipulation and visualization
  "brms",       # For Bayesian regression modeling
  "bayesplot",  # For visualization of Bayesian models
  "tidybayes",  # For working with Bayesian samples
  "cmdstanr"    # For Stan implementation
)

# Install and load packages
for (pkg in required_packages) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg)
    library(pkg, character.only = TRUE)
  }
}

```

## Part 1: Exploring the Pizza Stone Temperature Data

In this study, we collected temperature measurements from a pizza stone in a gas-fired oven using an infrared temperature gun. Three different raters (N, TR, and R) took measurements over time to track how the stone heated up. Understanding how pizza stones heat up is crucial for achieving the perfect pizza crust, as consistent and sufficient stone temperature is essential for proper baking.

The measurements were taken as follows:

```{r}
# Load and examine the data
data <- tibble(
  Order = rep(0:18, 3),
  Seconds = rep(c(0, 175, 278, 333, 443, 568, 731, 773, 851, 912, 980, 
                  1040, 1074, 1124, 1175, 1237, 1298, 1359, 1394), 3),
  Temperature = c(15.1, 233, 244, 280, 289, 304, 343, NA, 333, 341, 320, 
                  370, 325, 362, 363, 357, 380, 376, 380,
                  14.5, 139.9, 153, 36.1, 254, 459, 263, 369, rep(NA, 11),
                  12.9, 149.5, 159, 179.4, 191.7, 201, 210, NA, 256, 257, 
                  281, 293, 297, 309, 318, 321, rep(NA, 3)),
  Rater = rep(c("N", "TR", "R"), each = 19)
)



# Create summary statistics
summary_stats <- data %>%
  group_by(Rater) %>%
  summarize(
    n_measurements = sum(!is.na(Temperature)),
    mean_temp = mean(Temperature, na.rm = TRUE),
    sd_temp = sd(Temperature, na.rm = TRUE),
    min_temp = min(Temperature, na.rm = TRUE),
    max_temp = max(Temperature, na.rm = TRUE)
  )

# Display summary statistics
knitr::kable(summary_stats, digits = 1)


```

### Initial Data Visualization

Let's visualize how the temperature evolves over time for each rater:

```{r}
ggplot(data, aes(x = Seconds/60, y = Temperature, color = Rater)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_line(alpha = 0.5) +
  labs(
    title = "Pizza Stone Temperature Evolution",
    subtitle = "Measurements by three different raters",
    x = "Time (minutes)",
    y = "Temperature (Â°C)",
    color = "Rater"
  ) +
  theme_bw() +
  scale_color_brewer(palette = "Set1")

```

### Key Observations

Several interesting patterns emerge from our data:

*Heating Patterns*: The temperature generally increases over time, but not uniformly. We observe some fluctuations that might be due to:

* Variation in gas flame intensity
* Different measurement locations on the stone
* Measurement technique differences between raters

*Measurement Patterns by Rater*

* Rater N maintained consistent measurements throughout the experiment
* Rater TR shows more variability and fewer total measurements
* Rater R shows a more gradual temperature increase pattern


*Missing Data*: Some measurements are missing (NA values), particularly in the later time points for Rater TR. This is common in real-world data collection and needs to be considered in our analysis.

Let's examine the rate of temperature change:

```{r}
# Calculate temperature change rate
data_with_rate <- data %>%
  group_by(Rater) %>%
  arrange(Seconds) %>%
  mutate(
    temp_change = (Temperature - lag(Temperature)) / (Seconds - lag(Seconds)) * 60,
    minutes = Seconds/60
  ) %>%
  filter(!is.na(temp_change))

# Visualize temperature change rate
ggplot(data_with_rate, aes(x = minutes, y = temp_change, color = Rater)) +
  geom_point() +
  geom_smooth(se = FALSE, span = 0.75) +
  labs(
    title = "Rate of Temperature Change Over Time",
    subtitle = "Degrees Celsius per minute",
    x = "Time (minutes)",
    y = "Temperature Change Rate (Â°C/min)",
    color = "Rater"
  ) +
  theme_bw() +
  scale_color_brewer(palette = "Set1")
```

This visualization reveals that the heating rate is highest in the first few minutes and gradually decreases as the stone temperature approaches the oven temperature. This aligns with Newton's Law of Cooling/Heating, which we will explore in the next section.

## Part 2: Initial Statistical Modeling

Before developing our physics-based model, let's explore how standard statistical approaches perform in modeling our temperature data. We'll implement two types of models using the brms package: a linear mixed-effects model and a lognormal mixed-effects model. Both models will account for variations between raters.

### Model Setup and Priors
First, let's ensure we have a directory for our models and set up our computational parameters:

```{r}
# Create models directory if it doesn't exist
dir.create("models", showWarnings = FALSE)

# Define computational parameters
mc_settings <- list(
  chains = 2,
  iter = 6000,
  seed = 123,
  backend = "cmdstanr"
)
```


### Linear Mixed-Effects Model

We begin with a linear mixed-effects model, which assumes that temperature increases linearly with time but allows for different patterns across raters. This model includes both fixed effects (overall time trend) and random effects (rater-specific variations).

```{r}
# Define priors for linear model
linear_priors <- c(
  prior(normal(15, 20), class = "Intercept"),  # Centered around room temperature
  prior(normal(0, 1), class = "b"),          # Expected temperature change per second
  prior(normal(0, 100), class = "sigma"),         # Residual variation
  prior(normal(0, 100), class = "sd"),            # Random effects variation
  prior(lkj(3), class = "cor")                    # Random effects correlation
)

# Fit linear mixed-effects model
linear_model <- brm(
  Temperature ~ Seconds + (1 + Seconds | Rater),
  data = data,
  family = gaussian,
  prior = linear_priors,
  chains = mc_settings$chains,
  iter = mc_settings$iter,
  seed = mc_settings$seed,
  backend = mc_settings$backend,
  file = "models/01_pizza_linear_model",
  cores = 2,
  adapt_delta = 0.99,
  max_treedepth = 20
)

# Display model summary
summary(linear_model)

# Generate predictions
linear_preds <- fitted(
  linear_model,
  newdata = data,
  probs = c(0.025, 0.975)
) %>%
  as_tibble() %>%
  bind_cols(data)
```

### Lognormal Mixed-Effects Model

The lognormal model accounts for the fact that temperature changes might be proportional rather than additive, and ensures predictions cannot go below zero (I don't bring my oven out in the freezing cold!).

```{r}
# Define priors for lognormal model
lognormal_priors <- c(
  prior(normal(2.7, 1), class = "Intercept"),     # Log scale for room temperature
  prior(normal(0, 0.01), class = "b"),     # Expected log-scale change per second
  prior(normal(0, 1), class = "sigma"),        # Log-scale residual variation
  prior(normal(0, 1), class = "sd"),           # Random effects variation
  prior(lkj(3), class = "cor")                   # Random effects correlation
)

# Fit lognormal mixed-effects model
lognormal_model <- brm(
  Temperature ~ Seconds + (1 + Seconds | Rater),
  data = data,
  family = lognormal,
  prior = lognormal_priors,
  chains = mc_settings$chains,
  cores = 2,
  adapt_delta = 0.99,
  max_treedepth = 20,
  iter = mc_settings$iter,
  seed = mc_settings$seed,
  backend = mc_settings$backend,
  file = "models/01_pizza_lognormal_model"
)

# Generate predictions
lognormal_preds <- fitted(
  lognormal_model,
  newdata = data,
  probs = c(0.025, 0.975)
) %>%
  as_tibble() %>%
  bind_cols(data)
```

### Model Comparison and Visualization
Let's compare how these models fit our data:
```{r}
# Compare models using LOO
model_comparison <- loo_compare(
  loo(linear_model),
  loo(lognormal_model)
)

# Create comparison plot
ggplot() +
  # Raw data points
  geom_point(data = data, 
            aes(x = Seconds/60, y = Temperature, color = Rater),
            alpha = 0.5) +
  # Linear model predictions
  geom_line(data = linear_preds,
            aes(x = Seconds/60, y = Estimate, linetype = "Linear"),
            color = "blue") +
  geom_ribbon(data = linear_preds,
              aes(x = Seconds/60, ymin = Q2.5, ymax = Q97.5),
              fill = "blue", alpha = 0.1) +
  # Lognormal model predictions
  geom_line(data = lognormal_preds,
            aes(x = Seconds/60, y = Estimate, linetype = "Lognormal"),
            color = "red") +
  geom_ribbon(data = lognormal_preds,
              aes(x = Seconds/60, ymin = Q2.5, ymax = Q97.5),
              fill = "red", alpha = 0.1) +
  # Formatting
  facet_wrap(~Rater) +
  labs(
    title = "Comparison of Statistical Models",
    subtitle = "Linear vs Lognormal Mixed-Effects Models",
    x = "Time (minutes)",
    y = "Temperature (Â°C)",
    linetype = "Model Type"
  ) +
  theme_bw()


# Create comparison plot but capping the y axis
ggplot() +
  # Raw data points
  geom_point(data = data, 
            aes(x = Seconds/60, y = Temperature, color = Rater),
            alpha = 0.5) +
  # Linear model predictions
  geom_line(data = linear_preds,
            aes(x = Seconds/60, y = Estimate, linetype = "Linear"),
            color = "blue") +
  geom_ribbon(data = linear_preds,
              aes(x = Seconds/60, ymin = Q2.5, ymax = Q97.5),
              fill = "blue", alpha = 0.1) +
  # Lognormal model predictions
  geom_line(data = lognormal_preds,
            aes(x = Seconds/60, y = Estimate, linetype = "Lognormal"),
            color = "red") +
  geom_ribbon(data = lognormal_preds,
              aes(x = Seconds/60, ymin = Q2.5, ymax = Q97.5),
              fill = "red", alpha = 0.1) +
  ylim(0, 1000) +
  # Formatting
  facet_wrap(~Rater) +
  labs(
    title = "Comparison of Statistical Models",
    subtitle = "Linear vs Lognormal Mixed-Effects Models",
    x = "Time (minutes)",
    y = "Temperature (Â°C)",
    linetype = "Model Type"
  ) +
  theme_bw()
```

### Model Assessment
I have seen worse models in my time, but they do seem to have important issues:

* The linear mixed-effects model assumes a constant rate of temperature change, which we can see is not at all accurate. The actual temperature increase is fast at the beginning and appears to slow down over time, particularly at higher temperatures. While this model has the advantage of simplicity, it is not likely to produce accurate predictions as it seem to fail to capture the underlying physics of heat transfer.

* The lognormal mixed-effects model is completely off.

Further, the models produce some divergences, which is often a sign that they are not well suited to the data.
I suggest that the issue is that neither model incorporates our knowledge of heat transfer physics, which suggests an exponential approach to equilibrium temperature. This limitation motivates our next section, where we'll develop a physics-based model.

## Part 3: Understanding the Physics Model

Temperature evolution in a pizza stone follows Newton's Law of Cooling/Heating. We'll start by exploring this physical model before applying it to real data.

### The Basic Temperature Evolution Equation

The temperature evolution of a pizza stone in a gas-fired oven is governed by the heat diffusion equation, which describes how heat flows through solid materials: 


$$\rho c_p \frac{\partial T}{\partial t} = k\nabla^2T + Q$$

where:
$\rho$ represents the stone's density (kg/mÂ³)
$c_p$ denotes specific heat capacity (J/kgÂ·K)
$T$ is temperature (K)
$t$ represents time (s)
$k$ is thermal conductivity (W/mÂ·K)
$\nabla^2$ is the Laplacian operator
$Q$ represents heat input from the oven (W/mÂ³)

While this equation provides a complete description of heat flow, we can significantly simplify our analysis by applying the lumped capacitance model. This simplification assumes that the temperature throughout the pizza stone remains uniform at any given time - not perfect, but a reasonable assumption given the stone's relatively thin profile and good thermal conductivity. This approach reduces our model to:

$$\frac{dT}{dt} = \frac{hA}{mc_p}(T_{\infty} - T)$$

where: 
$h$ is the heat transfer coefficient (W/mÂ²Â·K)
$A$ is the surface area exposed to heat (mÂ²)
$m$ is the stone's mass (kg)
$T_{\infty}$ is the oven temperature (K)

This simplified equation relates the rate of temperature change to the difference between the current stone temperature T and the flame temperature Tâ. The coefficient h represents the heat transfer coefficient between the flame and stone, A is the stone's surface area exposed to heat, m is its mass, and cp remains the specific heat capacity.

To solve this differential equation, we begin by separating variables:

$$\frac{dT}{T_{\infty} - T} = \left(\frac{hA}{mc_p}\right)dt$$

Integration of both sides yields:

$$-\ln|T_{\infty} - T| = \left(\frac{hA}{mc_p}\right)t + C$$

where C is an integration constant.

Using the initial condition $T = T_i$ at $t = 0$, we can determine the integration constant:

$$C = -\ln|T_{\infty} - T_i|$$

Substituting this back and solving for temperature gives us:

$$T = T_{\infty} + (T_i - T_{\infty})\exp\left(-\frac{hA}{mc_p}t\right)$$

For practical reasons, we combine physical parameters into a single coefficient $\theta$:

$$HOT = \frac{hA}{mc_p}$$
Giving our working equation:
$$T = T_{\infty} + (T_i - T_{\infty})\exp(-HOT * t)$$

This equation retains the essential physics while providing a practical model for analyzing our experimental data. The HOT coefficient encapsulates the combined effects of heat transfer efficiency, stone geometry, and material properties into a single parameter that determines how quickly the stone approaches the flame temperature.

## Part 4: Implementing the Physics-Based Model

Having established the theoretical foundation for our heat transfer model, we now move to its practical implementation. We will use Stan to create a Bayesian implementation of our physics-based model, allowing us to account for measurement uncertainty and variation between raters.
First, we prepare our data for the Stan model. Our model requires initial temperatures, time measurements, and observed temperatures from each rater:

```{r}
# Create data structure for Stan
stan_data <- list(
  N = nrow(data %>% filter(!is.na(Temperature))),
  time = data %>% filter(!is.na(Temperature)) %>% pull(Seconds),
  temp = data %>% filter(!is.na(Temperature)) %>% pull(Temperature),
  n_raters = 3,
  rater = as.numeric(factor(data %>% 
                           filter(!is.na(Temperature)) %>% 
                           pull(Rater))),
  Ti = c(100, 100, 100),  # Initial temperature estimates
  Tinf = 450              # Flame temperature estimate
)
```

Next, we implement our physics-based model in Stan. The model incorporates our derived equation while allowing for rater-specific heating coefficients:

```{r}
stan_code <- "
data {
  int<lower=0> N;                   // Number of observations
  vector[N] time;                   // Time points
  vector[N] temp;                   // Observed temperatures
  int<lower=0> n_raters;           // Number of raters
  array[N] int<lower=1,upper=n_raters> rater;  // Rater indices
  vector[n_raters] Ti;             // Initial temperatures
  real Tinf;                       // Flame temperature
}

parameters {
  vector<lower=0>[n_raters] HOT;   // Heating coefficients
  vector<lower=0>[n_raters] sigma; // Measurement error
}

model {
  vector[N] mu;
  
  // Physics-based temperature prediction
  for (i in 1:N) {
    mu[i] = Tinf + (Ti[rater[i]] - Tinf) * exp(-HOT[rater[i]] * time[i]);
  }
  
  // Prior distributions
  target += normal_lpdf(HOT | 0.005, 0.005);    // Prior for heating rate
  target += exponential_lpdf(sigma | 1);         // Prior for measurement error
  
  // Likelihood
  target += normal_lpdf(temp | mu, sigma[rater]);
}
"

# Save the model
writeLines(stan_code, "models/pizza_physics_model.stan")

# Compile and fit the model
mod <- cmdstan_model("models/pizza_physics_model.stan")
fit <- mod$sample(
  data = stan_data,
  seed = 123,
  chains = 2,
  parallel_chains = 2
)
```

The Stan implementation translates our mathematical model into a computational framework. We assign informative priors to our parameters based on physical understanding: the heating coefficient (HOT) is expected to be small but positive, while measurement error (sigma) follows an exponential distribution to ensure positivity while allowing for varying levels of uncertainty between raters.
To visualize our model's predictions and assess its performance, we extract posterior samples and generate predictions across our time range:

```{r}
# Extract draws
post <- as_draws_df(fit$draws()) %>%
  select(starts_with("HOT"), starts_with("sigma")) %>%
  slice_sample(n = 100)

# Create prediction grid
pred_data <- crossing(
  time = seq(0, max(stan_data$time), length.out = 100),
  rater = 1:stan_data$n_raters
) %>%
  mutate(
    Ti = stan_data$Ti[rater],
    Tinf = stan_data$Tinf
  )

# Generate predictions
pred_matrix <- matrix(NA, nrow = nrow(pred_data), ncol = 100)
for (i in 1:nrow(pred_data)) {
  pred_matrix[i,] <- with(pred_data[i,], 
                         Tinf + (Ti - Tinf) * exp(-as.matrix(post)[,rater] * time))
}

# Summarize predictions
predictions <- pred_data %>%
  mutate(
    mean = rowMeans(pred_matrix),
    lower = apply(pred_matrix, 1, quantile, 0.025),
    upper = apply(pred_matrix, 1, quantile, 0.975)
  )

# Create visualization
ggplot(predictions, aes(x = time/60)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
  geom_line(aes(y = mean)) +
  geom_point(
    data = data %>% 
      filter(!is.na(Temperature)) %>%
      mutate(rater = case_when(
        Rater == "N" ~ 1,
        Rater == "TR" ~ 2,
        Rater == "R" ~ 3
      )), 
    aes(x = Seconds/60, y = Temperature)
  ) +
  facet_wrap(~rater, labeller = labeller(rater = c(
    "1" = "Rater N", 
    "2" = "Rater TR", 
    "3" = "Rater R"
  ))) +
  labs(
    title = "Physics-Based Model Predictions",
    x = "Time (minutes)",
    y = "Temperature (Â°C)"
  ) +
  theme_bw()
```

Our implementation combines the theoretical understanding developed in Part 3 with practical considerations for real-world data analysis. The model accounts for measurement uncertainty while maintaining the fundamental physics of heat transfer, providing a robust framework for understanding pizza stone temperature evolution.

## Part 5: Model Analysis and Practical Applications

Having implemented our physics-based model, we can now analyze its predictions and develop practical insights for pizza stone temperature management. A key question for pizza making is how long it takes to reach optimal cooking temperatures under different conditions.
We begin by creating a function that calculates the time needed to reach a target temperature:
```{r}
time_to_temp <- function(target_temp, HOT, Ti, Tinf) {
  # Solve: target = Tinf + (Ti - Tinf) * exp(-HOT * t)
  # for t
  t = -1/HOT * log((target_temp - Tinf)/(Ti - Tinf))
  return(t/60)  # Convert seconds to minutes
}
```
To understand heating times across different oven conditions, we examine how varying flame temperatures affect the time needed to reach pizza-making temperatures. We extract the heating coefficients from our fitted model and analyze temperature scenarios:
```{r}
# Extract HOT samples from our posterior
hot_samples <- as_draws_df(fit$draws()) %>%
  select(starts_with("HOT"))

# Create prediction grid for different flame temperatures
pred_data <- crossing(
  Tinf = seq(450, 1200, by = 50),  # Range of flame temperatures
  rater = 1:3
) %>%
  mutate(
    Ti = stan_data$Ti[rater],
    target_temp = 400  # Target temperature for pizza cooking
  )

# Calculate heating times across conditions
n_samples <- 100
time_preds <- map_dfr(1:nrow(pred_data), function(i) {
  times <- sapply(1:n_samples, function(j) {
    hot <- hot_samples[j, paste0("HOT[", pred_data$rater[i], "]")][[1]]
    time_to_temp(
      pred_data$target_temp[i], 
      hot, 
      pred_data$Ti[i], 
      pred_data$Tinf[i]
    )
  })
  
  data.frame(
    rater = pred_data$rater[i],
    Tinf = pred_data$Tinf[i],
    mean_time = mean(times),
    lower = quantile(times, 0.025),
    upper = quantile(times, 0.975)
  )
})

# Visualize heating time predictions
ggplot(time_preds, aes(x = Tinf)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
  geom_line(aes(y = mean_time)) +
  facet_wrap(~rater, labeller = labeller(rater = c(
    "1" = "Rater N", 
    "2" = "Rater TR", 
    "3" = "Rater R"
  ))) +
  labs(
    title = "Time Required to Reach Pizza-Making Temperature",
    subtitle = "Target temperature: 400Â°C",
    x = "Flame Temperature (Â°C)", 
    y = "Minutes to reach target"
  ) +
  theme_bw()
```

Our analysis reveals several important insights for practical pizza making. First, the heating time decreases nonlinearly with flame temperature, showing diminishing returns at very high temperatures. 
We can also observe differences between raters in their measured heating times. These variations likely stem from differences in measurement technique and location on the stone, highlighting the importance of consistent temperature monitoring practices.
For practical application, we can provide specific heating guidelines based on our model. At a typical flame temperature of 800Â°C, the model predicts it will take approximately 20-30 minutes to reach optimal pizza-making temperature, assuming room temperature start. However, this time can vary significantly based on:

* Initial stone temperature
* Flame temperature and consistency
* Environmental conditions.

Can we really wait that long?

## Conclusion: From Pizza to Principles

The journey from modeling a heating pizza stone to understanding cognitive processes might seem unusual, but it illustrates fundamental principles that will guide us throughout this course.

Through this seemingly simple physics problem, we have encountered the core challenges that cognitive scientists face daily. Just relying on standard statistical models is not enough. We need to understand the underlying generative processes. We discovered how choosing the right level of analysis shapes our understanding - just as we simplified complex heat equations into workable models, cognitive scientists must decide which aspects of the mental processes to model explicitly and which to abstract. We learned that even well-understood physical processes require careful statistical treatment, foreshadowing the challenges we will face with more complex cognitive phenomena.

The pizza stone experiment also demonstrated the importance of rigorous methodology. We saw how multiple measurements from different raters revealed variability in our data, leading us to consider measurement error and individual differences - themes that will become crucial when studying human behavior. Our exploration of different statistical approaches, from simple linear models to more sophisticated Bayesian frameworks, established a foundation for the modeling techniques we will develop throughout this course.

Perhaps most importantly, this chapter starts showing that successful modeling requires balancing competing demands. We must weigh theoretical complexity against practical utility, statistical sophistication against interpretability, and mathematical elegance against real-world applicability. These trade-offs will become even more prominent as we move into modeling cognitive processes.

As we progress through this course, we will encounter increasingly complex cognitive phenomena. The principles we learned here - careful data collection, thoughtful model specification, rigorous validation, and balanced interpretation - will serve as our guide. While human cognition presents challenges far beyond those of heating pizza stones, the fundamental approach remains the same: start with clear observations, build theoretically motivated models, and test them systematically against data.

In the next chapter, we will begin applying these principles directly to cognitive processes, starting with simple decision-making tasks. The mathematical tools and statistical frameworks introduced here will provide the foundation for understanding how humans process information and make choices.


Finally, I hope you are hungry now. I know I am. Let's go and make some pizza!






<!--chapter:end:01-PizzaExperiment.Rmd-->


# Building Models of Strategic Decision-Making

## Learning goals


* Becoming more aware of the issue involved in theory building (and assessment); 

* Identifying a small set of verbal models that we can then formalize in mathematical cognitive models and algorithms for simulations and model fitting.

## Introduction

In order to do computational models we need a phenomenon to study (and ideally some data), throughout the course you will be asked undergo several experiments, which provides specific behaviors to model.

The matching pennies game provides a fun starting point for exploring cognitive modeling. This simple game allows us to examine how humans make decisions in strategic situations, while introducing fundamental concepts in model development and validation. Through this chapter, we will progress from observing actual gameplay behavior to developing formal models that capture decision-making processes.

## The Matching Pennies Game

In the matching pennies game, two players engage in a series of choices. One player attempts to match the other's choice, while the other player aims to achieve a mismatch, and they repeatedly play with each other. This is a prototypical example of interacting behaviors that are usually tackled by game theory, and bring up issues of theory of mind and recursivity.

For an introduction see the paper: Waade, Peter T., et al. "Introducing tomsup: Theory of mind simulations using Python." Behavior Research Methods 55.5 (2023): 2197-2231.

## Game Structure

The game proceeds as follows:

1. Two players sit facing each other
2. Each round, both players choose either "left" or "right" to indicate where they believe a penny is hidden
3. The matcher wins by choosing the same hand as their opponent
4. The hider wins by choosing the opposite hand
5. Points are awarded: +1 for winning, -1 for losing
6. Repeat

This simple structure creates a rich environment for studying decision-making strategies, learning, and adaptation.

## Empirical Investigation

### Data Collection Protocol

If you are attending my class you have been (or will be) asked to participate in a matching pennies game. This game provides the foundation for our modeling efforts. By observing gameplay and collecting data, we can develop models that capture the cognitive processes underlying decision-making in strategic situations.

Participants play 30 rounds as the matcher and 30 rounds as the hider, allowing us to observe behavior in both roles. While playing, participants track their scores, which can provide quantitative data for later analysis. Participants are also asked to reflect on their strategies and the strategies they believe their opponents are using, as that provides valuable materials to build models on.

### Initial Observations

Through the careful observation and discussion of gameplay we do in class, several patterns typically emerge. For instance, players often demonstrate strategic adaptation, adjusting their choices based on their opponent's previous moves. They may attempt to identify patterns in their opponent's behavior while trying to make their own choices less predictable. The tension between exploitation of perceived patterns and maintenance of unpredictability creates fascinating dynamics for modeling.


## Empirical explorations

Below you can observe how a previous year of CogSci did against bots (computational agents) playing according to different strategies. Look at the plots below, where the x axes indicate trial, the y axes how many points the CogSci'ers scored (0 being chance, negative means being completely owned by the bots, positive owning the bot) and the different colors indicate different strategies employed by the bots. Strategy "-2" was a Win-Stay-Lose-Shift bot: when it got a +1, it repeated its previous move (e.g. right if it had just played right), otherwise it would perform the opposite move (e.g. left if it had just played right). Strategy "-1" was a biased Nash both, playing "right" 80% of the time. Strategy "0" indicates a reinforcement learning bot; "1" a bot assuming you were playing according to a reinforcement learning strategy and trying to infer your learning and temperature parameters; "2" a bot assuming you were following strategy "1" and trying to accordingly infer your parameters.

```{r 01 plot collective performance in MP}
library(tidyverse)
d <- read_csv("data/MP_MSc_CogSci22.csv") %>% 
  mutate(BotStrategy = as.factor(BotStrategy))

d$Role <- ifelse(d$Role == 0, "Matcher", "Hider")

ggplot(d, aes(Trial, Payoff, group = BotStrategy, color = BotStrategy)) + 
  geom_smooth(se = F) + 
  theme_classic() + 
  facet_wrap(.~Role)

```


That doesn't look too good, ah? What about individual variability? In the plot below we indicate the score of each of the former students, against the different bots.

```{r 01 plot individual performance in MP}
d1 <- d %>% group_by(ID, BotStrategy) %>% 
  dplyr::summarize(Score = sum(Payoff))

ggplot(d1, aes(BotStrategy, Score, label = ID)) +
  geom_point(aes(color = ID)) +
  geom_boxplot(alpha = 0.3) +
  theme_classic()

```


Now, let's take a bit of group discussion. Get together in groups, and discuss which strategies and cognitive processes might underlie your and the agents' behaviors in the game. One thing to keep in mind is what a model is: a simplification that can help us make sense of the world. In other words,  any behavior is incredibly complex and involves many complex cognitive mechanisms. So start simple, and if you think it's too simple, progressively add simple components.


Once your study group has discussed a few (during the PE), let's discuss them.

## Notes from previous years

### From Observation to Theory
The transition from observing gameplay to building formal models requires careful consideration of multiple factors. We must identify which aspects of behavior to model explicitly while deciding which details can be abstracted away.

### Core Modeling Considerations
When developing models of matching pennies behavior, we must address several key questions:

* What information do players use to make decisions?

* How do players integrate past experiences with current choices?

* What role does randomness play in decision-making?

* How do players adapt their strategies over time?

* Are there notions and models from previous cognitive science courses that can help us understand the behavior?

These questions guide our model development process, helping us move from verbal theories to mathematical formulations.


### The distinction between participant and researcher perspectives

As participants we might not be aware of the strategy we use, or we might believe something erroneous. The exercise here is to act as researchers: what are the principles underlying the participants' behaviors, no matter what the participants know or believe? Note that talking to participants and being participants helps developing ideas, but it's not the end point of the process. Also note that as cognitive scientists we can rely on what we have learned about cognitive processes (e.g. memory).

Another important component of the distinction is that participants leave in a rich world: they rely on facial expressions and bodily posture, the switch strategies, etc. On the other hand, the researcher is trying to identify one or few at most "simple" strategies. Rich bodily interactions and mixtures or sequences of multiple strategies are not a good place to start modeling. These aspects are a poor starting point for building your first model, and are often pretty difficult to fit to empirical data. Nevertheless, they are important intuitions that the researcher should (eventually?) accommodate.


## Building Formal Models

Based on observed behavior patterns and theoretical considerations, we can develop several candidate models of decision-making in the matching pennies game.

### Random Choice Model

The simplest model assumes players make choices randomly, independent of history or context. Players might simply be randomly choosing "head" or "tail" independently on the opponent's choices and of how well they are doing. Choices could be fully at random (50% "head", 50% "tail") or biased (e.g. 60% "head", 40% tail). While this may seem overly simplistic, it provides an important baseline for comparison and introduces key concepts in model specification.

### Immediate reaction (Win-Stay-Lose-Shift)

Another simple strategy is simply to follow the previous choice: if it was successful keep it, if not change it. This strategy is also called Win-Stay-Lose-Shift (WSLS).

The model can be formalized as:
$$P(a_t = a_{t-1}) = \begin{cases}
p_w & \text{if win at } t-1 \
1 - p_l & \text{if loss at } t-1
\end{cases}$$
where $a_t$ represents the action at time $t$, and $p_w$ and $p_l$ are the probabilities of staying after wins and losses respectively.

Alternatively, one could do the opposite: Win-Shift-Lose-Stay.

### Keep track of the bias (perfect memory)

A more sophisticated approach considers how players track and respond to their opponent's choice patterns. This model maintains a running estimate of the opponent's choice probabilities and updates these estimates based on observed choices.

### Keep track of the bias (imperfect memory)

A player could not be able to keep in mind all previous trials, or decide to forget old trials, in case the biase shifts over time. So we could use only the last n trials, or do a weighted mean with weigths proportional to temporal closeness (the more recent, the higher the weight).

### Reinforcement learning

Since there is a lot of leeway in how much memory we should keep of previous trials, we could also use a model that explicitly estimates how much players are learning on a trial by trial basis (high learning, low memory; low learning, high memory). This is the model of reinforcement learning, which we will deal with in future chapters. 
Shortly described, reinforcement learning assumes that each choice has a possible reward (probability of winning) and at every trial given the feedback received updates the expected value of the choice taken. The update depends on the prediction error (difference between expected and actual reward) and the learning rate. 


### k-ToM

Reinforcement learning is a neat model, but can be problematic when playing against other agents: what the game is really about is not assessing the probability of the opponent choosing "head" generalizing from their past choices, but predicting what they will do. This requires making an explicit model of how the opponent chooses. k-ToM models will be dealt with in future chapters, but can be here anticipated as models assuming that the opponent follows a random bias (0-ToM), or models us as following a random bias (1-ToM), or models us modeling them as following a random bias (2-ToM), etc. 

### Other possible strategies

Many additional strategies can be generated by combining former strategies. Generating random output is hard, so if we want to confuse the opponent, we could act first choosing tail 8 times, and then switching to a WSLS strategy for 4 trials, and then choosing head 4 times. Or implementing any of the previous strategies and doing the opposite "to mess with the opponent".

## Cognitive constraints

As we discuss strategies, we can also identify several cognitive constraints that we know from former studies: in particular, memory, perseveration, and errors.

### Memory

Humans have limited memory and a tendency to forget that is roughly exponential. Models assuming perfect memory for longer stretches of trials are unrealistic. We could for instance use the exponential decay of memory to create weights following the same curve in the "keeping track of bias" models. Roughly, this is what reinforcement learning is doing via the learning rate parameter.

### Perseveration

Winning choice is not changed. People tend to have a tendency to perseverate with "good" choices independently of which other strategy they might be using.

### Errors

Humans make mistakes, get distracted, push the wrong button, forget to check whether they won or lost before. So a realistic model of what happens in these games should contain a certain chance of making a mistake. E.g. a 10% chance that any choice will be perfectly random instead of following the strategy.

Such random deviations from the strategy might also be conceptualized as explorations: keeping the door open to the strategy not being optimal and therefore testing other choices. For instance, one could have an imperfect WSLS where the probability of staying if winning (or shifting if losing) is only 80% and not 100%. Further, these deviations could be asymmetric, with the probability of staying if winning is 80% and of shifting if losing is 100%; for instance if negative and positive feedback are perceived asymmetrically.


## Continuity between models

Many of these models are simply extreme cases of others. For instance, WSLS is a reinforcement learning model with an extreme learning rate (reward replaces the formerly expected value without any moderation), which is also a memory model with a memory of 1 previous trial. k-ToM builds on reinforcement learning: at level 1 assumes the other is a RL agent.

## Mixture of strategies

We discussed that there are techniques to consider the data generated by a mixture of models: estimating the probability that they are generated by model 1 or 2 or n. This probability can then be conditioned, according to our research question, to group (are people w schizophrenia more likely to employ model 1) or ID (are different participants using different models), or condition, or... We discussed that we often need lots of data to disambiguate between models, so conditioning e.g. on trial would in practice almost (?) never work.

## Differences from more traditional (general linear model-based) approaches

In a more traditional approach we would carefully set up the experiment to discriminate between hypotheses. For instance, if the hypothesis is that humans deploy ToM only when playing against intentional agents, we can set agents with increasing levels of k-ToM against humans, set up two framings (this is a human playing hide and seek, this is a slot machine), and assess whether humans perform differently. E.g. whether they perform better when thinking it's a human. We analyze performance e.g. as binary outcome on a trial by trial base and condition its rate on framing and complexity. If framing makes a difference in the expected direction, we are good.

If we do this properly, thanks to the clever experimental designs we set up, we can discriminate between hypotheses. And that is good. However, cognitive modeling opens additional opportunities. 
For instance, we can actually reconstruct which level of recursion the participants are enacting and if it changes over time. This might be very useful in the experimental setup, and crucial in more observational setups.
Cognitive modeling also allows us to discriminate between different cognitive components more difficult to assess by looking at performance only. For instance, why are participants performing less optimally when facing a supposedly non-intentional agent? Is their learning rate different? Is their estimate of volatility different?

In other setups, e.g. a gambling context, we might observe that some participants (e.g. parkinson's patients) are gambling away much. Is this due to changes in their risk-seeking propensities, loss aversion, or changes in the ability to actually learn the reward structure? Experimental setups help, but cognitive modeling can provide more nuanced and direct evidence.

<!--chapter:end:02-BuildingModels.Rmd-->


# From verbal descriptions to formal models

This chapter bridges the gap between verbal theories and computational implementations of cognitive models. Building on our observations of the matching pennies game, we now develop precise mathematical formulations that can generate testable predictions.

## Learning Goals

After completing this chapter, you will be able to:

* Transform verbal descriptions of decision-making strategies into precise mathematical formulations, which implications can be more easily explored and that can be empirically tested

* Create computational implementations of these mathematical models as agent-based models in R

* Generate and analyze simulated data to understand model behavior under different conditions

## The Value of Formalization

Moving from verbal to formal models represents a crucial step in cognitive science. When we describe behavior in words, ambiguities often remain hidden. For instance, a verbal description might state that players "tend to repeat successful choices." But what exactly constitutes "tend to"? How strongly should past successes influence future choices? Mathematical formalization forces us to be precise about these specifications.

By computationally implementing the our models, 

* we are forced to make them very explicit in their assumptions;

* we become able to simulate the models in a variety of different situations and therefore better understand their implications

So, what we'll do throughout the chapter is to:

1. choose two of the models and formalize them, that is, produce an algorithm that enacts the strategy, so we can simulate them.

2. implement the algorithms as functions: getting an input and producing an output, so we can more easily implement them across various contexts (e.g. varying amount of trials, input, etc). See R4DataScience, if you need a refresher: https://r4ds.had.co.nz/functions.html

3. implement a Random Bias agent (choosing "head" 70% of the times) and get your agents to play against it for 120 trials (and save the data)

4. implement a Win-Stay-Lose-Shift agent (keeping the same choice if it won, changing it if it lost) and do the same.

5. scale up the simulation: have 100 agents for each of your strategy playing against both Random Bias and Win-Stay-Lose-Shift and save their data.

6. figure out a good way to visualize the data to assess which strategy performs better, whether that changes over time and generally explore what the agents are doing.


## Defining general conditions

```{r 02 setting general parameters}

pacman::p_load(tidyverse, patchwork)

# Number of trials per simulation
trials <- 120  

# Number of agents to simulate
agents <- 100  

# Optional: Set random seed for reproducibility
# set.seed(123)

```

## Implementing a random agent

Remember a random agent is an agent that picks at random between "right" and "left" independently on what the opponent is doing.
A random agent might be perfectly random (50% chance of choosing "right", same for "left") or biased. The variable "rate" determines the rate of choosing "right".

```{r 02 implementing random agent}

rate <- 0.5

RandomAgent <- rbinom(trials, 1, rate) # we simply sample randomly from a binomial

# Now let's plot how it's choosing
d1 <- tibble(trial = seq(trials), choice = RandomAgent)

p1 <- ggplot(d1, aes(trial, choice)) + 
  geom_line() + 
  labs(
    title = "Random Agent Behavior (rate 0.5)",
    x = "Trial Number",
    y = "Choice (0/1)"
  ) +
  theme_classic()
p1

# What if we were to compare it to an agent being biased?
rate <- 0.8

RandomAgent <- rbinom(trials, 1, rate) # we simply sample randomly from a binomial

# Now let's plot how it's choosing
d2 <- tibble(trial = seq(trials), choice = RandomAgent)
p2 <- ggplot(d2, aes(trial, choice)) + 
  geom_line() + 
  labs(
    title = "Biased Random Agent Behavior",
    x = "Trial Number",
    y = "Choice (0/1)"
  ) + 
  theme_classic()

p1 + p2

print("This first visualization shows the behavior of a purely random agent - one that chooses between options with equal probability (rate = 0.5). Looking at the jagged line jumping between 0 and 1, we can see that the agent's choices appear truly random, with no discernible pattern. This represents what we might expect from a player who is deliberately trying to be unpredictable in the matching pennies game.
However, this raw choice plot can be hard to interpret. A more informative way to look at the agent's behavior is to examine how its average rate of choosing option 1 evolves over time:")

# Tricky to see, let's try writing the cumulative rate:

d1$cumulativerate <- cumsum(d1$choice) / seq_along(d1$choice)
d2$cumulativerate <- cumsum(d2$choice) / seq_along(d2$choice)

p3 <- ggplot(d1, aes(trial, cumulativerate)) + 
  geom_line() + 
  ylim(0,1) + 
  labs(
    title = "Random Agent Behavior",
    x = "Trial Number",
    y = "Cumulative probability of choosing 1 (0-1)"
  ) + 
  theme_classic()

p4 <- ggplot(d2, aes(trial, cumulativerate)) + 
  geom_line() + 
  labs(
    title = "Random Agent Behavior",
    x = "Trial Number",
    y = "Cumulative probability of choosing 1 (0-1)"
  ) + 
  ylim(0,1) + 
  theme_classic()

p3 + p4
print("This cumulative rate plot helps us better understand the agent's overall tendencies. For a truly random agent, we expect this line to converge toward 0.5 as the number of trials increases. Early fluctuations away from 0.5 are possible due to random chance, but with more trials, these fluctuations tend to even out.
When we compare agents with different underlying biases (rate = 0.5 vs rate = 0.8):")
## Now in the same plot
d1$rate <- 0.5
d2$rate <- 0.8
d <- rbind(d1,d2) %>% 
  mutate(rate = as.factor(rate))

p5 <- ggplot(d, aes(trial, cumulativerate, color = rate, group = rate)) + 
  geom_line() + 
  labs(
    title = "Random Agents Behavior",
    x = "Trial Number",
    y = "Cumulative probability of choosing 1 (0-1)"
  ) + 
  ylim(0,1) + 
  theme_classic()
p5
print("We can clearly see how bias affects choice behavior. The unbiased agent (rate = 0.5) stabilizes around choosing each option equally often, while the biased agent (rate = 0.8) shows a strong preference for option 1, choosing it approximately 80% of the time. This comparison helps us understand how we might detect biases in real players' behavior - consistent deviation from 50-50 choice proportions could indicate an underlying preference or strategy.")

# Now as a function
#' Create a random decision-making agent
#' @param input Vector of previous choices (not used but included for API consistency)
#' @param rate Probability of choosing option 1 (default: 0.5 for unbiased)
#' @return Vector of binary choices
#' @examples 
#' # Create unbiased random agent for 10 trials
#' choices <- RandomAgent_f(rep(1,10), 0.5)
RandomAgent_f <- function(input, rate = 0.5) {
  # Input validation
  if (!is.numeric(rate) || rate < 0 || rate > 1) {
    stop("Rate must be a probability between 0 and 1")
  }
  
  n <- length(input)
  choice <- rbinom(n, 1, rate)
  return(choice)
}

input <- rep(1,trials) # it doesn't matter, it's not taken into account
choice <- RandomAgent_f(input, rate)
d3 <- tibble(trial = seq(trials), choice)

ggplot(d3, aes(trial, choice)) + 
  geom_line() + 
  labs(
    title = "Random Agent Behavior",
    x = "Trial Number",
    y = "Cumulative probability of choosing 1 (0-1)"
  ) + 
  theme_classic()

## What if there's noise?
RandomAgentNoise_f <- function(input, rate, noise){
  n <- length(input)
  choice <- rbinom(n, 1, rate)
  if (rbinom(1, 1, noise) == 1) {choice = rbinom(1,1,0.5)}
  return(choice)
}
```


## Implementing a Win-Stay-Lose-Shift agent

```{r 02 Implementing a Win-Stay-Lose-Shift agent}

#' Create a Win-Stay-Lose-Shift decision-making agent
#' @param prevChoice Previous choice made by the agent (0 or 1)
#' @param feedback Success of previous choice (1 for win, 0 for loss)
#' @param noise Optional probability of random choice (default: 0)
#' @return Next choice (0 or 1)
#' @examples
#' # Basic WSLS decision after a win
#' next_choice <- WSLSAgent_f(prevChoice = 1, feedback = 1)
WSLSAgent_f <- function(prevChoice, feedback, noise = 0) {
  # Input validation
  if (!is.numeric(prevChoice) || !prevChoice %in% c(0,1)) {
    stop("Previous choice must be 0 or 1")
  }
  if (!is.numeric(feedback) || !feedback %in% c(0,1)) {
    stop("Feedback must be 0 or 1")
  }
  if (!is.numeric(noise) || noise < 0 || noise > 1) {
    stop("Noise must be a probability between 0 and 1")
  }
  
  # Core WSLS logic
  choice <- if (feedback == 1) {
    prevChoice  # Stay with previous choice if won
  } else {
    1 - prevChoice  # Switch to opposite choice if lost
  }
  
  # Apply noise if specified
  if (noise > 0 && runif(1) < noise) {
    choice <- sample(c(0,1), 1)
  }
  
  return(choice)
}


WSLSAgentNoise_f <- function(prevChoice, Feedback, noise){
  if (Feedback == 1) {
    choice = prevChoice
  } else if (Feedback == 0) {
      choice = 1 - prevChoice
  }
  if (rbinom(1, 1, noise) == 1) {choice <- rbinom(1, 1, .5)}
  return(choice)
}

WSLSAgent <- WSLSAgent_f(1, 0)


# Against a random agent

Self <- rep(NA, trials)
Other <- rep(NA, trials)

Self[1] <- RandomAgent_f(1, 0.5)
Other <- RandomAgent_f(seq(trials), rate)
  

for (i in 2:trials) {
  if (Self[i - 1] == Other[i - 1]) {
    Feedback = 1
  } else {Feedback = 0}
  Self[i] <- WSLSAgent_f(Self[i - 1], Feedback)
}

sum(Self == Other)

df <- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other))

ggplot(df) + theme_classic() +
  geom_line(color = "red", aes(trial, Self)) +
  geom_line(color = "blue", aes(trial, Other)) +
  labs(
    title = "WSLS Agent (red) vs Biased Random Opponent (blue)",
    x = "Trial Number",
    y = "Choice (0/1)",
    color = "Agent Type"
  )

ggplot(df) + theme_classic() +
  geom_line(color = "red", aes(trial, Feedback)) +
  geom_line(color = "blue", aes(trial, 1 - Feedback)) +
  labs(
    title = "WSLS Agent (red) vs Biased Random Opponent (blue)",
    x = "Trial Number",
    y = "Feedback received (0/1)",
    color = "Agent Type"
  )

print("These plots compare how a Win-Stay-Lose-Shift (WSLS) agent performs against different opponents. The red line shows the WSLS agent's choices, while the blue line shows the opponent's choices. When playing against a biased random opponent, we can see clearer patterns in the WSLS agent's behavior as it responds to wins and losses. Against another WSLS agent, the interaction becomes more complex, as each agent is trying to adapt to the other's adaptations. This kind of visualization helps us understand how different strategies might interact in actual gameplay.")

df$cumulativerateSelf <- cumsum(df$Feedback) / seq_along(df$Feedback)
df$cumulativerateOther <- cumsum(1 - df$Feedback) / seq_along(df$Feedback)

ggplot(df) + theme_classic() +
  geom_line(color = "red", aes(trial, cumulativerateSelf)) +
  geom_line(color = "blue", aes(trial, cumulativerateOther))  +
  labs(
    title = "WSLS Agent (red) vs Biased Random Opponent (blue)",
    x = "Trial Number",
    y = "Cumulative probability of choosing 1 (0-1)",
    color = "Agent Type"
  )

# Against a Win-Stay-Lose Shift
Self <- rep(NA, trials)
Other <- rep(NA, trials)

Self[1] <- RandomAgent_f(1, 0.5)
Other[1] <- RandomAgent_f(1, 0.5)

for (i in 2:trials) {
  if (Self[i - 1] == Other[i - 1]) {
    Feedback = 1
  } else {Feedback = 0}
  Self[i] <- WSLSAgent_f(Self[i - 1], Feedback)
  Other[i] <- WSLSAgent_f(Other[i - 1], 1 - Feedback)
}

sum(Self == Other)

df <- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other))

ggplot(df) + theme_classic() +
  geom_line(color = "red", aes(trial, Self)) +
  geom_line(color = "blue", aes(trial, Other))

ggplot(df) + theme_classic() +
  geom_line(color = "red", aes(trial, Feedback)) +
  geom_line(color = "blue", aes(trial, 1 - Feedback))

df$cumulativerateSelf <- cumsum(df$Feedback) / seq_along(df$Feedback)
df$cumulativerateOther <- cumsum(1 - df$Feedback) / seq_along(df$Feedback)

ggplot(df) + theme_classic() +
  geom_line(color = "red", aes(trial, cumulativerateSelf)) +
  geom_line(color = "blue", aes(trial, cumulativerateOther))

print("This cumulative performance plot reveals the overall effectiveness of the WSLS strategy. By tracking the running average of successes, we can see whether the strategy leads to above-chance performance in the long run. When playing against a biased random opponent, the WSLS agent can potentially exploit the opponent's predictable tendencies, though success depends on how strong and consistent the opponent's bias is.
When we pit the WSLS agent against another WSLS agent, the dynamics become more complex. Both agents are now trying to adapt to each other's adaptations, creating a more sophisticated strategic interaction. The resulting behavior often shows interesting patterns of mutual adaptation, where each agent's attempts to exploit the other's strategy leads to evolving patterns of play.")
```

## Now we scale it up

```{r 02 scaling WSLS up}
trials = 120
agents = 100

# WSLS vs agents with varying rates

for (rate in seq(from = 0.5, to = 1, by = 0.05)) {
  
  for (agent in seq(agents)) {
    Self <- rep(NA, trials)
    Other <- rep(NA, trials)
    
    Self[1] <- RandomAgent_f(1, 0.5)
    Other <- RandomAgent_f(seq(trials), rate)
    
    
    for (i in 2:trials) {
      if (Self[i - 1] == Other[i - 1]) {
        Feedback = 1
      } else {Feedback = 0}
      Self[i] <- WSLSAgent_f(Self[i - 1], Feedback)
    }
    
    temp <- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other), agent, rate)
    
    if (agent == 1 & rate == 0.5) {df <- temp} else {df <- bind_rows(df, temp)}
  }
}

## WSLS with another WSLS

for (agent in seq(agents)) {
    Self <- rep(NA, trials)
    Other <- rep(NA, trials)
    
    Self[1] <- RandomAgent_f(1, 0.5)
    Other[1] <- RandomAgent_f(1, 0.5)
    
    
    for (i in 2:trials) {
      if (Self[i - 1] == Other[i - 1]) {
        Feedback = 1
      } else {Feedback = 0}
      Self[i] <- WSLSAgent_f(Self[i - 1], Feedback)
      Other[i] <- WSLSAgent_f(Other[i - 1], 1 - Feedback)
    }
    
    temp <- tibble(Self, Other, trial = seq(trials), Feedback = as.numeric(Self == Other), agent, rate)
    
    if (agent == 1 ) {df1 <- temp} else {df1 <- bind_rows(df1, temp)}
  }


```

### And we visualize it

```{r 02 visualizing}

ggplot(df, aes(trial, Feedback, group = rate, color = rate)) +
  geom_smooth(se = F) + theme_classic()

```

We can see that the bigger the bias in the random agent, the bigger the performance in the WSLS (the higher the chances the random agent picks the same hand more than once in a row).

Now it's your turn to follow a similar process for your 2 chosen strategies.

## Conclusion

Moving from verbal descriptions to formal computational models represents a crucial step in cognitive science. Through our work with the matching pennies game, we have seen how this transformation process requires careful consideration of theoretical assumptions, mathematical precision, and practical implementation details.

The development of formal models forces us to be explicit about mechanisms that might remain ambiguous in verbal descriptions. When we state that an agent "learns from experience" or "responds to patterns," we must specify exactly how these processes work. This precision not only clarifies our theoretical understanding but also enables rigorous empirical testing.
Our implementation of different agent types - from simple random choice to more sophisticated strategies - demonstrates how computational modeling can reveal surprising implications of seemingly straightforward theories. Through simulation, we discovered that even basic strategies can produce complex patterns of behavior, especially when agents interact with each other over multiple trials.

Perhaps most importantly, this chapter has established a foundational workflow for cognitive modeling: begin with careful observation, think carefully and develop precise mathematical formulations, implement these as computational models, and validate predictions against data. Don't be afraid to make mistakes, or rethink your strategy and iterate the modeling process. This systematic approach will serve as our template as we progress to more complex cognitive phenomena in subsequent chapters.

While our matching pennies models may seem simple compared to the rich complexity of human cognition, they exemplify the essential principles of good modeling practice: clarity of assumptions, precision in implementation, and rigorous validation against empirical data. These principles will guide our exploration of more sophisticated cognitive models throughout this course. For more advanced examples of models that can underly behavior in the Matching Pennies game check:

 * Chapter 12 on reinforcement learning.
 
 * the paper by Waade et al mentioned at the beginning of the chapter.
 
 


<!--chapter:end:03-BuildingFormalModels.Rmd-->


# From simulation to model fitting

This chapter introduces essential techniques for moving from theoretical models to empirical validation. Building on our implementation of decision-making agents, we now tackle the challenge of determining whether these models accurately describe observed behavior.

## Learning Goals

After completing this chapter, you will be able to:

* Design and implement Bayesian parameter estimation for cognitive models using Stan

* Create and interpret prior and posterior predictive checks to validate model behavior

* Evaluate model quality through systematic parameter recovery studies

## The Challenge of Model Fitting

Understanding human behavior requires more than just implementing plausible models - we must determine whether these models actually capture meaningful empirical patterns. Consider our biased agent model that tends to favor one choice over another. While we can specify different levels of bias in our simulations, real-world application requires determining what bias values best explain observed behavior, and for instance whether a pharmacological manipulation can affect the bias.

Bayesian inference provides a powerful framework for this challenge. It allows us to:

* Express our prior beliefs about reasonable parameter values

* Update these beliefs based on observed data

* Quantify uncertainty in our parameter estimates

* Generate predictions that account for parameter uncertainty

## Simulating data

As usual we start with simulated data, where we know the underlying mechanisms and parameter values.

Simulated data are rarely enough (empirical data often offer unexpected challenges), but they are a great starting point to stress test your model: does the model reconstruct the right parameter values? Does it reproduce the overall patterns in the data?

Here we build a new simulation of random agents with bias and noise. The code and visualization is really nothing different from last chapter.


```{r, 03 simulating data}

pacman::p_load(tidyverse,
        here,
        posterior,
        cmdstanr,
        brms, tidybayes)

trials <- 120

RandomAgentNoise_f <- function(rate, noise) {

  choice <- rbinom(1, 1, rate) # generating noiseless choices
  
  if (rbinom(1, 1, noise) == 1) {
    choice = rbinom(1, 1, 0.5) # introducing noise
  }
  
  return(choice)
}

d <- NULL
for (noise in seq(0, 0.5, 0.1)) { # looping through noise levels

  for (rate in seq(0, 1, 0.1)) { # looping through rate levels
    randomChoice <- rep(NA, trials)
    
    for (t in seq(trials)) { # looping through trials (to make it homologous to more reactive models)
      randomChoice[t] <- RandomAgentNoise_f(rate, noise)
    }
    temp <- tibble(trial = seq(trials), choice = randomChoice, rate, noise)
    temp$cumulativerate <- cumsum(temp$choice) / seq_along(temp$choice)

    if (exists("d")) {
      d <- rbind(d, temp)
    } else{
      d <- temp
    }
  }
}

write_csv(d, "simdata/W3_randomnoise.csv")

# Now we visualize it 
p1 <- ggplot(d, aes(trial, cumulativerate, group = rate, color = rate)) + 
  geom_line() + 
  geom_hline(yintercept = 0.5, linetype = "dashed") + 
  ylim(0,1) + 
  facet_wrap(.~noise) + 
  theme_classic()
p1
```

## Building our basic model in Stan

N.B. Refer to the video and slides for the step by step build-up of the Stan code.

Now we subset to a simple case, no noise and rate of 0.8, to focus on the Stan model.
We make it into the right format for Stan, build the Stan model, and fit it.

### Data

Here we define the data and format it for Stan. Stan likes data as a list. Why a list? Well, dataframes (now tibbles) are amazing. But they have a big drawback: they require each variable to have the same length. Lists do not have that limitation, they are more flexible. So, lists. We'll have to learn how to live with them. 

```{r, 03 create data from one agent for stan}
d1 <- d %>% subset(noise == 0 & rate == 0.8)

## Create the data. N.B. note the two variables have different lengths: 1 for n, n for h.
data <- list(
  n = 120,  # n of trials
  h = d1$choice # sequence of choices (h stands for hand)
)

```


### Model

We write the stan code within the R code (so I can show it to you more easily), then we save it as a stan file, which can be loaded at a later stage in order to compile it. [Missing: more info on compiling etc.]

Remember that the minimal Stan model requires 3 chunks, one specifying the data it will need as input; one specifying the parameters to be estimated; one specifying the model within which the parameters appear, and the priors for those parameters.

```{r, 03 defining the biased model, eval = F}
stan_model <- "
// This model infers a random bias from a sequences of 1s and 0s (right and left hand choices)

// The input (data) for the model. n of trials and the sequence of choices (right as 1, left as 0)
data {
 int<lower=1> n; // n of trials
 array[n] int h; // sequence of choices (right as 1, left as 0) as long as n
}

// The parameters that the model needs to estimate (theta)
parameters {
  real<lower=0, upper=1> theta; // rate or theta is a probability and therefore bound between 0 and 1 
}

// The model to be estimated (a bernoulli, parameter theta, prior on the theta)
model {
  // The prior for theta is a beta distribution alpha of 1, beta of 1, equivalent to a uniform between 0 and 1 
  target += beta_lpdf(theta | 1, 1);
  // N.B. you could also define the parameters of the priors as variables to be found in the data
  // target += beta_lpdf(theta | beta_alpha, beta_beta); BUT remember to add beta_alpha and beta_beta to the data list
  
  // The model consists of a bernoulli distribution (binomial w 1 trial only) with a rate theta
  target += bernoulli_lpmf(h | theta);
}
"
write_stan_file(
  stan_model,
  dir = "stan/",
  basename = "W3_SimpleBernoulli.stan")

```


### Compiling and fitting the model

```{r 03 fit the biased model, eval = F}
## Specify where the model is
file <- file.path("stan/W3_SimpleBernoulli.stan")

# Compile the model
mod <- cmdstan_model(file, 
                     # this specifies we can parallelize the gradient estimations on multiple cores
                     cpp_options = list(stan_threads = TRUE), 
                     # this is a trick to make it faster
                     stanc_options = list("O1")) 

# The following command calls Stan with specific options.
samples <- mod$sample(
  data = data, # the data :-)
  seed = 123,  # a seed, so I always get the same results
  chains = 2,  # how many chains should I fit (to check whether they give the same results)
  parallel_chains = 2, # how many of the chains can be run in parallel?
  threads_per_chain = 2, # distribute gradient estimations within chain across multiple cores
  iter_warmup = 1000,  # warmup iterations through which hyperparameters (steps and step length) are adjusted
  iter_sampling = 2000, # total number of iterations
  refresh = 0,  # how often to show that iterations have been run
  output_dir = "simmodels", # saves the samples as csv so it can be later loaded
  max_treedepth = 20, # how many steps in the future to check to avoid u-turns
  adapt_delta = 0.99, # how high a learning rate to adjust hyperparameters during warmup
)

# Same the fitted model
samples$save_object("simmodels/W3_SimpleBernoulli.rds")

```

### Summarizing the model

Now the model is ready to be assessed. First we simply generate a summary of the estimates to have a first idea.

```{r 03 summarizing the biased model samples}
samples <- readRDS("simmodels/W3_SimpleBernoulli.rds")

samples$summary() # summarize the model

```

### Assessing model quality

Then we need to look more in the details at the quality of the estimation:
* the markov chains
* how the prior and the posterior estimates relate to each other (whether the prior is constraining the posterior estimate)

```{r 03 biased model quality}

# Extract posterior samples and include sampling of the prior:
draws_df <- as_draws_df(samples$draws())

# Checking the model's chains
ggplot(draws_df, aes(.iteration, theta, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()


# add a prior for theta (ugly, but we'll do better soon)
draws_df <- draws_df %>% mutate(
  theta_prior = rbeta(nrow(draws_df), 1, 1)
)

# Now let's plot the density for theta (prior and posterior)
ggplot(draws_df) +
  geom_density(aes(theta), fill = "blue", alpha = 0.3) +
  geom_density(aes(theta_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.8, linetype = "dashed", color = "black", linewidth = 1.5) +
  xlab("Rate") +
  ylab("Posterior Density") +
  theme_classic()
```


As we can see from the posterior estimates and the prior posterior update check, our model is doing a decent job. It doesn't exactly reconstruct the rate of 0.8, but 0.755 is pretty close and 0.8 is included within the credible interval.

Now we build the same model, but using the log odds scale for the theta parameter, which will become useful later when we condition theta on variables and build multilevel models (as we can do what we want in a log odds space and it will always be bound between 0 and 1).


```{r, 03 defining the log-odds biased model}

stan_model <- "
// This model infers a random bias from a sequences of 1s and 0s (right and left hand choices)

// The input (data) for the model. n of trials and the sequence of choices (right as 1, left as 0)
data {
 int<lower=1> n; // n of trials
 array[n] int h; // sequence of choices (right as 1, left as 0) as long as n
}

// The parameters that the model needs to estimate (theta)
parameters {
    real theta; // note it is unbounded as we now work on log odds
}

// The model to be estimated (a bernoulli, parameter theta, prior on the theta)
model {
  // The prior for theta on a log odds scale is a normal distribution with a mean of 0 and a sd of 1.
  // This covers most of the probability space between 0 and 1, after being converted to probability.
  target += normal_lpdf(theta | 0, 1);
  // as before the parameters of the prior could be fed as variables
  // target += normal_lpdf(theta | normal_mu, normal_sigma);
  
  // The model consists of a bernoulli distribution (binomial w 1 trial only) with a rate theta,
  // note we specify it uses a logit link (theta is in logodds)
  target += bernoulli_logit_lpmf(h | theta);
  
}
"
write_stan_file(
  stan_model,
  dir = "stan/",
  basename = "W3_SimpleBernoulli_logodds.stan")

## With the logit format
## Specify where the model is
file <- file.path("stan/W3_SimpleBernoulli_logodds.stan")
mod <- cmdstan_model(file, 
                     cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

# The following command calls Stan with specific options.
samples <- mod$sample(
  data = data,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 1000,
  iter_sampling = 2000,
  refresh = 0,
  output_dir = "simmodels",
  max_treedepth = 20,
  adapt_delta = 0.99,
)

# Same the fitted model
samples$save_object("simmodels/W3_SimpleBernoulli_logodds.rds")
```

### Summarizing the results
```{r 03 biased model log-odds quality assessment}

samples <- readRDS("simmodels/W3_SimpleBernoulli_logodds.rds")
# Diagnostics
samples$cmdstan_diagnose()

# Extract posterior samples and include sampling of the prior:
draws_df <- as_draws_df(samples$draws()) 

ggplot(draws_df, aes(.iteration, theta, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()

# add a prior for theta (ugly, but we'll do better soon)
draws_df <- draws_df %>% mutate(
  theta_prior = rnorm(nrow(draws_df), 0, 1)
)

# Now let's plot the density for theta (prior and posterior)
ggplot(draws_df) +
  geom_density(aes(theta), fill = "blue", alpha = 0.3) +
  geom_density(aes(theta_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 1.38, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Rate") +
  ylab("Posterior Density") +
  theme_classic()

# Summary
samples$summary()
```

We can see that the results are very similar.

## Parameter recovery

Now that we see that the model works in one case, we can run it throughout all possible rate and noise levels in the simulation. N.B. here is using loops, parallelized version in the next code chunk.

```{r 03 biased parameter recovery, eval = FALSE}
# Now we need to scale it up to all possible rates and noises
# recovery_df <- NULL
# 
# for (noiseLvl in unique(d$noise)) {
#   
#   for (rateLvl in unique(d$rate)) {
#     
#     dd <- d %>% subset(
#       noise == noiseLvl  & rate == rateLvl
#     )
#     
#     data <- list(
#       n = 120,
#       h = dd$choice
#     )
#     
#     samples <- mod$sample(
#       data = data,
#       seed = 123,
#       chains = 1,
#       parallel_chains = 1,
#       threads_per_chain = 1,
#       iter_warmup = 1000,
#       iter_sampling = 2000,
#       refresh = 0,
#       max_treedepth = 20,
#       adapt_delta = 0.99,
#     )
#     
#     draws_df <- as_draws_df(samples$draws()) 
#     temp <- tibble(biasEst = inv_logit_scaled(draws_df$theta), 
#                    biasTrue = rateLvl, noise = noiseLvl)
#     
#     
#     if (exists("recovery_df")) {recovery_df <- rbind(recovery_df, temp)} else {recovery_df <- temp}
#     
#   }
#   
# }
# 
# write_csv(recovery_df, "simdata/W3_recoverydf_simple.csv")



```

Now we can look at the relation between the "true" bias value we inputted in the simulation and the inferred bias value - the posterior estimates of bias.

```{r 03 plot parameter recovery}
recovery_df <- read_csv("simdata/W3_recoverydf_simple.csv")

ggplot(recovery_df, aes(biasTrue, biasEst)) +
  geom_point(alpha = 0.1) +
  geom_smooth() +
  facet_wrap(.~noise) +
  theme_classic()
```


There's much to be said about the final plot, but for now let's just say that it looks good. We can reconstruct in a nice ordered way true rate values. However, our ability to do so decreases with the increase in noise. So far no surprises. Wait, you say, shouldn't we actually model the generative process, that is, include noise in the Stan model? Gold star, there! But let's wait a bit before we get there, we'll need mixture models. 

One final note before moving to the memory model: what if we parallelized the parameter recovery, so that different models / datasets run on different cores? This was not necessary above (it ran in a few minutes anyway), but will become crucial with more complex models.

To parallelize, we rely on furrr, a neat R package that distributes parallel operations across cores.
First we need to define the function that will define the operations to be run on each core separately, here we simulate the data according to a seed, a n of trials, a rate and a noise, and then we fit the model to them.
Second, we need to create a tibble of the seeds, n of trials, rate and noise values that should be simulated.
Third, we use future_pmap_dfr to run the function on each row of the tibble above separately on a different core. Note that I set the system to split across 4 parallel cores (to work on my computer without clogging it). Do change it according to the system you are using. Note that if you have 40 "jobs" (rows of the tibble, sets of parameter values to run), using e.g. 32 cores will not substantially speed things more than using 20.



```{r 03 parallelizing the code, eval = F}

# pacman::p_load(future, purrr, furrr)
# 
# plan(multisession, workers = 4)
# 
# sim_d_and_fit <- function(seed, trials, rateLvl, noiseLvl) {
#   
#     for (t in seq(trials)) { # looping through trials (to make it homologous to more reactive models)
#       randomChoice[t] <- RandomAgentNoise_f(rateLvl, noiseLvl)
#     }
#     temp <- tibble(trial = seq(trials), choice = randomChoice, rate, noise)
#     
#     data <- list(
#       n = 120,
#       h = temp$choice
#     )
#     
#     samples <- mod$sample(
#       data = data,
#       seed = 1000,
#       chains = 1,
#       parallel_chains = 1,
#       threads_per_chain = 1,
#       iter_warmup = 1000,
#       iter_sampling = 2000,
#       refresh = 0,
#       max_treedepth = 20,
#       adapt_delta = 0.99,
#     )
#     
#     draws_df <- as_draws_df(samples$draws()) 
#     temp <- tibble(biasEst = inv_logit_scaled(draws_df$theta), 
#                    biasTrue = rateLvl, noise = noiseLvl)
#     
#     return(temp)
#   
# }
# 
# 
# temp <- tibble(unique(d[,c("rate", "noise")])) %>% 
#   mutate(seed = 1000, trials = 120) %>%
#   rename(rateLvl = rate, noiseLvl = noise)
# 
# recovery_df <- future_pmap_dfr(temp, sim_d_and_fit, .options = furrr_options(seed = TRUE))
# 
# write_csv(recovery_df, "simdata/W3_recoverydf_parallel.csv")

recovery_df <- read_csv("simdata/W3_recoverydf_parallel.csv")
```

And now we load the data and visualize it as before.

```{r 03 visualizing the parallelization}
ggplot(recovery_df, aes(biasTrue, biasEst)) +
  geom_point(alpha = 0.1) +
  geom_smooth() +
  facet_wrap(.~noise) +
  theme_classic()
```


## The memory model: conditioning theta

Now that we fitted the base model, we can move onto more complex models. For instance a memory model (including all previous trials). Here we rely on a generalized linear model kind of thinking: the theta is the expression of a linear model (bias + b1 * PreviousRate). To make the variable more intuitive we code previous rate - which is bound to a probability 0-1 space - into log-odds via a logit link/transformation. In this way a previous rate with more left than right choices will result in a negative value, thereby decreasing our propensity to choose right; and one with more right than left choices will result in a positive value, thereby increasing our propensity to choose right.

```{r, 03 generate data for the memory agent model}

# We subset to only include no noise and a specific rate
d1 <- d %>% 
  subset(noise == 0 & rate == 0.8) %>% 
  rename(Other = choice) %>% 
  mutate(cumulativerate = lag(cumulativerate, 1))

d1$cumulativerate[1] <- 0.5 # no prior info at first trial
d1$cumulativerate[d1$cumulativerate == 0] <- 0.01
d1$cumulativerate[d1$cumulativerate == 1] <- 0.99

# Now we create the memory agent with a coefficient of 1 (in log odds)
MemoryAgent_f <- function(bias, beta, cumulativerate){
    choice = rbinom(1, 1, inv_logit_scaled(bias + beta * logit_scaled(cumulativerate)))
  return(choice)
}

d1$Self[1] <- RandomAgentNoise_f(0.5, 0)

for (i in 2:trials) {
  d1$Self[i] <- MemoryAgent_f(bias = 0, beta = 1, d1$cumulativerate[i])
}

## Create the data
data <- list(
  n = 120,
  h = d1$Self,
  memory = d1$cumulativerate # this creates the new parameter: the rate of right hands so far in log-odds
)

```


```{r, 03 memory stan model, eval = F}

stan_model <- "
// The input (data) for the model. n of trials and h for (right and left) hand
data {
 int<lower=1> n;
 array[n] int h;
 vector[n] memory; // here we add the new parameter. N.B. Log odds
}

// The parameters accepted by the model. 
parameters {
  real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)?
  real beta; // how strongly is previous rate impacting the decision?
}



// The model to be estimated. 
model {
  // priors
  target += normal_lpdf(bias | 0, .3);
  target += normal_lpdf(beta | 0, .5);
  
  // model
  target += bernoulli_logit_lpmf(h | bias + beta * logit(memory));
}

"
write_stan_file(
  stan_model,
  dir = "stan/",
  basename = "W3_MemoryBernoulli.stan")

## Specify where the model is
file <- file.path("stan/W3_MemoryBernoulli.stan")
mod <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

# The following command calls Stan with specific options.
samples <- mod$sample(
  data = data,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 0,
  output_dir = "simmodels",
  max_treedepth = 20,
  adapt_delta = 0.99,
)


# Same the fitted model
samples$save_object("simmodels/W3_MemoryBernoulli.rds")
```

### Summarizing the results
```{r 03 memory model log-odds quality assessment}

samples <- readRDS("simmodels/W3_MemoryBernoulli.rds")

# Diagnostics
samples$cmdstan_diagnose()

# Extract posterior samples and include sampling of the prior:
draws_df <- as_draws_df(samples$draws()) 

ggplot(draws_df, aes(.iteration, bias, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()

ggplot(draws_df, aes(.iteration, beta, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()

# add a prior for theta (ugly, but we'll do better soon)
draws_df <- draws_df %>% mutate(
  bias_prior = rnorm(nrow(draws_df), 0, .3),
  beta_prior = rnorm(nrow(draws_df), 0, .5),
)

# Now let's plot the density for theta (prior and posterior)
ggplot(draws_df) +
  geom_density(aes(bias), fill = "blue", alpha = 0.3) +
  geom_density(aes(bias_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Bias") +
  ylab("Posterior Density") +
  theme_classic()

ggplot(draws_df) +
  geom_density(aes(beta), fill = "blue", alpha = 0.3) +
  geom_density(aes(beta_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Beta") +
  ylab("Posterior Density") +
  theme_classic()

samples$summary() 
```


We can see that the model has now estimated both the bias and the role of previous memory. Bias should reflect the bias in the setup (0.5 which in log odds is 0), and the beta coefficient for memory (roughly 1). More on the quality checks of the models in the next chapter.

## Memory agent with internal parameter

So far we behaved like in GLM: we keep feeding to the model an external variable of memory, but what if we coded memory as an internal parameter? This opens up to further possibilities to model how long memory is kept and weighted by distance from the current moment, etc.

[Missing: discussion of the equation of the model, how it relates to Kalman filters, Rescorla-Wagner, and hierarchical gaussian filters]

```{r}
## Create the data
data <- list(
  n = 120,
  h = d1$Self,
  other = d1$Other
)

stan_model <- "
// The input (data) for the model. n of trials and h for (right and left) hand
data {
 int<lower=1> n;
 array[n] int h;
 array[n] int other;
}

// The parameters accepted by the model. 
parameters {
  real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)?
  real beta; // how strongly is previous rate impacting the decision?
}

transformed parameters{
  vector[n] memory;

  for (trial in 1:n){
  if (trial == 1) {
    memory[trial] = 0.5;
  } 
  if (trial < n){
      memory[trial + 1] = memory[trial] + ((other[trial] - memory[trial]) / (trial + 1));
      if (memory[trial + 1] == 0){memory[trial + 1] = 0.01;}
      if (memory[trial + 1] == 1){memory[trial + 1] = 0.99;}
    }
  }
}

// The model to be estimated. 
model {
  // Priors
  target += normal_lpdf(bias | 0, .3);
  target += normal_lpdf(beta | 0, .5);
  
  // Model, looping to keep track of memory
  for (trial in 1:n) {
    target += bernoulli_logit_lpmf(h[trial] | bias + beta * logit(memory[trial]));
  }
}

"
write_stan_file(
  stan_model,
  dir = "stan/",
  basename = "W3_InternalMemory.stan")

## Specify where the model is
file <- file.path("stan/W3_InternalMemory.stan")
mod <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

# The following command calls Stan with specific options.
samples <- mod$sample(
  data = data,
  seed = 123,
  chains = 1,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 0,
  max_treedepth = 20,
  adapt_delta = 0.99,
)


samples$summary() 
```

Now that we know how to model memory as an internal state, we can play with making the update discount the past, setting a parameter that indicates after how many trials memory is lost, etc. 

### Trying out a more complex memory model, with a rate of forgetting that exponentially discounts the past

```{r}
stan_model <- "
// The input (data) for the model. n of trials and h for (right and left) hand
data {
  int<lower=1> n;
  array[n] int h;
  array[n] int other;
}

// The parameters accepted by the model. 
parameters {
  real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)?
  real beta; // how strongly is previous rate impacting the decision?
  real<lower=0, upper=1> forgetting;
}

// The model to be estimated. 
model {
  
  vector[n] memory;
  // Priors
  target += beta_lpdf(forgetting | 1, 1);
  target += normal_lpdf(bias | 0, .3);
  target += normal_lpdf(beta | 0, .5);
  
  // Model, looping to keep track of memory
  for (trial in 1:n) {
    if (trial == 1) {
      memory[trial] = 0.5;
    }
    target += bernoulli_logit_lpmf(h[trial] | bias + beta * logit(memory[trial]));
    if (trial < n){
      memory[trial + 1] = (1 - forgetting) * memory[trial] + forgetting * other[trial];
      if (memory[trial + 1] == 0){memory[trial + 1] = 0.01;}
      if (memory[trial + 1] == 1){memory[trial + 1] = 0.99;}
    }
    
  }
}
"
write_stan_file(
  stan_model,
  dir = "stan/",
  basename = "W3_InternalMemory2.stan")

## Specify where the model is
file <- file.path("stan/W3_InternalMemory2.stan")
mod <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

# The following command calls Stan with specific options.
samples <- mod$sample(
  data = data,
  seed = 123,
  chains = 1,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 0,
  max_treedepth = 20,
  adapt_delta = 0.99,
)


samples$summary() 
```

The memory model we've implemented can be seen as part of a broader family of models that track and update beliefs based on incoming evidence. Let's explore how it relates to some key frameworks.

### Connection to Kalman Filters

Our memory model updates beliefs about the probability of right-hand choices using a weighted average of past observations. This is conceptually similar to how a Kalman filter works, though simpler:

* Kalman filters maintain both an estimate and uncertainty about that estimate

* They optimally weight new evidence based on relative uncertainty

* Our model uses a fixed weighting scheme (1/trial or the forgetting parameter)

The key difference is that Kalman filters dynamically adjust how much they learn from new evidence based on uncertainty, while our model uses a fixed learning scheme.


## Relationship to Rescorla-Wagner

The Rescorla-Wagner model of learning follows the form:

V(t+1) = V(t) + Î±(Î» - V(t))

where:

* V(t) is the current estimate

* Î± is the learning rate

* Î» is the observed outcome

* (Î» - V(t)) is the prediction error

Our memory model with forgetting parameter follows a very similar structure:

memory(t+1) = (1-forgetting) * memory(t) + forgetting * outcome(t)

This can be rewritten as:

memory(t+1) = memory(t) + forgetting * (outcome(t) - memory(t))

Making the parallel clear: our forgetting parameter acts as the learning rate Î± in Rescorla-Wagner.

### Connection to Hierarchical Gaussian Filter (HGF)

The HGF extends these ideas by:

* Tracking beliefs at multiple levels

* Allowing learning rates to vary over time

* Explicitly modeling environmental volatility

Our model could be seen as the simplest case of an HGF where:

* We only track one level (probability of right-hand choice)

* Have a fixed learning rate (forgetting parameter)

* Don't explicitly model environmental volatility

### Implications for Model Development

Understanding these relationships helps us think about how models relate to each other and to extend our model:

* We could add uncertainty estimates to get Kalman-like behavior

* We could make the forgetting parameter dynamic to capture changing learning rates

* We could add multiple levels to track both immediate probabilities and longer-term trends

Each extension would make the model more flexible but also more complex to fit to data. The choice depends on our specific research questions and available data.

## Bayesian memory agent

We can also model the memory agent in a Bayesian framework. This allows us to model the agent as (optimally) estimating a possible distribution of rates from the other's behavior and keep all the uncertainty. 

```{r}
stan_model <- "
data {
  int<lower=1> n;  // number of trials
  array[n] int h;  // agent's choices (0 or 1)
  array[n] int other;  // other player's choices (0 or 1)
}

parameters {
  real<lower=0> alpha_prior;  // Prior alpha parameter
  real<lower=0> beta_prior;   // Prior beta parameter
}

transformed parameters {
  vector[n] alpha;  // Alpha parameter at each trial
  vector[n] beta;   // Beta parameter at each trial
  vector[n] rate;   // Expected rate at each trial
  
  // Initialize with prior
  alpha[1] = alpha_prior;
  beta[1] = beta_prior;
  rate[1] = alpha[1] / (alpha[1] + beta[1]);
  
  // Sequential updating of Beta distribution
  for(t in 2:n) {
    // Update Beta parameters based on previous observation
    alpha[t] = alpha[t-1] + other[t-1];
    beta[t] = beta[t-1] + (1 - other[t-1]);
    
    // Calculate expected rate
    rate[t] = alpha[t] / (alpha[t] + beta[t]);
  }
}

model {
  // Priors on hyperparameters
  target += gamma_lpdf(alpha_prior | 2, 1);
  target += gamma_lpdf(beta_prior | 2, 1);
  
  // Agent's choices follow current rate estimates
  for(t in 1:n) {
    target += bernoulli_lpmf(h[t] | rate[t]);
  }
}

generated quantities {
  array[n] int prior_preds;
  array[n] int posterior_preds;
  real initial_rate = alpha_prior / (alpha_prior + beta_prior);
  
  // Prior predictions use initial rate
  for(t in 1:n) {
    prior_preds[t] = bernoulli_rng(initial_rate);
  }
  
  // Posterior predictions use sequentially updated rates
  for(t in 1:n) {
    posterior_preds[t] = bernoulli_rng(rate[t]);
  }
}
"
write_stan_file(
  stan_model,
  dir = "stan/",
  basename = "W3_BayesianMemory.stan")

## Specify where the model is
file <- file.path("stan/W3_BayesianMemory.stan")
mod <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

# The following command calls Stan with specific options.
samples <- mod$sample(
  data = data,
  seed = 123,
  chains = 1,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 0,
  max_treedepth = 20,
  adapt_delta = 0.99,
)


samples$summary() 

library(posterior)
library(bayesplot)

# Extract draws
draws_df <- as_draws_df(samples$draws())

# First let's look at the priors
ggplot(draws_df) +
  geom_density(aes(alpha_prior), fill = "blue", alpha = 0.3) +
  geom_density(aes(beta_prior), fill = "red", alpha = 0.3) +
  theme_classic() +
  labs(title = "Prior Distributions",
       x = "Parameter Value",
       y = "Density")

# Now let's look at how the rate evolves over trials
# First melt the rate values across trials into long format
rate_df <- draws_df %>%
  select(starts_with("rate[")) %>%
  pivot_longer(everything(), 
               names_to = "trial",
               values_to = "rate",
               names_pattern = "rate\\[(\\d+)\\]") %>%
  mutate(trial = as.numeric(trial))

# Calculate summary statistics for each trial
rate_summary <- rate_df %>%
  group_by(trial) %>%
  summarise(
    mean_rate = mean(rate),
    lower = quantile(rate, 0.025),
    upper = quantile(rate, 0.975)
  )


plot_data <- tibble(trial = seq(120), choices = data$other)

# Plot the evolution of rate estimates
ggplot(rate_summary, aes(x = trial)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
  geom_line(aes(y = mean_rate), color = "blue") +
  # Add true data points
  geom_point(data = plot_data, 
             aes(x = trial, y = choices), color = "orange", alpha = 0.5) +
  theme_classic() +
  labs(title = "Evolution of Rate Estimates",
       x = "Trial",
       y = "Rate",
       subtitle = "Blue line: posterior mean, Gray band: 95% CI") +
  ylim(0, 1)

# Let's also look at the correlation between alpha and beta parameters
ggplot(draws_df) +
  geom_point(aes(alpha_prior, beta_prior), alpha = 0.1) +
  theme_classic() +
  labs(title = "Correlation between Alpha and Beta Parameters",
       x = "Alpha",
       y = "Beta")

```



## Conclusion: From Simple Models to Complex Cognitive Processes

Throughout this chapter, we've progressed from basic parameter estimation to increasingly sophisticated models of decision-making. We began with a simple biased agent model, demonstrating how Bayesian inference allows us to recover underlying parameters from observed behavior. We saw how we can transform parameters from one scale to another - here from probability-scale to log-odds parameterizations -, thus gaining flexibility that will prove valuable for more complex models.

The transition to memory-based models illustrated how we can incorporate psychological theory into our statistical framework. We explored different approaches to modeling memory - from treating it as an external predictor to implementing it as an internal state variable that evolves over time. The final exploration of exponential forgetting demonstrated how we can capture more nuanced cognitive processes while maintaining mathematical tractability. This progression sets the stage for Chapter 12, where we'll explore how these memory updating mechanisms relate to reinforcement learning models. The exponential discounting of past events we implemented here represents a simplified version of the learning mechanisms we'll encounter in reinforcement learning.

Several key principles emerged that will guide our future modeling work:

* The importance of systematic model validation through parameter recovery studies and prior-posterior checks. These techniques help ensure our models can meaningfully capture the processes we aim to study.

* The value of starting simple and gradually adding complexity. Each model we implemented built upon previous ones, allowing us to understand the impact of new components while maintaining a solid foundation. This principle will become particularly important when we tackle reinforcement learning models, where multiple parameters interact in complex ways to produce learning behavior.

* The relationship between mathematical convenience and psychological reality. The log-odds transformation, for instance, provides both computational benefits and psychological insights about how humans might represent probabilities. Similarly, the memory updating rules we explored here foreshadow the prediction error calculations central to reinforcement learning and relates very tightly to other popular models like the Kalman filter and the Hierarchical Gaussian Filter.

In the next chapters, we will build upon these foundations to tackle even more sophisticated cognitive models. Chapter 5 will introduce multilevel modeling, allowing us to capture individual differences while maintaining population-level insights. This will set the stage for exploring how different individuals might employ different strategies or show varying levels of memory decay in their decision-making processes. These individual differences become again relevant in future models where parameters like learning rate, or bias for social information can vary substantially across individuals.

<!--chapter:end:04-InferringRates.Rmd-->

---
title: "04-ModelQualityChecks"
output: html_document
date: "2023-02-22"
---

# Model Quality Assessment

## Introduction

Building computational models is only the first step in understanding cognitive processes. We must rigorously evaluate whether our models actually capture meaningful patterns in behavior and provide reliable insights. This chapter introduces systematic approaches for assessing model quality, focusing on techniques that help us understand both the strengths and limitations of our cognitive models.

This document covers: 
- generating and plotting priors (against posteriors)
- generating and plotting predictive checks (prior and posterior ones)
- prior sensitivity checks

[I SHOULD RESTRUCTURE THE DOCUMENT SO THAT PRIOR PREDICTIVE CHECKS COME BEFORE PRIOR / POSTERIOR UPDATE CHECKS]

## Generating and plotting additional variables

As we try to understand our model, we might want to plot how the prior relates to the posterior, or - in other words, what has the model learned from looking at the data? We can do so by overlaying the prior and the posterior distributions, what is also called a "prior - posterior update check".

Stan does not automatically save the prior distribution, so we need to tell it to generate and save prior distributions in a convenient place so we can easily plot or use them at will from R. Luckily, Stan gives us a dedicated code chunk to do that: the generated quantities chunk. As before, we need to define the kind of variable we want to save, and then how to generate it.

If we take the example of the random agent (with a bias), we have one parameter: theta.
We can then generate theta according to the prior in generated quantities. While we are at this, we can also generate a nicer version of the posterior estimate for the theta parameter, now in probability scale (instead of log odds). 

However, prior and posterior estimates are not always the most immediate thing to understand. For instance, we might have trouble having a good grasp for how the uncertainty in the estimate will play out on 120 trials, or 6 trials, or however many trials we are planning for our experiment. Luckily, we can ask Stan to run predictions from either priors or posteriors, or both: given the priors how many trials will have "right hand" choice? and given the posterior estimates?

As we use complex models, the relation between prior/posterior estimates and predictions becomes less and less intuitive. Simulating their implications for the outcomes - also called prior/posterior predictive checks - becomes a very useful tool to adjust our priors and their uncertainty so that they reflect what we know of the outcome scale; as well as to assess whether the model (and its posterior estimates) can appropriately describe the data we observe, or there's some bias there. More discussion of this can be found at https://4ccoxau.github.io/PriorsWorkshop/.

```{r adding priors, warning = F, message = F}
pacman::p_load(tidyverse,
        here,
        posterior,
        cmdstanr,
        brms, tidybayes)

d <- read_csv("simdata/W3_randomnoise.csv")

stan_model <- "
// This model infers a random bias from a sequences of 1s and 0s (right and left hand choices)

// The input (data) for the model. n of trials and the sequence of choices (right as 1, left as 0)
data {
 int<lower=1> n; // n of trials
 array[n] int h; // sequence of choices (right as 1, left as 0) as long as n
}

// The parameters that the model needs to estimate (theta)
parameters {
    real theta; // note it is unbounded as we now work on log odds
}

// The model to be estimated (a bernoulli, parameter theta, prior on the theta)
model {
  // The prior for theta on a log odds scale is a normal distribution with a mean of 0 and a sd of 1.
  // This covers most of the probability space between 0 and 1, after being converted to probability.
  target += normal_lpdf(theta | 0, 1);
  
  // The model consists of a bernoulli distribution (binomial w 1 trial only) with a rate theta,
  // note we specify it uses a logit link (theta is in logodds)
  target += bernoulli_logit_lpmf(h | theta);
  
}

generated quantities{
  real<lower=0, upper=1> theta_prior;  // theta prior parameter, on a prob scale (0-1)
  real<lower=0, upper=1> theta_posterior; // theta posterior parameter, on a prob scale (0-1)
  int<lower=0, upper=n> prior_preds;  // distribution of right hand choices according to the prior
  int<lower=0, upper=n> posterior_preds; // distribution of right hand choices according to the posterior
  
  theta_prior = inv_logit(normal_rng(0,1)); // generating the prior on a log odds scale and converting
  theta_posterior = inv_logit(theta);  // converting the posterior estimate from log odds to prob.
  prior_preds = binomial_rng(n, theta_prior);
  posterior_preds = binomial_rng(n, inv_logit(theta));
}
"

write_stan_file(
  stan_model,
  dir = "stan/",
  basename = "W4_SimpleBernoulli_logodds.stan")

## With the logit format
## Specify where the model is
file <- file.path("stan/W4_SimpleBernoulli_logodds.stan")
mod <- cmdstan_model(file, 
                     cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))




d1 <- d %>% subset(noise == 0 & rate == 0.8)

## Create the data. N.B. note the two variables have different lengths: 1 for n, n for h.
data <- list(
  n = 120,  # n of trials
  h = d1$choice # sequence of choices (h stands for hand)
)

# The following command calls Stan with specific options.
samples <- mod$sample(
  data = data,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 1000,
  iter_sampling = 2000,
  refresh = 0,
  max_treedepth = 20,
  adapt_delta = 0.99,
)

draws_df <- as_draws_df(samples$draws()) 

```

## Assessing priors

```{r assessing priors, warning = F, message = F}

# Now let's plot the density for theta (prior and posterior)
ggplot(draws_df) +
  geom_density(aes(theta_posterior), fill = "blue", alpha = 0.3) +
  geom_density(aes(theta_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.8, linetype = "dashed", color = "black", size = 1.5) +
  xlab("Rate") +
  ylab("Estimate Densities") +
  theme_classic()

```

## Prior Predictive Checks

Prior predictive checks involve simulating data from our model using only the prior distributions, before seeing any actual data. This helps us understand what kinds of patterns our model assumes are possible before we begin fitting to real observations.

These predictions should be assessed for:

* Plausible ranges of behavior
* Appropriate levels of uncertainty
* Preservation of known constraints
* Coverage of theoretically important patterns

## Posterior Predictive Checks

After fitting our models, posterior predictive checks help us determine whether the fitted model can reproduce key patterns in our observed data. We generate new data using parameters sampled from the posterior distribution and compare these simulations to our actual observations.
For decision-making models, important patterns to check include:

* Overall choice proportions
* Sequential dependencies in choices
* Learning curves
* Response to feedback
* Individual differences in strategies

```{r, predictive checks, warning = F, message = F}
ggplot(draws_df) +
  geom_histogram(aes(prior_preds), color = "darkblue", fill = "blue", alpha = 0.3) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()


ggplot(draws_df) +
  geom_histogram(aes(posterior_preds), color = "darkblue", fill = "blue", alpha = 0.3, bins = 90) +
  geom_point(x = sum(data$h), y = 0, color = "red", shape = 17, size = 5) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()


ggplot(draws_df) +
  geom_histogram(aes(prior_preds), color = "lightblue", fill = "blue", alpha = 0.3, bins = 90) +
  geom_histogram(aes(posterior_preds), color = "darkblue", fill = "blue", alpha = 0.3, bins = 90) +
  geom_point(x = sum(data$h), y = 0, color = "red", shape = 17, size = 5) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()

```

## Prior sensitivity analysis

```{r prior sensitivity analysis, warning = FALSE, message = FALSE, eval = FALSE}
## Now we adding different priors for theta
prior_mean <- seq(-3, 3, .5)
prior_sd <- seq(0.1, 1, 0.1)
priors <-  expand.grid(prior_mean, prior_sd)
priors <- tibble(prior_mean = priors$Var1, prior_sd = priors$Var2)

stan_model <- "
  // The input (data) for the model
data {
  int<lower=1> n;
  array[n] int h;
  real prior_mean;
  real<lower=0> prior_sd;
}

// The parameters accepted by the model. 
parameters {
  real theta;
}

// The model to be estimated. 
model {
  // Prior
  target += normal_lpdf(theta | prior_mean, prior_sd);
  
  // Model
  target += bernoulli_logit_lpmf(h | theta);
}

generated quantities{
  real<lower=0, upper=1> theta_prior;
  real<lower=0, upper=1> theta_posterior;
  int<lower=0, upper=n> prior_preds;
  int<lower=0, upper=n> posterior_preds;
  
  theta_prior = inv_logit(normal_rng(0,1));
  theta_posterior = inv_logit(theta);
  prior_preds = binomial_rng(n, theta_prior);
  posterior_preds = binomial_rng(n, inv_logit(theta));
  
}
"

write_stan_file(
  stan_model,
  dir = "stan/",
  basename = "W4_PriorBernoulli.stan")

file <- file.path("stan/W4_PriorBernoulli.stan")
mod <- cmdstan_model(file, 
                     cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

dd <- d %>% subset(noise == 0.1 & rate == 0.8)

pacman::p_load(future, purrr, furrr)
plan(multisession, workers = 4)

sim_d_and_fit <- function(prior_mean, prior_sd) {
  
    data <- list(
        n = nrow(dd),
        h = dd$choice,
        prior_mean = prior_mean,
        prior_sd = prior_sd
      )
    
    samples <- mod$sample(
      data = data,
      seed = 1000,
      chains = 1,
      parallel_chains = 1,
      threads_per_chain = 1,
      iter_warmup = 1000,
      iter_sampling = 2000,
      refresh = 0,
      max_treedepth = 20,
      adapt_delta = 0.99,
    )
    
    draws_df <- as_draws_df(samples$draws()) 
      temp <- tibble(theta_prior = draws_df$theta_prior, 
                     theta_posterior = draws_df$theta_posterior, 
                     prior_preds = draws_df$prior_preds, 
                     posterior_preds = draws_df$posterior_preds, 
                     prior_mean = prior_mean,
                     prior_sd = prior_sd)
    
    return(temp)
  
}



# Commenting this out to ensure faster compiling time for the book. Uncomment to run the code
# recovery_df <- future_pmap_dfr(priors, sim_d_and_fit, .options = furrr_options(seed = TRUE))
# write_csv(recovery_df, "simdata/W4_priorSensitivityRecovery.csv")

```

Now we load the data and plot it
```{r}
recovery_df <- read_csv("simdata/W4_priorSensitivityRecovery.csv")

ggplot(recovery_df, aes(prior_mean, theta_posterior)) +
  geom_point(alpha = 0.1) +
  geom_hline(yintercept = 0.8, color = "red") +
  geom_smooth() +
  facet_wrap(.~prior_sd) +
  theme_classic()


```



## The memory model

We can do the same for the memory model: generate prior distributions to overlay to the posteriors (prior-posterior update checks), generate predicted outcomes based on the priors (prior predictive checks) and on the posteriors (posterior predictive checks).
N.B. prior and posterior predictions now depend on the value on memory. I identified 3 meaningful values for the memory value (e.g. 0.5, 0.7, 0.9) and used those to generate 3 prior and posterior predictive checks.


```{r memory model, warning = FALSE, message = FALSE}

# We subset to only include no noise and a specific rate
d1 <- d %>% 
  subset(noise == 0 & rate == 0.8) %>% 
  rename(Other = choice) %>% 
  mutate(cumulativerate = lag(cumulativerate, 1))

d1$cumulativerate[1] <- 0.5 # no prior info at first trial
d1$cumulativerate[d1$cumulativerate == 0] <- 0.01
d1$cumulativerate[d1$cumulativerate == 1] <- 0.99

# Now we create the memory agent with a coefficient of 0.9
bias = 0
beta = 0.9

MemoryAgent_f <- function(bias, beta, cumulativerate){
    choice = rbinom(1, 1, inv_logit_scaled(bias + beta * logit_scaled(cumulativerate)))
  return(choice)
}

for (i in 1:trials) {
  d1$Self[i] <- MemoryAgent_f(bias, beta, d1$cumulativerate[i])
}


## Create the data. 
data <- list(
  n = 120,
  h = d1$Self,
  other = d1$Other
)

stan_model <- "
// The input (data) for the model. n of trials and h for (right and left) hand
data {
 int<lower=1> n;
 array[n] int h;
 array[n] int other;
}

// The parameters accepted by the model. 
parameters {
  real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)?
  real beta; // how strongly is previous rate impacting the decision?
}

transformed parameters{
  vector[n] memory;

  for (trial in 1:n){
  if (trial == 1) {
    memory[trial] = 0.5;
  } 
  if (trial < n){
      memory[trial + 1] = memory[trial] + ((other[trial] - memory[trial]) / trial);
      if (memory[trial + 1] == 0){memory[trial + 1] = 0.01;}
      if (memory[trial + 1] == 1){memory[trial + 1] = 0.99;}
    }
  }
}

// The model to be estimated. 
model {
  // Priors
  target += normal_lpdf(bias | 0, .3);
  target += normal_lpdf(beta | 0, .5);
  
  // Model, looping to keep track of memory
  for (trial in 1:n) {
    target += bernoulli_logit_lpmf(h[trial] | bias + beta * logit(memory[trial]));
  }
}

generated quantities{
  real bias_prior;
  real beta_prior;
  int<lower=0, upper=n> prior_preds5;
  int<lower=0, upper=n> post_preds5;
  int<lower=0, upper=n> prior_preds7;
  int<lower=0, upper=n> post_preds7;
  int<lower=0, upper=n> prior_preds9;
  int<lower=0, upper=n> post_preds9;
  
  bias_prior = normal_rng(0, 0.3);
  beta_prior = normal_rng(0, 0.5);
  prior_preds5 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.5)));
  prior_preds7 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.7)));
  prior_preds9 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.9)));
  post_preds5 = binomial_rng(n, inv_logit(bias + beta * logit(0.5)));
  post_preds7 = binomial_rng(n, inv_logit(bias + beta * logit(0.7)));
  post_preds9 = binomial_rng(n, inv_logit(bias + beta * logit(0.9)));

}

"
write_stan_file(
  stan_model,
  dir = "stan/",
  basename = "W4_MemoryBernoulli.stan")

## Specify where the model is
file <- file.path("stan/W4_MemoryBernoulli.stan")
mod <- cmdstan_model(file, 
                     cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

# The following command calls Stan with specific options.
samples <- mod$sample(
  data = data,
  seed = 123,
  chains = 1,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 1000,
  iter_sampling = 1000,
  refresh = 0,
  max_treedepth = 20,
  adapt_delta = 0.99,
)


samples$summary() 


# Extract posterior samples and include sampling of the prior:
draws_df <- as_draws_df(samples$draws())


# Now let's plot the density for bias (prior and posterior)
ggplot(draws_df) +
  geom_density(aes(bias), fill = "blue", alpha = 0.3) +
  geom_density(aes(bias_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0, size = 2) +
  xlab("Bias") +
  ylab("Posterior Density") +
  theme_classic()

ggplot(draws_df) +
  geom_density(aes(beta), fill = "blue", alpha = 0.3) +
  geom_density(aes(beta_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.9, size = 2) +
  xlab("MemoryBeta") +
  ylab("Posterior Density") +
  theme_classic()

ggplot(draws_df) +
  geom_histogram(aes(`prior_preds5`), color = "yellow", fill = "lightyellow", alpha = 0.2) +
  geom_histogram(aes(`prior_preds7`), color = "green", fill = "lightgreen", alpha = 0.2) +
  geom_histogram(aes(`prior_preds9`), color = "blue", fill = "lightblue", alpha = 0.2) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()


ggplot(draws_df) +
  geom_histogram(aes(`post_preds5`), color = "yellow", fill = "lightyellow", alpha = 0.3, bins = 90) +
  geom_histogram(aes(`post_preds7`), color = "green", fill = "lightgreen", alpha = 0.3, bins = 90) +
  geom_histogram(aes(`post_preds9`), color = "blue", fill = "lightblue", alpha = 0.3, bins = 90) +
  #geom_point(x = sum(data$h), y = 0, color = "red", shape = 17, size = 5) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()


ggplot(draws_df) +
  geom_histogram(aes(`prior_preds5`), color = "lightblue", fill = "blue", alpha = 0.3, bins = 90) +
  geom_histogram(aes(`post_preds5`), color = "darkblue", fill = "blue", alpha = 0.3, bins = 90) +
  xlab("Predicted heads out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()
```

## Prior sensitivity check for the memory model

```{r prior sensitivity check for memory, warning = FALSE, message = FALSE, eval = FALSE}
## Now we adding different priors for theta
prior_mean_bias <- 0
prior_sd_bias <- seq(0.1, 0.5, 0.1)
prior_mean_beta <- 0
prior_sd_beta <- seq(0.1, 0.5, 0.1)
priors <-  tibble(expand.grid(tibble(prior_mean_bias, prior_sd_bias, prior_mean_beta, prior_sd_beta)))

stan_model <- "
  // The input (data) for the model
data {
  int<lower=1> n;
  array[n] int h;
  array[n] int other;
  real prior_mean_bias;
  real<lower=0> prior_sd_bias;
  real prior_mean_beta;
  real<lower=0> prior_sd_beta;
}

// The parameters accepted by the model. 
parameters {
  real bias; // how likely is the agent to pick right when the previous rate has no information (50-50)?
  real beta; // how strongly is previous rate impacting the decision?
}

transformed parameters{
  vector[n] memory;

  for (trial in 1:n){
  if (trial == 1) {
    memory[trial] = 0.5;
  } 
  if (trial < n){
      memory[trial + 1] = memory[trial] + ((other[trial] - memory[trial]) / trial);
      if (memory[trial + 1] == 0){memory[trial + 1] = 0.01;}
      if (memory[trial + 1] == 1){memory[trial + 1] = 0.99;}
    }
  }
}

// The model to be estimated. 
model {
  // The priors 
  target += normal_lpdf(bias | prior_mean_bias, prior_sd_bias);
  target += normal_lpdf(beta | prior_mean_beta, prior_sd_beta);
  
  // The model
  target += bernoulli_logit_lpmf(h | bias + beta * logit(memory));
}

generated quantities{
  real bias_prior;
  real beta_prior;
  int<lower=0, upper=n> prior_preds5;
  int<lower=0, upper=n> post_preds5;
  int<lower=0, upper=n> prior_preds7;
  int<lower=0, upper=n> post_preds7;
  int<lower=0, upper=n> prior_preds9;
  int<lower=0, upper=n> post_preds9;
  
  bias_prior = normal_rng(prior_mean_bias, prior_sd_bias);
  beta_prior = normal_rng(prior_mean_beta, prior_sd_beta);
  prior_preds5 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.5)));
  prior_preds7 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.7)));
  prior_preds9 = binomial_rng(n, inv_logit(bias_prior + beta_prior * logit(0.9)));
  post_preds5 = binomial_rng(n, inv_logit(bias + beta * logit(0.5)));
  post_preds7 = binomial_rng(n, inv_logit(bias + beta * logit(0.7)));
  post_preds9 = binomial_rng(n, inv_logit(bias + beta * logit(0.9)));
  
}
"

write_stan_file(
  stan_model,
  dir = "stan/",
  basename = "W4_PriorMemory.stan")

file <- file.path("stan/W4_PriorMemory.stan")
mod <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE))

dd <- d %>% subset(noise == 0.1 & rate == 0.8) %>%
  mutate(memory = lag(cumulativerate, 1))

dd$memory[1] <- 0.5

pacman::p_load(future, purrr, furrr)
plan(multisession, workers = 4)

sim_d_and_fit <- function(prior_mean_bias, prior_sd_bias, prior_mean_beta, prior_sd_beta) {
  
    data <- list(
        n = nrow(dd),
        h = dd$choice,
        memory = dd$memory,
        prior_mean_bias = prior_mean_bias,
        prior_sd_bias = prior_sd_bias,
        prior_mean_beta = prior_mean_beta,
        prior_sd_beta = prior_sd_beta
      )
    
    samples <- mod$sample(
      data = data,
      seed = 1000,
      chains = 1,
      parallel_chains = 1,
      threads_per_chain = 1,
      iter_warmup = 1000,
      iter_sampling = 2000,
      refresh = 0,
      max_treedepth = 20,
      adapt_delta = 0.99,
    )
    
    draws_df <- as_draws_df(samples$draws()) 
      temp <- tibble(bias_prior = draws_df$bias_prior, 
                     beta_prior = draws_df$beta_prior, 
                     bias_posterior = draws_df$bias, 
                     beta_posterior = draws_df$beta, 
                     prior_preds5 = draws_df$prior_preds5, 
                     prior_preds7 = draws_df$prior_preds7, 
                     prior_preds9 = draws_df$prior_preds9, 
                     posterior_preds5 = draws_df$post_preds5,
                     posterior_preds7 = draws_df$post_preds7,
                     posterior_preds9 = draws_df$post_preds9, 
                     prior_mean_bias = prior_mean_bias,
                     prior_sd_bias = prior_sd_bias, 
                     prior_mean_beta = prior_mean_beta,
                     prior_sd_beta = prior_sd_beta)
    
    return(temp)
  
}



# Commenting this out to ensure the book compiles faster. Uncomment to run the code.
#recovery_df <- future_pmap_dfr(priors, sim_d_and_fit, .options = furrr_options(seed = TRUE))
#write_csv(recovery_df, "simdata/W4_MemoryPriorSensitivity.csv")

```


```{r}
recovery_df <- read_csv("simdata/W4_MemoryPriorSensitivity.csv")

ggplot(recovery_df, aes(prior_sd_beta, beta_posterior)) +
  geom_point(alpha = 0.1) +
  geom_hline(yintercept = 0.8, color = "red") +
  geom_smooth(method = lm) +
  facet_wrap(.~prior_sd_bias) +
  theme_classic()
```

## Conclusion

Rigorous model assessment is essential for developing reliable insights into cognitive processes. The techniques covered in this chapter provide a systematic framework for validating our models and understanding their limitations. As we move forward to more complex models incorporating individual differences and learning mechanisms, these quality checks become increasingly important for ensuring our conclusions are well-supported by the evidence.
In the next chapter, we'll build on these foundations as we explore multilevel modeling approaches that can capture individual differences while maintaining population-level insights.

<!--chapter:end:05-ModelQualityChecks.Rmd-->

---
title: "05-MultilevelModeling"
output: html_document
date: "2023-02-27"
---

```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

# Individual Differences in Cognitive Strategies (Multilevel modeling)

## Introduction

Our exploration of decision-making models has so far focused on single agents or averaged behavior. However, cognitive science reveals that individuals often differ systematically in how they approach tasks and process information. This chapter introduces multilevel modeling as a powerful framework for capturing these individual differences while still identifying population-level patterns.

Consider our matching pennies game: different players might vary in their strategic sophistication, memory capacity, or learning rates. Some may show strong biases toward particular choices while others adapt more flexibly to their opponents. Multilevel modeling allows us to capture these variations while still understanding what patterns hold across the population.

## Learning Objectives

After completing this chapter, you will be able to:

* Understand how multilevel modeling balances individual and group-level information

* Implement multilevel versions of our previous decision-making models

* Compare different approaches to modeling individual variation

* Evaluate model quality through systematic parameter recovery studies

* Apply these techniques to real behavioral data

## The Value of Multilevel Modeling

Traditional approaches to handling individual differences often force a choice between two extremes:

* Complete Pooling: Treating all participants as identical by averaging their data together. This approach can mask important individual variations.

* No Pooling: Analyzing each participant separately. This fails to leverage information shared across participants and can lead to unstable estimates.

Multilevel modeling offers a middle ground through partial pooling. Individual estimates are informed by both individual-level data and the overall population distribution. This approach is particularly valuable when:

* Data per individual is limited
* Individual differences are meaningful but not completely independent
* We want to make predictions about new individuals from the same population


## A multilevel version of the biased agent and of the simple memory agent

We are now conceptualizing our agents as being part of (sampled from) a more general population. This general population is characterized by a population level average parameter value (e.g. a general bias of 0.8 as we all like right hands more) and a certain variation in the population (e.g. a standard deviation of 0.1, as we are all a bit different from each other). Each biased agent's rate is then sampled from that distribution. Same for the memory agents.

[MISSING: DAG PLOTS OF THE TWO SCENARIOS]

Again, it's practical to work in log odds. Why? Well, it's not unconceivable that an agent would be 3 sd from the mean. So a biased agent could have a rate of 0.8 + 3 * 0.1, which gives a rate of 1.1. It's kinda impossible to choose 110% of the time the right hand. We want an easy way to avoid these situations without too carefully tweaking our parameters, or including exception statements (e.g. if rate > 1, then rate = 1). Conversion to log odds is again a wonderful way to work in a boundless space, and in the last step shrinking everything back to 0-1 probability space.

N.B. we model all agents with some added noise as we assume it cannot be eliminated from our studies.

```{r Setting the parameters}
pacman::p_load(tidyverse,
               here,
               posterior,
               cmdstanr,
               brms, tidybayes, patchwork)

# Shared parameters
agents <- 100
trials <- 120
noise <- 0

# Biased agents parameters
rateM <- 1.386 # roughly 0.8 once inv_logit scaled
rateSD <- 0.65 # roughly giving a sd of 0.1 in prob scale

# Memory agents parameters
biasM <- 0
biasSD <- 0.1
betaM <- 1.5
betaSD <- 0.3

```

```{r Defining the agents functions}

# Functions of the agents
RandomAgentNoise_f <- function(rate, noise) {
  choice <- rbinom(1, 1, inv_logit_scaled(rate))
  if (rbinom(1, 1, noise) == 1) {
    choice = rbinom(1, 1, 0.5)
  }
  return(choice)
}

MemoryAgentNoise_f <- function(bias, beta, otherRate, noise) {
  rate <- inv_logit_scaled(bias + beta * logit_scaled(otherRate))
  choice <- rbinom(1, 1, rate)
  if (rbinom(1, 1, noise) == 1) {
    choice = rbinom(1, 1, 0.5)
  }
  return(choice)
}


```

## Generating the agents

[MISSING: PARALLELIZE]

```{r Generating the agents}
# Looping through all the agents to generate the data.
d <- NULL

for (agent in 1:agents) {
  
  rate <- rnorm(1, rateM, rateSD)
  bias <- rnorm(1, biasM, biasSD)
  beta <- rnorm(1, betaM, betaSD)
  
  randomChoice <- rep(NA, trials)
  memoryChoice <- rep(NA, trials)
  memoryRate <- rep(NA, trials)
  
  for (trial in 1:trials) {
    
    randomChoice[trial] <- RandomAgentNoise_f(rate, noise)
    if (trial == 1) {
      memoryChoice[trial] <- rbinom(1,1,0.5)
    } else {
      memoryChoice[trial] <- MemoryAgentNoise_f(bias, beta, mean(randomChoice[1:trial], na.rm = T), noise)
    }
  }
  
  temp <- tibble(agent, trial = seq(trials), randomChoice, randomRate = rate, memoryChoice, memoryRate, noise, rateM, rateSD, bias, beta, biasM, biasSD, betaM, betaSD)
  
  if (agent > 1) {
    d <- rbind(d, temp)
  } else{
    d <- temp
  }
  
}

d <- d %>% group_by(agent) %>% mutate(
  randomRate = cumsum(randomChoice) / seq_along(randomChoice),
  memoryRate = cumsum(memoryChoice) / seq_along(memoryChoice)
)
```

## Plotting the agents

```{r Plotitng the agents}

# A plot of the proportion of right hand choices for the random agents
p1 <- ggplot(d, aes(trial, randomRate, group = agent, color = agent)) + 
  geom_line(alpha = 0.5) + 
  geom_hline(yintercept = 0.5, linetype = "dashed") + 
  ylim(0,1) + 
  theme_classic() 
# A plot of the proportion of right hand choices for the memory agents
p2 <- ggplot(d, aes(trial, memoryRate, group = agent, color = agent)) + 
  geom_line(alpha = 0.5) + 
  geom_hline(yintercept = 0.5, linetype = "dashed") + 
  ylim(0,1) + 
  theme_classic() 
p1 + p2


# A plot of whether memory and random agents are matched in proportion at different stages

p3 <- d %>% subset(trial == 10) %>% ggplot(aes(randomRate, memoryRate)) +
  geom_point() +
  geom_smooth(method = lm) +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  xlim(0.25, 1) +
  ylim(0.25, 1) +
  xlab("correlation at 10 trials") +
  theme_bw()

p4 <- d %>% subset(trial == 60) %>% ggplot(aes(randomRate, memoryRate)) +
  geom_point() +
  geom_smooth(method = lm) +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  xlim(0.25, 1) +
  ylim(0.25, 1) +
  xlab("correlation at 60 trials") +
  theme_bw()

p5 <- d %>% subset(trial == 120) %>% ggplot(aes(randomRate, memoryRate)) +
  geom_point() +
  geom_smooth(method = lm) +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  xlim(0.25, 1) +
  ylim(0.25, 1) +
  xlab("correlation at 120 trials") +
  theme_bw()

p3 + p4 + p5

```

Note that as the n of trials increases, the memory model matches the random model better and better

## Coding the multilevel agents

### Multilevel random

Remember that the simulated parameters are:
* biasM <- 0
* biasSD <- 0.1
* betaM <- 1.5
* betaSD <- 0.3

Prep the data

```{r}
d1 <- d %>% 
  subset(select = c(agent, randomChoice)) %>% 
  mutate(row = row_number()) %>% 
  pivot_wider(names_from = agent, values_from = randomChoice)

## Create the data
data <- list(
  trials = trials,
  agents = agents,
  h = as.matrix(d1[,2:101])
)
```


```{r Coding and fitting the multilevel random agents in Stan, eval = FALSE}

stan_model <- "
/* Multilevel Bernoulli Model
 * This model infers agent-specific choice biases from sequences of binary choices (0/1)
 * The model assumes each agent has their own bias (theta) drawn from a population distribution
 */

functions {
  // Generate random numbers from truncated normal distribution
  real normal_lb_rng(real mu, real sigma, real lb) {
    real p = normal_cdf(lb | mu, sigma);
    real u = uniform_rng(p, 1);
    return (sigma * inv_Phi(u)) + mu;
  }
}

data {
  int<lower=1> trials;  // Number of trials per agent
  int<lower=1> agents;  // Number of agents
  array[trials, agents] int<lower=0, upper=1> h;  // Choice data: 0 or 1 for each trial/agent
}

parameters {
  real thetaM;                // Population-level mean bias (log-odds scale)
  real<lower=0> thetaSD;      // Population-level SD of bias
  array[agents] real theta;    // Agent-specific biases (log-odds scale)
}

model {
  // Population-level priors
  target += normal_lpdf(thetaM | 0, 1);        // Prior for population mean 
  target += normal_lpdf(thetaSD | 0, 0.3)      // Half-normal prior for population SD
    - normal_lccdf(0 | 0, 0.3);
  
  // Agent-level model
  target += normal_lpdf(theta | thetaM, thetaSD);    // Agent biases drawn from population
  
  // Likelihood
  for (i in 1:agents) {
    target += bernoulli_logit_lpmf(h[,i] | theta[i]);  // Choice likelihood
  }
}

generated quantities {
  // Prior predictive samples
  real thetaM_prior = normal_rng(0, 1);
  real<lower=0> thetaSD_prior = normal_lb_rng(0, 0.3, 0);
  real<lower=0, upper=1> theta_prior = inv_logit(normal_rng(thetaM_prior, thetaSD_prior));
  
  // Posterior predictive samples 
  real<lower=0, upper=1> theta_posterior = inv_logit(normal_rng(thetaM, thetaSD));
  
  // Predictive simulations
  int<lower=0, upper=trials> prior_preds = binomial_rng(trials, inv_logit(thetaM_prior));
  int<lower=0, upper=trials> posterior_preds = binomial_rng(trials, inv_logit(thetaM));
}
"
write_stan_file(
  stan_model,
  dir = "stan/",
  basename = "W5_MultilevelBias.stan")

# Commented to ensure fast compiling time for the book. Uncomment to run the code.
file <- file.path("stan/W5_MultilevelBias.stan")
mod <- cmdstan_model(file,
                     cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

# The following command calls Stan with specific options.
samples <- mod$sample(
  data = data,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 1,
  iter_warmup = 2000,
  iter_sampling = 2000,
  refresh = 500,
  max_treedepth = 20,
  adapt_delta = 0.99,
)

# Save both object and CSV files
samples$save_object(file = "simmodels/W5_MultilevelBias.RDS")

```

### Assessing multilevel random agents

Besides the usual prior predictive checks, prior posterior update checks, posterior predictive checks, based on the population level estimates; we also want to plot at least a few of the single agents to assess how well the model is doing for them.

[MISSING: PLOT MODEL ESTIMATES AGAINST N OF HEADS BY PARTICIPANT]

```{r Assessing pop level features of multilevel random agents}

samples <- readRDS("simmodels/W5_MultilevelBias.RDS")
#samples$cmdstan_diagnose()
samples$summary() 

draws_df <- as_draws_df(samples$draws()) 

ggplot(draws_df, aes(.iteration, thetaM, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()

ggplot(draws_df, aes(.iteration, thetaSD, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()

ggplot(draws_df) +
  geom_histogram(aes(prior_preds), color = "darkblue", fill = "blue", alpha = 0.3) +
  xlab("Predicted right hands out of 120 trials") +
  ylab("Prior Density") +
  theme_classic()

ggplot(draws_df) +
  geom_density(aes(thetaM), fill = "blue", alpha = 0.3) +
  geom_density(aes(thetaM_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 1.386) +
  xlab("Mean Rate") +
  ylab("Posterior Density") +
  theme_classic()

ggplot(draws_df) +
  geom_density(aes(thetaSD), fill = "blue", alpha = 0.3) +
  geom_density(aes(thetaSD_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.65) +
  xlab("Variance of Rate") +
  ylab("Posterior Density") +
  theme_classic()

ggplot(draws_df) +
  geom_density(aes(theta_posterior), fill = "blue", alpha = 0.3) +
  geom_density(aes(theta_prior), fill = "red", alpha = 0.3) +
  xlab("Overall Rate") +
  ylab("Posterior Density") +
  theme_classic()

ggplot(draws_df) +
  geom_histogram(aes(prior_preds), color = "darkblue", fill = "lightblue", alpha = 0.3) +
  geom_histogram(aes(posterior_preds), color = "darkblue", fill = "blue", alpha = 0.3) +
  xlab("Predicted right hands out of 120 trials") +
  ylab("Predictive Density") +
  theme_classic()

```


```{r Assessing individual level features of multilevel random agents}

ggplot(draws_df) +
  geom_histogram(aes(inv_logit_scaled(`theta[1]`)), fill = "blue", alpha = 0.3) +
  geom_histogram(aes(inv_logit_scaled(`theta[15]`)), fill = "green", alpha = 0.3) +
  geom_histogram(aes(inv_logit_scaled(`theta[21]`)), fill = "lightblue", alpha = 0.3) +
  geom_histogram(aes(inv_logit_scaled(`theta[31]`)), fill = "darkblue", alpha = 0.3) +
  geom_histogram(aes(inv_logit_scaled(`theta[41]`)), fill = "yellow", alpha = 0.3) +
  geom_histogram(aes(inv_logit_scaled(`theta[51]`)), fill = "darkgreen", alpha = 0.3) +
  geom_histogram(aes(inv_logit_scaled(`theta[61]`)), fill = "lightgreen", alpha = 0.3) +
  geom_histogram(aes(inv_logit_scaled(thetaM_prior)), fill = "pink", alpha = 0.3) +
  geom_histogram(aes(theta_prior), fill = "purple", alpha = 0.3) +
  xlab("Mean Rate") +
  ylab("Posterior Density") +
  theme_classic()



draws_df <- draws_df %>% mutate(
  preds1 = rbinom(4000,120, inv_logit_scaled(`theta[1]`)),
  preds11 = rbinom(4000,120, inv_logit_scaled(`theta[11]`)),
  preds21 = rbinom(4000,120, inv_logit_scaled(`theta[21]`)),
  preds31 = rbinom(4000,120, inv_logit_scaled(`theta[31]`)),
  preds41 = rbinom(4000,120, inv_logit_scaled(`theta[41]`)),
  preds51 = rbinom(4000,120, inv_logit_scaled(`theta[51]`)),
  preds61 = rbinom(4000,120, inv_logit_scaled(`theta[61]`)),
  preds71 = rbinom(4000,120, inv_logit_scaled(`theta[71]`)),
  preds81 = rbinom(4000,120, inv_logit_scaled(`theta[81]`)),
  preds91 = rbinom(4000,120, inv_logit_scaled(`theta[91]`)),
)

d2 <- d %>% group_by(agent) %>% dplyr::summarise(right = sum(randomChoice))

ggplot(draws_df) +
  geom_histogram(aes(posterior_preds), color = "skyblue1", alpha = 0.3) +
  geom_histogram(data = d2, aes(right),  color = "darkblue",alpha = 0.8) +
  xlab("Predicted right hands out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()

p1 <- ggplot(draws_df) +
  geom_density(aes(preds1), color = "skyblue1", alpha = 0.3) +
  geom_point(x = subset(d2, agent == 1)$right, y = 0, shape = 23, color = "darkblue", fill = "darkblue") +
  theme_classic()

p2 <- ggplot(draws_df) +
  geom_density(aes(preds11), color = "skyblue1", alpha = 0.3) +
  geom_point(x = subset(d2, agent == 11)$right, y = 0, shape = 23, color = "darkblue", fill = "darkblue") +
  theme_classic()
  
p3 <- ggplot(draws_df) +
  geom_density(aes(preds21), color = "skyblue1", alpha = 0.3) +
  geom_point(x = subset(d2, agent == 21)$right, y = 0, shape = 23, color = "darkblue", fill = "darkblue") +
  theme_classic()

library(patchwork)
p1 + p2 + p3

```

### Multilevel memory

[MISSING: DAGS]
[MISSING: EXPLAIN NEW STAN CODE]
[MISSING: POP VS IND LEVEL PREDICTIONS]

Prep the data
```{r}
## Create the data 
d1 <- d %>% 
  subset(select = c(agent, memoryChoice)) %>% 
  mutate(row = row_number()) %>% 
  pivot_wider(names_from = agent, values_from = memoryChoice)

d2 <- d %>% 
  subset(select = c(agent, randomChoice)) %>% 
  mutate(row = row_number()) %>% 
  pivot_wider(names_from = agent, values_from = randomChoice)


data <- list(
  trials = trials,
  agents = agents,
  h = as.matrix(d1[1:120,2:101]),
  other = as.matrix(d2[1:120,2:101])
)
```

Code, compile and fit the model

```{r Coding and fitting the multilevel memory agents in Stan, eval = FALSE}

stan_model <- "
//
//
functions{
  real normal_lb_rng(real mu, real sigma, real lb) {
    real p = normal_cdf(lb | mu, sigma);  // cdf for bounds
    real u = uniform_rng(p, 1);
    return (sigma * inv_Phi(u)) + mu;  // inverse cdf for value
  }
}

// The input (data) for the model. 
data {
 int<lower = 1> trials;
 int<lower = 1> agents;
 array[trials, agents] int h;
 array[trials, agents] int other;
}

// The parameters accepted by the model. 
parameters {
  real biasM;
  real<lower = 0> biasSD;
  real betaM;
  real<lower = 0> betaSD;
  array[agents] real bias;
  array[agents] real beta;
}

transformed parameters {
  array[trials, agents] real memory;
  
  for (agent in 1:agents){
    for (trial in 1:trials){
      if (trial == 1) {
        memory[trial, agent] = 0.5;
      } 
      if (trial < trials){
        memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial);
        if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;}
        if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;}
      }
    }
  }
 }


// The model to be estimated. 
model {
  target += normal_lpdf(biasM | 0, 1);
  target += normal_lpdf(biasSD | 0, .3)  -
    normal_lccdf(0 | 0, .3);
  target += normal_lpdf(betaM | 0, .3);
  target += normal_lpdf(betaSD | 0, .3)  -
    normal_lccdf(0 | 0, .3);

  target += normal_lpdf(bias | biasM, biasSD); 
  target += normal_lpdf(beta | betaM, betaSD); 
 
  for (agent in 1:agents)
    for (trial in 1:trials){
      target += bernoulli_logit_lpmf(h[trial,agent] | 
            bias[agent] +  logit(memory[trial, agent]) * (beta[agent]));
    }
}

generated quantities{
   real biasM_prior;
   real<lower=0> biasSD_prior;
   real betaM_prior;
   real<lower=0> betaSD_prior;
   
   real bias_prior;
   real beta_prior;
   
   int<lower=0, upper = trials> prior_preds0;
   int<lower=0, upper = trials> prior_preds1;
   int<lower=0, upper = trials> prior_preds2;
   int<lower=0, upper = trials> posterior_preds0;
   int<lower=0, upper = trials> posterior_preds1;
   int<lower=0, upper = trials> posterior_preds2;
   array[agents] int<lower=0, upper = trials> posterior_predsID0;
   array[agents] int<lower=0, upper = trials> posterior_predsID1;
   array[agents] int<lower=0, upper = trials> posterior_predsID2;
   
   biasM_prior = normal_rng(0,1);
   biasSD_prior = normal_lb_rng(0,0.3,0);
   betaM_prior = normal_rng(0,1);
   betaSD_prior = normal_lb_rng(0,0.3,0);
   
   bias_prior = normal_rng(biasM_prior, biasSD_prior);
   beta_prior = normal_rng(betaM_prior, betaSD_prior);
   
   prior_preds0 = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior));
   prior_preds1 = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior));
   prior_preds2 = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior));
   posterior_preds0 = binomial_rng(trials, inv_logit(biasM + 0 * betaM));
   posterior_preds1 = binomial_rng(trials, inv_logit(biasM + 1 * betaM));
   posterior_preds2 = binomial_rng(trials, inv_logit(biasM + 2 * betaM));
    

  for (agent in 1:agents){
    posterior_predsID0[agent] = binomial_rng(trials, inv_logit(bias[agent] +  0 * beta[agent]));
	  posterior_predsID1[agent] = binomial_rng(trials, inv_logit(bias[agent] +  1 * beta[agent]));
	  posterior_predsID2[agent] = binomial_rng(trials, inv_logit(bias[agent] +  2 * beta[agent]));
    }
   
}

"


write_stan_file(
  stan_model,
  dir = "stan/",
  basename = "W5_MultilevelMemory.stan")

# Commented out to ensure faster compiling time for the book. Uncomment to run the code.
# file <- file.path("stan/W5_MultilevelMemory.stan")
# mod <- cmdstan_model(file, 
#                      cpp_options = list(stan_threads = TRUE),
#                      stanc_options = list("O1"))
# 
# # The following command calls Stan with specific options.
# samples <- mod$sample(
#   data = data,
#   seed = 123,
#   chains = 2,
#   parallel_chains = 2,
#   threads_per_chain = 2,
#   iter_warmup = 2000,
#   iter_sampling = 2000,
#   refresh = 500,
#   max_treedepth = 20,
#   adapt_delta = 0.99,
# )
# 
# samples$save_object(file = "simmodels/W5_MultilevelMemory_centered.RDS")

```

### Assessing multilevel memory

```{r Assessing multilevel memory centered: markov chains}
samples <- readRDS("simmodels/W5_MultilevelMemory_centered.RDS")

#samples$cmdstan_diagnose()
samples$summary(c("biasM", "betaM", "biasSD", "betaSD"))

draws_df <- as_draws_df(samples$draws()) 

p1 <- ggplot(draws_df, aes(.iteration, biasM, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()

p2 <- ggplot(draws_df, aes(.iteration, biasSD, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()

p3 <- ggplot(draws_df, aes(.iteration, betaM, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()

p4 <- ggplot(draws_df, aes(.iteration, betaSD, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()

p1 + p2 + p3 + p4

```

#### Predictive prior checks


```{r Assessing multilevel memory centered: prior checks}
##
ggplot(draws_df) +
  geom_histogram(aes(`prior_preds0`), color = "darkblue", fill = "blue", alpha = 0.3) +
  geom_histogram(aes(`prior_preds1`), color = "darkblue", fill = "green", alpha = 0.3) +
  geom_histogram(aes(`prior_preds2`), color = "darkblue", fill = "red", alpha = 0.3) +
  xlab("Predicted right hands out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()

```

#### Prior posterior update checks
biasM <- 0
biasSD <- 0.1
betaM <- 1.5
betaSD <- 0.3

```{r Assessing multilevel memory centered: prior posterior update checks}
##
p1 <- ggplot(draws_df) +
  geom_density(aes(biasM), fill = "blue", alpha = 0.3) +
  geom_density(aes(biasM_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0) +
  xlab("Mean bias") +
  ylab("Posterior Density") +
  theme_classic()

p2 <- ggplot(draws_df) +
  geom_density(aes(biasSD), fill = "blue", alpha = 0.3) +
  geom_density(aes(biasSD_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.1) +
  xlab("Variance of bias") +
  ylab("Posterior Density") +
  theme_classic()

p3 <- ggplot(draws_df) +
  geom_density(aes(betaM), fill = "blue", alpha = 0.3) +
  geom_density(aes(betaM_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 1.5) +
  xlab("Mean Beta") +
  ylab("Posterior Density") +
  theme_classic()

p4 <- ggplot(draws_df) +
  geom_density(aes(betaSD), fill = "blue", alpha = 0.3) +
  geom_density(aes(betaSD_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.3) +
  xlab("Variance of beta") +
  ylab("Posterior Density") +
  theme_classic()

p1 + p2 + p3 + p4 
```

#### Posterior predictive checks


```{r Assessing multilevel memory centered: posterior predictive checks}

p1 <- ggplot(draws_df) +
  geom_histogram(aes(`prior_preds0`), color = "darkblue", fill = "lightblue", alpha = 0.3) +
  geom_histogram(aes(`posterior_preds0`), color = "darkblue", fill = "blue", alpha = 0.3) +
  xlab("Predicted right hands out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()

p2 <- ggplot(draws_df) +
  geom_histogram(aes(`prior_preds1`), color = "darkblue", fill = "lightblue", alpha = 0.3) +
  geom_histogram(aes(`posterior_preds1`), color = "darkblue", fill = "blue", alpha = 0.3) +
  xlab("Predicted right hands out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()

p3 <- ggplot(draws_df) +
  geom_histogram(aes(`prior_preds2`), color = "darkblue", fill = "lightblue", alpha = 0.3) +
  geom_histogram(aes(`posterior_preds2`), color = "darkblue", fill = "blue", alpha = 0.3) +
  xlab("Predicted right hands out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()

p1 + p2 + p3

p1 <- ggplot(draws_df, aes(biasM, biasSD, group = .chain, color = .chain)) +
  geom_point(alpha = 0.1) +
  theme_classic()
p2 <- ggplot(draws_df, aes(betaM, betaSD, group = .chain, color = .chain)) +
  geom_point(alpha = 0.1) +
  theme_classic()
p3 <- ggplot(draws_df, aes(biasM, betaM, group = .chain, color = .chain)) +
  geom_point(alpha = 0.1) +
  theme_classic()
p4 <- ggplot(draws_df, aes(biasSD, betaSD, group = .chain, color = .chain)) +
  geom_point(alpha = 0.1) +
  theme_classic()

p1 + p2 + p3 + p4


```

### Multilevel memory with non centered parameterization

Prep the data
```{r, prep the data}
## Create the data 
d1 <- d %>% 
  subset(select = c(agent, memoryChoice)) %>% 
  mutate(row = row_number()) %>% 
  pivot_wider(names_from = agent, values_from = memoryChoice)

d2 <- d %>% 
  subset(select = c(agent, randomChoice)) %>% 
  mutate(row = row_number()) %>% 
  pivot_wider(names_from = agent, values_from = randomChoice)


data <- list(
  trials = trials,
  agents = agents,
  h = as.matrix(d1[1:120,2:101]),
  other = as.matrix(d2[1:120,2:101])
)
```

Code, compile and and fit the model

```{r Fitting multilevel memory with non centered parameterization, eval = FALSE}

## NON-CENTERED PARAMETRIZATION

stan_model_nc <- "

//
// This STAN model is a multilevel memory agent
//
functions{
  real normal_lb_rng(real mu, real sigma, real lb) {
    real p = normal_cdf(lb | mu, sigma);  // cdf for bounds
    real u = uniform_rng(p, 1);
    return (sigma * inv_Phi(u)) + mu;  // inverse cdf for value
  }
}

// The input (data) for the model. 
data {
 int<lower = 1> trials;
 int<lower = 1> agents;
 array[trials, agents] int h;
 array[trials, agents] int other;
}

// The parameters accepted by the model. 
parameters {
  real biasM;
  real<lower = 0> biasSD;
  real betaM;
  real<lower = 0> betaSD;
  vector[agents] biasID_z;
  vector[agents] betaID_z;
}

transformed parameters {
  array[trials, agents] real memory;
  vector[agents] biasID;
  vector[agents] betaID;
  
  for (agent in 1:agents){
    for (trial in 1:trials){
      if (trial == 1) {
        memory[trial, agent] = 0.5;
      } 
      if (trial < trials){
        memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial);
        if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;}
        if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;}
      }
    }
  }
  biasID = biasID_z * biasSD;
  betaID = betaID_z * betaSD;
 }

// The model to be estimated. 
model {
  target += normal_lpdf(biasM | 0, 1);
  target += normal_lpdf(biasSD | 0, .3)  -
    normal_lccdf(0 | 0, .3);
  target += normal_lpdf(betaM | 0, .3);
  target += normal_lpdf(betaSD | 0, .3)  -
    normal_lccdf(0 | 0, .3);

  target += std_normal_lpdf(to_vector(biasID_z)); // target += normal_lpdf(to_vector(biasID_z) | 0, 1);
  target += std_normal_lpdf(to_vector(betaID_z)); // target += normal_lpdf(to_vector(betaID_z) | 0, 1);
 
  for (agent in 1:agents){
    for (trial in 1:trials){
      target += bernoulli_logit_lpmf(h[trial,agent] | 
            biasM + biasID[agent] +  logit(memory[trial, agent]) * (betaM + betaID[agent]));
    }
  }
  
  
}

generated quantities{
   real biasM_prior;
   real<lower=0> biasSD_prior;
   real betaM_prior;
   real<lower=0> betaSD_prior;
   
   real bias_prior;
   real beta_prior;
   
   array[agents] int<lower=0, upper = trials> prior_preds0;
   array[agents] int<lower=0, upper = trials> prior_preds1;
   array[agents] int<lower=0, upper = trials> prior_preds2;
   array[agents] int<lower=0, upper = trials> posterior_preds0;
   array[agents] int<lower=0, upper = trials> posterior_preds1;
   array[agents] int<lower=0, upper = trials> posterior_preds2;
   
   biasM_prior = normal_rng(0,1);
   biasSD_prior = normal_lb_rng(0,0.3,0);
   betaM_prior = normal_rng(0,1);
   betaSD_prior = normal_lb_rng(0,0.3,0);
   
   bias_prior = normal_rng(biasM_prior, biasSD_prior);
   beta_prior = normal_rng(betaM_prior, betaSD_prior);
   


for (agent in 1:agents){
    prior_preds0[agent] = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior));
    prior_preds1[agent] = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior));
    prior_preds2[agent] = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior));
	  posterior_preds0[agent] = binomial_rng(trials, inv_logit(biasM + biasID[agent] +  0 * (betaM + betaID[agent])));
	  posterior_preds1[agent] = binomial_rng(trials, inv_logit(biasM + biasID[agent] +  1 * (betaM + betaID[agent])));
	  posterior_preds2[agent] = binomial_rng(trials, inv_logit(biasM + biasID[agent] +  2 * (betaM + betaID[agent])));
    }
}

"

write_stan_file(
  stan_model_nc,
  dir = "stan/",
  basename = "W5_MultilevelMemory_nc.stan")

file <- file.path("stan/W5_MultilevelMemory_nc.stan")
mod_nc <- cmdstan_model(file, 
                     cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

# The following command calls Stan with specific options.
samples <- mod_nc$sample(
  data = data,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 2000,
  iter_sampling = 2000,
  refresh = 500,
  max_treedepth = 20,
  adapt_delta = 0.99,
)

samples$save_object(file = "simmodels/W5_MultilevelMemory_noncentered.RDS")
```

### Assessing multilevel memory

```{r Assessing multilevel memory nc: markov chains}
samples <- readRDS("simmodels/W5_MultilevelMemory_noncentered.RDS")

#samples$cmdstan_diagnose()
samples$summary(c("biasM", "betaM", "biasSD", "betaSD"))

draws_df <- as_draws_df(samples$draws()) 

p1 <- ggplot(draws_df, aes(.iteration, biasM, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()

p2 <- ggplot(draws_df, aes(.iteration, biasSD, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()

p3 <- ggplot(draws_df, aes(.iteration, betaM, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()

p4 <- ggplot(draws_df, aes(.iteration, betaSD, group = .chain, color = .chain)) +
  geom_line() +
  theme_classic()

p1 + p2 + p3 + p4

```

#### Predictive prior checks


```{r Assessing multilevel memory nc: prior checks}
##
ggplot(draws_df) +
  geom_histogram(aes(`prior_preds0[1]`), color = "darkblue", fill = "blue", alpha = 0.3) +
  geom_histogram(aes(`prior_preds1[1]`), color = "darkblue", fill = "green", alpha = 0.3) +
  geom_histogram(aes(`prior_preds2[1]`), color = "darkblue", fill = "red", alpha = 0.3) +
  xlab("Predicted right hands out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()

```

#### Prior posterior update checks
biasM <- 0
biasSD <- 0.1
betaM <- 1.5
betaSD <- 0.3

```{r Assessing multilevel memory nc: prior posterior update checks}
##
p1 <- ggplot(draws_df) +
  geom_density(aes(logit_scaled(biasM)), fill = "blue", alpha = 0.3) +
  geom_density(aes(biasM_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0) +
  xlab("Mean bias") +
  ylab("Posterior Density") +
  theme_classic()

p2 <- ggplot(draws_df) +
  geom_density(aes(biasSD), fill = "blue", alpha = 0.3) +
  geom_density(aes(biasSD_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.1) +
  xlab("Variance of bias") +
  ylab("Posterior Density") +
  theme_classic()

p3 <- ggplot(draws_df) +
  geom_density(aes(betaM), fill = "blue", alpha = 0.3) +
  geom_density(aes(betaM_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 1.5) +
  xlab("Mean Beta") +
  ylab("Posterior Density") +
  theme_classic()

p4 <- ggplot(draws_df) +
  geom_density(aes(betaSD), fill = "blue", alpha = 0.3) +
  geom_density(aes(betaSD_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.3) +
  xlab("Variance of beta") +
  ylab("Posterior Density") +
  theme_classic()

p1 + p2 + p3 + p4 
```

#### Posterior predictive checks

```{r Assessing multilevel memory nc: posterior predictive checks}

p1 <- ggplot(draws_df) +
  geom_histogram(aes(`prior_preds0[1]`), color = "darkblue", fill = "lightblue", alpha = 0.3) +
  geom_histogram(aes(`posterior_preds0[1]`), color = "darkblue", fill = "blue", alpha = 0.3) +
  xlab("Predicted right hands out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()

p2 <- ggplot(draws_df) +
  geom_histogram(aes(`prior_preds1[1]`), color = "darkblue", fill = "lightblue", alpha = 0.3) +
  geom_histogram(aes(`posterior_preds1[1]`), color = "darkblue", fill = "blue", alpha = 0.3) +
  xlab("Predicted right hands out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()

p3 <- ggplot(draws_df) +
  geom_histogram(aes(`prior_preds2[1]`), color = "darkblue", fill = "lightblue", alpha = 0.3) +
  geom_histogram(aes(`posterior_preds2[1]`), color = "darkblue", fill = "blue", alpha = 0.3) +
  xlab("Predicted right hands out of 120 trials") +
  ylab("Posterior Density") +
  theme_classic()

p1 + p2 + p3

p1 <- ggplot(draws_df, aes(biasM, biasSD, group = .chain, color = .chain)) +
  geom_point(alpha = 0.1) +
  theme_classic()
p2 <- ggplot(draws_df, aes(betaM, betaSD, group = .chain, color = .chain)) +
  geom_point(alpha = 0.1) +
  theme_classic()
p3 <- ggplot(draws_df, aes(biasM, betaM, group = .chain, color = .chain)) +
  geom_point(alpha = 0.1) +
  theme_classic()
p4 <- ggplot(draws_df, aes(biasSD, betaSD, group = .chain, color = .chain)) +
  geom_point(alpha = 0.1) +
  theme_classic()

p1 + p2 + p3 + p4

ggplot(draws_df) +
  geom_density(aes(inv_logit_scaled(`biasID[1]`)), fill = "blue", alpha = 0.3) +
  geom_density(aes(inv_logit_scaled(`biasID[15]`)), fill = "green", alpha = 0.3) +
  geom_density(aes(inv_logit_scaled(`biasID[21]`)), fill = "lightblue", alpha = 0.3) +
  geom_density(aes(inv_logit_scaled(`biasID[31]`)), fill = "darkblue", alpha = 0.3) +
  geom_density(aes(inv_logit_scaled(`biasID[41]`)), fill = "yellow", alpha = 0.3) +
  geom_density(aes(inv_logit_scaled(`biasID[51]`)), fill = "darkgreen", alpha = 0.3) +
  geom_density(aes(inv_logit_scaled(`biasID[61]`)), fill = "lightgreen", alpha = 0.3) +
  geom_density(aes(inv_logit_scaled(biasM_prior)), fill = "pink", alpha = 0.3) +
  geom_density(aes(bias_prior), fill = "purple", alpha = 0.3) +
  xlab("Bias parameter") +
  ylab("Posterior Density") +
  theme_classic()

ggplot(draws_df) +
  geom_density(aes(inv_logit_scaled(`betaID[1]`)), fill = "blue", alpha = 0.3) +
  geom_density(aes(inv_logit_scaled(`betaID[15]`)), fill = "green", alpha = 0.3) +
  geom_density(aes(inv_logit_scaled(`betaID[21]`)), fill = "lightblue", alpha = 0.3) +
  geom_density(aes(inv_logit_scaled(`betaID[31]`)), fill = "darkblue", alpha = 0.3) +
  geom_density(aes(inv_logit_scaled(`betaID[41]`)), fill = "yellow", alpha = 0.3) +
  geom_density(aes(inv_logit_scaled(`betaID[51]`)), fill = "darkgreen", alpha = 0.3) +
  geom_density(aes(inv_logit_scaled(`betaID[61]`)), fill = "lightgreen", alpha = 0.3) +
  geom_density(aes(inv_logit_scaled(betaM_prior)), fill = "pink", alpha = 0.3) +
  geom_density(aes(beta_prior), fill = "purple", alpha = 0.3) +
  xlab("Beta parameter") +
  ylab("Posterior Density") +
  theme_classic()


```

### Multilevel memory with correlation between parameters

```{r Multilevel memory with correlation between parameters, eval = FALSE}

stan_model_nc_cor <- "
//
// This STAN model infers a random bias from a sequences of 1s and 0s (heads and tails)
//
functions{
  real normal_lb_rng(real mu, real sigma, real lb) {
    real p = normal_cdf(lb | mu, sigma);  // cdf for bounds
    real u = uniform_rng(p, 1);
    return (sigma * inv_Phi(u)) + mu;  // inverse cdf for value
  }
}

// The input (data) for the model. 
data {
 int<lower = 1> trials;
 int<lower = 1> agents;
 array[trials, agents] int h;
 array[trials, agents] int other;
}

// The parameters accepted by the model. 
parameters {
  real biasM;
  real betaM;
  vector<lower = 0>[2] tau;
  matrix[2, agents] z_IDs;
  cholesky_factor_corr[2] L_u;
}

transformed parameters {
  array[trials, agents] real memory;
  matrix[agents,2] IDs;
  IDs = (diag_pre_multiply(tau, L_u) * z_IDs)';
  
  for (agent in 1:agents){
    for (trial in 1:trials){
      if (trial == 1) {
        memory[trial, agent] = 0.5;
      } 
      if (trial < trials){
        memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial);
        if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;}
        if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;}
      }
    }
  }
}

// The model to be estimated. 
model {
  target += normal_lpdf(biasM | 0, 1);
  target += normal_lpdf(tau[1] | 0, .3)  -
    normal_lccdf(0 | 0, .3);
  target += normal_lpdf(betaM | 0, .3);
  target += normal_lpdf(tau[2] | 0, .3)  -
    normal_lccdf(0 | 0, .3);
  target += lkj_corr_cholesky_lpdf(L_u | 2);

  target += std_normal_lpdf(to_vector(z_IDs));
  for (agent in 1:agents){
    for (trial in 1:trials){
      target += bernoulli_logit_lpmf(h[trial, agent] | biasM + IDs[agent, 1] +  memory[trial, agent] * (betaM + IDs[agent, 2]));
    }
  }
    
}


generated quantities{
   real biasM_prior;
   real<lower=0> biasSD_prior;
   real betaM_prior;
   real<lower=0> betaSD_prior;
   
   real bias_prior;
   real beta_prior;
   
   array[agents] int<lower=0, upper = trials> prior_preds0;
   array[agents] int<lower=0, upper = trials> prior_preds1;
   array[agents] int<lower=0, upper = trials> prior_preds2;
   array[agents] int<lower=0, upper = trials> posterior_preds0;
   array[agents] int<lower=0, upper = trials> posterior_preds1;
   array[agents] int<lower=0, upper = trials> posterior_preds2;
   
   biasM_prior = normal_rng(0,1);
   biasSD_prior = normal_lb_rng(0,0.3,0);
   betaM_prior = normal_rng(0,1);
   betaSD_prior = normal_lb_rng(0,0.3,0);
   
   bias_prior = normal_rng(biasM_prior, biasSD_prior);
   beta_prior = normal_rng(betaM_prior, betaSD_prior);
   
   for (i in 1:agents){
      prior_preds0[i] = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior));
      prior_preds1[i] = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior));
      prior_preds2[i] = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior));
      posterior_preds0[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] +  0 * (betaM + IDs[i,2])));
      posterior_preds1[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] +  1 * (betaM + IDs[i,2])));
      posterior_preds2[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] +  2 * (betaM + IDs[i,2])));
      
  }
  
}
"

write_stan_file(
  stan_model_nc_cor,
  dir = "stan/",
  basename = "W5_MultilevelMemory_nc_cor.stan")

file <- file.path("stan/W5_MultilevelMemory_nc_cor.stan")
mod <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

# The following command calls Stan with specific options.
samples <- mod$sample(
  data = data,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 2000,
  iter_sampling = 2000,
  refresh = 500,
  max_treedepth = 20,
  adapt_delta = 0.99,
)

samples$save_object(file = "simmodels/Memory_noncentered_corr.RDS")
```

### Assessing multilevel memory

[MISSING LOTS OF EVALUATION]

```{r Assessing multilevel memory: markov chains}
samples <- readRDS("simmodels/W5_MultilevelMemory_noncentered_corr.RDS")

#samples$cmdstan_diagnose()

```

### Multilevel memory no pooling

[MISSING: EXPLANATION OF NO POOLING]

```{r Multilevel memory with no pooling, eval = FALSE}

stan_model <- "

// The input (data) for the model. n of trials and h of heads
data {
 int<lower = 1> trials;
 int<lower = 1> agents;
 array[trials, agents] int h;
 array[trials, agents] int other;
}

// The parameters accepted by the model. 
parameters {
  array[trials] real bias;
  array[trials] real beta;
}


transformed parameters {
  array[trials, agents] real memory;
  
  for (agent in 1:agents){
    for (trial in 1:trials){
      if (trial == 1) {
        memory[trial, agent] = 0.5;
      } 
      if (trial < trials){
        memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial);
        if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;}
        if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;}
      }
    }
  }
}

// The model to be estimated. 
model {
  target += normal_lpdf(bias | 0, 1);
  target += normal_lpdf(beta | 0, 1);

  for (agent in 1:agents){
    for (trial in 1:trials){
      target += bernoulli_logit_lpmf(h[trial, agent] | bias[agent] +  memory[trial, agent] * (beta[agent]));
    }
  }
    
}


generated quantities{
   real bias_prior;
   real beta_prior;
   
   int<lower=0, upper = trials> prior_preds0;
   int<lower=0, upper = trials> prior_preds1;
   int<lower=0, upper = trials> prior_preds2;
   array[agents] int<lower=0, upper = trials> posterior_preds0;
   array[agents] int<lower=0, upper = trials> posterior_preds1;
   array[agents] int<lower=0, upper = trials> posterior_preds2;
   
   bias_prior = normal_rng(0,1);
   beta_prior = normal_rng(0,1);
   
   prior_preds0 = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior));
   prior_preds1 = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior));
   prior_preds2 = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior));
   
   for (i in 1:agents){
      posterior_preds0[i] = binomial_rng(trials, inv_logit(bias[i] +  0 * (beta[i])));
      posterior_preds1[i] = binomial_rng(trials, inv_logit(bias[i] +  1 * (beta[i])));
      posterior_preds2[i] = binomial_rng(trials, inv_logit(bias[i] +  2 * (beta[i])));
  }
  
}
"

write_stan_file(
  stan_model,
  dir = "stan/",
  basename = "W5_MultilevelMemory_nopooling.stan")

file <- file.path("stan/W5_MultilevelMemory_nopooling.stan")
mod <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

# The following command calls Stan with specific options.
samples <- mod$sample(
  data = data,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 2000,
  iter_sampling = 2000,
  refresh = 500,
  max_treedepth = 20,
  adapt_delta = 0.99,
)

samples$save_object(file = "simmodels/W5_MultilevelMemory_nopooling.RDS")

```

[MISSING: Evaluation of NO POOLING]


## Multilevel full pooling
[MISSING: EXPLANATION OF FULL POOLING]

```{r Multilevel memory with full pooling, eval = FALSE}

stan_model <- "

// The input (data) for the model. n of trials and h of heads
data {
 int<lower = 1> trials;
 int<lower = 1> agents;
 array[trials, agents] int h;
 array[trials, agents] int other;
}

// The parameters accepted by the model. 
parameters {
  real bias;
  real beta;
}


transformed parameters {
  array[trials, agents] real memory;
  
  for (agent in 1:agents){
    for (trial in 1:trials){
      if (trial == 1) {
        memory[trial, agent] = 0.5;
      } 
      if (trial < trials){
        memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial);
        if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;}
        if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;}
      }
    }
  }
}

// The model to be estimated. 
model {
  target += normal_lpdf(bias | 0, 1);
  target += normal_lpdf(beta | 0, 1);

  for (agent in 1:agents){
    for (trial in 1:trials){
      target += bernoulli_logit_lpmf(h[trial, agent] | bias +  memory[trial, agent] * beta);
    }
  }
    
}


generated quantities{
   real bias_prior;
   real beta_prior;
   
   int<lower=0, upper = trials> prior_preds0;
   int<lower=0, upper = trials> prior_preds1;
   int<lower=0, upper = trials> prior_preds2;
   int<lower=0, upper = trials> posterior_preds0;
   int<lower=0, upper = trials> posterior_preds1;
   int<lower=0, upper = trials> posterior_preds2;
   
   bias_prior = normal_rng(0,1);
   beta_prior = normal_rng(0,1);
   
   prior_preds0 = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior));
   prior_preds1 = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior));
   prior_preds2 = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior));
   
   posterior_preds0 = binomial_rng(trials, inv_logit(bias +  0 * (beta)));
   posterior_preds1 = binomial_rng(trials, inv_logit(bias +  1 * (beta)));
   posterior_preds2 = binomial_rng(trials, inv_logit(bias +  2 * (beta)));
  
}
"

write_stan_file(
  stan_model,
  dir = "stan/",
  basename = "W5_MultilevelMemory_fullpooling.stan")

file <- file.path("stan/W5_MultilevelMemory_fullpooling.stan")
mod <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

# The following command calls Stan with specific options.
samples <- mod$sample(
  data = data,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 2000,
  iter_sampling = 2000,
  refresh = 500,
  max_treedepth = 20,
  adapt_delta = 0.99,
)

samples$save_object(file = "simmodels/W5_MultilevelMemory_fullpooling.RDS")


```

[MISSING: Evaluation of FULL POOLING]

[MISSING: PARAMETER RECOVERY IN A MULTILEVEL FRAMEWORK (IND VS POP)]

<!--chapter:end:06-MultilevelModels.Rmd-->

---
title: "06-ModelComparison"
output: html_document
date: "2023-03-10"
---

# Model Comparison in Cognitive Science

Understanding human cognition often involves choosing between competing theoretical explanations. When faced with behavioral data - whether from matching pennies games, learning tasks, or decision-making scenarios - we can implement different theories of the underlying cognitive processes, or switch on and off specific cognitive components. Model comparison is the set of procedure that allows allows us to determine which cognitive model best explains the observed patterns. But remember, model comparison is not a fail-safe procedure to determine which model embodies the truth, as always we need to be careful, tentative and open about the probabilistic and fallible nature of our inference.

## Learning Objectives 

After completing this chapter, you will be able to:

* Implement cross-validation techniques for comparing cognitive models using Stan
* Calculate and interpret expected log predictive density (ELPD) scores
* Assess model predictions through posterior and prior predictive checks
* Understand the strengths and limitations of different model comparison approaches
* Apply these techniques to compare competing cognitive models using real data

## Why Compare Models?

Model comparison serves multiple purposes in cognitive science. Some examples:

1. Theory Testing: Different models often represent competing theoretical accounts of cognitive processes. Comparing their fit to data helps evaluate these theories.

2. Parsimony: When multiple models can explain the data, one of the reason to prefer more complex models is if they are justified by better predictive performance.

3. Generalization: By assessing how well different models predict new data, we can evaluate their ability to capture general patterns rather than just fitting to specific samples.

4. Individual Differences: Model comparison can reveal whether different individuals or groups are better described by different cognitive strategies.

This chapter demonstrates these principles using our matching pennies models as concrete examples. We'll compare simple random choice models against more sophisticated memory-based approaches, showing how to rigorously evaluate which better explains observed behavior.

Imagine having several models of what might be going on and want to know which is the best explanation of the data. E.g. Are people more likely to use a memory strategy, or a win stay lose shift strategy? Or are we justified in assuming that people react differently to losses than to wins (e.g. by being more likely to shift when losing, than to stay when winning)? Or would we be justified in assuming that capuchin monkeys and cognitive science students use the same model?

Model comparison defines a broad range of practices aimed at identifying among a set of models the best model for a given data set. What "best" means is, however, a non-trivial question. Ideally, "best" would mean the model describing the mechanism that actually generated the data. However, as we will see that is a tricky proposition and we analysts tend to rely on proxies. There are many of such proxies in the literature. For instance, Nicenboim et al (2023) suggests employing either Bayes Factors or cross-validation (https://vasishth.github.io/bayescogsci/book/ch-comparison.html). In this course, we rely on cross-validation based predictive performance (this chapter) and mixture models (next chapter).

In other words, this chapter will assess models in terms of their (estimated) ability to predict new (test) data. Remember that predictive performance is a very useful tool, but not a magical solution. It allows us to combat overfitting to the training sample (your model snuggling to your data so much that it fits both signal and noise), but it has key limitations, which we will discuss at the end of the chapter. 

To learn how to make model comparison, in this chapter, we rely on our usual simulation based approach to ensure that the method is doing what we want. We simulate the behavior of biased agents playing against the memory agents. This provides us with data generated according to two different mechanisms: biased agents and memory agents. We can fit both models separately on each of the two sets of agents, so we can compare the relative performance of the two models: can we identify the true model generating the data (in a setup where truth is known)? This is what is usually called "model recovery" and complements nicely "parameter recovery". In model recovery we assess whether we can identify the correct model, in parameter recovery we assess whether - once we know the correct model - we can identify the correct parameter values.

Let's get going.

## Define parameters

```{r 06 define parameters}
pacman::p_load(tidyverse,
               here,
               posterior,
               cmdstanr,
               brms, 
               tidybayes, 
               loo, job)

# Shared parameters
agents <- 100
trials <- 120
noise <- 0

# Biased agents parameters
rateM <- 1.386 # roughly 0.8 once inv_logit scaled
rateSD <- 0.65 # roughly giving a sd of 0.1 in prob scale

# Memory agents parameters
biasM <- 0
biasSD <- 0.1
betaM <- 1.5
betaSD <- 0.3

```

## Define biased and memory agents


```{r 06 Defining the agents functions}

# Functions of the agents
RandomAgentNoise_f <- function(rate, noise) {
  choice <- rbinom(1, 1, inv_logit_scaled(rate))
  if (rbinom(1, 1, noise) == 1) {
    choice = rbinom(1, 1, 0.5)
  }
  return(choice)
}

MemoryAgentNoise_f <- function(bias, beta, otherRate, noise) {
  rate <- inv_logit_scaled(bias + beta * logit_scaled(otherRate))
  choice <- rbinom(1, 1, rate)
  if (rbinom(1, 1, noise) == 1) {
    choice = rbinom(1, 1, 0.5)
  }
  return(choice)
}


```

## Generating the agents

[MISSING: PARALLELIZE]

```{r Generating the agents bla}
# Looping through all the agents to generate the data.
d <- NULL

for (agent in 1:agents) {
  
  rate <- rnorm(1, rateM, rateSD)
  bias <- rnorm(1, biasM, biasSD)
  beta <- rnorm(1, betaM, betaSD)
  
  randomChoice <- rep(NA, trials)
  memoryChoice <- rep(NA, trials)
  memoryRate <- rep(NA, trials)
  
  for (trial in 1:trials) {
    
    randomChoice[trial] <- RandomAgentNoise_f(rate, noise)
    if (trial == 1) {
      memoryChoice[trial] <- rbinom(1,1,0.5)
    } else {
      memoryChoice[trial] <- MemoryAgentNoise_f(bias, beta, mean(randomChoice[1:trial], na.rm = T), noise)
    }
  }
  
  temp <- tibble(agent, trial = seq(trials), randomChoice, randomRate = rate, memoryChoice, memoryRate, noise, rateM, rateSD, bias, beta, biasM, biasSD, betaM, betaSD)
  
  if (agent > 1) {
    d <- rbind(d, temp)
  } else{
    d <- temp
  }
  
}

d <- d %>% group_by(agent) %>% mutate(
  randomRate = cumsum(randomChoice) / seq_along(randomChoice),
  memoryRate = cumsum(memoryChoice) / seq_along(memoryChoice)
)
```

## Prep the data

```{r}
d1 <- d %>% 
  subset(select = c(agent, randomChoice)) %>% 
  mutate(row = row_number()) %>% 
  pivot_wider(names_from = agent, values_from = randomChoice)

d2 <- d %>% 
  subset(select = c(agent, memoryChoice)) %>% 
  mutate(row = row_number()) %>% 
  pivot_wider(names_from = agent, values_from = memoryChoice)

## Create the data
data_biased <- list(
  trials = trials,
  agents = agents,
  h = as.matrix(d1[,2:101]),
  other = as.matrix(d2[,2:101])
)

data_memory <- list(
  trials = trials,
  agents = agents,
  h = as.matrix(d2[,2:101]),
  other = as.matrix(d1[,2:101])
)
```

## Log posterior likelihood

While the previous sections did not present any new materials (and therefore weren't much commented), as we create our Stan models to fit to the data, we need to (re)introduce the notion of log-likelihood, or even better, log posterior likelihood. 

Given certain values for our parameters (let's say a bias of 0 and beta for memory of 1) and for our variables (let's say the vector of memory values estimated by the agent on a trial by trial basis), the model will predict a certain distribution of outcomes, that is, a certain distribution of choices (n times right, m times left hand). Comparing this to the actual data, we can identify how likely the model is to produce it. In other words, the probability that the model will actually generate the data we observed out of all its possible outcomes. Remember that we are doing Bayesian statistics, so this probability needs to be combined with the probability of the parameter values given the priors on those parameters. This would give us a *posterior likelihood* of the model's parameter values given the data. The last step is that we need to work on a log scale. Working on a log scale is very useful because it avoids low probabilities (close to 0) being rounded down to exactly 0. [MISSING A LINK TO A LENGTHIER EXPLANATION]. By log-transforming the posterior likelihood, we now have the *log-posterior likelihood*.

Now, remember that our agent's memory varies on a trial by trial level. In other words, for each data point, for each agent we can calculate separate values of log-posterior likelihood for each of the possible values of the parameters. That is, we can have a distribution of log-posterior likelihood for each data point.

Luckily for us telling Stan to calculate and such distributions is extremely easy: we just need to add to the generated quantities block the same log probability density/mass statement that we use in the model block, but here we specify it should be saved (replacing target += with an actual variable to be filled).

N.B. Some of you might be wandering: if Stan is already using the log-posterior probability in the sampling process, why do we need to tell it to calculate and save it? Fair enough point. But Stan does not save by default (to avoid clogging your computer with endless data) and we need the log posterior likelihood saved as "log_lik" in order to be able to use more automated functions later on.

## Create the models: multilevel biased agents

Remember to add the log_lik part in the generated quantities block!


```{r 06 Multilevel baised agents, eval = F}

stan_biased_model <- "
functions{
  real normal_lb_rng(real mu, real sigma, real lb) { // normal distribution with a lower bound
    real p = normal_cdf(lb | mu, sigma);  // cdf for bounds
    real u = uniform_rng(p, 1);
    return (sigma * inv_Phi(u)) + mu;  // inverse cdf for value
  }
}

// The input (data) for the model. n of trials and h of hands
data {
 int<lower = 1> trials;
 int<lower = 1> agents;
 array[trials, agents] int h;
}

// The parameters accepted by the model. 
parameters {
  real thetaM;
  real<lower = 0> thetaSD;
  array[agents] real theta;
}

// The model to be estimated. 
model {
  target += normal_lpdf(thetaM | 0, 1);
  target += normal_lpdf(thetaSD | 0, .3)  -
    normal_lccdf(0 | 0, .3);

  // The prior for theta is a uniform distribution between 0 and 1
  target += normal_lpdf(theta | thetaM, thetaSD); 
 
  for (i in 1:agents)
    target += bernoulli_logit_lpmf(h[,i] | theta[i]);
  
}


generated quantities{
   real thetaM_prior;
   real<lower=0> thetaSD_prior;
   real<lower=0, upper=1> theta_prior;
   real<lower=0, upper=1> theta_posterior;
   
   int<lower=0, upper = trials> prior_preds;
   int<lower=0, upper = trials> posterior_preds;
   
   array[trials, agents] real log_lik;
   
   thetaM_prior = normal_rng(0,1);
   thetaSD_prior = normal_lb_rng(0,0.3,0);
   theta_prior = inv_logit(normal_rng(thetaM_prior, thetaSD_prior));
   theta_posterior = inv_logit(normal_rng(thetaM, thetaSD));
   
   prior_preds = binomial_rng(trials, inv_logit(thetaM_prior));
   posterior_preds = binomial_rng(trials, inv_logit(thetaM));
   
   for (i in 1:agents){
    for (t in 1:trials){
      log_lik[t,i] = bernoulli_logit_lpmf(h[t,i] | theta[i]);
    }
   }
  
}
"
write_stan_file(
  stan_biased_model,
  dir = "stan/",
  basename = "W6_MultilevelBias.stan")

file <- file.path("stan/W6_MultilevelBias.stan")
mod_biased <- cmdstan_model(file, 
                     cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

```


## Multilevel memory model

```{r 06 Multilevel memory agents, eval = F}
stan_memory_model <- "
functions{
  real normal_lb_rng(real mu, real sigma, real lb) {
    real p = normal_cdf(lb | mu, sigma);  // cdf for bounds
    real u = uniform_rng(p, 1);
    return (sigma * inv_Phi(u)) + mu;  // inverse cdf for value
  }
}

// The input (data) for the model. 
data {
 int<lower = 1> trials;
 int<lower = 1> agents;
 array[trials, agents] int h;
 array[trials, agents] int other;
}

// The parameters accepted by the model. 
parameters {
  real biasM;
  real betaM;
  vector<lower = 0>[2] tau;
  matrix[2, agents] z_IDs;
  cholesky_factor_corr[2] L_u;
}

transformed parameters {
  array[trials, agents] real memory;
  matrix[agents,2] IDs;
  IDs = (diag_pre_multiply(tau, L_u) * z_IDs)';
  
  for (agent in 1:agents){
    for (trial in 1:trials){
      if (trial == 1) {
        memory[trial, agent] = 0.5;
      } 
      if (trial < trials){
        memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial);
        if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;}
        if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;}
      }
    }
  }
}

// The model to be estimated. 
model {
  target += normal_lpdf(biasM | 0, 1);
  target += normal_lpdf(tau[1] | 0, .3)  -
    normal_lccdf(0 | 0, .3);
  target += normal_lpdf(betaM | 0, .3);
  target += normal_lpdf(tau[2] | 0, .3)  -
    normal_lccdf(0 | 0, .3);
  target += lkj_corr_cholesky_lpdf(L_u | 2);

  target += std_normal_lpdf(to_vector(z_IDs));
  for (agent in 1:agents){
    for (trial in 1:trials){
      target += bernoulli_logit_lpmf(h[trial, agent] | biasM + IDs[agent, 1] +  memory[trial, agent] * (betaM + IDs[agent, 2]));
    }
  }
    
}


generated quantities{
   real biasM_prior;
   real<lower=0> biasSD_prior;
   real betaM_prior;
   real<lower=0> betaSD_prior;
   
   real bias_prior;
   real beta_prior;
   
   array[agents] int<lower=0, upper = trials> prior_preds0;
   array[agents] int<lower=0, upper = trials> prior_preds1;
   array[agents] int<lower=0, upper = trials> prior_preds2;
   array[agents] int<lower=0, upper = trials> posterior_preds0;
   array[agents] int<lower=0, upper = trials> posterior_preds1;
   array[agents] int<lower=0, upper = trials> posterior_preds2;
   
   array[trials, agents] real log_lik;
   
   biasM_prior = normal_rng(0,1);
   biasSD_prior = normal_lb_rng(0,0.3,0);
   betaM_prior = normal_rng(0,1);
   betaSD_prior = normal_lb_rng(0,0.3,0);
   
   bias_prior = normal_rng(biasM_prior, biasSD_prior);
   beta_prior = normal_rng(betaM_prior, betaSD_prior);
   
   for (i in 1:agents){
      prior_preds0[i] = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior));
      prior_preds1[i] = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior));
      prior_preds2[i] = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior));
      posterior_preds0[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] +  0 * (betaM + IDs[i,2])));
      posterior_preds1[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] +  1 * (betaM + IDs[i,2])));
      posterior_preds2[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] +  2 * (betaM + IDs[i,2])));
      
      for (t in 1:trials){
        log_lik[t,i] = bernoulli_logit_lpmf(h[t, i] | biasM + IDs[i, 1] +  memory[t, i] * (betaM + IDs[i, 2]));
      }
   }
  
}
"

write_stan_file(
  stan_memory_model,
  dir = "stan/",
  basename = "W6_MultilevelMemory.stan")

file <- file.path("stan/W6_MultilevelMemory.stan")
mod_memory <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))
```

## Fitting the models to the data

```{r, 06 fitting models, eval = F}
# # Fitting biased agent model to biased agent data
# fit_biased2biased <- mod_biased$sample(
#   data = data_biased,
#   seed = 123,
#   chains = 1,
#   parallel_chains = 1,
#   threads_per_chain = 1,
#   iter_warmup = 2000,
#   iter_sampling = 2000,
#   refresh = 0,
#   output_dir = "simmodels",
#   max_treedepth = 20,
#   adapt_delta = 0.99
# )
# 
# fit_biased2biased$save_object(file = "simmodels/W6_fit_biased2biased.RDS")
# 
# 
# # Fitting biased agent model to memory agent data
# fit_biased2memory <- mod_biased$sample(
#   data = data_memory,
#   seed = 123,
#   chains = 1,
#   parallel_chains = 1,
#   threads_per_chain = 1,
#   iter_warmup = 2000,
#   iter_sampling = 2000,
#   refresh = 0,
#   output_dir = "simmodels",
#   max_treedepth = 20,
#   adapt_delta = 0.99
# )
# 
# fit_biased2memory$save_object(file = "simmodels/W6_fit_biased2memory.RDS")
# 
# fit_memory2biased <- mod_memory$sample(
#   data = data_biased,
#   seed = 123,
#   chains = 1,
#   parallel_chains = 1,
#   threads_per_chain = 4,
#   iter_warmup = 2000,
#   iter_sampling = 2000,
#   refresh = 0,
#   output_dir = "simmodels",
#   max_treedepth = 20,
#   adapt_delta = 0.99
# )
# 
# fit_memory2biased$save_object(file = "simmodels/W6_fit_memory2biased.RDS")
# 
# fit_memory2memory <- mod_memory$sample(
#   data = data_memory,
#   seed = 123,
#   chains = 1,
#   parallel_chains = 1,
#   threads_per_chain = 4,
#   iter_warmup = 2000,
#   iter_sampling = 2000,
#   refresh = 0,
#   output_dir = "simmodels",
#   max_treedepth = 20,
#   adapt_delta = 0.99
# )
# 
# fit_memory2memory$save_object(file = "simmodels/W6_fit_memory2memory.RDS")
```




## Calculating the expected log predictive density of a model

In the previous section, we fitted each model (biased and memory) to each dataset (biased and memory), and calculated and saved the log-posterior likelihood distributions for each data point. However, as we know from previous courses, calculating the goodness of fit of a model on the actual data it has been trained/fitted on is a bad idea. Models - expecially complex models - tend to overfit to the data. The multilevel implementation we have used is a bit skeptical of the data (it pools information across agents and combines it with the data from any given agent, thus de facto regularizing the estimates). Still overfitting is a serious risk.

Machine learning has made common practices of validation, that is, of keeping parts of the dataset out of the training/fitting process, in order to then see how well the trained model can predict those untouched data, and get an out of sample error. 

***
### Rant on internal vs external validity
However, we need to think carefully about what we mean by "out of sample." There are actually two distinct types of test sets we might consider: internal and external.
Internal test sets come from the same data collection effort as our training data - for example, we might randomly set aside 20% of our matching pennies games to test on. While this approach helps us detect overfitting to specific participants or trials, it cannot tell us how well our model generalizes to truly new contexts. Our test set participants were recruited from the same population, played the game under the same conditions, and were influenced by the same experimental setup as our training participants.
External test sets, in contrast, come from genuinely different contexts. For our matching pennies model, this might mean testing on games played:

* In different cultures or age groups
* Under time pressure versus relaxed conditions
* For real money versus just for fun
* Against human opponents versus computer agents
* In laboratory versus online settings

The distinction matters because cognitive models often capture not just universal mental processes, but also specific strategies that people adopt in particular contexts. A model that perfectly predicts behavior in laboratory matching pennies games might fail entirely when applied to high-stakes poker games, even though both involve similar strategic thinking.
This raises deeper questions about what kind of generalization we want our models to achieve. Are we trying to build models that capture universal cognitive processes, or are we content with models that work well within specific contexts? The answer affects not just how we evaluate our models, but how we design them in the first place.
In practice, truly external test sets are rare in cognitive science - they require additional data collection under different conditions, which is often impractical. This means we must be humble about our claims of generalization. When we talk about a model's predictive accuracy, we should be clear that we're usually measuring its ability to generalize within a specific experimental context, not its ability to capture human cognition in all its diversity.
This limitation of internal test sets is one reason why cognitive scientists often complement predictive accuracy metrics with other forms of model evaluation, such as testing theoretical predictions on new tasks or examining whether model parameters correlate sensibly with individual differences. These approaches help us build confidence that our models capture meaningful cognitive processes rather than just statistical patterns specific to our experimental setup.
***

When the datasets are small, as it is often the case in cognitive science, keeping a substantial portion of the data out - substantial enough to be representative of a more general population - is problematic as it risks starving the model of data: there might not be enough data for reliable estimation of the parameter values. This is where the notion of cross-validation comes in: we can split the dataset in k folds, let's say k = 10. Then each fold is in turn kept aside as validation set, the model is fitted on the other folds, and its predictive performance tested on the validation set. Repeat this operation of each of the folds. This operation ensures that all the data can be used for training as well as for validation, and is in its own terms quite genial. However, this does not mean it is free of shortcomings. First, small validation folds might not be representative of the diversity of true out-of-sample populations - and there is a tendency to set k equal to the number of datapoints (leave-one-out cross validation). Second, there are many ways in which information could leak or contaminate across folds if the pipeline is not very careful (e.g. via data preprocessing scaling the full dataset, or hyper-parameter estimation). Third, and crucial for our case here, cross validation implies refitting the model k times, which for Bayesian models might be very cumbersome (I once had a model that took 6 weeks to run).

The elpd (expected log predictive density) is an attempt at estimating the out-of-sample error without actually re-running the model. To understand elpd we need to decompose it in several steps.

* Log pointwise predictive density (lppd) is the sum of the logarithm of the average log posterior likelihood of each observation ( Pr(yi) )

* A penalty is given according to the sum of the variance in log posterior likelihood per each observation. The more unstable (varying) the higher the penalty.

* This is all still fully based on the training sample. Elpd moves it one step forward by weighting the lppd according to the frequency of the observation in the dataset excluding that observation. The more frequent, the more it matters. N.B. elpd only keeps one datapoint out, meaning that dependencies within larger clusters (e.g. repeated measures by participants) confound the measure.

Let's calculate this, and then we will implement a more properly cross-validated version.


```{r, 06 assess predictive performance}

fit_biased2biased <- readRDS("simmodels/W6_fit_memory2memory.RDS")

Loo_biased2biased <- fit_biased2biased$loo(save_psis = TRUE, cores = 4)

p1 <- plot(Loo_biased2biased)

p1 <- p1 + ylim(-0.4, 0.4)

fit_biased2memory <- readRDS("simmodels/W6_fit_biased2memory.RDS")
Loo_biased2memory <- fit_biased2memory$loo(save_psis = TRUE, cores = 4)
plot(Loo_biased2memory)

fit_memory2biased <- readRDS("simmodels/W6_fit_memory2biased.RDS")
Loo_memory2biased <- fit_memory2biased$loo(save_psis = TRUE, cores = 4)
plot(Loo_memory2biased)

fit_memory2memory <- readRDS("simmodels/W6_fit_memory2memory.RDS")
Loo_memory2memory <- fit_memory2memory$loo(save_psis = TRUE, cores = 4)
plot(Loo_memory2memory)

elpd <- tibble(
  n = seq(12000),
  biased_diff_elpd = 
  Loo_biased2biased$pointwise[, "elpd_loo"] - 
  Loo_memory2biased$pointwise[, "elpd_loo"],
  memory_diff_elpd = 
  Loo_memory2memory$pointwise[, "elpd_loo"] -
  Loo_biased2memory$pointwise[, "elpd_loo"])

p1 <- ggplot(elpd, aes(x = n, y = biased_diff_elpd)) +
  geom_point(alpha = .1) +
  #xlim(.5,1.01) +
  #ylim(-1.5,1.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  theme_bw()

p2 <- ggplot(elpd, aes(x = n, y = memory_diff_elpd)) +
  geom_point(alpha = .1) +
  #xlim(.5,1.01) +
  #ylim(-1.5,1.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  theme_bw()

library(patchwork)
p1 + p2

loo_compare(Loo_biased2biased, Loo_memory2biased)
loo_compare(Loo_biased2memory, Loo_memory2memory)
loo_model_weights(list(Loo_biased2biased, Loo_memory2biased))
loo_model_weights(list(Loo_biased2memory, Loo_memory2memory))

```

## Implementing Cross-Validation

As we mentioned, elpd per se is only an approximation of the cross-validated performance and it only leaves one datapoint out at a time.
[MISSING: VERSION W TRANSFORMED DATA]

### Create cross-validation ready stan model for biased agents

N.B. compared to before we also need to include specifics for test data 

```{r}
stan_biased_cv_model <- "
//
// This STAN model infers a random bias from a sequences of 1s and 0s (right and left). Now multilevel
//

functions{
  real normal_lb_rng(real mu, real sigma, real lb) { // normal distribution with a lower bound
    real p = normal_cdf(lb | mu, sigma);  // cdf for bounds
    real u = uniform_rng(p, 1);
    return (sigma * inv_Phi(u)) + mu;  // inverse cdf for value
  }
}

// The input (data) for the model. n of trials and h of hands
data {
 int<lower = 1> trials;
 int<lower = 1> agents;
 array[trials, agents] int h;
 
 int<lower = 1> agents_test;
 array[trials, agents_test] int h_test;
}

// The parameters accepted by the model. 
parameters {
  real thetaM;
  real<lower = 0> thetaSD;
  array[agents] real theta;
}

// The model to be estimated. 
model {
  target += normal_lpdf(thetaM | 0, 1);
  target += normal_lpdf(thetaSD | 0, .3)  -
    normal_lccdf(0 | 0, .3);

  // The prior for theta is a uniform distribution between 0 and 1
  target += normal_lpdf(theta | thetaM, thetaSD); 
 
  for (i in 1:agents)
    target += bernoulli_logit_lpmf(h[,i] | theta[i]);
  
}


generated quantities{
   real thetaM_prior;
   real<lower=0> thetaSD_prior;
   real<lower=0, upper=1> theta_prior;
   real<lower=0, upper=1> theta_posterior;
   
   int<lower=0, upper = trials> prior_preds;
   int<lower=0, upper = trials> posterior_preds;
   
   array[trials, agents] real log_lik;
   array[trials, agents_test] real log_lik_test;
   
   thetaM_prior = normal_rng(0,1);
   thetaSD_prior = normal_lb_rng(0,0.3,0);
   theta_prior = inv_logit(normal_rng(thetaM_prior, thetaSD_prior));
   theta_posterior = inv_logit(normal_rng(thetaM, thetaSD));
   
   prior_preds = binomial_rng(trials, inv_logit(thetaM_prior));
   posterior_preds = binomial_rng(trials, inv_logit(thetaM));
   
   for (i in 1:agents){
    for (t in 1:trials){
      log_lik[t,i] = bernoulli_logit_lpmf(h[t,i] | theta[i]);
    }
   }
   
   for (i in 1:agents_test){
    for (t in 1:trials){
      log_lik_test[t,i] = bernoulli_lpmf(h_test[t,i] | theta_posterior);
    }
  }
  
}
"
write_stan_file(
  stan_biased_cv_model,
  dir = "stan/",
  basename = "W6_MultilevelBias_cv.stan")

file <- file.path("stan/W6_MultilevelBias_cv.stan")
mod_biased_cv <- cmdstan_model(file, 
                     cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

```

### Create cross-validation ready stan model for memory agents

```{r}
stan_memory_cv_model <- "
//
// This STAN model infers a random bias from a sequences of 1s and 0s (heads and tails)
//
functions{
  real normal_lb_rng(real mu, real sigma, real lb) {
    real p = normal_cdf(lb | mu, sigma);  // cdf for bounds
    real u = uniform_rng(p, 1);
    return (sigma * inv_Phi(u)) + mu;  // inverse cdf for value
  }
}

// The input (data) for the model. 
data {
 int<lower = 1> trials;
 int<lower = 1> agents;
 array[trials, agents] int h;
 array[trials, agents] int other;
 
 int<lower = 1> agents_test;
 array[trials, agents_test] int h_test;
 array[trials, agents_test] int other_test;
}

// The parameters accepted by the model. 
parameters {
  real biasM;
  real betaM;
  vector<lower = 0>[2] tau;
  matrix[2, agents] z_IDs;
  cholesky_factor_corr[2] L_u;
}

transformed parameters {
  array[trials, agents] real memory;
  array[trials, agents_test] real memory_test;
  matrix[agents,2] IDs;
  IDs = (diag_pre_multiply(tau, L_u) * z_IDs)';
  
  for (agent in 1:agents){
    for (trial in 1:trials){
      if (trial == 1) {
        memory[trial, agent] = 0.5;
      } 
      if (trial < trials){
        memory[trial + 1, agent] = memory[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial);
        if (memory[trial + 1, agent] == 0){memory[trial + 1, agent] = 0.01;}
        if (memory[trial + 1, agent] == 1){memory[trial + 1, agent] = 0.99;}
      }
    }
  }
  
  for (agent in 1:agents_test){
    for (trial in 1:trials){
      if (trial == 1) {
        memory_test[trial, agent] = 0.5;
      } 
      if (trial < trials){
        memory_test[trial + 1, agent] = memory_test[trial, agent] + ((other[trial, agent] - memory[trial, agent]) / trial);
        if (memory_test[trial + 1, agent] == 0){memory_test[trial + 1, agent] = 0.01;}
        if (memory_test[trial + 1, agent] == 1){memory_test[trial + 1, agent] = 0.99;}
      }
    }
  }
  
}

// The model to be estimated. 
model {
  target += normal_lpdf(biasM | 0, 1);
  target += normal_lpdf(tau[1] | 0, .3)  -
    normal_lccdf(0 | 0, .3);
  target += normal_lpdf(betaM | 0, .3);
  target += normal_lpdf(tau[2] | 0, .3)  -
    normal_lccdf(0 | 0, .3);
  target += lkj_corr_cholesky_lpdf(L_u | 2);

  target += std_normal_lpdf(to_vector(z_IDs));
  for (agent in 1:agents){
    for (trial in 1:trials){
      target += bernoulli_logit_lpmf(h[trial, agent] | biasM + IDs[agent, 1] +  memory[trial, agent] * (betaM + IDs[agent, 2]));
    }
  }
    
}


generated quantities{
   real biasM_prior;
   real<lower=0> biasSD_prior;
   real betaM_prior;
   real<lower=0> betaSD_prior;
   
   real bias_prior;
   real beta_prior;
   
   array[agents] int<lower=0, upper = trials> prior_preds0;
   array[agents] int<lower=0, upper = trials> prior_preds1;
   array[agents] int<lower=0, upper = trials> prior_preds2;
   array[agents] int<lower=0, upper = trials> posterior_preds0;
   array[agents] int<lower=0, upper = trials> posterior_preds1;
   array[agents] int<lower=0, upper = trials> posterior_preds2;
   
   array[trials, agents] real log_lik;
   array[trials, agents_test] real log_lik_test;
   
   biasM_prior = normal_rng(0,1);
   biasSD_prior = normal_lb_rng(0,0.3,0);
   betaM_prior = normal_rng(0,1);
   betaSD_prior = normal_lb_rng(0,0.3,0);
   
   bias_prior = normal_rng(biasM_prior, biasSD_prior);
   beta_prior = normal_rng(betaM_prior, betaSD_prior);
   
   for (i in 1:agents){
      prior_preds0[i] = binomial_rng(trials, inv_logit(bias_prior + 0 * beta_prior));
      prior_preds1[i] = binomial_rng(trials, inv_logit(bias_prior + 1 * beta_prior));
      prior_preds2[i] = binomial_rng(trials, inv_logit(bias_prior + 2 * beta_prior));
      posterior_preds0[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] +  0 * (betaM + IDs[i,2])));
      posterior_preds1[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] +  1 * (betaM + IDs[i,2])));
      posterior_preds2[i] = binomial_rng(trials, inv_logit(biasM + IDs[i,1] +  2 * (betaM + IDs[i,2])));
      
      for (t in 1:trials){
        log_lik[t,i] = bernoulli_logit_lpmf(h[t, i] | biasM + IDs[i, 1] +  memory[t, i] * (betaM + IDs[i, 2]));
      }
   }
   
   for (i in 1:agents_test){
    for (t in 1:trials){
      log_lik_test[t,i] = bernoulli_logit_lpmf(h_test[t,i] | biasM +  memory_test[t, i] * betaM);
    }
  }
  
}
"

write_stan_file(
  stan_memory_cv_model,
  dir = "stan/",
  basename = "W6_MultilevelMemory_cv.stan")

file <- file.path("stan/W6_MultilevelMemory_cv.stan")
mod_memory_cv <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))
```


[MISSING: PARALLELIZE]

```{r, eval = F}
d$fold <- kfold_split_grouped(K = 10, x = d$agent)

log_pd_biased_kfold <- matrix(nrow = 1000, ncol = 12000)
log_pd_memory_kfold <- matrix(nrow = 1000, ncol = 12000)

for (k in unique(d$fold)) { 
  
  # Training set for k 
  d_train <- d %>% filter(fold != k)  
  
  ## Create the data
  d_memory1_train <- d_train %>% 
    subset(select = c(agent, memoryChoice)) %>% 
    mutate(row = row_number()) %>% 
    pivot_wider(names_from = agent, values_from = memoryChoice)
  d_memory2_train <- d_train %>% 
    subset(select = c(agent, randomChoice)) %>% 
    mutate(row = row_number()) %>% 
    pivot_wider(names_from = agent, values_from = randomChoice)
  
  agents_n <- length(unique(d_train$agent))
  
  d_test <- d %>% 
    filter(fold == k) 
  d_memory1_test <- d_test %>% 
    subset(select = c(agent, memoryChoice)) %>% 
    mutate(row = row_number()) %>% 
    pivot_wider(names_from = agent, values_from = memoryChoice)
  d_memory2_test <- d_test %>% 
    subset(select = c(agent, randomChoice)) %>% 
    mutate(row = row_number()) %>% 
    pivot_wider(names_from = agent, values_from = randomChoice)
  
  agents_test_n <- length(unique(d_test$agent))
  
  data_memory <- list(
    trials = trials,
    agents =  agents_n,
    agents_test = agents_test_n,
    h = as.matrix(d_memory1_train[,2:(agents_n + 1)]),
    other = as.matrix(d_memory2_train[,2:(agents_n + 1)]),
    
    h_test = as.matrix(d_memory1_test[,2:(agents_test_n + 1)]),
    other_test = as.matrix(d_memory2_test[,2:(agents_test_n + 1)]))
  
  # Train the models 
  fit_random <- mod_biased_cv$sample(
    data = data_memory,
    seed = 123,
    chains = 1,
    threads_per_chain = 4,
    iter_warmup = 1000,
    iter_sampling = 1000,
    refresh = 1000,
    max_treedepth = 20,
    adapt_delta = 0.99
  )
  
  fit_memory <- mod_memory_cv$sample(
    data = data_memory,
    seed = 123,
    chains = 1,
    threads_per_chain = 4,
    iter_warmup = 1000,
    iter_sampling = 1000,
    refresh = 1000,
    max_treedepth = 20,
    adapt_delta = 0.99
  )
  
  # Extract log likelihood which represents 
  # the pointwise predictive density. 
  # n.b. the matrix has 1000 row, and 12000 columns. 
  # d$fold==k yields 12000 logical values, of which 1200 TRUEs, identifying 1200 columns
  ## the fit blabla yields 1000 obs (samples) and 1190 variables instead of 1200
  log_pd_biased_kfold[, d$fold == k] <- fit_random$draws("log_lik_test", format = "matrix")
  log_pd_memory_kfold[, d$fold == k] <- fit_memory$draws("log_lik_test", format = "matrix")

}

save(log_pd_biased_kfold, log_pd_memory_kfold, file = "simmodels/W6_CV_Biased&Memory.RData")
```

## Calculating elpd and comparing

```{r}
load("simmodels/W6_CV_Biased&Memory.RData") 

elpd_biased_kfold <- elpd(log_pd_biased_kfold)
elpd_memory_kfold <- elpd(log_pd_memory_kfold)

loo_compare(elpd_biased_kfold, elpd_memory_kfold)
#loo_model_weights(elpd_biased_kfold, elpd_memory_kfold)
```

## Limitations of model comparison techniques

1) it might be overfitting to the training population, that is, to the 

<!--chapter:end:07-ModelComparison.Rmd-->

---
title: "07-MixtureModels"
output: html_document
date: "2023-03-13"
---

# Mixture models

Mixture models are another powerful tool to compare the fit of different models to the data or to different portions of the data. This feature makes mixture models also a great tool to explore the possibility of multiple strategies involved in the mechanisms generating the data.

Indeed, human behaviors rarely follow a single, simple strategy. People may switch between different approaches, combine multiple strategies, or show inconsistent behavior due to factors like attention and fatigue. This creates a significant challenge for cognitive modeling - how can we account for this complexity while maintaining models that are tractable and interpretable?

Mixture models offer a powerful solution to this challenge. Rather than assuming behavior follows a single process, mixture models allow us to combine multiple cognitive strategies within a unified framework. For example, a participant in a decision-making task might sometimes respond based on careful deliberation and other times rely on quick heuristics or even random guessing; or different participants might be using different strategies. Mixture models let us estimate not only the parameters of these different strategies but also their relative frequencies.
In this chapter, we'll explore how to implement mixture models using Stan, beginning with a simple case that combines a biased choice strategy with random responses. We'll then extend this to more sophisticated models that can capture multiple cognitive strategies. Through this process, we'll learn:

* How to formally specify mixture models in Stan
* Techniques for estimating mixture proportions and component parameters
* Methods for validating mixture models through posterior predictive checks
* Approaches for comparing different mixture specifications

Understanding mixture models is crucial for cognitive modeling as they bridge the gap between simplified theoretical models and the messy reality of human behavior. Let's begin by examining how we can combine two simple decision strategies in a mixture model framework.

### Load the dataset

We load the data set from chapter NN, where we loop through possible rates and noise levels, and pick one agent to build up the model progressively.

```{r}
d <- read_csv("simdata/W3_randomnoise.csv")

dd <- d %>% subset(rate == 0.8 & noise == 0.1)

data <- list(
  n = 120,
  h = dd$choice
)
```


## Stan model mixing biased and noise

We then build a Stan model with the noise parameter

```{r}
stan_mixture_model <- "
// This Stan model defines a mixture of bernoulli (random bias + noise)
//

// The input (data) for the model. n of trials and h of heads
data {
 int<lower=1> n;
 array[n] int h;
}

// The parameters accepted by the model. 
parameters {
  real bias;
  real noise;
}

// The model to be estimated. 
model {
  // The prior for theta is a uniform distribution between 0 and 1
  target += normal_lpdf(bias | 0, 1);
  target += normal_lpdf(noise | 0, 1);
  
  // The model consists of a binomial distributions with a rate theta
  target += log_sum_exp(log(inv_logit(noise)) +
            bernoulli_logit_lpmf(h | 0),
            log1m(inv_logit(noise)) +  bernoulli_logit_lpmf(h | bias));
            
}
generated quantities{
  real<lower=0, upper=1> noise_p;
  real<lower=0, upper=1> bias_p;
  noise_p = inv_logit(noise);
  bias_p = inv_logit(bias);
}

"

write_stan_file(
  stan_mixture_model,
  dir = "stan/",
  basename = "W6_MixtureSingle.stan")

file <- file.path("stan/W6_MixtureSingle.stan")
mod_mixture <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))
```

## Fitting and assessing the model
```{r}

samples <- mod_mixture$sample(
  data = data,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 2000,
  iter_sampling = 2000,
  refresh = 500,
  max_treedepth = 20,
  adapt_delta = 0.99,
)

save(samples, data, 
          file = "simmodels/W7_singlemixture.RData") 
samples$save_object(file = "simmodels/W7_singlemixture.RDS")
samples$save_output_files(dir = "simmodels", basename = "W7_singlemixture")

```

[MISSING: EVALUATION]

## Basic evaluation
```{r}
samples$summary()
```


## Multilevel mixture model


```{r}
### Multilevel mixture
stan_multilevelMixture_model <- "
//
// This Stan model defines a mixture of bernoulli (random bias + noise)
//
functions{
  real normal_lb_rng(real mu, real sigma, real lb) {
    real p = normal_cdf(lb | mu, sigma);  // cdf for bounds
    real u = uniform_rng(p, 1);
    return (sigma * inv_Phi(u)) + mu;  // inverse cdf for value
  }
}

// The input (data) for the model. n of trials and h of heads
data {
 int<lower = 1> trials;
 int<lower = 1> agents;
 array[trials, agents] int h;
}

// The parameters accepted by the model. 
parameters {
  real thetaM;
  real noiseM; // p of noise
  
  vector<lower = 0>[2] tau;
  matrix[2, agents] z_IDs;
  cholesky_factor_corr[2] L_u;
}

transformed parameters {
  matrix[agents,2] IDs;
  IDs = (diag_pre_multiply(tau, L_u) * z_IDs)';
 }

// The model to be estimated. 
model {
  target += normal_lpdf(thetaM | 0, 1);
  target += normal_lpdf(tau[1] | 0, .3)  -
    normal_lccdf(0 | 0, .3);

  target += normal_lpdf(noiseM | -1, .5);
  target += normal_lpdf(tau[2] | 0, .3)  -
    normal_lccdf(0 | 0, .3);
    
  target += lkj_corr_cholesky_lpdf(L_u | 2);
  
  target += std_normal_lpdf(to_vector(z_IDs));

  for (i in 1:agents)
    target += log_sum_exp(
            log(inv_logit(noiseM + IDs[i,2])) +  // p of noise
                    bernoulli_logit_lpmf(h[,i] | 0), // times post likelihood of the noise model
            log1m(inv_logit(noiseM + IDs[i,2])) + // 1 - p of noise
                    bernoulli_logit_lpmf(h[,i] | thetaM + IDs[i,1])); // times post likelihood of the bias model
                    

}

generated quantities{
  real thetaM_prior;
  real<lower=0> thetaSD_prior;
  real noiseM_prior;
  real<lower=0> noiseSD_prior;
  real<lower=0, upper=1> theta_prior;
  real<lower=0, upper=1> noise_prior;
  real<lower=0, upper=1> theta_posterior;
  real<lower=0, upper=1> noise_posterior;
  
  array[trials,agents] int<lower=0, upper = trials> prior_noise;
  array[trials,agents] int<lower=0, upper = trials> posterior_noise;
  array[trials,agents] int<lower=0, upper = trials> prior_preds;
  array[trials,agents] int<lower=0, upper = trials> posterior_preds;

  array[trials, agents] real log_lik;

  thetaM_prior = normal_rng(0,1);
  thetaSD_prior = normal_lb_rng(0,0.3,0);
  theta_prior = inv_logit(normal_rng(thetaM_prior, thetaSD_prior));
  noiseM_prior = normal_rng(-1,.5);
  noiseSD_prior = normal_lb_rng(0,0.3,0);
  noise_prior = inv_logit(normal_rng(noiseM_prior, noiseSD_prior));
  
  theta_posterior = inv_logit(normal_rng(thetaM, tau[1]));
  noise_posterior = inv_logit(normal_rng(noiseM, tau[2]));
  
   
   for (i in 1:agents){
     
    for (t in 1:trials){
      
      prior_noise[t,i] = bernoulli_rng(noise_prior);
      posterior_noise[t,i] = bernoulli_rng(inv_logit(noiseM + IDs[i,2]));
      
      if(prior_noise[t,i]==1){
        prior_preds[t,i] = bernoulli_rng(theta_prior);
      } else{
        prior_preds[t,i] = bernoulli_rng(0.5);
      }
      if(posterior_noise[t,i]==1){
        posterior_preds[t,i] = bernoulli_rng(inv_logit(thetaM + IDs[i,1]));
      } else{
        posterior_preds[t,i] = bernoulli_rng(0.5);
      }
      
      
      log_lik[t,i] = log_sum_exp(
            log(inv_logit(noiseM + IDs[i,2])) +  // p of noise
                    bernoulli_logit_lpmf(h[t,i] | 0), // times post likelihood of the noise model
            log1m(inv_logit(noiseM + IDs[i,2])) + // 1 - p of noise
                    bernoulli_logit_lpmf(h[t,i] | thetaM + IDs[i,1])); // times post likelihood of the bias model
      
    }
  }
  
}
"

write_stan_file(
  stan_multilevelMixture_model,
  dir = "stan/",
  basename = "W6_MixtureMultilevel.stan")

file <- file.path("stan/W6_MixtureMultilevel.stan")
mod_mixture <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))


# samples <- mod_mixture$sample(
#   data = data_biased,
#   seed = 123,
#   chains = 2,
#   parallel_chains = 2,
#   threads_per_chain = 2,
#   iter_warmup = 2000,
#   iter_sampling = 2000,
#   refresh = 500,
#   max_treedepth = 20,
#   adapt_delta = 0.99,
# )
# 
# save(samples, data, 
#           file = "simmodels/W7_multimixture.RData") 
# samples$save_object(file = "simmodels/W7_multimixture.RDS")
# samples$save_output_files(dir = "simmodels", basename = "W7_multimixture")
```

[MISSING: EVALUATION]
```{r}
samples <- readRDS("simmodels/W7_multimixture.RDS")

samples$summary()

samples$loo()
```


[MISSING: PARAMETER RECOVERY]

[MISSING: BIASED VS. MEMORY?]

Mixture models represent a crucial step forward in our cognitive modeling toolkit, allowing us to capture the complexity and variability inherent in human behavior. Through this chapter, we've seen how combining multiple cognitive strategies within a single model can provide richer and more realistic accounts of decision-making processes.

Several key insights emerge from our exploration of mixture models:

First, mixture models allow us to move beyond the false choice between oversimplified single-strategy models and intractably complex specifications. By combining a small number of interpretable components, we can capture substantial behavioral complexity while maintaining mathematical and computational tractability.

Second, the Bayesian implementation of mixture models in Stan provides powerful tools for inference. We can estimate not only the parameters of different cognitive strategies but also their relative contributions to behavior. This allows us to quantify the importance of different processes and how they might vary across individuals or conditions.

Third, mixture models require careful attention to identifiability and validation. Through parameter recovery studies and posterior predictive checks, we've seen how to verify that our mixture specifications can reliably recover true parameter values and generate realistic behavioral patterns.
As we move forward in the course, mixture models will continue to play an important role in our modeling toolkit. They provide a bridge between simple theoretical models and complex empirical data, allowing us to build increasingly sophisticated accounts of cognitive processes while maintaining scientific rigor and interpretability.

The next chapters will build on these foundations as we explore hierarchical models that can capture individual differences, and more complex cognitive architectures that combine multiple processing stages. The principles we've learned about specifying, fitting, and validating mixture models will serve as essential tools in these more advanced applications.


<!--chapter:end:08-MixtureModels.Rmd-->

